{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rosan-international/video_classifier_bugs/blob/main/quantizing_movinet_stream.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2uC5wWEL-KC"
      },
      "source": [
        "# Transfer learning for video classification with MoViNet\n",
        "\n",
        "MoViNets (Mobile Video Networks) provide a family of efficient video classification models, supporting inference on streaming video. We take a pre-trained MoViNet model to classify custom actions. A pre-trained model is a saved network that was previously trained on a larger dataset. You can find more details about MoViNets in the [MoViNets: Mobile Video Networks for Efficient Video Recognition](https://arxiv.org/abs/2103.11511) paper by Kondratyuk, D. et al. (2021). This notebook will: \n",
        "\n",
        "* Download a pre-trained MoViNet model\n",
        "* Create a new model using a pre-trained model with a new classifier by freezing the convolutional base of the MoViNet model\n",
        "* Replace the classifier head with the number of labels of a new dataset\n",
        "* Perform transfer learning on the custom actions dataset\n",
        "* Export the trained/tuned MoViNet-A2-Stream model, including a int8 quantized version\n",
        "* Illustrate streaming action recognition with a sample video\n",
        "\n",
        "The model downloaded in this notebook is from [official/projects/movinet](https://github.com/tensorflow/models/tree/master/official/projects/movinet). This repository contains a collection of MoViNet models that TF Hub uses in the TensorFlow 2 SavedModel format. The transfer learning strategy is adapted from https://github.com/tensorflow/models/blob/master/official/projects/movinet/movinet_streaming_model_training_and_inference.ipynb\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHpRxpzdQc5b"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8BfmcGZMYIs"
      },
      "source": [
        "## Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/okankop/vidaug.git\n",
        "!pip install apache_beam\n",
        "import vidaug \n",
        "from vidaug import augmentors as va"
      ],
      "metadata": {
        "id": "i6eelzv5WzHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bf06c33-9aa3-4114-d71d-99154a916d8a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/okankop/vidaug.git\n",
            "  Cloning https://github.com/okankop/vidaug.git to /tmp/pip-req-build-ssf_u6hj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/okankop/vidaug.git /tmp/pip-req-build-ssf_u6hj\n",
            "  Resolved https://github.com/okankop/vidaug.git to commit 1c1ddf2640fe4a9171267d64ae5e3bd70c24d54a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: apache_beam in /usr/local/lib/python3.10/dist-packages (2.47.0)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.7)\n",
            "Requirement already satisfied: orjson<4.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (3.8.14)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (0.3.1.1)\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2.2.1)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.7.4)\n",
            "Requirement already satisfied: fasteners<1.0,>=0.3 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (0.18)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.54.0)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2.7.0)\n",
            "Requirement already satisfied: httplib2<0.22.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (0.21.0)\n",
            "Requirement already satisfied: numpy<1.25.0,>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.23.5)\n",
            "Requirement already satisfied: objsize<0.7.0,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (0.6.1)\n",
            "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (4.3.3)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.22.2)\n",
            "Requirement already satisfied: protobuf<4.23.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (3.20.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2022.7.1)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2022.10.31)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (4.5.0)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (0.21.0)\n",
            "Requirement already satisfied: pyarrow<12.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (9.0.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache_beam) (0.6.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache_beam) (1.16.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.22.0,>=0.8->apache_beam) (3.0.9)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo<5.0.0,>=3.8.0->apache_beam) (2.3.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache_beam) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache_beam) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache_beam) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache_beam) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WlKju7ieLRFE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eece9a35-cc7a-4ca1-86bd-a4df65611591"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas_profiling in /usr/local/lib/python3.10/dist-packages (3.6.6)\n",
            "Requirement already satisfied: ydata-profiling in /usr/local/lib/python3.10/dist-packages (from pandas_profiling) (4.2.0)\n",
            "Requirement already satisfied: scipy<1.11,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (1.10.1)\n",
            "Requirement already satisfied: pandas!=1.4.0,<2,>1.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (1.5.3)\n",
            "Requirement already satisfied: matplotlib<4,>=3.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (3.7.1)\n",
            "Requirement already satisfied: pydantic<2,>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (1.10.7)\n",
            "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (5.4.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (3.1.2)\n",
            "Requirement already satisfied: visions[type_image_path]==0.7.5 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (0.7.5)\n",
            "Requirement already satisfied: numpy<1.24,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (1.23.5)\n",
            "Requirement already satisfied: htmlmin==0.1.12 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (0.1.12)\n",
            "Requirement already satisfied: phik<0.13,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (0.12.3)\n",
            "Requirement already satisfied: requests<3,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (2.27.1)\n",
            "Requirement already satisfied: tqdm<5,>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (4.65.0)\n",
            "Requirement already satisfied: seaborn<0.13,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (0.12.2)\n",
            "Requirement already satisfied: multimethod<2,>=1.4 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (1.9.1)\n",
            "Requirement already satisfied: statsmodels<1,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (0.13.5)\n",
            "Requirement already satisfied: typeguard<3,>=2.13.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (2.13.3)\n",
            "Requirement already satisfied: imagehash==4.3.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (4.3.1)\n",
            "Requirement already satisfied: wordcloud>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (1.9.2)\n",
            "Requirement already satisfied: dacite>=1.8 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (1.8.1)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from imagehash==4.3.1->ydata-profiling->pandas_profiling) (1.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imagehash==4.3.1->ydata-profiling->pandas_profiling) (8.4.0)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas_profiling) (23.1.0)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas_profiling) (3.1)\n",
            "Requirement already satisfied: tangled-up-in-unicode>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas_profiling) (0.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=2.11.1->ydata-profiling->pandas_profiling) (2.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas_profiling) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas_profiling) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas_profiling) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas_profiling) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas_profiling) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas_profiling) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas_profiling) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.4.0,<2,>1.1->ydata-profiling->pandas_profiling) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from phik<0.13,>=0.11.1->ydata-profiling->pandas_profiling) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1.8.1->ydata-profiling->pandas_profiling) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas_profiling) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas_profiling) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas_profiling) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas_profiling) (3.4)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels<1,>=0.13.2->ydata-profiling->pandas_profiling) (0.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels<1,>=0.13.2->ydata-profiling->pandas_profiling) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U -q \"tf-models-official\"\n",
        "!command -v ffmpeg >/dev/null || (apt update && apt install -y ffmpeg)\n",
        "!pip install -q mediapy remotezip\n",
        "!pip install -U -q git+https://github.com/tensorflow/docs\n",
        "!pip install tensorflow --upgrade\n",
        "!pip install --upgrade pandas_profiling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yf4FyzCxN7J6"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5mHJiqIQN6hV"
      },
      "outputs": [],
      "source": [
        "import os, shutil\n",
        "import functools\n",
        "import tqdm\n",
        "import random\n",
        "import pathlib\n",
        "import imageio\n",
        "import itertools\n",
        "import collections\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import mediapy as media\n",
        "import math\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from zipfile import ZipFile\n",
        "from tensorflow_docs.vis import embed\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "vXSPpYXnCGQr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "olyCDB2Z2PmB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB75hbE0Qjsl"
      },
      "source": [
        "## Distribution strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "eIrFqkSTQUAG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1707f801-d26b-40ec-cb4a-f0665fb8a479"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on single GPU  /device:GPU:0\n",
            "Number of accelerators:  1\n"
          ]
        }
      ],
      "source": [
        "# Detect hardware\n",
        "try:\n",
        "  tpu_resolver = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "except ValueError:\n",
        "  tpu_resolver = None\n",
        "  gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
        "\n",
        "# Select appropriate distribution strategy\n",
        "if tpu_resolver:\n",
        "  tf.config.experimental_connect_to_cluster(tpu_resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu_resolver)\n",
        "  distribution_strategy = tf.distribute.experimental.TPUStrategy(tpu_resolver)\n",
        "  print('Running on TPU ', tpu_resolver.cluster_spec().as_dict()['worker'])\n",
        "elif len(gpus) > 1:\n",
        "  distribution_strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n",
        "  print('Running on multiple GPUs ', [gpu.name for gpu in gpus])\n",
        "elif len(gpus) == 1:\n",
        "  distribution_strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('Running on single GPU ', gpus[0].name)\n",
        "else:\n",
        "  distribution_strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('Running on CPU')\n",
        "\n",
        "print(\"Number of accelerators: \", distribution_strategy.num_replicas_in_sync)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tuning parameters"
      ],
      "metadata": {
        "id": "bP01fTkCBIpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#See original paper for recommended parameters: https://arxiv.org/pdf/2103.11511.pdf\n",
        "\n",
        "clean = True\n",
        "random_seed = 789\n",
        "model_id = 'a2'\n",
        "resolution = 172\n",
        "num_frames = 30\n",
        "frame_steps = 5\n",
        "batch_size = 10"
      ],
      "metadata": {
        "id": "uf1RYoQKBNJQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2M1aztFPxzM"
      },
      "source": [
        "# Load data\n",
        "\n",
        "The cell below defines helper functions to upload the custom actions, and load it into a `tf.data.Dataset`. The `FrameGenerator` class at the end of the hidden block is the most important utility here. It creates an iterable object that can feed data into the TensorFlow data pipeline. Specifically, this class contains a Python generator that loads the video frames along with its encoded label. The generator (`__call__`) function yields the frame array produced by `frames_from_video_file` and a one-hot encoded vector of the label associated with the set of frames."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download directory"
      ],
      "metadata": {
        "id": "e4HmTR081rDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "download_dir = pathlib.Path('/content/custom_actions_subset/')"
      ],
      "metadata": {
        "id": "xOw7hNwyfNBN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Builder"
      ],
      "metadata": {
        "id": "dlrR3H-HK_s1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "MR1Bp5iNObb5"
      },
      "outputs": [],
      "source": [
        "# custom_action Data  Builder\n",
        "\n",
        "def list_files_per_class(zip_path):\n",
        "  \"\"\"\n",
        "    List the files in each class of the dataset given the zip path.\n",
        "\n",
        "    Args:\n",
        "      zip_path: URL from which the files can be unzipped. \n",
        "\n",
        "    Return:\n",
        "      files: List of files in each of the classes.\n",
        "  \"\"\"\n",
        "  files = []\n",
        "  with ZipFile(zip_path, 'r') as zip:\n",
        "    for zip_info in zip.infolist():\n",
        "      files.append(zip_info.filename)\n",
        "  return files\n",
        "\n",
        "def get_class(fname):\n",
        "    # Get the directory path from the file path\n",
        "    dir_path = os.path.dirname(fname)\n",
        "   \n",
        "    # Get the folder name from the directory path\n",
        "    folder_name = os.path.basename(dir_path)\n",
        "   \n",
        "    # Return the folder name\n",
        "    return folder_name\n",
        "\n",
        "def get_files_per_class(files):\n",
        "  \"\"\"\n",
        "    Retrieve the files that belong to each class. \n",
        "\n",
        "    Args:\n",
        "      files: List of files in the dataset.\n",
        "\n",
        "    Return:\n",
        "      Dictionary of class names (key) and files (values).\n",
        "  \"\"\"\n",
        "  files_for_class = collections.defaultdict(list)\n",
        "  for fname in files:\n",
        "    class_name = get_class(fname)\n",
        "    files_for_class[class_name].append(fname)\n",
        "  return files_for_class\n",
        "\n",
        "def download_from_zip(zip_path, to_dir, file_names):\n",
        "  \"\"\"\n",
        "    Download the contents of the zip file from the zip path.\n",
        "\n",
        "    Args:\n",
        "      zip_path: Zip path containing data.\n",
        "      to_dir: Directory to download data to.\n",
        "      file_names: Names of files to download.\n",
        "  \"\"\"\n",
        "  with ZipFile(zip_path, 'r') as zip:\n",
        "    for fn in tqdm.tqdm(file_names):\n",
        "      class_name = get_class(fn)\n",
        "      zip.extract(fn, str(to_dir / class_name))\n",
        "      unzipped_file = to_dir / class_name / fn\n",
        "\n",
        "      fn = pathlib.Path(fn).parts[-1]\n",
        "      output_file = to_dir / class_name / fn\n",
        "      unzipped_file.rename(output_file,)\n",
        "\n",
        "def split_class_lists(files_for_class, count):\n",
        "  \"\"\"\n",
        "    Returns the list of files belonging to a subset of data as well as the remainder of\n",
        "    files that need to be downloaded.\n",
        "\n",
        "    Args:\n",
        "      files_for_class: Files belonging to a particular class of data.\n",
        "      count: Number of files to download.\n",
        "\n",
        "    Return:\n",
        "      split_files: Files belonging to the subset of data.\n",
        "      remainder: Dictionary of the remainder of files that need to be downloaded.\n",
        "  \"\"\"\n",
        "  split_files = []\n",
        "  remainder = {}\n",
        "  for cls in files_for_class:\n",
        "    split_files.extend(files_for_class[cls][:count])\n",
        "    remainder[cls] = files_for_class[cls][count:]\n",
        "  return split_files, remainder\n",
        "\n",
        "def upload_custom_actions_subset(zip_path, num_classes, splits, download_dir):\n",
        "  \"\"\"\n",
        "    Download a subset of the custom_actions dataset and split them into various parts, such as\n",
        "    training, validation, and test. \n",
        "\n",
        "    Args:\n",
        "      zip_path: Zip path containing data.\n",
        "      num_classes: Number of labels.\n",
        "      splits: Dictionary specifying the training, validation, test, etc. (key) division of data \n",
        "              (value is number of files per split).\n",
        "      download_dir: Directory to download data to.\n",
        "\n",
        "    Return:\n",
        "      dir: Posix path of the resulting directories containing the splits of data.\n",
        "  \"\"\"\n",
        "  files = list_files_per_class(zip_path)\n",
        "  for f in files:\n",
        "    tokens = f.split('/')\n",
        "    if len(tokens) <= 1:\n",
        "      files.remove(f) # Remove that item from the list if it does not have a filename\n",
        "\n",
        "  files_for_class = get_files_per_class(files)\n",
        "\n",
        "  classes = list(files_for_class.keys())[:num_classes]\n",
        "\n",
        "  for cls in classes:\n",
        "    new_files_for_class = files_for_class[cls]\n",
        "    random.seed(random_seed) # Added random seed for reproducibility\n",
        "    random.shuffle(new_files_for_class)\n",
        "    files_for_class[cls] = new_files_for_class\n",
        "\n",
        "  # Only use the number of classes you want in the dictionary\n",
        "  files_for_class = {x: files_for_class[x] for x in list(files_for_class)[:num_classes]}\n",
        "\n",
        "  dirs = {}\n",
        "  for split_name, split_count in splits.items():\n",
        "    print(split_name, \":\")\n",
        "    split_dir = download_dir / split_name\n",
        "    split_files, files_for_class = split_class_lists(files_for_class, split_count)\n",
        "    download_from_zip(zip_path, split_dir, split_files)\n",
        "    dirs[split_name] = split_dir\n",
        "\n",
        "  return dirs\n",
        "\n",
        "def format_frames(frame, output_size):\n",
        "  \"\"\"\n",
        "    Pad and resize an image from a video.\n",
        "\n",
        "    Args:\n",
        "      frame: Image that needs to resized and padded. \n",
        "      output_size: Pixel size of the output frame image.\n",
        "\n",
        "    Return:\n",
        "      Formatted frame with padding of specified output size.\n",
        "  \"\"\"\n",
        "  frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
        "  #frame = tf.image.resize_with_pad(frame, *output_size)\n",
        "  frame = tf.image.resize(frame, [resolution, resolution], method='nearest')  # Modified original resize_with_pad as it left some black padding. \n",
        "  return frame\n",
        "\n",
        "def frames_from_video_file(video_path, n_frames, output_size = (resolution, resolution), frame_step = frame_steps):\n",
        "  \"\"\"\n",
        "    Creates frames from each video file present for each category.\n",
        "\n",
        "    Args:\n",
        "      video_path: File path to the video.\n",
        "      n_frames: Number of frames to be created per video file.\n",
        "      output_size: Pixel size of the output frame image.\n",
        "\n",
        "    Return:\n",
        "      An NumPy array of frames in the shape of (n_frames, height, width, channels).\n",
        "  \"\"\"\n",
        "  # Read each video frame by frame\n",
        "  result = []\n",
        "  src = cv2.VideoCapture(str(video_path))  \n",
        "\n",
        "  video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "  need_length = 1 + (n_frames - 1) * frame_step\n",
        "\n",
        "  if need_length > video_length:\n",
        "    start = 0\n",
        "  else:\n",
        "    max_start = video_length - need_length\n",
        "    start = random.randint(0, max_start + 1)\n",
        "\n",
        "  src.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
        "  # ret is a boolean indicating whether read was successful, frame is the image itself\n",
        "  ret, frame = src.read()\n",
        "  result.append(format_frames(frame, output_size))\n",
        "\n",
        "  for _ in range(n_frames - 1):\n",
        "    for _ in range(frame_step):\n",
        "      ret, frame = src.read()\n",
        "    if ret:\n",
        "      frame = format_frames(frame, output_size)\n",
        "      result.append(frame)\n",
        "    else:\n",
        "      result.append(np.zeros_like(result[0]))\n",
        "  src.release()\n",
        "  result = np.array(result)[..., [2, 1, 0]]\n",
        "\n",
        "  return result\n",
        "\n",
        "def to_gif(images):\n",
        "  converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
        "  imageio.mimsave('/content/animation.gif', converted_images, fps=10)\n",
        "  return embed.embed_file('./animation.gif')\n",
        "\n",
        "class FrameGenerator:\n",
        "  def __init__(self, path, n_frames, training = False):\n",
        "    \"\"\" Returns a set of frames with their associated label. \n",
        "\n",
        "      Args:\n",
        "        path: Video file paths.\n",
        "        n_frames: Number of frames. \n",
        "        training: Boolean to determine if training dataset is being created.\n",
        "    \"\"\"\n",
        "    self.path = path\n",
        "    self.n_frames = n_frames\n",
        "    self.training = training\n",
        "    self.class_names = sorted(set(p.name for p in self.path.iterdir() if p.is_dir()))\n",
        "    self.class_ids_for_name = dict((name, idx) for idx, name in enumerate(self.class_names))\n",
        "\n",
        "  def get_files_and_class_names(self):\n",
        "    video_paths = list(self.path.glob('*/*.avi'))\n",
        "    classes = [p.parent.name for p in video_paths] \n",
        "    return video_paths, classes\n",
        "\n",
        "  def __call__(self):\n",
        "    video_paths, classes = self.get_files_and_class_names()\n",
        "\n",
        "    pairs = list(zip(video_paths, classes))\n",
        "\n",
        "    if self.training:\n",
        "      random.shuffle(pairs)\n",
        "\n",
        "    for path, name in pairs:\n",
        "      video_frames = frames_from_video_file(path, self.n_frames) \n",
        "      label = self.class_ids_for_name[name] # Encode labels\n",
        "      yield video_frames, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P74UoQabPY7"
      },
      "source": [
        "## Clean custom_actions_subset directory (Optional)\n",
        "\n",
        "Only executed if clean = true (See \"Tuning parameters)*texto en cursiva*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "i1kj3vbRbUx6"
      },
      "outputs": [],
      "source": [
        "## If need to clean the whole directory, replace '/content/custom_actions_subset' with '/content' below\n",
        "\n",
        "if os.path.exists(download_dir) and clean:\n",
        "    for filename in os.listdir(download_dir):\n",
        "        file_path = os.path.join(download_dir, filename)\n",
        "        try:\n",
        "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                os.unlink(file_path)\n",
        "            elif os.path.isdir(file_path):\n",
        "                shutil.rmtree(file_path)\n",
        "        except Exception as e:\n",
        "            print('Failed to delete %s. Reason: %s' % (file_path, e))       "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80e07IQ7S1F2"
      },
      "source": [
        "## Upload files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvl3BsluXD20"
      },
      "source": [
        "### Upload train/test files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4C5t92VeTYda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fc2aade-bd05-4275-e252-da879b22a43a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# If uploading from local drive, code below will pop up menu.\n",
        "\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "\n",
        "# If uploading from drive, code below will pop up menu.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "oDJQF1DbTCNk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "851eb571-5fe7-4d59-eec0-10ca7960b2a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [00:48<00:00,  1.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:16<00:00,  1.11s/it]\n"
          ]
        }
      ],
      "source": [
        "subset_paths = upload_custom_actions_subset(zip_path = '/content/drive/MyDrive/custom_action_vids/videos_trim.zip', \n",
        "                        num_classes = 3, # 'Action1', 'Action2', 'Action3'\n",
        "                        splits = {\"train\": train_size, \"test\": test_size}, # Split per class (e.g. if \"train\": 10, \"test\": 5, 10 'Action3' videos go to training set, 5 to testing set, and same for the other classes)\n",
        "                        download_dir = download_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdUWBbdFXIbL"
      },
      "source": [
        "### Upload validation file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KlzxBVyhXPWf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e1956a9-979c-486a-8247-23021613b8e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 593.17it/s]\n"
          ]
        }
      ],
      "source": [
        "subset_paths2 = upload_custom_actions_subset(zip_path = '/content/drive/MyDrive/custom_action_vids/sequence.zip', \n",
        "                        num_classes = 1,\n",
        "                        splits = {\"val\": 1},\n",
        "                        download_dir = download_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if video is actually in custom_actions_subset/val, otherwise upload manually from unzipped video in drive or local folder"
      ],
      "metadata": {
        "id": "PLycw_T02PKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check number of frames per video"
      ],
      "metadata": {
        "id": "Z2vFsb0TMX4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_video_stats(directory):\n",
        "    total_length = 0\n",
        "    num_videos = 0\n",
        "    max_length = 0\n",
        "    min_length = float('inf')\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith('.avi'):\n",
        "                path = os.path.join(root, file)\n",
        "                src = cv2.VideoCapture(path)  \n",
        "                video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "                total_length += video_length\n",
        "                num_videos += 1\n",
        "                if video_length > max_length:\n",
        "                    max_length = video_length\n",
        "                if video_length < min_length:\n",
        "                    min_length = video_length\n",
        "                src.release()\n",
        "\n",
        "    if num_videos > 0:\n",
        "        avg_length = total_length / num_videos\n",
        "        print(f\"Average video length: {avg_length:.2f} frames\")\n",
        "        print(f\"Maximum video length: {max_length:.0f} frames\")\n",
        "        print(f\"Minimum video length: {min_length:.0f} frames\")\n",
        "    else:\n",
        "        print(\"No .avi files found in directory\")"
      ],
      "metadata": {
        "id": "TMD9bKf-MYkO"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_video_stats('/content/custom_actions_subset/train')"
      ],
      "metadata": {
        "id": "BpMOxrnOMdlT",
        "outputId": "e4614c7f-4868-4c23-8bf0-38d1028957db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average video length: 164.80 frames\n",
            "Maximum video length: 178 frames\n",
            "Minimum video length: 79 frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_video_stats('/content/custom_actions_subset/test')"
      ],
      "metadata": {
        "id": "yCGU51U1Mi2a",
        "outputId": "776557eb-4d67-4e20-cd8c-44082d15e337",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average video length: 167.75 frames\n",
            "Maximum video length: 215 frames\n",
            "Minimum video length: 126 frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_video_stats('/content/custom_actions_subset/val')"
      ],
      "metadata": {
        "id": "xYFNdxkQMsgV",
        "outputId": "ec0eb32f-bafd-4a2b-c03b-af0839c65941",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No .avi files found in directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f8LtMIWYmbz"
      },
      "source": [
        "## Prepare train, valid and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "JnLzebFRYojg"
      },
      "outputs": [],
      "source": [
        "CLASSES = sorted(os.listdir('/content/custom_actions_subset/train'))\n",
        "\n",
        "output_signature = (tf.TensorSpec(shape = (None, None, None, 3), dtype = tf.float32),\n",
        "                    tf.TensorSpec(shape = (), dtype = tf.int16))\n",
        "\n",
        "train_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['train'], num_frames, training = True),\n",
        "                                          output_signature = output_signature)\n",
        "test_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['test'], num_frames),\n",
        "                                         output_signature = output_signature)\n",
        "val_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths2['val'], 150),\n",
        "                                         output_signature = output_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert to TF Lite quantized to int8 for edge devices (Raspberry Pi 3 A+)\n",
        "Source: https://github.com/tensorflow/models/blob/8d92444cc4aed9a2d9746cbde882c05f4a0e748c/official/projects/movinet/tools/quantize_movinet.py"
      ],
      "metadata": {
        "id": "nx58OctTtbpH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/tensorflow/models/8d92444cc4aed9a2d9746cbde882c05f4a0e748c/official/projects/movinet/tools/quantize_movinet.py"
      ],
      "metadata": {
        "id": "tBHnI9AETUhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sh = \"\"\"\n",
        "python3 quantize_movinet.py \\\n",
        "--saved_model_dir='/model' \\\n",
        "--saved_model_with_states_dir='/model/init_states' \\\n",
        "--output_dataset_dir='/model_quantized' \\\n",
        "--output_tflite='/model_quantized' \\\n",
        "--quantization_mode='int8' \\\n",
        "--save_dataset_to_tfrecords=True\n",
        "\"\"\"\n",
        "with open('script.sh', 'w') as file:\n",
        "  file.write(sh)\n",
        "\n",
        "!bash script.sh\n",
        "# See ValueError: `tfds_name` is , but `tfds_split` is not specified.\n",
        "# This error is associated with quantize_movinet.py attempting to load the kinetics600 dataset, which is not on tfds\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4giiv37qn3vv",
        "outputId": "a058b854-9d69-4b80-9eae-08c0b4df4b0c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-31 12:25:57.756034: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/quantize_movinet.py\", line 331, in <module>\n",
            "    app.run(main)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/quantize_movinet.py\", line 321, in main\n",
            "    tflite_buffer = quantize_movinet(dataset_fn=get_dataset)\n",
            "  File \"/content/quantize_movinet.py\", line 268, in quantize_movinet\n",
            "    valid_dataset = dataset_fn()\n",
            "  File \"/content/quantize_movinet.py\", line 168, in get_dataset\n",
            "    valid_dataset = task.build_inputs(config.task.validation_data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/official/vision/tasks/video_classification.py\", line 148, in build_inputs\n",
            "    reader = input_reader_factory.input_reader_generator(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/official/vision/dataloaders/input_reader_factory.py\", line 43, in input_reader_generator\n",
            "    return core_input_reader.InputReader(params, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/official/core/input_reader.py\", line 275, in __init__\n",
            "    raise ValueError(\n",
            "ValueError: `tfds_name` is , but `tfds_split` is not specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "from typing import Any, Callable, Mapping, Optional\n",
        "from absl import app\n",
        "from absl import flags\n",
        "from absl import logging\n",
        "import numpy as np\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from official.vision.configs import video_classification as video_classification_configs\n",
        "from official.vision.tasks import video_classification"
      ],
      "metadata": {
        "id": "QJD8aOq5sA-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1817a90-d782-45fe-9d40-25798e38f674"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy()  # BytesList won't unpack string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
        "\n",
        "def _build_tf_example(feature):\n",
        "  return tf.train.Example(\n",
        "      features=tf.train.Features(feature=feature)).SerializeToString()\n",
        "\n",
        "def save_to_tfrecord(input_frame: tf.Tensor,\n",
        "                     input_states: Mapping[str, tf.Tensor],\n",
        "                     frame_index: int,\n",
        "                     predictions: tf.Tensor,\n",
        "                     output_states: Mapping[str, tf.Tensor],\n",
        "                     groundtruth_label_id: tf.Tensor,\n",
        "                     output_dataset_dir: str,\n",
        "                     file_index: int):\n",
        "  \"\"\"Save results to tfrecord.\"\"\"\n",
        "  features = {}\n",
        "  features['frame_id'] = _int64_feature([frame_index])\n",
        "  features['groundtruth_label'] = _int64_feature(\n",
        "      groundtruth_label_id.numpy().flatten().tolist())\n",
        "  features['predictions'] = _float_feature(\n",
        "      predictions.numpy().flatten().tolist())\n",
        "  image_string = tf.io.encode_png(\n",
        "      tf.squeeze(tf.cast(input_frame * 255., tf.uint8), axis=[0, 1]))\n",
        "  features['image'] = _bytes_feature(image_string.numpy())\n",
        "\n",
        "  # Input/Output states at time T\n",
        "  for k, v in output_states.items():\n",
        "    dtype = v[0].dtype\n",
        "    if dtype == tf.int32:\n",
        "      features['input/' + k] = _int64_feature(\n",
        "          input_states[k].numpy().flatten().tolist())\n",
        "      features['output/' + k] = _int64_feature(\n",
        "          output_states[k].numpy().flatten().tolist())\n",
        "    elif dtype == tf.float32:\n",
        "      features['input/' + k] = _float_feature(\n",
        "          input_states[k].numpy().flatten().tolist())\n",
        "      features['output/' + k] = _float_feature(\n",
        "          output_states[k].numpy().flatten().tolist())\n",
        "    else:\n",
        "      raise ValueError(f'Unrecongized dtype: {dtype}')\n",
        "\n",
        "  tfe = _build_tf_example(features)\n",
        "  record_file = '{}/movinet_stream_{:06d}.tfrecords'.format(\n",
        "      output_dataset_dir, file_index)\n",
        "  logging.info('Saving to %s.', record_file)\n",
        "  with tf.io.TFRecordWriter(record_file) as writer:\n",
        "    writer.write(tfe)\n",
        "\n",
        "\n",
        "def stateful_representative_dataset_generator(\n",
        "    model: tf.keras.Model,\n",
        "    dataset_iter: Any,\n",
        "    init_states: Mapping[str, tf.Tensor],\n",
        "    save_dataset_to_tfrecords: bool = False,\n",
        "    max_saved_files: int = 100,\n",
        "    output_dataset_dir: Optional[str] = None,\n",
        "    num_samples_per_video: int = num_frames,\n",
        "    num_calibration_videos: int = 10):\n",
        "  \"\"\"Generates sample input data with states.\n",
        "\n",
        "  Args:\n",
        "    model: the inference keras model.\n",
        "    dataset_iter: the dataset source.\n",
        "    init_states: the initial states for the model.\n",
        "    save_dataset_to_tfrecords: whether to save the representative dataset to\n",
        "      tfrecords on disk.\n",
        "    max_saved_files: the max number of saved tfrecords files.\n",
        "    output_dataset_dir: the directory to store the saved tfrecords.\n",
        "    num_samples_per_video: number of randomly sampled frames per video.\n",
        "    num_calibration_videos: number of calibration videos to run.\n",
        "\n",
        "  Yields:\n",
        "    A dictionary of model inputs.\n",
        "  \"\"\"\n",
        "  counter = 0\n",
        "  for i in range(num_calibration_videos):\n",
        "    if i % 100 == 0:\n",
        "      logging.info('Reading representative dateset id %d.', i)\n",
        "\n",
        "    example_input, example_label = next(dataset_iter)\n",
        "    groundtruth_label_id = tf.argmax(tf.reshape(example_label, [1]), axis=0) # Replace original code: 'tf.argmax(example_label, axis=-1)' with tf.argmax(tf.reshape(example_label, [1]), axis=0)\n",
        "    input_states = init_states\n",
        "    # split video into frames along the temporal dimension.\n",
        "    frames = tf.split(example_input, num_or_size_splits=num_frames, axis=0)\n",
        "    frames = [tf.reshape(frame, shape=(1, 1, 172, 172, 3)) for frame in frames]\n",
        "\n",
        "    random_indices = np.random.randint(\n",
        "        low=1, high=len(frames), size=num_samples_per_video)\n",
        "    # always include the first frame\n",
        "    random_indices[0] = 0\n",
        "    random_indices = set(random_indices)\n",
        "\n",
        "    for frame_index, frame in enumerate(frames):\n",
        "      predictions, output_states = model({'image': frame, **input_states})\n",
        "      if frame_index in random_indices:\n",
        "        if save_dataset_to_tfrecords and counter < max_saved_files:\n",
        "          save_to_tfrecord(\n",
        "              input_frame=frame,\n",
        "              input_states=input_states,\n",
        "              frame_index=frame_index,\n",
        "              predictions=predictions,\n",
        "              output_states=output_states,\n",
        "              groundtruth_label_id=groundtruth_label_id,\n",
        "              output_dataset_dir=output_dataset_dir,\n",
        "              file_index=counter)\n",
        "        yield {'image': frame, **input_states}\n",
        "        counter += 1\n",
        "\n",
        "      # update states for the next inference step\n",
        "      input_states = output_states\n",
        "\n",
        "\n",
        "def get_tflite_converter(\n",
        "    saved_model_dir: str,\n",
        "    quantization_mode: str,\n",
        "    representative_dataset: Optional[Callable[..., Any]] = None\n",
        ") -> tf.lite.TFLiteConverter:\n",
        "  \"\"\"Gets tflite converter.\"\"\"\n",
        "  converter = tf.lite.TFLiteConverter.from_saved_model(\n",
        "      saved_model_dir=saved_model_dir)\n",
        "  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "  if quantization_mode == 'float16':\n",
        "    logging.info('Using float16 quantization.')\n",
        "    converter.target_spec.supported_types = [tf.float16]\n",
        "\n",
        "  elif quantization_mode == 'int8':\n",
        "    logging.info('Using full interger quantization.')\n",
        "    converter.representative_dataset = representative_dataset\n",
        "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "    converter.inference_input_type = tf.int8\n",
        "    converter.inference_output_type = tf.int8\n",
        "\n",
        "  elif quantization_mode == 'int_float_fallback':\n",
        "    logging.info('Using interger quantization with float-point fallback.')\n",
        "    converter.representative_dataset = representative_dataset\n",
        "\n",
        "  else:\n",
        "    logging.info('Using dynamic range quantization.')\n",
        "  return converter"
      ],
      "metadata": {
        "id": "TEmFhCrwtBLh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = hub.KerasLayer('/model/init_states', trainable=False)"
      ],
      "metadata": {
        "id": "3ZvwO2PTHeRq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa011b03-6958-43e2-e507-01e375f17cb7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270421) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259139) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275661) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274671) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277299) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260919) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274331) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271871) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271761) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258629) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259839) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272281) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270621) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271341) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271151) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261139) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267989) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271541) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263989) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269499) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274871) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270241) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274361) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275411) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274281) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274131) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272881) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273301) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269509) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274231) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274411) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272971) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267869) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265289) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265299) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263799) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277999) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263209) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270311) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262839) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264429) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271461) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273791) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272221) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273441) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275331) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273611) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271911) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276929) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267209) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272661) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270811) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260209) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261359) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275351) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270011) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267839) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262919) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272501) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271591) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274001) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270231) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278499) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264279) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272931) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258429) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260869) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275771) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274701) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272481) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274161) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273801) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265629) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273671) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272331) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277929) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273591) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271671) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263839) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268359) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271701) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262359) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270201) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270511) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271171) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278779) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266989) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264509) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273821) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266919) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272711) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277509) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274761) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272611) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273701) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275521) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270771) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260839) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277209) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275231) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272591) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262139) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261839) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273331) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273621) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262869) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258499) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272551) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275201) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266209) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258989) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272011) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277569) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272811) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274201) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270911) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273361) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271941) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276279) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276569) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260929) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269941) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273771) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1257999) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271411) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273741) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271291) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266869) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1257969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261929) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272581) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266359) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264919) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275929) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270721) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269429) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260289) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274421) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274911) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265509) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273651) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274391) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271821) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273761) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271301) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266289) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272781) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268799) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267289) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276359) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275311) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264799) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274351) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262779) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264359) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272571) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268289) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272561) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270871) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259209) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272671) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273371) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278799) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262509) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275551) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275081) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272651) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265429) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1257939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261279) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270991) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262929) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277779) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272361) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258929) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1257929) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259499) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272511) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274301) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269971) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272871) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272641) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273881) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265209) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277799) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275391) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273971) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273861) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275301) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270981) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271211) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269279) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266629) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272461) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263359) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270131) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1257899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271181) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1257989) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273841) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267929) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271201) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277499) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271631) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278569) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274711) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267359) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259989) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268839) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267999) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275151) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270611) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271551) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273781) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264299) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273461) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268989) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270171) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265989) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263499) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269289) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274831) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273471) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259789) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266139) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275741) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270851) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260789) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274881) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273641) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273921) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275161) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274721) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262429) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270221) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276789) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274341) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270341) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270661) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274171) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276139) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271191) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272371) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273831) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271061) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276429) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271491) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273171) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270581) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271351) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267279) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273001) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273571) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274521) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273631) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266569) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272921) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270881) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264289) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273421) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271141) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274861) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273931) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260359) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273351) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270271) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264839) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265139) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272391) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272911) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267499) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270921) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264499) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268209) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271831) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274571) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275071) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265999) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264789) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262569) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274551) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275839) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263869) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271431) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259919) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278209) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274471) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272851) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271011) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274981) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273281) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266839) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271971) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276299) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272301) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263929) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266509) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271851) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273321) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278279) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269629) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270081) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264929) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265929) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272621) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274071) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274801) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270801) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271361) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272311) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273071) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267299) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268789) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270301) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278139) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270841) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263569) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263789) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271711) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268509) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270791) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272081) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1257979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267429) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277869) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273161) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270541) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277279) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271921) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266929) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273711) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263429) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275181) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269931) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274431) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268869) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269299) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277839) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271811) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268299) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274971) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273551) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270821) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259509) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272821) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274081) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267919) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271781) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261989) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271281) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277919) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274621) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273341) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272981) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264869) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271721) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273081) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270331) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269981) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272791) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269209) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273411) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273291) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272771) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273061) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260509) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259289) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258139) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1257889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271741) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259929) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274901) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274791) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274141) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274441) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275711) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258359) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260779) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267779) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265359) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260139) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275869) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274501) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275341) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272211) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272741) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278289) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261569) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274491) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272151) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275191) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274661) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273871) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272491) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274151) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272271) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273521) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278299) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262989) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265799) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271521) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276779) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271241) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270861) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274511) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267799) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261209) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271581) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271471) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271881) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270001) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269871) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275061) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269881) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1257909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261629) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270521) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273481) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275671) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259569) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275989) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274591) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278629) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272831) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274271) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276919) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274651) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276209) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270471) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261509) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274991) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261429) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261919) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272471) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271131) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262289) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271321) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270501) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264999) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271791) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273981) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263299) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270291) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258299) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272901) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277139) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264779) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274811) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272351) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271621) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263279) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273151) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270551) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273271) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270761) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261869) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272241) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270631) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265779) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274641) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270571) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273311) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275431) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258779) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271931) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265839) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274841) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263999) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273541) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258839) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275271) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274191) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271001) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271981) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275651) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275481) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276799) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273581) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271271) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273391) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274931) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272431) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258569) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274581) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272341) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276989) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271561) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270151) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271801) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260569) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266499) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272181) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262499) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275171) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267569) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270361) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263629) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275471) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260989) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272061) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273941) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271391) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270071) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268999) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269139) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274291) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264139) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272291) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275791) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268499) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275281) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270211) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260429) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262629) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277989) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275011) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271991) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262279) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274371) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274851) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274181) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275241) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271311) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273661) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270191) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261999) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260629) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265499) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271841) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259999) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276509) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275571) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273901) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272321) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272761) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277629) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271501) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262799) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274611) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272411) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275581) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270831) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271641) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274561) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271771) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273141) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272161) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274321) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263289) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270971) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274631) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270281) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270441) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266799) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275131) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274781) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272721) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270781) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260299) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270371) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272991) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273181) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270321) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260799) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261789) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263509) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259629) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272441) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258509) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270941) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267789) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273241) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271651) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270141) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258799) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275999) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277789) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278789) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275721) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267629) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261799) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276869) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275491) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268429) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275641) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273851) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268919) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268569) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275291) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272631) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275221) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271481) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272801) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269901) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260499) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273501) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274461) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269359) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272701) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272071) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262999) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275361) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261299) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276629) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270351) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275761) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259799) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277289) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270431) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270161) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273221) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270671) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270591) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269921) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275621) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270741) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273491) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276999) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272141) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274311) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268779) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272841) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260279) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269569) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262299) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259869) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271611) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271331) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275501) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266279) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273811) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264629) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271901) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274241) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263779) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278509) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264209) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274821) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273011) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272201) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271661) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273131) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269991) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272541) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259299) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276289) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275591) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262789) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273201) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273911) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261779) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272171) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274741) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270391) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274011) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275541) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263919) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271421) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275701) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270411) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265789) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272131) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258919) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265869) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266299) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259279) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259429) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271081) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270181) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1257959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266999) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270651) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275371) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268929) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261499) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275321) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273721) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273991) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273231) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270461) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275511) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275561) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259779) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275211) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270061) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273561) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267509) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275611) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258999) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274771) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266789) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265569) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273211) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271371) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275781) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268629) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266429) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272861) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270931) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270561) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268279) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1263139) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270711) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258279) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274941) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275001) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275461) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271221) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274211) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262209) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267139) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1257879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270901) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275421) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272191) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272421) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270701) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276499) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273191) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272231) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274921) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276839) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274061) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272001) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270481) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275141) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272521) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264569) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273431) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271861) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271441) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274541) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270641) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278359) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273511) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258289) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1257949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258789) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265919) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278429) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1278239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270491) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271161) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274221) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1257919) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259359) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269911) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266779) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268139) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275441) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275919) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271231) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271571) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275801) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1259849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271071) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264989) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1271511) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258869) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277429) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1266959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1273111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261289) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277359) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1258209) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1262549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1272941) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1261229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1275631) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1269749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1268029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1274481) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1267559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1260999) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1264109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1277309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1276129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1270111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_1265279) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  inputs = tf.keras.layers.Input(\n",
        "      shape=[1, resolution, resolution, 3],\n",
        "      dtype=tf.float32,\n",
        "      name='image')\n",
        "\n",
        "  # Define the state inputs, which is a dict that maps state names to tensors.\n",
        "  init_states_fn = encoder.resolved_object.signatures['init_states']\n",
        "  state_shapes = {\n",
        "      name: ([s if s > 0 else None for s in state.shape], state.dtype)\n",
        "      for name, state in init_states_fn(\n",
        "          tf.constant([1, 1, resolution, resolution, 3])).items()\n",
        "  }\n",
        "  states_input = {\n",
        "      name: tf.keras.Input(shape[1:], dtype=dtype, name=name)\n",
        "      for name, (shape, dtype) in state_shapes.items()\n",
        "  }\n",
        "\n",
        "  # The inputs to the model are the states and the video\n",
        "  inputs = {**states_input, 'image': inputs}\n",
        "  outputs = encoder(inputs)\n",
        "  model = tf.keras.Model(inputs, outputs, name='movinet_stream')\n",
        "  input_shape = tf.constant(\n",
        "      [1, num_frames, resolution, resolution, 3])\n",
        "  init_states = init_states_fn(input_shape)\n",
        "\n",
        "\n",
        "  # config representative_datset_fn\n",
        "  representative_dataset = functools.partial(\n",
        "      stateful_representative_dataset_generator,\n",
        "      model=model,\n",
        "      dataset_iter=iter(test_ds),\n",
        "      init_states=init_states,\n",
        "      save_dataset_to_tfrecords=False,\n",
        "      max_saved_files=100,\n",
        "      output_dataset_dir='/model_quantized',\n",
        "      num_samples_per_video=3,\n",
        "      num_calibration_videos=10)\n"
      ],
      "metadata": {
        "id": "mmSwhA2BuGBZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From https://www.tensorflow.org/lite/performance/post_training_quantization\n",
        "\n",
        "import tensorflow as tf\n",
        "saved_model_dir = '/model'\n",
        "quantized_dir = '/model.tflite.quantized'\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8  # or tf.uint8\n",
        "converter.inference_output_type = tf.int8  # or tf.uint8\n",
        "tflite_quant_model = converter.convert()\n",
        "with open(quantized_dir, 'wb') as f:\n",
        "  f.write(tflite_quant_model)\n",
        "\n",
        "# Problems: Does not have quantize (start)/dequantize(send), and no quantization after buffer layers. "
      ],
      "metadata": {
        "id": "dDcuXc78FsIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50a66249-8bd7-44b0-f888-23b0f634c83f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617168) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623390) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613318) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626450) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611758) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626080) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610508) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622000) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613468) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624180) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619478) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617318) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625830) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626030) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610728) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626670) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626710) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623810) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618958) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622460) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624250) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616898) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618508) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614038) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627400) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620758) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611958) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627090) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625610) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628898) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626620) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619828) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614758) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620318) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622590) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623480) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620328) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627200) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626990) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618328) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620038) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622120) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629728) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623090) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626040) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629528) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616038) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621388) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612898) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626390) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629828) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622090) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618898) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617758) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620468) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616828) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624080) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624650) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622890) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626210) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628758) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622180) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617728) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624470) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626440) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626840) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625200) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619318) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616728) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614828) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614598) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622400) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609958) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627240) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621850) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619038) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629608) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630388) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626590) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628528) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625570) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625470) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626910) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614328) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618618) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623330) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610898) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627678) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623650) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622320) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629328) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622520) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626630) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617508) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620598) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618608) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626090) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611478) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627570) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618038) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622630) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625890) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624870) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613728) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626410) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613328) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630318) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617388) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627828) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623110) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625110) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625030) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623530) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622800) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625190) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620728) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625960) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611168) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628678) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622820) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614608) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610038) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615898) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625250) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614618) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626960) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621528) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624030) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628328) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621468) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619608) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626310) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616618) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615318) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614958) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628608) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612318) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625820) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629598) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625320) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622650) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627080) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622910) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623910) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625840) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626750) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611508) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621890) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624120) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611598) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623230) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618318) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613958) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623760) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611318) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625040) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626890) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615478) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625810) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621710) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619728) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615388) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619598) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617478) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612168) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612508) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623190) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629678) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619468) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620388) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623100) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623080) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615328) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625880) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619958) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615758) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627758) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624760) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620168) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626770) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618758) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625150) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628038) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615678) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621990) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620898) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624320) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627728) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625630) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624670) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627460) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622190) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622810) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611678) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622250) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624710) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610828) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612478) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624130) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616528) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619618) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618468) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615468) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622600) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610528) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624910) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612608) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629468) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627120) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614898) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624460) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623840) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611898) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623210) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611618) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619168) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625130) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609898) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612468) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620828) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622760) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626480) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622620) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622310) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622680) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623890) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620958) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615528) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621508) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626000) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623960) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610468) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616468) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622960) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627600) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624550) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624520) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624790) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622130) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626870) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615618) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626250) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625240) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623970) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621800) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620528) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610318) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623120) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622510) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626150) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622200) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624620) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626460) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623620) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625680) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623000) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622330) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616508) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621750) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613618) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622440) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613508) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626470) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618598) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624310) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628388) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622040) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623150) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615038) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616478) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624810) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623800) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623690) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622450) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629478) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626760) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615598) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628508) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614388) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621168) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625510) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622210) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613758) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626200) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622160) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626570) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628168) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624510) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627100) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619758) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617328) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623370) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623850) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625670) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621328) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612758) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627510) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621830) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618728) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629508) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624630) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624040) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611528) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623410) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615508) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623590) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610758) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623450) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630328) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623380) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625170) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611038) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623770) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623510) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617598) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613608) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627370) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610598) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620508) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626380) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630528) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613828) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618678) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621690) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628598) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619898) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610678) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623670) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624170) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625650) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625850) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627190) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626400) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613388) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626520) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624690) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628618) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622770) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622850) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615728) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617898) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626190) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619388) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621820) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618388) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626880) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625790) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624200) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630598) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616958) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622570) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627030) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614528) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626610) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627440) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627480) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624210) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623630) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611728) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624970) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626240) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625770) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610328) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622970) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615958) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626970) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623240) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622470) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625310) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617828) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613038) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624410) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613898) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627180) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622870) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621910) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616598) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615168) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625750) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628828) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624770) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623600) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616388) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623610) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618528) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625760) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612618) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617608) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614728) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620608) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628478) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626230) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623830) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624750) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616318) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624240) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622990) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624230) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629318) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625910) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626820) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626690) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629168) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622610) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610958) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623870) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611328) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622840) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623990) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622240) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625120) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616608) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624600) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617038) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620678) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621840) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627320) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610388) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612328) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624570) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626370) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625530) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623710) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623320) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621960) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624110) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625410) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625180) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627230) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624590) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622750) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612388) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625970) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614318) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627450) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623520) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624150) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625990) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621038) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622110) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627130) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629388) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627410) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626850) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624800) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609758) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613478) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612728) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627390) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613168) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627310) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621870) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625550) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622710) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614478) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627170) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617678) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626330) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612528) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623460) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625620) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623310) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623400) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616758) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627250) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627330) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617618) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623130) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615608) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613528) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623790) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625230) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614678) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623550) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622670) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619328) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626320) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626130) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610608) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624820) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625590) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625080) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626680) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622030) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628728) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616328) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622080) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623680) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610478) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624840) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630038) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626790) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611608) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624830) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627380) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626180) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621770) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611828) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629958) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612958) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622550) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612038) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623880) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614468) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623200) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622380) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624370) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622530) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622880) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616168) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626600) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630468) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625400) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624960) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625520) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612678) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626120) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627470) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621760) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621880) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624680) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624610) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609828) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625800) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629898) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625690) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623440) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624850) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625460) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611468) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625210) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629618) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624190) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624530) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618168) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621478) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626530) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622100) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625600) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622170) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630168) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627160) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627110) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623040) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624380) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621670) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609678) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628468) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626830) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624400) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626100) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609728) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624100) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630478) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627520) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624330) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624090) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621810) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623470) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626170) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611388) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619508) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616678) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615828) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613678) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625450) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625480) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620478) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622830) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630508) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621318) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627150) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625870) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627590) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618478) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623750) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625100) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624480) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622370) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625440) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624450) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624890) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625370) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622230) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627530) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617528) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624440) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622480) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620618) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617468) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625380) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610618) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627550) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623570) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621790) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629758) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621970) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612598) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612828) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625710) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624390) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628958) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625330) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622390) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622690) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619528) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627040) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627210) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625000) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628318) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623030) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622150) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622790) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626510) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613598) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614508) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627898) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626550) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_618828) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_613818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627000) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624880) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621680) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_627958) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626160) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624160) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614168) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623160) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626810) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623180) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626800) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626110) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626650) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624000) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617958) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623170) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622410) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_624990) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_621730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_620068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_628148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625390) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623820) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629038) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_626560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610168) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_609748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619678) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_623250) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_611648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_619858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_610978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_629018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625090) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_615708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_630098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_614518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_617698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_616078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_625160) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_612498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_internal_grad_fn_622260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show details of quantized model"
      ],
      "metadata": {
        "id": "2H8yFHc0mynk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Quantized TensorFlow Lite model\n",
        "interpreter = tf.lite.Interpreter(model_path=quantized_dir)\n",
        "# Allocate the tensors\n",
        "interpreter.allocate_tensors()\n",
        "# Get the details of the model's inputs and outputs\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "# Get the tensor details, including the weights\n",
        "tensor_details = interpreter.get_tensor_details()\n",
        "print(tensor_details)"
      ],
      "metadata": {
        "id": "5PmC9_Rrmv1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b77da8d9-e7e5-4da6-baa6-02d232bce910"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'name': 'serving_default_state_block4_layer1_pool_frame_count:0', 'index': 0, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block1_layer1_stream_buffer:0', 'index': 1, 'shape': array([  1,   2,  22,  22, 120], dtype=int32), 'shape_signature': array([  1,   2,  22,  22, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1392422914505005, -125), 'quantization_parameters': {'scales': array([0.13924229], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block1_layer2_stream_buffer:0', 'index': 2, 'shape': array([ 1,  2, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1,  2, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.17720718681812286, -126), 'quantization_parameters': {'scales': array([0.17720719], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block3_layer1_pool_frame_count:0', 'index': 3, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block3_layer2_pool_buffer:0', 'index': 4, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.3222709000110626, -98), 'quantization_parameters': {'scales': array([0.3222709], dtype=float32), 'zero_points': array([-98], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block2_layer4_stream_buffer:0', 'index': 5, 'shape': array([  1,   2,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   2,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.09928026050329208, -124), 'quantization_parameters': {'scales': array([0.09928026], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block3_layer3_pool_frame_count:0', 'index': 6, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block4_layer0_pool_buffer:0', 'index': 7, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4712628722190857, -106), 'quantization_parameters': {'scales': array([0.47126287], dtype=float32), 'zero_points': array([-106], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_head_pool_frame_count:0', 'index': 8, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block4_layer4_pool_buffer:0', 'index': 9, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.6727928519248962, -113), 'quantization_parameters': {'scales': array([0.67279285], dtype=float32), 'zero_points': array([-113], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block3_layer0_stream_buffer:0', 'index': 10, 'shape': array([  1,   4,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   4,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.08295381814241409, -123), 'quantization_parameters': {'scales': array([0.08295382], dtype=float32), 'zero_points': array([-123], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block2_layer2_stream_buffer:0', 'index': 11, 'shape': array([  1,   2,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   2,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10641761869192123, -124), 'quantization_parameters': {'scales': array([0.10641762], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block4_layer5_stream_buffer:0', 'index': 12, 'shape': array([  1,   2,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   2,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11984407156705856, -125), 'quantization_parameters': {'scales': array([0.11984407], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block2_layer1_pool_buffer:0', 'index': 13, 'shape': array([  1,   1,   1,   1, 160], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.5359465479850769, -109), 'quantization_parameters': {'scales': array([0.53594655], dtype=float32), 'zero_points': array([-109], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block2_layer1_stream_buffer:0', 'index': 14, 'shape': array([  1,   2,  11,  11, 160], dtype=int32), 'shape_signature': array([  1,   2,  11,  11, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.12421826273202896, -125), 'quantization_parameters': {'scales': array([0.12421826], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block3_layer1_stream_buffer:0', 'index': 15, 'shape': array([  1,   2,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   2,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10401120036840439, -124), 'quantization_parameters': {'scales': array([0.1040112], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block4_layer0_pool_frame_count:0', 'index': 16, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block1_layer3_pool_frame_count:0', 'index': 17, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block2_layer3_stream_buffer:0', 'index': 18, 'shape': array([  1,   2,  11,  11, 192], dtype=int32), 'shape_signature': array([  1,   2,  11,  11, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1339057981967926, -125), 'quantization_parameters': {'scales': array([0.1339058], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block0_layer2_pool_buffer:0', 'index': 19, 'shape': array([ 1,  1,  1,  1, 64], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.23345336318016052, -89), 'quantization_parameters': {'scales': array([0.23345336], dtype=float32), 'zero_points': array([-89], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block4_layer5_pool_frame_count:0', 'index': 20, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block4_layer4_pool_frame_count:0', 'index': 21, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block3_layer3_stream_buffer:0', 'index': 22, 'shape': array([  1,   2,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   2,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.09885547310113907, -124), 'quantization_parameters': {'scales': array([0.09885547], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block1_layer1_pool_buffer:0', 'index': 23, 'shape': array([  1,   1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.5580324530601501, -110), 'quantization_parameters': {'scales': array([0.55803245], dtype=float32), 'zero_points': array([-110], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block3_layer2_pool_frame_count:0', 'index': 24, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block0_layer0_pool_buffer:0', 'index': 25, 'shape': array([ 1,  1,  1,  1, 40], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4721129834651947, -111), 'quantization_parameters': {'scales': array([0.47211298], dtype=float32), 'zero_points': array([-111], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block0_layer1_pool_buffer:0', 'index': 26, 'shape': array([ 1,  1,  1,  1, 40], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.36263859272003174, -107), 'quantization_parameters': {'scales': array([0.3626386], dtype=float32), 'zero_points': array([-107], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block0_layer0_pool_frame_count:0', 'index': 27, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block0_layer2_stream_buffer:0', 'index': 28, 'shape': array([ 1,  2, 43, 43, 64], dtype=int32), 'shape_signature': array([ 1,  2, 43, 43, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.20781420171260834, -126), 'quantization_parameters': {'scales': array([0.2078142], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block2_layer4_pool_buffer:0', 'index': 29, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.8980833292007446, -117), 'quantization_parameters': {'scales': array([0.8980833], dtype=float32), 'zero_points': array([-117], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block1_layer0_pool_frame_count:0', 'index': 30, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block0_layer1_pool_frame_count:0', 'index': 31, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block3_layer0_pool_buffer:0', 'index': 32, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.36663761734962463, -99), 'quantization_parameters': {'scales': array([0.36663762], dtype=float32), 'zero_points': array([-99], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block2_layer2_pool_frame_count:0', 'index': 33, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block2_layer0_pool_frame_count:0', 'index': 34, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block4_layer5_pool_buffer:0', 'index': 35, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.5550479888916016, -109), 'quantization_parameters': {'scales': array([0.555048], dtype=float32), 'zero_points': array([-109], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block4_layer2_pool_frame_count:0', 'index': 36, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block1_layer1_pool_frame_count:0', 'index': 37, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block1_layer4_pool_frame_count:0', 'index': 38, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block1_layer4_stream_buffer:0', 'index': 39, 'shape': array([  1,   2,  22,  22, 120], dtype=int32), 'shape_signature': array([  1,   2,  22,  22, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.23924721777439117, -126), 'quantization_parameters': {'scales': array([0.23924722], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block2_layer3_pool_buffer:0', 'index': 40, 'shape': array([  1,   1,   1,   1, 192], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4555276930332184, -105), 'quantization_parameters': {'scales': array([0.4555277], dtype=float32), 'zero_points': array([-105], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block3_layer2_stream_buffer:0', 'index': 41, 'shape': array([  1,   2,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   2,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.08464442193508148, -124), 'quantization_parameters': {'scales': array([0.08464442], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block4_layer0_stream_buffer:0', 'index': 42, 'shape': array([  1,   4,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   4,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.14083890616893768, -125), 'quantization_parameters': {'scales': array([0.1408389], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block1_layer0_stream_buffer:0', 'index': 43, 'shape': array([ 1,  2, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1,  2, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1357191950082779, -125), 'quantization_parameters': {'scales': array([0.1357192], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block3_layer1_pool_buffer:0', 'index': 44, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.43733468651771545, -105), 'quantization_parameters': {'scales': array([0.4373347], dtype=float32), 'zero_points': array([-105], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block3_layer4_pool_frame_count:0', 'index': 45, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block1_layer4_pool_buffer:0', 'index': 46, 'shape': array([  1,   1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.3195478618144989, -95), 'quantization_parameters': {'scales': array([0.31954786], dtype=float32), 'zero_points': array([-95], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block4_layer6_pool_frame_count:0', 'index': 47, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block4_layer3_pool_buffer:0', 'index': 48, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.7569623589515686, -114), 'quantization_parameters': {'scales': array([0.75696236], dtype=float32), 'zero_points': array([-114], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block1_layer0_pool_buffer:0', 'index': 49, 'shape': array([ 1,  1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.23220112919807434, -85), 'quantization_parameters': {'scales': array([0.23220113], dtype=float32), 'zero_points': array([-85], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block1_layer3_stream_buffer:0', 'index': 50, 'shape': array([ 1,  2, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1,  2, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1880284696817398, -126), 'quantization_parameters': {'scales': array([0.18802847], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block3_layer0_pool_frame_count:0', 'index': 51, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block0_layer1_stream_buffer:0', 'index': 52, 'shape': array([ 1,  2, 43, 43, 40], dtype=int32), 'shape_signature': array([ 1,  2, 43, 43, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.19203461706638336, -126), 'quantization_parameters': {'scales': array([0.19203462], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block2_layer0_stream_buffer:0', 'index': 53, 'shape': array([  1,   4,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   4,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11277470737695694, -125), 'quantization_parameters': {'scales': array([0.11277471], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block3_layer5_stream_buffer:0', 'index': 54, 'shape': array([  1,   2,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   2,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.15381567180156708, -126), 'quantization_parameters': {'scales': array([0.15381567], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block4_layer6_pool_buffer:0', 'index': 55, 'shape': array([  1,   1,   1,   1, 576], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 576], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.7719916105270386, -115), 'quantization_parameters': {'scales': array([0.7719916], dtype=float32), 'zero_points': array([-115], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block2_layer2_pool_buffer:0', 'index': 56, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.7679204940795898, -114), 'quantization_parameters': {'scales': array([0.7679205], dtype=float32), 'zero_points': array([-114], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_head_pool_buffer:0', 'index': 57, 'shape': array([  1,   1,   1,   1, 640], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 640], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.21933883428573608, -98), 'quantization_parameters': {'scales': array([0.21933883], dtype=float32), 'zero_points': array([-98], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block4_layer1_pool_buffer:0', 'index': 58, 'shape': array([  1,   1,   1,   1, 384], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.5464414358139038, -110), 'quantization_parameters': {'scales': array([0.54644144], dtype=float32), 'zero_points': array([-110], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block1_layer2_pool_frame_count:0', 'index': 59, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_image:0', 'index': 60, 'shape': array([  1,   1, 172, 172,   3], dtype=int32), 'shape_signature': array([  1,   1, 172, 172,   3], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.003921568859368563, -128), 'quantization_parameters': {'scales': array([0.00392157], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block1_layer2_pool_buffer:0', 'index': 61, 'shape': array([ 1,  1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.27840766310691833, -94), 'quantization_parameters': {'scales': array([0.27840766], dtype=float32), 'zero_points': array([-94], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block2_layer0_pool_buffer:0', 'index': 62, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4731212854385376, -107), 'quantization_parameters': {'scales': array([0.4731213], dtype=float32), 'zero_points': array([-107], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block4_layer3_pool_frame_count:0', 'index': 63, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block1_layer3_pool_buffer:0', 'index': 64, 'shape': array([ 1,  1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.651642382144928, -113), 'quantization_parameters': {'scales': array([0.6516424], dtype=float32), 'zero_points': array([-113], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block3_layer4_pool_buffer:0', 'index': 65, 'shape': array([  1,   1,   1,   1, 144], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.3313746750354767, -98), 'quantization_parameters': {'scales': array([0.33137468], dtype=float32), 'zero_points': array([-98], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block2_layer4_pool_frame_count:0', 'index': 66, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block4_layer2_pool_buffer:0', 'index': 67, 'shape': array([  1,   1,   1,   1, 384], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.630398690700531, -112), 'quantization_parameters': {'scales': array([0.6303987], dtype=float32), 'zero_points': array([-112], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block3_layer5_pool_frame_count:0', 'index': 68, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block2_layer3_pool_frame_count:0', 'index': 69, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block3_layer5_pool_buffer:0', 'index': 70, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.664547860622406, -112), 'quantization_parameters': {'scales': array([0.66454786], dtype=float32), 'zero_points': array([-112], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block3_layer3_pool_buffer:0', 'index': 71, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.8458091616630554, -116), 'quantization_parameters': {'scales': array([0.84580916], dtype=float32), 'zero_points': array([-116], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block2_layer1_pool_frame_count:0', 'index': 72, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_state_block0_layer2_pool_frame_count:0', 'index': 73, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/stem/stem/conv2d/Reshape/shape', 'index': 74, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/feature/conv2d/Reshape_1/shape', 'index': 75, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/global_average_pool3d_27/Mean/reduction_indices', 'index': 76, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/projection/conv2d/Reshape_1/shape', 'index': 77, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/se/global_average_pool3d_52/strided_slice_1', 'index': 78, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/se/global_average_pool3d_28/strided_slice_1', 'index': 79, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/global_average_pool3d_27/Reshape/shape', 'index': 80, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/projection/conv2d/strided_slice_4', 'index': 81, 'shape': array([], dtype=int32), 'shape_signature': array([], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_reduce/conv2d/Reshape/shape', 'index': 82, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_expand/conv2d/Reshape_1/shape', 'index': 83, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/mul', 'index': 84, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int64'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/projection/conv2d/Reshape/shape', 'index': 85, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/skip/skip_project/conv2d/Reshape/shape', 'index': 86, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d_temporal/Reshape/shape', 'index': 87, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/expansion/conv2d/Reshape_1/shape', 'index': 88, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/stream_buffer_37/strided_slice', 'index': 89, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/stream_buffer_19/strided_slice', 'index': 90, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d_temporal/Reshape/shape', 'index': 91, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/se/global_average_pool3d_29/strided_slice_1', 'index': 92, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_reduce/conv2d/Reshape/shape', 'index': 93, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_expand/conv2d/Reshape_1/shape', 'index': 94, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/se/mul', 'index': 95, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int64'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d/Reshape/shape', 'index': 96, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d/Reshape_1/shape', 'index': 97, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/skip/Reshape/shape', 'index': 98, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/projection/conv2d/Reshape_1/shape', 'index': 99, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/stream_buffer_20/strided_slice', 'index': 100, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d_temporal/Reshape/shape', 'index': 101, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/se/global_average_pool3d_33/strided_slice_1', 'index': 102, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_reduce/conv2d/Reshape/shape', 'index': 103, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_expand/conv2d/Reshape_1/shape', 'index': 104, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/se/mul', 'index': 105, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int64'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/projection/conv2d/Reshape/shape', 'index': 106, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/expansion/conv2d/Reshape/shape', 'index': 107, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/expansion/conv2d/Reshape_1/shape', 'index': 108, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/stream_buffer_24/strided_slice', 'index': 109, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d_temporal/Reshape/shape', 'index': 110, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/se/global_average_pool3d_34/strided_slice_1', 'index': 111, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_reduce/conv2d/Reshape/shape', 'index': 112, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_expand/conv2d/Reshape_1/shape', 'index': 113, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/se/mul', 'index': 114, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int64'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d/Reshape/shape', 'index': 115, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/stream_buffer_25/strided_slice', 'index': 116, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d/Reshape_1/shape', 'index': 117, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/skip/Reshape/shape', 'index': 118, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/projection/conv2d/Reshape_1/shape', 'index': 119, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d_temporal/Reshape/shape', 'index': 120, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/se/global_average_pool3d_45/strided_slice_1', 'index': 121, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_reduce/conv2d/Reshape/shape', 'index': 122, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_expand/conv2d/Reshape_1/shape', 'index': 123, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/se/mul', 'index': 124, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int64'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/projection/conv2d/Reshape/shape', 'index': 125, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/expansion/conv2d/Reshape/shape', 'index': 126, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/expansion/conv2d/Reshape_1/shape', 'index': 127, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/stream_buffer_36/strided_slice', 'index': 128, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/stream_buffer_35/strided_slice', 'index': 129, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d_temporal/Reshape/shape', 'index': 130, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/se/global_average_pool3d_36/strided_slice_1', 'index': 131, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_reduce/conv2d/Reshape/shape', 'index': 132, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_expand/conv2d/Reshape_1/shape', 'index': 133, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/se/mul', 'index': 134, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int64'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d/Reshape/shape', 'index': 135, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/stream_buffer_27/strided_slice', 'index': 136, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d_temporal/Reshape/shape', 'index': 137, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/expansion/conv2d/Reshape_1/shape', 'index': 138, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d_temporal/Reshape/shape', 'index': 139, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/se/global_average_pool3d_38/strided_slice_1', 'index': 140, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/Reshape/shape', 'index': 141, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_expand/conv2d/Reshape_1/shape', 'index': 142, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/se/mul', 'index': 143, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int64'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d/Reshape/shape', 'index': 144, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/stream_buffer_29/strided_slice', 'index': 145, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/expansion/conv2d/Reshape_1/shape', 'index': 146, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/se/global_average_pool3d_44/strided_slice_1', 'index': 147, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_reduce/conv2d/Reshape/shape', 'index': 148, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_expand/conv2d/Reshape_1/shape', 'index': 149, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/se/mul', 'index': 150, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int64'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/feature/conv2d/Reshape/shape', 'index': 151, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d/Reshape_1/shape', 'index': 152, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/skip/Reshape/shape', 'index': 153, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/projection/conv2d/Reshape_1/shape', 'index': 154, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d_temporal/Reshape/shape', 'index': 155, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/se/global_average_pool3d_51/strided_slice_1', 'index': 156, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_reduce/conv2d/Reshape/shape', 'index': 157, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_expand/conv2d/Reshape_1/shape', 'index': 158, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/se/mul', 'index': 159, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int64'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/projection/conv2d/Reshape/shape', 'index': 160, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/expansion/conv2d/Reshape/shape', 'index': 161, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/expansion/conv2d/Reshape_1/shape', 'index': 162, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/stream_buffer_37/strided_slice1', 'index': 163, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/se/global_average_pool3d_48/strided_slice_1', 'index': 164, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_reduce/conv2d/Reshape/shape', 'index': 165, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_expand/conv2d/Reshape_1/shape', 'index': 166, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/se/mul', 'index': 167, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int64'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/feature/conv2d/Reshape/shape', 'index': 168, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d_temporal/Reshape/shape', 'index': 169, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/expansion/conv2d/Reshape_1/shape', 'index': 170, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/se/global_average_pool3d_52/strided_slice_11', 'index': 171, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_reduce/conv2d/Reshape/shape', 'index': 172, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_expand/conv2d/Reshape_1/shape', 'index': 173, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/se/mul', 'index': 174, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int64'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/feature/conv2d/Reshape/shape', 'index': 175, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/head/project/conv2d/Reshape_1/shape', 'index': 176, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/head/global_average_pool3d_53/Sum/reduction_indices', 'index': 177, 'shape': array([3], dtype=int32), 'shape_signature': array([3], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/classifier_head_2/head/conv2d/Reshape/shape', 'index': 178, 'shape': array([4], dtype=int32), 'shape_signature': array([4], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/classifier_head_2/squeeze3d_2/Squeeze', 'index': 179, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/classifier_head_2/classifier/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 180, 'shape': array([10], dtype=int32), 'shape_signature': array([10], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([5.0081067e-06, 4.6972064e-06, 4.2287766e-06, 3.6994984e-06,\n",
            "       3.5770952e-06, 3.6481326e-06, 3.7341565e-06, 3.4666386e-06,\n",
            "       3.4098146e-06, 3.7081654e-06], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/classifier_head_2/classifier/conv2d/conv2d_1/Conv2D', 'index': 181, 'shape': array([  10,    1,    1, 2048], dtype=int32), 'shape_signature': array([  10,    1,    1, 2048], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00060301, 0.00056557, 0.00050917, 0.00044544, 0.0004307 ,\n",
            "       0.00043926, 0.00044961, 0.0004174 , 0.00041056, 0.00044649],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/classifier_head_2/head/conv2d/conv2d/BiasAdd/ReadVariableOp', 'index': 182, 'shape': array([2048], dtype=int32), 'shape_signature': array([2048], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.5669999e-05, 1.4709297e-05, 1.6871987e-05, ..., 1.6617942e-05,\n",
            "       1.4967364e-05, 1.4988699e-05], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/classifier_head_2/head/conv2d/conv2d/Conv2D', 'index': 183, 'shape': array([2048,    1,    1,  640], dtype=int32), 'shape_signature': array([2048,    1,    1,  640], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00115898, 0.00108793, 0.00124788, ..., 0.0012291 , 0.00110702,\n",
            "       0.00110859], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/head/global_average_pool3d_53/truediv;movinet_classifier_2/movinet_1/head/global_average_pool3d_53/Cast', 'index': 184, 'shape': array([  1,   1,   1,   1, 640], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 640], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00010893246508203447, -128), 'quantization_parameters': {'scales': array([0.00010893], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/head/project/conv2d/bn/batchnorm/sub', 'index': 185, 'shape': array([640], dtype=int32), 'shape_signature': array([640], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.54197075e-04, 4.25010425e-04, 3.57117882e-04, 3.77842662e-04,\n",
            "       3.27918620e-04, 3.12573829e-04, 3.40103667e-04, 3.18325212e-04,\n",
            "       1.61619872e-04, 2.66705436e-04, 2.27006516e-04, 2.70595192e-04,\n",
            "       3.08274146e-04, 2.59819644e-04, 3.29113536e-04, 2.46535434e-04,\n",
            "       2.13833409e-04, 3.08195595e-04, 2.92100682e-04, 2.91393750e-04,\n",
            "       2.79300933e-04, 2.73329497e-04, 3.10982141e-04, 2.85070215e-04,\n",
            "       2.82842637e-04, 2.31718339e-04, 3.04281944e-04, 3.33029457e-04,\n",
            "       2.35908723e-04, 2.13425417e-04, 2.53593636e-04, 2.27291224e-04,\n",
            "       2.49038887e-04, 4.22581157e-04, 3.15650192e-04, 2.46459298e-04,\n",
            "       2.89084739e-04, 3.36575147e-04, 3.00053420e-04, 4.15562536e-04,\n",
            "       3.42346029e-04, 2.88334442e-04, 2.44082185e-04, 3.27331683e-04,\n",
            "       2.69350945e-04, 3.48632311e-04, 3.21686181e-04, 3.41889390e-04,\n",
            "       3.62636696e-04, 3.08835268e-04, 2.91997741e-04, 3.26624955e-04,\n",
            "       2.67192896e-04, 2.67731259e-04, 2.65189417e-04, 2.92417069e-04,\n",
            "       3.86434636e-04, 2.48336379e-04, 2.50126061e-04, 2.90166121e-04,\n",
            "       2.64014350e-04, 2.48878729e-04, 2.89793184e-04, 2.72026111e-04,\n",
            "       2.76121165e-04, 2.95286678e-04, 3.54962423e-04, 1.11807334e-04,\n",
            "       2.80988374e-04, 3.17822705e-04, 2.55023857e-04, 3.41635372e-04,\n",
            "       3.75989592e-04, 2.32907929e-04, 1.98495676e-04, 2.49201781e-04,\n",
            "       2.91408185e-04, 2.97627441e-04, 2.36722539e-04, 2.71198602e-04,\n",
            "       2.30768594e-04, 2.80128763e-04, 1.22889105e-04, 3.07577866e-04,\n",
            "       2.75239989e-04, 2.92547425e-04, 2.46197189e-04, 2.66451505e-04,\n",
            "       3.01578984e-04, 2.72140693e-04, 2.84274138e-04, 2.17016277e-04,\n",
            "       2.60355446e-04, 3.66407854e-04, 2.42367605e-04, 2.80431646e-04,\n",
            "       2.29024474e-04, 2.72493635e-04, 2.87917414e-04, 2.69193260e-04,\n",
            "       3.91472946e-04, 3.17849946e-04, 2.26945034e-04, 3.34351847e-04,\n",
            "       1.14001479e-04, 2.92506214e-04, 3.25690460e-04, 2.83059868e-04,\n",
            "       2.58312153e-04, 2.71756056e-04, 2.87890434e-04, 3.57044133e-04,\n",
            "       2.73049023e-04, 2.47079850e-04, 2.47003569e-04, 2.94724479e-04,\n",
            "       3.10253003e-04, 2.92858254e-04, 2.38230597e-04, 3.10103525e-04,\n",
            "       2.85414048e-04, 2.89695890e-04, 3.41233768e-04, 3.63692932e-04,\n",
            "       2.36728913e-04, 2.77052546e-04, 3.34375392e-04, 2.71979923e-04,\n",
            "       2.63104797e-04, 3.18656064e-04, 2.93177291e-04, 2.27803641e-04,\n",
            "       2.47903226e-04, 2.92593235e-04, 2.71812372e-04, 2.86280294e-04,\n",
            "       2.05138364e-04, 3.05421505e-04, 2.50068813e-04, 3.20287334e-04,\n",
            "       2.95607693e-04, 8.84018300e-05, 2.14068772e-04, 3.62050021e-04,\n",
            "       3.45706008e-04, 2.59013934e-04, 2.11527964e-04, 3.34093173e-04,\n",
            "       2.43165297e-04, 2.90492550e-04, 3.29104660e-04, 2.51917518e-04,\n",
            "       3.12544347e-04, 3.27301153e-04, 2.45498464e-04, 2.70460325e-04,\n",
            "       1.18647629e-04, 3.59671831e-04, 2.81379529e-04, 3.36302677e-04,\n",
            "       3.62983701e-04, 2.33811865e-04, 2.81368120e-04, 2.90523370e-04,\n",
            "       3.43208172e-04, 3.16721504e-04, 2.89225049e-04, 3.04006302e-04,\n",
            "       2.61476089e-04, 2.36916720e-04, 2.74385384e-04, 2.81508546e-04,\n",
            "       2.64975621e-04, 3.08306713e-04, 2.13187363e-04, 2.70740682e-04,\n",
            "       4.39752301e-04, 2.76568258e-04, 2.29112833e-04, 1.17461306e-04,\n",
            "       3.19895567e-04, 3.39114456e-04, 3.15034849e-04, 2.54692131e-04,\n",
            "       1.87670012e-04, 3.21430678e-04, 3.09501047e-04, 3.46537214e-04,\n",
            "       2.88475916e-04, 2.93460180e-04, 2.85107119e-04, 3.00528249e-04,\n",
            "       2.71294295e-04, 3.13152530e-04, 2.54830375e-04, 3.63643281e-04,\n",
            "       2.56882253e-04, 3.70708702e-04, 3.48548958e-04, 2.31438346e-04,\n",
            "       3.03928886e-04, 3.57999408e-04, 2.03752323e-04, 2.68862670e-04,\n",
            "       1.84652774e-04, 2.99448438e-04, 3.24678113e-04, 3.27439891e-04,\n",
            "       3.79759236e-04, 3.01889639e-04, 2.45728501e-04, 2.80991400e-04,\n",
            "       3.38786282e-04, 1.02207800e-04, 3.33376694e-04, 2.24171818e-04,\n",
            "       2.65806477e-04, 2.49964593e-04, 2.13368912e-04, 2.15998210e-04,\n",
            "       2.69851997e-04, 2.82173045e-04, 3.00404179e-04, 2.35192609e-04,\n",
            "       3.04874935e-04, 3.11330048e-04, 3.10131145e-04, 2.15100037e-04,\n",
            "       2.35269807e-04, 2.51999125e-04, 2.85156915e-04, 2.63055030e-04,\n",
            "       3.21479893e-04, 3.57006560e-04, 2.84428359e-04, 4.54314868e-04,\n",
            "       2.63372756e-04, 1.22634345e-04, 3.24254972e-04, 2.63936206e-04,\n",
            "       2.63772352e-04, 2.60734116e-04, 2.89490039e-04, 2.65508745e-04,\n",
            "       3.85303632e-04, 3.46865767e-04, 2.52067635e-04, 3.04568006e-04,\n",
            "       2.84256734e-04, 2.17796958e-04, 2.48571392e-04, 2.84659240e-04,\n",
            "       2.84375943e-04, 2.75426486e-04, 2.57315201e-04, 2.94390426e-04,\n",
            "       2.29692028e-04, 9.22598265e-05, 2.05150689e-04, 2.45307077e-04,\n",
            "       2.98178929e-04, 2.72486504e-04, 3.07564478e-04, 2.93386925e-04,\n",
            "       2.81188812e-04, 2.22653864e-04, 2.90300202e-04, 2.54538085e-04,\n",
            "       2.73406331e-04, 2.84545269e-04, 3.99888057e-04, 2.91990989e-04,\n",
            "       2.57567852e-04, 2.26390097e-04, 9.83622449e-05, 2.64781498e-04,\n",
            "       3.36556637e-04, 2.70328135e-04, 3.61205515e-04, 2.91199103e-04,\n",
            "       3.38771264e-04, 3.56796692e-04, 3.27741844e-04, 2.42615701e-04,\n",
            "       3.82002007e-04, 2.48253520e-04, 2.87649513e-04, 1.29349108e-04,\n",
            "       2.49719451e-04, 3.56984558e-04, 3.02739238e-04, 3.32982861e-04,\n",
            "       3.21226107e-04, 2.67127849e-04, 2.38689798e-04, 2.48955854e-04,\n",
            "       3.24102788e-04, 4.36866132e-04, 2.55000195e-04, 2.70166609e-04,\n",
            "       2.07021847e-04, 2.31007813e-04, 2.50555109e-04, 2.90473748e-04,\n",
            "       2.64104223e-04, 3.11732874e-04, 2.03816118e-04, 2.90432392e-04,\n",
            "       2.80903623e-04, 3.66336375e-04, 3.31052201e-04, 3.30983457e-04,\n",
            "       3.76729935e-04, 2.37833447e-04, 2.50598037e-04, 2.80166452e-04,\n",
            "       4.38720017e-04, 2.54517276e-04, 2.48366181e-04, 2.51866120e-04,\n",
            "       4.17455158e-04, 2.94730067e-04, 3.56926699e-04, 2.90159136e-04,\n",
            "       3.13209603e-04, 2.59475928e-04, 2.50770914e-04, 2.72277714e-04,\n",
            "       3.45142063e-04, 3.09894414e-04, 2.44542549e-04, 2.75058264e-04,\n",
            "       2.32043356e-04, 3.32383031e-04, 2.52653699e-04, 2.57436623e-04,\n",
            "       2.43838658e-04, 3.63295258e-04, 3.01867229e-04, 2.54670565e-04,\n",
            "       3.03204724e-04, 2.30390637e-04, 5.01587987e-04, 2.75200349e-04,\n",
            "       2.74168211e-04, 2.76827923e-04, 2.38483495e-04, 3.27987043e-04,\n",
            "       2.06501427e-04, 2.62527028e-04, 2.53499253e-04, 3.39707360e-04,\n",
            "       1.27067469e-04, 2.76133564e-04, 3.00396379e-04, 2.92041514e-04,\n",
            "       2.58008688e-04, 2.10671074e-04, 2.53012462e-04, 3.87267733e-04,\n",
            "       2.57282751e-04, 2.71689962e-04, 2.44584546e-04, 2.54687824e-04,\n",
            "       3.13489174e-04, 2.54153449e-04, 2.27263430e-04, 1.91965417e-04,\n",
            "       2.28981226e-04, 2.09810009e-04, 3.01270367e-04, 3.29026021e-04,\n",
            "       1.68086786e-04, 2.63077614e-04, 2.78745400e-04, 2.35062820e-04,\n",
            "       2.77259882e-04, 2.69845215e-04, 1.37298033e-04, 2.63739290e-04,\n",
            "       3.23916232e-04, 3.93714989e-04, 2.71776982e-04, 2.76780280e-04,\n",
            "       2.91485048e-04, 3.20257706e-04, 2.44649476e-04, 2.06305558e-04,\n",
            "       3.49891547e-04, 3.00800486e-04, 3.93036316e-04, 1.01604412e-04,\n",
            "       2.74096878e-04, 2.43807008e-04, 3.46457382e-04, 2.41751593e-04,\n",
            "       4.11388493e-04, 3.03309818e-04, 2.77398096e-04, 2.37471730e-04,\n",
            "       2.38826324e-04, 3.65448039e-04, 3.28358612e-04, 2.63829250e-04,\n",
            "       2.97215913e-04, 1.02828417e-04, 3.31552292e-04, 2.78219755e-04,\n",
            "       2.21309485e-04, 3.64935724e-04, 2.63464492e-04, 3.00120388e-04,\n",
            "       3.08218936e-04, 3.07796668e-04, 3.03775800e-04, 2.97119463e-04,\n",
            "       4.27727093e-04, 3.09707568e-04, 2.45575793e-04, 2.23081355e-04,\n",
            "       2.80233624e-04, 2.31187747e-04, 1.05164807e-04, 2.83164176e-04,\n",
            "       2.75074621e-04, 3.24685447e-04, 2.58804823e-04, 2.59714026e-04,\n",
            "       2.57738837e-04, 2.19835085e-04, 3.17272352e-04, 2.74830352e-04,\n",
            "       2.91850418e-04, 2.24597679e-04, 2.55056948e-04, 2.81049259e-04,\n",
            "       3.29671049e-04, 3.61054175e-04, 2.92962737e-04, 2.93382851e-04,\n",
            "       2.49723438e-04, 3.70521506e-04, 2.48940632e-04, 2.87879433e-04,\n",
            "       3.64876032e-04, 3.02456552e-04, 3.95049865e-04, 2.18078785e-04,\n",
            "       2.66236719e-04, 2.53061502e-04, 2.55378982e-04, 3.11964395e-04,\n",
            "       2.80369393e-04, 2.97600229e-04, 2.38089764e-04, 2.28536519e-04,\n",
            "       1.23280624e-04, 2.33359038e-04, 3.02438682e-04, 2.95428908e-04,\n",
            "       4.31124645e-04, 2.83168454e-04, 3.17119557e-04, 2.47581687e-04,\n",
            "       2.49843841e-04, 2.74671766e-04, 2.61546345e-04, 3.71640985e-04,\n",
            "       2.63668830e-04, 2.58947024e-04, 9.73692659e-05, 2.02593437e-04,\n",
            "       2.40810827e-04, 3.03700741e-04, 1.25930703e-04, 2.89622811e-04,\n",
            "       2.66481889e-04, 2.45316827e-04, 2.76982959e-04, 3.60649341e-04,\n",
            "       2.37783854e-04, 2.31681013e-04, 3.14048200e-04, 2.96228798e-04,\n",
            "       3.41692794e-04, 2.68452801e-04, 3.00639396e-04, 2.47510499e-04,\n",
            "       2.72119709e-04, 2.65263137e-04, 3.36923782e-04, 2.58711778e-04,\n",
            "       2.65429670e-04, 3.48141766e-04, 3.61519400e-04, 2.77740561e-04,\n",
            "       2.55291845e-04, 2.53173232e-04, 3.38447135e-04, 3.36149184e-04,\n",
            "       3.20874969e-04, 3.21805273e-04, 2.60052300e-04, 3.24577704e-04,\n",
            "       2.95681122e-04, 2.63926719e-04, 3.10143572e-04, 2.75115250e-04,\n",
            "       2.91141449e-04, 2.39089874e-04, 3.81480466e-04, 2.71977653e-04,\n",
            "       2.28889898e-04, 3.68680194e-04, 2.10648956e-04, 3.06260277e-04,\n",
            "       2.49265489e-04, 2.64074217e-04, 2.34393534e-04, 2.84982350e-04,\n",
            "       4.02493140e-04, 2.52595288e-04, 2.44576804e-04, 2.21621187e-04,\n",
            "       2.56580301e-04, 2.36006599e-04, 2.39744782e-04, 2.86911411e-04,\n",
            "       3.18658131e-04, 2.63533293e-04, 2.90010503e-04, 2.31611935e-04,\n",
            "       2.79871572e-04, 2.91199191e-04, 3.45306471e-04, 2.68152740e-04,\n",
            "       3.67455592e-04, 2.83822679e-04, 2.83229834e-04, 2.24381423e-04,\n",
            "       2.49118544e-04, 2.26404009e-04, 3.17933387e-04, 3.18416918e-04,\n",
            "       2.82432651e-04, 2.80406675e-04, 2.85812450e-04, 2.09096819e-04,\n",
            "       2.53520557e-04, 2.19625581e-04, 2.97356048e-04, 2.84631969e-04,\n",
            "       1.34395596e-04, 4.41760727e-04, 2.11222388e-04, 3.03845620e-04,\n",
            "       3.48926871e-04, 2.95143720e-04, 2.40332811e-04, 3.35961406e-04,\n",
            "       2.67924392e-04, 3.37145379e-04, 3.62656167e-04, 2.56167521e-04,\n",
            "       3.11761920e-04, 2.69368611e-04, 2.93744321e-04, 2.40051741e-04,\n",
            "       3.28253896e-04, 2.82565336e-04, 3.33241129e-04, 2.20747970e-04,\n",
            "       2.50594952e-04, 2.31050828e-04, 2.60681147e-04, 2.90970958e-04,\n",
            "       3.18957551e-04, 3.33203003e-04, 2.97977560e-04, 2.26617180e-04,\n",
            "       2.38191191e-04, 3.62738007e-04, 2.11495353e-04, 2.54140177e-04,\n",
            "       2.71110999e-04, 2.74136080e-04, 3.30450974e-04, 3.10932548e-04,\n",
            "       3.61984887e-04, 2.96681654e-04, 2.88268959e-04, 3.05398920e-04,\n",
            "       2.60116009e-04, 3.21199157e-04, 2.48655997e-04, 2.15551947e-04,\n",
            "       2.88042997e-04, 2.77078914e-04, 3.20164690e-04, 2.72367091e-04,\n",
            "       5.46786527e-04, 2.76914740e-04, 2.03911550e-04, 2.68761505e-04,\n",
            "       3.46932909e-04, 3.15176963e-04, 2.88350479e-04, 2.41595990e-04,\n",
            "       2.39788758e-04, 2.81512388e-04, 2.99001782e-04, 2.54893821e-04,\n",
            "       3.02523666e-04, 1.71727312e-04, 2.71023629e-04, 3.49281996e-04,\n",
            "       3.07125709e-04, 2.75842380e-04, 2.65153591e-04, 2.36078413e-04,\n",
            "       2.90125085e-04, 2.48055992e-04, 2.42680209e-04, 2.69470213e-04,\n",
            "       3.06956645e-04, 2.07862147e-04, 2.16657019e-04, 3.23234621e-04,\n",
            "       2.46658659e-04, 2.53481441e-04, 3.02951899e-04, 3.18074017e-04,\n",
            "       2.60939996e-04, 2.71249970e-04, 2.47591262e-04, 2.59132852e-04,\n",
            "       2.54965562e-04, 2.98966508e-04, 2.49610253e-04, 3.23149434e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/head/project/conv2d/conv2d/Conv2D', 'index': 186, 'shape': array([640,   1,   1, 144], dtype=int32), 'shape_signature': array([640,   1,   1, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00045093, 0.00075395, 0.00063351, 0.00067027, 0.00058171,\n",
            "       0.00055449, 0.00060333, 0.00056469, 0.00028671, 0.00047312,\n",
            "       0.0004027 , 0.00048002, 0.00054686, 0.00046091, 0.00058383,\n",
            "       0.00043734, 0.00037933, 0.00054672, 0.00051817, 0.00051692,\n",
            "       0.00049547, 0.00048487, 0.00055167, 0.0005057 , 0.00050175,\n",
            "       0.00041106, 0.00053978, 0.00059078, 0.00041849, 0.00037861,\n",
            "       0.00044986, 0.0004032 , 0.00044178, 0.00074964, 0.00055995,\n",
            "       0.00043721, 0.00051282, 0.00059707, 0.00053228, 0.00073719,\n",
            "       0.0006073 , 0.00051149, 0.00043299, 0.00058067, 0.00047781,\n",
            "       0.00061846, 0.00057065, 0.00060649, 0.0006433 , 0.00054786,\n",
            "       0.00051799, 0.00057942, 0.00047399, 0.00047494, 0.00047043,\n",
            "       0.00051873, 0.00068552, 0.00044054, 0.00044371, 0.00051474,\n",
            "       0.00046835, 0.0004415 , 0.00051408, 0.00048256, 0.00048982,\n",
            "       0.00052382, 0.00062969, 0.00019834, 0.00049846, 0.0005638 ,\n",
            "       0.0004524 , 0.00060604, 0.00066699, 0.00041317, 0.00035212,\n",
            "       0.00044207, 0.00051694, 0.00052798, 0.00041993, 0.00048109,\n",
            "       0.00040937, 0.00049693, 0.000218  , 0.00054563, 0.00048826,\n",
            "       0.00051896, 0.00043674, 0.00047267, 0.00053499, 0.00048276,\n",
            "       0.00050429, 0.00038498, 0.00046186, 0.00064999, 0.00042995,\n",
            "       0.00049747, 0.00040628, 0.00048339, 0.00051075, 0.00047753,\n",
            "       0.00069445, 0.00056385, 0.00040259, 0.00059312, 0.00020223,\n",
            "       0.00051889, 0.00057776, 0.00050213, 0.00045823, 0.00048208,\n",
            "       0.0005107 , 0.00063338, 0.00048437, 0.00043831, 0.00043817,\n",
            "       0.00052283, 0.00055037, 0.00051952, 0.00042261, 0.00055011,\n",
            "       0.00050631, 0.00051391, 0.00060533, 0.00064517, 0.00041994,\n",
            "       0.00049148, 0.00059316, 0.00048248, 0.00046673, 0.00056528,\n",
            "       0.00052008, 0.00040411, 0.00043977, 0.00051905, 0.00048218,\n",
            "       0.00050785, 0.0003639 , 0.0005418 , 0.00044361, 0.00056817,\n",
            "       0.00052439, 0.00015682, 0.00037975, 0.00064226, 0.00061326,\n",
            "       0.00045948, 0.00037524, 0.00059266, 0.00043136, 0.00051532,\n",
            "       0.00058381, 0.00044689, 0.00055444, 0.00058062, 0.0004355 ,\n",
            "       0.00047978, 0.00021047, 0.00063804, 0.00049915, 0.00059658,\n",
            "       0.00064391, 0.00041477, 0.00049913, 0.00051537, 0.00060883,\n",
            "       0.00056185, 0.00051307, 0.00053929, 0.00046385, 0.00042028,\n",
            "       0.00048675, 0.00049938, 0.00047005, 0.00054692, 0.00037818,\n",
            "       0.00048028, 0.0007801 , 0.00049062, 0.00040643, 0.00020837,\n",
            "       0.00056748, 0.00060157, 0.00055886, 0.00045181, 0.00033292,\n",
            "       0.0005702 , 0.00054904, 0.00061474, 0.00051174, 0.00052058,\n",
            "       0.00050577, 0.00053312, 0.00048126, 0.00055552, 0.00045206,\n",
            "       0.00064508, 0.0004557 , 0.00065762, 0.00061831, 0.00041056,\n",
            "       0.00053915, 0.00063507, 0.00036145, 0.00047695, 0.00032756,\n",
            "       0.00053121, 0.00057596, 0.00058086, 0.00067367, 0.00053554,\n",
            "       0.00043591, 0.00049846, 0.00060099, 0.00018131, 0.00059139,\n",
            "       0.00039767, 0.00047153, 0.00044342, 0.00037851, 0.00038317,\n",
            "       0.0004787 , 0.00050056, 0.0005329 , 0.00041722, 0.00054083,\n",
            "       0.00055228, 0.00055016, 0.00038158, 0.00041736, 0.00044703,\n",
            "       0.00050585, 0.00046665, 0.00057029, 0.00063331, 0.00050456,\n",
            "       0.00080593, 0.00046721, 0.00021755, 0.00057521, 0.00046821,\n",
            "       0.00046792, 0.00046253, 0.00051354, 0.000471  , 0.00068351,\n",
            "       0.00061532, 0.00044715, 0.00054029, 0.00050426, 0.00038636,\n",
            "       0.00044095, 0.00050497, 0.00050447, 0.00048859, 0.00045646,\n",
            "       0.00052223, 0.00040746, 0.00016366, 0.00036393, 0.00043516,\n",
            "       0.00052895, 0.00048338, 0.0005456 , 0.00052045, 0.00049881,\n",
            "       0.00039498, 0.00051498, 0.00045154, 0.00048501, 0.00050477,\n",
            "       0.00070938, 0.00051798, 0.00045691, 0.0004016 , 0.00017449,\n",
            "       0.00046971, 0.00059703, 0.00047955, 0.00064076, 0.00051657,\n",
            "       0.00060096, 0.00063294, 0.0005814 , 0.00043039, 0.00067765,\n",
            "       0.00044039, 0.00051028, 0.00022946, 0.00044299, 0.00063327,\n",
            "       0.00053704, 0.00059069, 0.00056984, 0.00047387, 0.00042342,\n",
            "       0.00044163, 0.00057494, 0.00077498, 0.00045236, 0.00047926,\n",
            "       0.00036725, 0.0004098 , 0.00044447, 0.00051529, 0.00046851,\n",
            "       0.000553  , 0.00036156, 0.00051521, 0.00049831, 0.00064986,\n",
            "       0.00058727, 0.00058715, 0.0006683 , 0.0004219 , 0.00044455,\n",
            "       0.000497  , 0.00077827, 0.0004515 , 0.00044059, 0.0004468 ,\n",
            "       0.00074054, 0.00052284, 0.00063317, 0.00051473, 0.00055562,\n",
            "       0.0004603 , 0.00044485, 0.00048301, 0.00061226, 0.00054974,\n",
            "       0.00043381, 0.00048794, 0.00041163, 0.00058963, 0.00044819,\n",
            "       0.00045668, 0.00043256, 0.00064447, 0.0005355 , 0.00045177,\n",
            "       0.00053787, 0.0004087 , 0.00088979, 0.00048819, 0.00048636,\n",
            "       0.00049108, 0.00042306, 0.00058183, 0.00036632, 0.00046571,\n",
            "       0.00044969, 0.00060262, 0.00022541, 0.00048985, 0.00053289,\n",
            "       0.00051807, 0.00045769, 0.00037372, 0.00044883, 0.00068699,\n",
            "       0.00045641, 0.00048196, 0.00043388, 0.0004518 , 0.00055611,\n",
            "       0.00045086, 0.00040315, 0.00034054, 0.0004062 , 0.00037219,\n",
            "       0.00053444, 0.00058368, 0.00029818, 0.00046669, 0.00049448,\n",
            "       0.00041699, 0.00049184, 0.00047869, 0.00024356, 0.00046786,\n",
            "       0.00057461, 0.00069843, 0.00048212, 0.00049099, 0.00051708,\n",
            "       0.00056812, 0.000434  , 0.00036598, 0.00062069, 0.0005336 ,\n",
            "       0.00069723, 0.00018024, 0.00048623, 0.0004325 , 0.0006146 ,\n",
            "       0.00042885, 0.00072978, 0.00053806, 0.00049209, 0.00042126,\n",
            "       0.00042367, 0.00064829, 0.00058249, 0.00046802, 0.00052725,\n",
            "       0.00018241, 0.00058816, 0.00049355, 0.00039259, 0.00064738,\n",
            "       0.00046737, 0.0005324 , 0.00054676, 0.00054602, 0.00053888,\n",
            "       0.00052707, 0.00075877, 0.00054941, 0.00043564, 0.00039573,\n",
            "       0.00049712, 0.00041012, 0.00018656, 0.00050232, 0.00048797,\n",
            "       0.00057598, 0.00045911, 0.00046072, 0.00045722, 0.00038998,\n",
            "       0.00056282, 0.00048753, 0.00051773, 0.00039842, 0.00045246,\n",
            "       0.00049857, 0.00058482, 0.00064049, 0.0005197 , 0.00052045,\n",
            "       0.000443  , 0.00065729, 0.00044161, 0.00051068, 0.00064727,\n",
            "       0.00053654, 0.0007008 , 0.00038686, 0.00047229, 0.00044892,\n",
            "       0.00045303, 0.00055341, 0.00049736, 0.00052793, 0.00042236,\n",
            "       0.00040541, 0.00021869, 0.00041397, 0.00053651, 0.00052408,\n",
            "       0.00076479, 0.00050233, 0.00056255, 0.0004392 , 0.00044321,\n",
            "       0.00048725, 0.00046397, 0.00065927, 0.00046773, 0.00045936,\n",
            "       0.00017273, 0.00035939, 0.00042719, 0.00053875, 0.00022339,\n",
            "       0.00051378, 0.00047273, 0.00043518, 0.00049135, 0.00063977,\n",
            "       0.00042182, 0.00041099, 0.00055711, 0.00052549, 0.00060615,\n",
            "       0.00047622, 0.00053332, 0.00043907, 0.00048273, 0.00047056,\n",
            "       0.00059769, 0.00045894, 0.00047086, 0.00061759, 0.00064132,\n",
            "       0.0004927 , 0.00045287, 0.00044912, 0.00060039, 0.00059631,\n",
            "       0.00056922, 0.00057087, 0.00046132, 0.00057578, 0.00052452,\n",
            "       0.00046819, 0.00055018, 0.00048804, 0.00051647, 0.00042413,\n",
            "       0.00067673, 0.00048247, 0.00040604, 0.00065402, 0.00037368,\n",
            "       0.00054329, 0.00044218, 0.00046845, 0.0004158 , 0.00050554,\n",
            "       0.000714  , 0.00044809, 0.00043387, 0.00039314, 0.00045516,\n",
            "       0.00041866, 0.00042529, 0.00050897, 0.00056528, 0.00046749,\n",
            "       0.00051446, 0.00041087, 0.00049648, 0.00051657, 0.00061256,\n",
            "       0.00047569, 0.00065185, 0.00050349, 0.00050244, 0.00039804,\n",
            "       0.00044192, 0.00040163, 0.000564  , 0.00056486, 0.00050102,\n",
            "       0.00049743, 0.00050702, 0.00037093, 0.00044973, 0.0003896 ,\n",
            "       0.00052749, 0.00050492, 0.00023841, 0.00078366, 0.0003747 ,\n",
            "       0.00053901, 0.00061898, 0.00052357, 0.00042634, 0.00059598,\n",
            "       0.00047528, 0.00059808, 0.00064333, 0.00045443, 0.00055305,\n",
            "       0.00047785, 0.00052109, 0.00042584, 0.00058231, 0.00050126,\n",
            "       0.00059115, 0.0003916 , 0.00044454, 0.00040987, 0.00046243,\n",
            "       0.00051617, 0.00056581, 0.00059108, 0.0005286 , 0.00040201,\n",
            "       0.00042254, 0.00064348, 0.00037518, 0.00045083, 0.00048094,\n",
            "       0.0004863 , 0.0005862 , 0.00055158, 0.00064214, 0.0005263 ,\n",
            "       0.00051137, 0.00054176, 0.00046143, 0.00056979, 0.0004411 ,\n",
            "       0.00038238, 0.00051097, 0.00049152, 0.00056796, 0.00048317,\n",
            "       0.00096997, 0.00049123, 0.00036173, 0.00047677, 0.00061544,\n",
            "       0.00055911, 0.00051152, 0.00042858, 0.00042537, 0.00049939,\n",
            "       0.00053041, 0.00045217, 0.00053666, 0.00030464, 0.00048078,\n",
            "       0.00061961, 0.00054483, 0.00048933, 0.00047037, 0.00041879,\n",
            "       0.00051467, 0.00044004, 0.0004305 , 0.00047803, 0.00054453,\n",
            "       0.00036874, 0.00038434, 0.0005734 , 0.00043756, 0.00044966,\n",
            "       0.00053742, 0.00056425, 0.00046289, 0.00048118, 0.00043921,\n",
            "       0.00045969, 0.0004523 , 0.00053035, 0.0004428 , 0.00057325],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/rezero/mul', 'index': 187, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.010637731291353703, -128), 'quantization_parameters': {'scales': array([0.01063773], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 188, 'shape': array([144], dtype=int32), 'shape_signature': array([144], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00024711, 0.00045566, 0.0003248 , 0.00040984, 0.00040704,\n",
            "       0.00028362, 0.00038033, 0.00024823, 0.00035554, 0.00031704,\n",
            "       0.00033589, 0.00037039, 0.00035455, 0.00051733, 0.00035275,\n",
            "       0.00037271, 0.00031315, 0.00051303, 0.00064042, 0.00026562,\n",
            "       0.00032036, 0.000286  , 0.00027016, 0.00025733, 0.00027588,\n",
            "       0.00032981, 0.00043487, 0.00032623, 0.00025503, 0.00042506,\n",
            "       0.0003267 , 0.00024968, 0.00044093, 0.00035707, 0.00056047,\n",
            "       0.00036467, 0.00032679, 0.00027083, 0.00041504, 0.00052449,\n",
            "       0.00054229, 0.00038532, 0.00053888, 0.00022972, 0.00051982,\n",
            "       0.0003406 , 0.00048241, 0.00033786, 0.00033996, 0.00032005,\n",
            "       0.00031368, 0.0002942 , 0.00026378, 0.00055314, 0.00035476,\n",
            "       0.00021851, 0.00037128, 0.00040322, 0.000418  , 0.00039226,\n",
            "       0.00041559, 0.00033809, 0.00028864, 0.00058091, 0.00047356,\n",
            "       0.00063275, 0.00043575, 0.00034166, 0.00049606, 0.00044915,\n",
            "       0.00031134, 0.00029081, 0.00046735, 0.00026456, 0.00054744,\n",
            "       0.00043964, 0.00050885, 0.00037367, 0.00033012, 0.00058227,\n",
            "       0.00049128, 0.00039904, 0.00033315, 0.00041823, 0.00037962,\n",
            "       0.00023921, 0.00034092, 0.00022   , 0.00026357, 0.00038683,\n",
            "       0.00039739, 0.00024932, 0.00038077, 0.00038802, 0.00033703,\n",
            "       0.00053659, 0.00034001, 0.00020088, 0.000351  , 0.00057357,\n",
            "       0.00026958, 0.00037238, 0.00036731, 0.00021075, 0.00041731,\n",
            "       0.00029016, 0.00030812, 0.00045623, 0.00039612, 0.00022906,\n",
            "       0.00038419, 0.00056162, 0.00030804, 0.00036963, 0.00031548,\n",
            "       0.00029125, 0.00038788, 0.00027454, 0.00029358, 0.00046464,\n",
            "       0.00050048, 0.00038708, 0.00026837, 0.00063544, 0.0002298 ,\n",
            "       0.00032293, 0.00037338, 0.00030527, 0.00042094, 0.00042048,\n",
            "       0.00050167, 0.00040932, 0.00025291, 0.00043829, 0.00034575,\n",
            "       0.00068159, 0.00049825, 0.00038089, 0.00056743, 0.00028283,\n",
            "       0.00041216, 0.00039737, 0.00050244, 0.00058363], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 189, 'shape': array([144,   1,   1, 576], dtype=int32), 'shape_signature': array([144,   1,   1, 576], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.0060769 , 0.01120538, 0.0079873 , 0.01007868, 0.01000981,\n",
            "       0.0069747 , 0.00935292, 0.00610444, 0.00874328, 0.00779644,\n",
            "       0.00826004, 0.00910839, 0.00871883, 0.01272197, 0.00867461,\n",
            "       0.00916544, 0.00770086, 0.01261617, 0.01574904, 0.00653196,\n",
            "       0.00787813, 0.00703326, 0.00664365, 0.00632822, 0.00678442,\n",
            "       0.00811056, 0.0106942 , 0.00802256, 0.00627152, 0.01045289,\n",
            "       0.008034  , 0.00614014, 0.01084313, 0.00878089, 0.01378282,\n",
            "       0.00896773, 0.00803634, 0.00666011, 0.01020643, 0.01289793,\n",
            "       0.01333586, 0.00947552, 0.01325196, 0.00564907, 0.0127832 ,\n",
            "       0.008376  , 0.01186309, 0.0083085 , 0.00836027, 0.0078705 ,\n",
            "       0.00771387, 0.00723476, 0.00648685, 0.01360264, 0.00872404,\n",
            "       0.00537352, 0.00913025, 0.0099159 , 0.01027917, 0.00964638,\n",
            "       0.0102201 , 0.00831428, 0.0070981 , 0.01428553, 0.0116455 ,\n",
            "       0.01556039, 0.0107158 , 0.00840192, 0.01219882, 0.01104538,\n",
            "       0.0076564 , 0.00715145, 0.01149284, 0.00650606, 0.01346253,\n",
            "       0.01081141, 0.0125135 , 0.00918925, 0.00811807, 0.01431897,\n",
            "       0.01208132, 0.009813  , 0.00819262, 0.01028483, 0.00933534,\n",
            "       0.00588261, 0.00838377, 0.00541014, 0.0064815 , 0.00951279,\n",
            "       0.00977232, 0.00613123, 0.00936371, 0.00954205, 0.00828815,\n",
            "       0.01319551, 0.00836147, 0.00494003, 0.00863165, 0.01410498,\n",
            "       0.00662949, 0.00915737, 0.00903273, 0.00518259, 0.01026221,\n",
            "       0.00713553, 0.00757724, 0.0112194 , 0.00974125, 0.00563297,\n",
            "       0.00944795, 0.01381108, 0.00757528, 0.00908982, 0.00775813,\n",
            "       0.00716225, 0.00953856, 0.00675138, 0.00721962, 0.0114262 ,\n",
            "       0.01230757, 0.00951884, 0.0065996 , 0.01562649, 0.00565106,\n",
            "       0.00794133, 0.00918189, 0.00750707, 0.01035152, 0.01034021,\n",
            "       0.01233688, 0.01006585, 0.00621947, 0.01077821, 0.00850254,\n",
            "       0.01676133, 0.0122527 , 0.00936668, 0.01395406, 0.00695522,\n",
            "       0.01013565, 0.00977194, 0.01235583, 0.01435239], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 190, 'shape': array([576], dtype=int32), 'shape_signature': array([576], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([5.54375947e-05, 4.03301019e-05, 5.36294501e-05, 4.02348924e-05,\n",
            "       5.95208185e-05, 2.17690322e-05, 4.00174722e-05, 3.29813593e-05,\n",
            "       4.07522202e-05, 4.32372799e-05, 1.73919962e-05, 4.34853464e-05,\n",
            "       4.20526339e-05, 1.13921760e-05, 4.49811014e-05, 6.30918512e-05,\n",
            "       1.86675079e-05, 6.02331165e-05, 5.26768745e-05, 2.56142193e-05,\n",
            "       8.40830689e-05, 4.09005843e-05, 3.06992479e-05, 4.08568594e-05,\n",
            "       2.46247691e-05, 3.48530411e-05, 5.11070830e-05, 4.90057064e-05,\n",
            "       5.54575818e-05, 1.58916682e-05, 5.20463800e-05, 2.73792193e-05,\n",
            "       1.45658560e-05, 4.24269492e-05, 4.52118329e-05, 3.90145797e-05,\n",
            "       2.79268515e-05, 4.93588632e-05, 3.70997186e-05, 3.41539744e-05,\n",
            "       3.98827106e-05, 5.56365667e-05, 4.28792409e-05, 2.17983052e-05,\n",
            "       1.03871222e-04, 4.29330466e-05, 4.21092045e-05, 4.62568678e-05,\n",
            "       3.49162619e-05, 1.13501510e-05, 4.21705590e-05, 4.55414192e-05,\n",
            "       4.19489370e-05, 4.08678279e-05, 2.73882833e-05, 3.55150733e-05,\n",
            "       3.99918463e-05, 4.96482171e-05, 6.29857896e-05, 5.05869066e-05,\n",
            "       4.38358074e-05, 3.98300544e-05, 4.11049477e-05, 5.81701424e-05,\n",
            "       2.10842809e-05, 4.00726713e-05, 1.92827192e-05, 1.37915980e-04,\n",
            "       5.46551419e-05, 8.53441816e-05, 6.07426409e-05, 4.12151821e-05,\n",
            "       1.10682058e-05, 5.59210457e-05, 4.46724334e-05, 1.47593337e-05,\n",
            "       7.36581424e-05, 3.60145787e-05, 4.53047869e-05, 4.67500431e-05,\n",
            "       3.15203761e-05, 4.36278206e-05, 3.99426426e-05, 3.83152437e-05,\n",
            "       3.04252899e-05, 1.00207777e-04, 5.82575376e-05, 3.76957069e-05,\n",
            "       3.96353062e-05, 5.21667280e-05, 4.50850530e-05, 4.35927832e-05,\n",
            "       4.29145948e-05, 2.15417876e-05, 4.69262886e-05, 4.82069081e-05,\n",
            "       2.38013272e-05, 3.37139936e-05, 4.42141209e-05, 3.63221443e-05,\n",
            "       4.57272945e-05, 3.54312178e-05, 3.34989745e-05, 2.18747537e-05,\n",
            "       4.31473054e-05, 1.16985604e-04, 4.11450528e-05, 1.94783152e-05,\n",
            "       5.10192694e-05, 2.81814209e-05, 7.20827738e-05, 4.84296834e-05,\n",
            "       3.91023277e-05, 4.18851196e-05, 3.63214858e-05, 3.78948243e-05,\n",
            "       2.46952259e-05, 5.12459555e-05, 4.53656539e-05, 1.43122970e-05,\n",
            "       3.93575574e-05, 3.14597419e-05, 3.82362196e-05, 4.18940581e-05,\n",
            "       1.59483461e-05, 3.66677414e-05, 4.40734875e-05, 4.56448033e-05,\n",
            "       1.64152079e-05, 5.05164098e-05, 4.65854355e-05, 4.53303437e-05,\n",
            "       3.94261588e-05, 5.25294345e-05, 1.06807725e-04, 4.32345914e-05,\n",
            "       3.76034477e-05, 1.42813897e-05, 4.63777178e-05, 1.53091914e-05,\n",
            "       5.18838206e-05, 1.91327781e-05, 5.04294112e-05, 2.52354803e-05,\n",
            "       5.62738605e-05, 4.14065689e-05, 2.37965087e-05, 3.13929158e-05,\n",
            "       4.19931093e-05, 4.40676376e-05, 5.11165454e-05, 3.70104972e-05,\n",
            "       4.44887264e-05, 3.84829473e-05, 1.07724200e-05, 5.00704373e-05,\n",
            "       1.67665476e-05, 3.59023215e-05, 4.12539957e-05, 4.34578324e-05,\n",
            "       1.22825833e-04, 3.49318034e-05, 3.00334705e-05, 4.81189163e-05,\n",
            "       4.76743262e-05, 1.35524378e-05, 4.10565808e-05, 2.69143111e-05,\n",
            "       4.51427441e-05, 1.13303659e-05, 2.45051015e-05, 1.22655620e-04,\n",
            "       1.26437335e-05, 4.64018740e-05, 5.08910634e-05, 4.53870525e-05,\n",
            "       1.99267488e-05, 1.18974776e-05, 1.12045636e-04, 5.66994095e-05,\n",
            "       4.14442329e-05, 2.75521397e-05, 1.39072465e-04, 3.54979893e-05,\n",
            "       3.79261946e-05, 6.21695144e-05, 5.53339669e-05, 4.77526446e-05,\n",
            "       2.92407458e-05, 3.88958470e-05, 3.67443681e-05, 3.82946782e-05,\n",
            "       3.12582997e-05, 4.71949170e-05, 3.76732423e-05, 3.55866468e-05,\n",
            "       4.64300538e-05, 4.92107902e-05, 4.02106234e-05, 4.84036609e-05,\n",
            "       3.17495324e-05, 5.46005140e-05, 3.79622434e-05, 1.33808398e-05,\n",
            "       4.13892376e-05, 4.21048535e-05, 3.49012371e-05, 5.14976819e-05,\n",
            "       4.24923783e-05, 3.36509875e-05, 6.11699725e-05, 4.03077574e-05,\n",
            "       1.13420574e-04, 4.15968170e-05, 4.26396655e-05, 4.66062156e-05,\n",
            "       2.32070342e-05, 4.06741710e-05, 7.18092815e-06, 2.24340110e-05,\n",
            "       9.76208867e-06, 1.35096343e-05, 3.79007470e-05, 1.00414609e-05,\n",
            "       3.62109058e-05, 4.41316588e-05, 5.22134433e-05, 5.08590820e-05,\n",
            "       4.18992131e-05, 2.47110183e-05, 3.28249735e-05, 4.39220858e-05,\n",
            "       4.94620908e-05, 3.75526070e-05, 6.00563762e-05, 2.37840795e-05,\n",
            "       1.33369176e-05, 6.93682887e-05, 2.96899161e-05, 1.89338571e-05,\n",
            "       4.60248521e-05, 3.17531922e-05, 5.62041969e-05, 8.90443698e-06,\n",
            "       5.10073041e-05, 4.79388000e-05, 2.70553228e-05, 5.56953164e-05,\n",
            "       6.49531721e-05, 4.37758645e-05, 4.78771180e-05, 2.40161025e-05,\n",
            "       4.45813894e-05, 3.15280304e-05, 4.21303266e-05, 4.93393309e-05,\n",
            "       3.66150343e-05, 7.19615273e-05, 4.11712317e-05, 3.70042690e-05,\n",
            "       3.36156590e-05, 4.70039595e-05, 1.22057090e-05, 3.21129119e-05,\n",
            "       4.27844279e-05, 1.83179072e-05, 6.98260483e-05, 4.38160059e-05,\n",
            "       3.16297228e-05, 3.70248017e-05, 2.96575090e-05, 5.11648213e-05,\n",
            "       3.82749677e-05, 3.46365850e-05, 4.88580372e-05, 5.53512400e-05,\n",
            "       4.13097296e-05, 3.26585177e-05, 4.89629492e-05, 4.58317627e-05,\n",
            "       5.25618125e-05, 3.58164580e-05, 5.05859971e-05, 6.47660272e-05,\n",
            "       2.72673842e-05, 3.95667994e-05, 4.17889496e-05, 4.60309057e-05,\n",
            "       4.46711019e-05, 3.37741294e-05, 1.76433205e-05, 1.43041425e-05,\n",
            "       1.42376603e-05, 1.49487796e-05, 4.91123574e-05, 1.36094150e-05,\n",
            "       9.79837569e-05, 3.62960418e-05, 2.09134741e-05, 3.06388938e-05,\n",
            "       5.38734785e-05, 1.61403150e-05, 2.14872525e-05, 4.06011677e-05,\n",
            "       4.29995853e-05, 5.34692736e-05, 1.41457758e-05, 1.60819927e-05,\n",
            "       1.47400069e-05, 5.05343487e-05, 3.47680216e-05, 4.06443505e-05,\n",
            "       1.34945312e-05, 4.58785762e-05, 4.32070265e-05, 4.86988138e-05,\n",
            "       3.95941752e-05, 4.46606609e-05, 1.48739591e-05, 3.49773327e-05,\n",
            "       4.35710608e-05, 6.96307834e-05, 5.05681201e-05, 5.17946464e-05,\n",
            "       2.16438584e-05, 3.96546384e-05, 4.52790082e-05, 6.82919272e-05,\n",
            "       4.80629242e-05, 1.28410429e-05, 1.13187398e-05, 4.78793227e-05,\n",
            "       3.51225426e-05, 1.28125703e-05, 3.57521239e-05, 1.09250195e-05,\n",
            "       5.35061372e-05, 2.81024058e-05, 3.45020126e-05, 4.56778762e-05,\n",
            "       3.59040423e-05, 4.62985190e-05, 3.36604207e-05, 8.76931663e-05,\n",
            "       1.73961875e-04, 1.24618264e-05, 4.86875215e-05, 3.81782302e-05,\n",
            "       7.63907592e-05, 1.84977780e-05, 1.58235562e-05, 3.34693141e-05,\n",
            "       3.96566211e-05, 1.24516955e-05, 1.67636990e-05, 4.45616206e-05,\n",
            "       1.35429955e-05, 1.39762742e-05, 1.74645884e-05, 5.83812507e-05,\n",
            "       3.05477588e-05, 4.04706334e-05, 3.95466450e-05, 5.42798698e-05,\n",
            "       4.51867600e-05, 3.95116222e-05, 2.05150955e-05, 1.12106900e-05,\n",
            "       3.52342649e-05, 3.38534883e-05, 4.18841264e-05, 4.70761697e-05,\n",
            "       3.35349032e-05, 3.88821718e-05, 5.40080182e-05, 5.59082328e-05,\n",
            "       4.04828897e-05, 5.61423767e-05, 5.73166690e-05, 2.17255383e-05,\n",
            "       5.63623544e-05, 3.13876262e-05, 5.93780132e-05, 1.39274889e-05,\n",
            "       3.48023059e-05, 4.18517884e-05, 1.52436387e-05, 5.14454950e-05,\n",
            "       1.96261917e-05, 1.40677512e-05, 4.74508270e-05, 3.30728726e-05,\n",
            "       3.59997830e-05, 2.68540134e-05, 1.20487130e-05, 3.75380732e-05,\n",
            "       4.00980935e-05, 4.05930441e-05, 4.66065467e-05, 1.44000451e-05,\n",
            "       1.50840078e-05, 1.87532169e-05, 4.35915135e-05, 4.24192331e-05,\n",
            "       5.85203125e-05, 2.62790400e-05, 2.06047753e-05, 9.46711807e-05,\n",
            "       3.67191715e-05, 2.34877862e-05, 2.62901704e-05, 5.52679012e-05,\n",
            "       5.72854842e-05, 1.35208238e-05, 4.12594163e-05, 4.16747098e-05,\n",
            "       4.60656374e-05, 4.60289812e-05, 5.72083736e-05, 4.84599150e-05,\n",
            "       6.15203753e-05, 6.86299536e-05, 4.72701031e-05, 4.44428333e-05,\n",
            "       1.39167532e-05, 4.08745764e-05, 4.35554648e-05, 4.44314101e-05,\n",
            "       5.27358607e-05, 1.86038233e-05, 4.17327610e-05, 6.98068980e-05,\n",
            "       8.70057775e-05, 1.69376053e-05, 5.26893309e-05, 4.14665810e-05,\n",
            "       4.81857533e-05, 2.83411737e-05, 5.08328303e-05, 1.15117309e-05,\n",
            "       4.65863450e-05, 4.32722518e-05, 4.29412466e-05, 1.23914660e-05,\n",
            "       9.79132819e-05, 3.50693190e-05, 4.32390698e-05, 5.38179447e-05,\n",
            "       4.09990753e-05, 3.89588640e-05, 3.74013980e-05, 3.76916250e-05,\n",
            "       4.15297000e-05, 1.80708466e-05, 4.57650676e-05, 4.61481395e-05,\n",
            "       3.24365210e-05, 4.51492051e-05, 2.22117360e-05, 1.39452459e-05,\n",
            "       1.59786141e-05, 4.16575858e-05, 3.95893403e-05, 4.71113271e-05,\n",
            "       3.04777695e-05, 4.67379286e-05, 2.82900019e-05, 2.36853375e-05,\n",
            "       4.27872983e-05, 4.31208173e-05, 3.86404427e-05, 4.21418517e-05,\n",
            "       1.44784644e-05, 3.21224834e-05, 1.42500139e-05, 3.35929035e-05,\n",
            "       5.61639499e-05, 8.17309992e-05, 1.78863629e-05, 5.73702091e-05,\n",
            "       4.88041260e-05, 1.47337079e-04, 1.58104012e-05, 1.57181916e-04,\n",
            "       1.87379792e-05, 4.01372927e-05, 4.12446789e-05, 3.94930976e-05,\n",
            "       4.08788692e-05, 3.35977857e-05, 2.46824493e-05, 3.16929800e-05,\n",
            "       4.51576198e-05, 3.99169548e-05, 3.70923553e-05, 3.91414942e-05,\n",
            "       6.74312978e-05, 3.71732312e-05, 7.35190770e-05, 6.42332816e-05,\n",
            "       8.36153413e-05, 7.65268778e-05, 3.87866021e-05, 2.59756198e-05,\n",
            "       5.78142244e-05, 4.30309810e-05, 2.24978921e-05, 9.37950026e-05,\n",
            "       3.95732532e-05, 4.84418488e-05, 3.15314428e-05, 1.30558241e-04,\n",
            "       1.57075956e-05, 4.28515232e-05, 4.98913687e-05, 3.74824631e-05,\n",
            "       3.09072711e-05, 4.39545693e-05, 4.04879429e-05, 4.23672464e-05,\n",
            "       4.08319247e-05, 3.98997145e-05, 3.00664069e-05, 4.20236720e-05,\n",
            "       4.97083420e-05, 2.48712968e-05, 4.58146860e-05, 3.92644797e-05,\n",
            "       4.44271427e-05, 4.08274063e-05, 5.22746523e-05, 3.78965669e-05,\n",
            "       3.63803229e-05, 3.85175663e-05, 6.33521922e-05, 4.49613290e-05,\n",
            "       4.84108714e-05, 3.96823634e-05, 3.88805965e-05, 4.55633890e-05,\n",
            "       3.18665916e-05, 3.29793875e-05, 3.84747036e-05, 5.16998880e-05,\n",
            "       2.22415947e-05, 3.00925149e-05, 3.80270576e-05, 4.78754664e-05,\n",
            "       1.01371341e-04, 4.55181398e-05, 3.82530925e-05, 6.39298378e-05,\n",
            "       7.40545220e-05, 4.28640524e-05, 3.32020245e-05, 1.33571220e-05,\n",
            "       3.99953860e-05, 6.87851352e-05, 8.62235320e-05, 3.37927631e-05,\n",
            "       4.01048164e-05, 6.28837297e-05, 1.04322957e-04, 2.20519978e-05,\n",
            "       4.12863665e-05, 3.95995594e-05, 5.68829091e-05, 4.03421400e-05,\n",
            "       1.23939390e-05, 1.87886635e-05, 8.49660573e-05, 3.20083273e-05,\n",
            "       5.03705523e-05, 9.30521037e-06, 4.57738497e-05, 4.84913471e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 191, 'shape': array([576,   1,   1, 288], dtype=int32), 'shape_signature': array([576,   1,   1, 288], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00159805, 0.00116256, 0.00154593, 0.00115982, 0.00171575,\n",
            "       0.00062752, 0.00115355, 0.00095072, 0.00117473, 0.00124636,\n",
            "       0.00050134, 0.00125351, 0.00121221, 0.00032839, 0.00129663,\n",
            "       0.00181869, 0.00053811, 0.00173629, 0.00151847, 0.00073836,\n",
            "       0.00242379, 0.00117901, 0.00088494, 0.00117774, 0.00070984,\n",
            "       0.00100468, 0.00147322, 0.00141264, 0.00159863, 0.0004581 ,\n",
            "       0.0015003 , 0.00078924, 0.00041988, 0.001223  , 0.00130328,\n",
            "       0.00112464, 0.00080502, 0.00142282, 0.00106944, 0.00098453,\n",
            "       0.00114966, 0.00160379, 0.00123604, 0.00062836, 0.0029942 ,\n",
            "       0.00123759, 0.00121385, 0.00133341, 0.0010065 , 0.00032718,\n",
            "       0.00121561, 0.00131278, 0.00120923, 0.00117806, 0.0007895 ,\n",
            "       0.00102376, 0.00115281, 0.00143117, 0.00181564, 0.00145822,\n",
            "       0.00126362, 0.00114815, 0.0011849 , 0.00167682, 0.00060778,\n",
            "       0.00115514, 0.00055585, 0.00397558, 0.0015755 , 0.00246014,\n",
            "       0.00175097, 0.00118807, 0.00031905, 0.00161199, 0.00128773,\n",
            "       0.00042545, 0.00212328, 0.00103816, 0.00130596, 0.00134762,\n",
            "       0.00090861, 0.00125762, 0.00115139, 0.00110448, 0.00087704,\n",
            "       0.0028886 , 0.00167934, 0.00108662, 0.00114253, 0.00150376,\n",
            "       0.00129963, 0.00125661, 0.00123706, 0.00062097, 0.0013527 ,\n",
            "       0.00138962, 0.0006861 , 0.00097184, 0.00127452, 0.00104703,\n",
            "       0.00131814, 0.00102134, 0.00096565, 0.00063056, 0.00124377,\n",
            "       0.00337224, 0.00118605, 0.00056148, 0.00147069, 0.00081236,\n",
            "       0.00207787, 0.00139604, 0.00112717, 0.00120739, 0.00104701,\n",
            "       0.00109236, 0.00071187, 0.00147722, 0.00130772, 0.00041257,\n",
            "       0.00113453, 0.00090686, 0.0011022 , 0.00120764, 0.00045973,\n",
            "       0.00105699, 0.00127047, 0.00131576, 0.00047319, 0.00145619,\n",
            "       0.00134288, 0.0013067 , 0.0011365 , 0.00151422, 0.00307885,\n",
            "       0.00124629, 0.00108396, 0.00041168, 0.00133689, 0.0004413 ,\n",
            "       0.00149561, 0.00055152, 0.00145368, 0.00072744, 0.00162216,\n",
            "       0.00119359, 0.00068596, 0.00090494, 0.0012105 , 0.0012703 ,\n",
            "       0.00147349, 0.00106687, 0.00128244, 0.00110931, 0.00031053,\n",
            "       0.00144334, 0.00048331, 0.00103492, 0.00118919, 0.00125272,\n",
            "       0.00354059, 0.00100695, 0.00086575, 0.00138708, 0.00137427,\n",
            "       0.00039066, 0.0011835 , 0.00077584, 0.00130129, 0.00032661,\n",
            "       0.00070639, 0.00353569, 0.00036447, 0.00133759, 0.00146699,\n",
            "       0.00130833, 0.00057441, 0.00034296, 0.00322984, 0.00163442,\n",
            "       0.00119468, 0.00079422, 0.00400892, 0.00102327, 0.00109327,\n",
            "       0.00179211, 0.00159506, 0.00137652, 0.0008429 , 0.00112122,\n",
            "       0.0010592 , 0.00110389, 0.00090106, 0.00136045, 0.00108597,\n",
            "       0.00102583, 0.0013384 , 0.00141856, 0.00115912, 0.00139529,\n",
            "       0.00091522, 0.00157392, 0.0010943 , 0.00038572, 0.00119309,\n",
            "       0.00121372, 0.00100607, 0.00148448, 0.00122489, 0.00097003,\n",
            "       0.00176329, 0.00116192, 0.00326948, 0.00119907, 0.00122914,\n",
            "       0.00134348, 0.00066897, 0.00117248, 0.000207  , 0.00064669,\n",
            "       0.0002814 , 0.00038943, 0.00109253, 0.00028946, 0.00104382,\n",
            "       0.00127214, 0.00150511, 0.00146607, 0.00120779, 0.00071232,\n",
            "       0.00094622, 0.0012661 , 0.0014258 , 0.0010825 , 0.00173119,\n",
            "       0.0006856 , 0.00038445, 0.00199962, 0.00085585, 0.00054579,\n",
            "       0.00132672, 0.00091532, 0.00162015, 0.00025668, 0.00147034,\n",
            "       0.00138189, 0.0007799 , 0.00160548, 0.00187235, 0.00126189,\n",
            "       0.00138011, 0.00069229, 0.00128511, 0.00090883, 0.00121445,\n",
            "       0.00142226, 0.00105547, 0.00207437, 0.00118681, 0.00106669,\n",
            "       0.00096901, 0.00135494, 0.00035184, 0.00092569, 0.00123331,\n",
            "       0.00052803, 0.00201281, 0.00126305, 0.00091176, 0.00106728,\n",
            "       0.00085491, 0.00147488, 0.00110332, 0.00099844, 0.00140839,\n",
            "       0.00159556, 0.0011908 , 0.00094142, 0.00141141, 0.00132115,\n",
            "       0.00151515, 0.00103245, 0.0014582 , 0.00186695, 0.00078601,\n",
            "       0.00114056, 0.00120461, 0.00132689, 0.00128769, 0.00097358,\n",
            "       0.00050859, 0.00041233, 0.00041042, 0.00043092, 0.00141572,\n",
            "       0.00039231, 0.00282449, 0.00104627, 0.00060285, 0.0008832 ,\n",
            "       0.00155296, 0.00046526, 0.00061939, 0.00117037, 0.00123951,\n",
            "       0.00154131, 0.00040777, 0.00046358, 0.0004249 , 0.00145671,\n",
            "       0.00100223, 0.00117162, 0.000389  , 0.0013225 , 0.00124549,\n",
            "       0.0014038 , 0.00114135, 0.00128739, 0.00042876, 0.00100826,\n",
            "       0.00125598, 0.00200719, 0.00145768, 0.00149304, 0.00062391,\n",
            "       0.00114309, 0.00130522, 0.00196859, 0.00138547, 0.00037016,\n",
            "       0.00032628, 0.00138018, 0.00101245, 0.00036934, 0.0010306 ,\n",
            "       0.00031493, 0.00154237, 0.00081008, 0.00099456, 0.00131672,\n",
            "       0.00103497, 0.00133461, 0.0009703 , 0.00252785, 0.00501465,\n",
            "       0.00035923, 0.00140347, 0.00110053, 0.00220205, 0.00053322,\n",
            "       0.00045613, 0.00096479, 0.00114315, 0.00035893, 0.00048323,\n",
            "       0.00128454, 0.00039039, 0.00040288, 0.00050344, 0.00168291,\n",
            "       0.00088057, 0.00116661, 0.00113998, 0.00156468, 0.00130256,\n",
            "       0.00113897, 0.00059137, 0.00032316, 0.00101567, 0.00097586,\n",
            "       0.00120736, 0.00135702, 0.00096668, 0.00112082, 0.00155684,\n",
            "       0.00161162, 0.00116696, 0.00161837, 0.00165222, 0.00062626,\n",
            "       0.00162471, 0.00090478, 0.00171164, 0.00040148, 0.00100322,\n",
            "       0.00120642, 0.00043941, 0.00148297, 0.00056575, 0.00040552,\n",
            "       0.00136782, 0.00095336, 0.00103773, 0.0007741 , 0.00034732,\n",
            "       0.00108208, 0.00115587, 0.00117014, 0.00134349, 0.0004151 ,\n",
            "       0.00043481, 0.00054058, 0.00125657, 0.00122278, 0.00168691,\n",
            "       0.00075752, 0.00059396, 0.002729  , 0.00105847, 0.00067706,\n",
            "       0.00075784, 0.00159316, 0.00165132, 0.00038975, 0.00118935,\n",
            "       0.00120132, 0.00132789, 0.00132684, 0.0016491 , 0.00139691,\n",
            "       0.00177339, 0.00197834, 0.00136261, 0.00128111, 0.00040117,\n",
            "       0.00117826, 0.00125554, 0.00128079, 0.00152017, 0.00053628,\n",
            "       0.00120299, 0.00201226, 0.00250804, 0.00048825, 0.00151883,\n",
            "       0.00119532, 0.00138901, 0.00081697, 0.00146531, 0.00033184,\n",
            "       0.0013429 , 0.00124737, 0.00123783, 0.0003572 , 0.00282246,\n",
            "       0.00101091, 0.00124641, 0.00155136, 0.00118184, 0.00112303,\n",
            "       0.00107814, 0.0010865 , 0.00119714, 0.00052091, 0.00131923,\n",
            "       0.00133027, 0.00093502, 0.00130148, 0.00064028, 0.00040199,\n",
            "       0.0004606 , 0.00120083, 0.00114121, 0.00135804, 0.00087856,\n",
            "       0.00134727, 0.00081549, 0.00068276, 0.00123339, 0.00124301,\n",
            "       0.00111385, 0.00121479, 0.00041736, 0.00092597, 0.00041077,\n",
            "       0.00096835, 0.00161899, 0.00235599, 0.00051559, 0.00165376,\n",
            "       0.00140683, 0.00424716, 0.00045575, 0.00453095, 0.00054014,\n",
            "       0.001157  , 0.00118892, 0.00113843, 0.00117838, 0.00096849,\n",
            "       0.0007115 , 0.00091359, 0.00130172, 0.00115065, 0.00106923,\n",
            "       0.0011283 , 0.00194378, 0.00107156, 0.00211927, 0.0018516 ,\n",
            "       0.00241031, 0.00220597, 0.00111807, 0.00074878, 0.00166656,\n",
            "       0.00124042, 0.00064853, 0.00270375, 0.00114074, 0.00139639,\n",
            "       0.00090893, 0.00376349, 0.00045279, 0.00123524, 0.00143817,\n",
            "       0.00108047, 0.00089094, 0.00126704, 0.00116711, 0.00122128,\n",
            "       0.00117703, 0.00115015, 0.0008667 , 0.00121138, 0.0014329 ,\n",
            "       0.00071694, 0.00132066, 0.00113184, 0.00128066, 0.0011769 ,\n",
            "       0.00150688, 0.00109241, 0.0010487 , 0.00111031, 0.0018262 ,\n",
            "       0.00129606, 0.0013955 , 0.00114389, 0.00112078, 0.00131342,\n",
            "       0.00091859, 0.00095067, 0.00110908, 0.00149031, 0.00064114,\n",
            "       0.00086745, 0.00109617, 0.00138006, 0.00292214, 0.00131211,\n",
            "       0.00110269, 0.00184285, 0.0021347 , 0.0012356 , 0.00095709,\n",
            "       0.00038503, 0.00115291, 0.00198281, 0.00248549, 0.00097411,\n",
            "       0.00115607, 0.00181269, 0.00300723, 0.00063567, 0.00119013,\n",
            "       0.0011415 , 0.00163971, 0.00116291, 0.00035727, 0.0005416 ,\n",
            "       0.00244924, 0.00092268, 0.00145199, 0.00026823, 0.00131948,\n",
            "       0.00139782], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 192, 'shape': array([288], dtype=int32), 'shape_signature': array([288], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00043709, 0.00042883, 0.00014433, 0.00067224, 0.00035453,\n",
            "       0.00038956, 0.00023249, 0.00051758, 0.00023769, 0.00074076,\n",
            "       0.00047522, 0.00024097, 0.00063447, 0.00025284, 0.00040492,\n",
            "       0.00036513, 0.00029605, 0.00051697, 0.000303  , 0.00037806,\n",
            "       0.00049669, 0.00030976, 0.00041463, 0.00051158, 0.00038534,\n",
            "       0.00042835, 0.00037424, 0.00071887, 0.00040784, 0.00032293,\n",
            "       0.0003435 , 0.00047036, 0.0003275 , 0.00037289, 0.0006248 ,\n",
            "       0.00042944, 0.0003943 , 0.00031194, 0.00097443, 0.0001661 ,\n",
            "       0.00024159, 0.00047945, 0.0002636 , 0.00018116, 0.00027019,\n",
            "       0.0003109 , 0.00041443, 0.00053209, 0.00037969, 0.00058717,\n",
            "       0.00069178, 0.00053577, 0.00028954, 0.00032701, 0.00060785,\n",
            "       0.00037344, 0.00053301, 0.00043022, 0.00071903, 0.00052434,\n",
            "       0.00016905, 0.00024077, 0.00287489, 0.00020385, 0.00024044,\n",
            "       0.00048236, 0.00027387, 0.00033076, 0.00036905, 0.0004559 ,\n",
            "       0.00022739, 0.00029889, 0.00051481, 0.00048969, 0.00036238,\n",
            "       0.00023622, 0.000408  , 0.00035461, 0.00040509, 0.00030244,\n",
            "       0.0002999 , 0.0004754 , 0.00031113, 0.00018443, 0.00028674,\n",
            "       0.00031246, 0.00048114, 0.00026794, 0.00046059, 0.0002598 ,\n",
            "       0.00048512, 0.00094566, 0.0002269 , 0.00027854, 0.00042438,\n",
            "       0.00036013, 0.00080519, 0.00063628, 0.00047823, 0.00032477,\n",
            "       0.00041426, 0.00135564, 0.00047396, 0.00034308, 0.00048268,\n",
            "       0.00039662, 0.0003451 , 0.00066336, 0.00041735, 0.00033526,\n",
            "       0.0002967 , 0.00029428, 0.00079192, 0.00040234, 0.00054822,\n",
            "       0.0004092 , 0.00053593, 0.00029822, 0.00054651, 0.00025255,\n",
            "       0.00041894, 0.00037557, 0.00036433, 0.00054399, 0.00049928,\n",
            "       0.00042793, 0.00035674, 0.00042546, 0.00041302, 0.00042129,\n",
            "       0.00038961, 0.00038255, 0.00032518, 0.00030161, 0.00035263,\n",
            "       0.0004188 , 0.00071703, 0.00040951, 0.00042791, 0.00046213,\n",
            "       0.00045025, 0.00032035, 0.00052105, 0.00032516, 0.00032947,\n",
            "       0.00090224, 0.00038948, 0.00026986, 0.00045627, 0.00063969,\n",
            "       0.00026697, 0.00046473, 0.00037276, 0.00028169, 0.00044251,\n",
            "       0.00036426, 0.00086379, 0.00036555, 0.00048423, 0.00031967,\n",
            "       0.00025832, 0.00051484, 0.00029747, 0.00067314, 0.00027002,\n",
            "       0.00040732, 0.0006263 , 0.00050972, 0.00032296, 0.00026582,\n",
            "       0.00025253, 0.00034906, 0.00032141, 0.00042617, 0.00037618,\n",
            "       0.00024873, 0.00039933, 0.00031086, 0.00045364, 0.00020399,\n",
            "       0.00031105, 0.00026424, 0.00031659, 0.00055696, 0.00030333,\n",
            "       0.00039363, 0.00044848, 0.00027503, 0.00046009, 0.0003267 ,\n",
            "       0.00058453, 0.0002127 , 0.0003046 , 0.00051232, 0.00040224,\n",
            "       0.0002481 , 0.00056193, 0.00032004, 0.00043099, 0.0005007 ,\n",
            "       0.00034446, 0.00025975, 0.00032143, 0.00054515, 0.00040075,\n",
            "       0.00023623, 0.00044439, 0.00037968, 0.00025344, 0.00039264,\n",
            "       0.000245  , 0.00036853, 0.000273  , 0.00074211, 0.00026192,\n",
            "       0.0001493 , 0.00034234, 0.00044909, 0.00077036, 0.00028204,\n",
            "       0.00041842, 0.00049644, 0.00032085, 0.00066169, 0.00027109,\n",
            "       0.00041095, 0.00031745, 0.00080864, 0.00048232, 0.00052439,\n",
            "       0.00035502, 0.00015798, 0.00038408, 0.00036075, 0.00028259,\n",
            "       0.00053738, 0.00031101, 0.00046911, 0.00025525, 0.00047084,\n",
            "       0.00031824, 0.00029392, 0.00032933, 0.00027205, 0.00042382,\n",
            "       0.00051134, 0.00053993, 0.00033834, 0.00045971, 0.00041548,\n",
            "       0.00025287, 0.00026015, 0.00032289, 0.00049964, 0.00024012,\n",
            "       0.00032053, 0.00041869, 0.00027572, 0.00034628, 0.00035315,\n",
            "       0.00051366, 0.00049245, 0.00043932, 0.00039348, 0.00044255,\n",
            "       0.00027844, 0.00086005, 0.00035411, 0.00041353, 0.00058726,\n",
            "       0.00067001, 0.00028552, 0.00026223, 0.00032076, 0.00066789,\n",
            "       0.00041305, 0.00029479, 0.00046135, 0.00059405, 0.00051443,\n",
            "       0.00028474, 0.00093765, 0.00020555, 0.0002989 , 0.00053341,\n",
            "       0.00059064, 0.00033349, 0.00025844], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 193, 'shape': array([ 288,    1,    1, 1152], dtype=int32), 'shape_signature': array([ 288,    1,    1, 1152], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.0020638 , 0.00202481, 0.00068149, 0.00317409, 0.00167395,\n",
            "       0.00183936, 0.00109775, 0.00244387, 0.00112229, 0.00349762,\n",
            "       0.00224382, 0.00113777, 0.00299575, 0.00119382, 0.00191192,\n",
            "       0.00172402, 0.00139787, 0.00244096, 0.00143067, 0.00178508,\n",
            "       0.0023452 , 0.00146257, 0.00195774, 0.00241553, 0.00181947,\n",
            "       0.00202255, 0.00176704, 0.00339426, 0.0019257 , 0.00152476,\n",
            "       0.0016219 , 0.00222088, 0.00154636, 0.00176067, 0.00295012,\n",
            "       0.00202767, 0.00186176, 0.00147288, 0.00460095, 0.00078427,\n",
            "       0.00114072, 0.00226383, 0.00124465, 0.00085538, 0.00127577,\n",
            "       0.00146797, 0.00195679, 0.00251237, 0.00179276, 0.00277245,\n",
            "       0.00326636, 0.00252971, 0.00136711, 0.00154401, 0.00287008,\n",
            "       0.00176325, 0.00251672, 0.00203136, 0.00339503, 0.00247579,\n",
            "       0.00079818, 0.00113685, 0.01357432, 0.00096252, 0.00113528,\n",
            "       0.00227757, 0.00129314, 0.00156175, 0.00174254, 0.00215259,\n",
            "       0.00107365, 0.00141125, 0.00243076, 0.00231216, 0.00171102,\n",
            "       0.00111535, 0.00192646, 0.00167436, 0.0019127 , 0.00142802,\n",
            "       0.00141603, 0.0022447 , 0.00146907, 0.00087082, 0.00135389,\n",
            "       0.00147534, 0.00227177, 0.00126512, 0.00217474, 0.0012267 ,\n",
            "       0.00229059, 0.0044651 , 0.00107133, 0.0013152 , 0.00200379,\n",
            "       0.00170041, 0.00380184, 0.00300429, 0.00225803, 0.00153346,\n",
            "       0.001956  , 0.00640088, 0.00223787, 0.0016199 , 0.00227908,\n",
            "       0.0018727 , 0.00162945, 0.00313217, 0.00197059, 0.00158301,\n",
            "       0.0014009 , 0.00138951, 0.00373919, 0.00189973, 0.00258851,\n",
            "       0.0019321 , 0.00253048, 0.0014081 , 0.00258043, 0.00119246,\n",
            "       0.00197809, 0.00177333, 0.00172024, 0.00256854, 0.00235743,\n",
            "       0.00202053, 0.00168442, 0.00200889, 0.00195013, 0.00198917,\n",
            "       0.00183963, 0.00180626, 0.00153538, 0.00142408, 0.00166502,\n",
            "       0.00197743, 0.00338557, 0.00193357, 0.00202045, 0.00218204,\n",
            "       0.00212591, 0.00151258, 0.00246025, 0.00153531, 0.00155564,\n",
            "       0.00426008, 0.001839  , 0.00127421, 0.00215438, 0.00302041,\n",
            "       0.00126055, 0.00219429, 0.00176004, 0.00133003, 0.00208937,\n",
            "       0.00171992, 0.00407855, 0.001726  , 0.0022864 , 0.00150938,\n",
            "       0.00121973, 0.00243088, 0.00140456, 0.00317834, 0.00127495,\n",
            "       0.00192324, 0.00295721, 0.00240674, 0.00152491, 0.00125511,\n",
            "       0.00119236, 0.00164814, 0.0015176 , 0.00201222, 0.00177622,\n",
            "       0.00117443, 0.00188549, 0.00146777, 0.00214195, 0.0009632 ,\n",
            "       0.00146868, 0.00124767, 0.00149482, 0.00262979, 0.00143224,\n",
            "       0.00185858, 0.00211758, 0.0012986 , 0.00217238, 0.00154258,\n",
            "       0.00275996, 0.00100431, 0.00143823, 0.002419  , 0.00189924,\n",
            "       0.00117143, 0.00265325, 0.00151112, 0.00203498, 0.00236414,\n",
            "       0.00162641, 0.00122646, 0.00151767, 0.00257402, 0.0018922 ,\n",
            "       0.0011154 , 0.00209827, 0.00179274, 0.00119664, 0.00185393,\n",
            "       0.00115682, 0.00174009, 0.00128902, 0.00350402, 0.00123668,\n",
            "       0.00070495, 0.0016164 , 0.00212045, 0.00363741, 0.00133172,\n",
            "       0.00197566, 0.00234401, 0.00151495, 0.00312426, 0.00128   ,\n",
            "       0.00194039, 0.00149892, 0.00381814, 0.00227737, 0.002476  ,\n",
            "       0.00167628, 0.00074591, 0.00181348, 0.00170333, 0.0013343 ,\n",
            "       0.00253732, 0.00146849, 0.00221498, 0.0012052 , 0.00222314,\n",
            "       0.00150261, 0.0013878 , 0.001555  , 0.00128454, 0.00200115,\n",
            "       0.00241439, 0.0025494 , 0.00159751, 0.00217059, 0.00196178,\n",
            "       0.00119398, 0.00122835, 0.00152457, 0.00235914, 0.00113378,\n",
            "       0.00151343, 0.0019769 , 0.00130187, 0.00163504, 0.00166747,\n",
            "       0.00242535, 0.00232517, 0.00207432, 0.00185787, 0.00208957,\n",
            "       0.0013147 , 0.00406087, 0.001672  , 0.00195257, 0.00277284,\n",
            "       0.00316356, 0.00134815, 0.00123814, 0.00151452, 0.00315355,\n",
            "       0.00195028, 0.00139188, 0.00217835, 0.00280491, 0.00242895,\n",
            "       0.00134446, 0.00442727, 0.00097053, 0.00141131, 0.00251858,\n",
            "       0.00278882, 0.00157465, 0.00122026], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 194, 'shape': array([576], dtype=int32), 'shape_signature': array([576], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00114622, 0.0013251 , 0.00058233, 0.00122927, 0.00157985,\n",
            "       0.0019827 , 0.00088977, 0.00108636, 0.0017142 , 0.00072101,\n",
            "       0.000345  , 0.00114927, 0.00167795, 0.00343803, 0.00112513,\n",
            "       0.00062917, 0.00090844, 0.00060298, 0.00149068, 0.0018073 ,\n",
            "       0.00087215, 0.0013345 , 0.00060178, 0.00184458, 0.00168616,\n",
            "       0.00185587, 0.00111685, 0.00106338, 0.00092263, 0.00169326,\n",
            "       0.00143999, 0.00124191, 0.00048142, 0.00116368, 0.00116436,\n",
            "       0.00191969, 0.00250522, 0.00109518, 0.00130776, 0.00261029,\n",
            "       0.00133163, 0.00192949, 0.00110955, 0.00054875, 0.00051744,\n",
            "       0.00236999, 0.00094289, 0.0010908 , 0.00113732, 0.0018722 ,\n",
            "       0.00167326, 0.00162522, 0.00095185, 0.00086766, 0.00230142,\n",
            "       0.00096488, 0.00095011, 0.00092161, 0.00117352, 0.00140247,\n",
            "       0.00123401, 0.00168173, 0.00103302, 0.00135393, 0.00065543,\n",
            "       0.0017066 , 0.00377424, 0.00085384, 0.00099428, 0.00081924,\n",
            "       0.00113039, 0.00129821, 0.00334018, 0.00090313, 0.00110567,\n",
            "       0.00046247, 0.00141924, 0.00152755, 0.00042811, 0.00136431,\n",
            "       0.00086082, 0.00163498, 0.0011942 , 0.00098812, 0.00129538,\n",
            "       0.00686977, 0.0006348 , 0.00180431, 0.00088681, 0.00076586,\n",
            "       0.00173099, 0.00115435, 0.00092988, 0.00127838, 0.00140825,\n",
            "       0.00177346, 0.00138516, 0.00128395, 0.00097463, 0.00140059,\n",
            "       0.00081446, 0.0010313 , 0.00155245, 0.00181571, 0.00146279,\n",
            "       0.00881363, 0.00139809, 0.00099148, 0.00151796, 0.00350756,\n",
            "       0.00149337, 0.00079288, 0.00155758, 0.00146308, 0.00101923,\n",
            "       0.00179341, 0.00198671, 0.0012385 , 0.00172785, 0.00242563,\n",
            "       0.00103395, 0.00148636, 0.00118672, 0.00154043, 0.00113456,\n",
            "       0.00230216, 0.0020235 , 0.00094971, 0.00212735, 0.00135221,\n",
            "       0.00114288, 0.00147768, 0.0011292 , 0.0009293 , 0.00092171,\n",
            "       0.00079739, 0.00146802, 0.00071715, 0.00087961, 0.00179289,\n",
            "       0.00134723, 0.00317026, 0.0015318 , 0.00177769, 0.00127025,\n",
            "       0.00137561, 0.00213772, 0.00104288, 0.00137948, 0.00162908,\n",
            "       0.00083712, 0.00076592, 0.00177954, 0.00103286, 0.00250571,\n",
            "       0.00134697, 0.00048068, 0.00196624, 0.00153087, 0.00128884,\n",
            "       0.00015896, 0.00145799, 0.00209537, 0.00106077, 0.00148419,\n",
            "       0.00104359, 0.00087011, 0.00107144, 0.00135337, 0.00110727,\n",
            "       0.0013218 , 0.00088491, 0.00611107, 0.00093117, 0.00193248,\n",
            "       0.00099611, 0.00061243, 0.00040991, 0.0013034 , 0.0010573 ,\n",
            "       0.00129231, 0.00043575, 0.00075736, 0.00192724, 0.00295073,\n",
            "       0.00122497, 0.00098826, 0.0033392 , 0.0013309 , 0.00101905,\n",
            "       0.00115554, 0.0018186 , 0.00151418, 0.0014614 , 0.00197252,\n",
            "       0.00087108, 0.00145325, 0.00087109, 0.00134807, 0.00071887,\n",
            "       0.00169339, 0.00095411, 0.00189223, 0.00191397, 0.00143775,\n",
            "       0.00103206, 0.00142073, 0.0010045 , 0.00114501, 0.00105001,\n",
            "       0.0015635 , 0.00091945, 0.00075513, 0.001085  , 0.00156413,\n",
            "       0.00186137, 0.00274485, 0.00138644, 0.00088479, 0.00406258,\n",
            "       0.00176005, 0.00267904, 0.00130822, 0.00382183, 0.00074285,\n",
            "       0.00093017, 0.00114539, 0.00146693, 0.00111495, 0.00098765,\n",
            "       0.00091028, 0.00083435, 0.00093531, 0.0011136 , 0.00075647,\n",
            "       0.0023208 , 0.00192937, 0.00114642, 0.00149922, 0.0047763 ,\n",
            "       0.00135496, 0.00073283, 0.0013132 , 0.00224262, 0.00114138,\n",
            "       0.00097752, 0.00273003, 0.00101071, 0.00160587, 0.00094672,\n",
            "       0.00104162, 0.00136033, 0.00085626, 0.00122279, 0.00108465,\n",
            "       0.00097437, 0.00084758, 0.00148003, 0.00151673, 0.00129466,\n",
            "       0.00171103, 0.00120367, 0.00307252, 0.00138609, 0.0016394 ,\n",
            "       0.00110438, 0.00105723, 0.00127835, 0.00142225, 0.00149349,\n",
            "       0.00098455, 0.00048437, 0.00086799, 0.00175761, 0.00197903,\n",
            "       0.00114565, 0.00092474, 0.00189742, 0.00057183, 0.0014884 ,\n",
            "       0.00092279, 0.00121902, 0.00136553, 0.00163709, 0.00195443,\n",
            "       0.00089821, 0.00143386, 0.0010296 , 0.00066933, 0.00118837,\n",
            "       0.00092137, 0.00170819, 0.00105829, 0.00212085, 0.00143252,\n",
            "       0.00395264, 0.00496389, 0.00101532, 0.00065272, 0.0007518 ,\n",
            "       0.00072465, 0.00245812, 0.00145613, 0.00192484, 0.00108834,\n",
            "       0.00173088, 0.00249476, 0.00368125, 0.00239694, 0.00154159,\n",
            "       0.00144215, 0.00073628, 0.00065922, 0.00141185, 0.00103081,\n",
            "       0.00103988, 0.00091917, 0.00125863, 0.00064455, 0.00138514,\n",
            "       0.00099664, 0.00195437, 0.00098276, 0.00063105, 0.00027457,\n",
            "       0.00169519, 0.00129484, 0.00123693, 0.00114504, 0.00137502,\n",
            "       0.00320308, 0.00114436, 0.00147447, 0.00208913, 0.00284496,\n",
            "       0.00297013, 0.00095732, 0.00278315, 0.00213501, 0.00143228,\n",
            "       0.00152333, 0.00255764, 0.00188471, 0.00457761, 0.00065024,\n",
            "       0.00353209, 0.00097314, 0.00081261, 0.00138826, 0.00352857,\n",
            "       0.00244989, 0.00255083, 0.00154574, 0.00062266, 0.00278864,\n",
            "       0.00099468, 0.00295905, 0.00269021, 0.00047576, 0.00118599,\n",
            "       0.001046  , 0.00142776, 0.00173151, 0.00228593, 0.00074967,\n",
            "       0.00119541, 0.00104202, 0.00089875, 0.00140895, 0.00118595,\n",
            "       0.00122861, 0.00067123, 0.00105252, 0.00137983, 0.00133738,\n",
            "       0.00120774, 0.0018228 , 0.00178757, 0.000929  , 0.00253467,\n",
            "       0.00162965, 0.00106696, 0.00170728, 0.00433057, 0.00115644,\n",
            "       0.00071409, 0.0002803 , 0.00108057, 0.00096662, 0.00368972,\n",
            "       0.00107363, 0.00079899, 0.00075066, 0.00143604, 0.00357256,\n",
            "       0.00138482, 0.00160407, 0.00067629, 0.00105045, 0.00189763,\n",
            "       0.00660825, 0.00124687, 0.00121626, 0.00090627, 0.00073522,\n",
            "       0.00157657, 0.00256945, 0.00035447, 0.00208441, 0.00398486,\n",
            "       0.00103179, 0.00076529, 0.00124538, 0.00120802, 0.00061325,\n",
            "       0.00071347, 0.00078682, 0.00071033, 0.00332495, 0.00081077,\n",
            "       0.00136173, 0.00142737, 0.00153   , 0.00125587, 0.00322422,\n",
            "       0.00085068, 0.00151689, 0.00136285, 0.0014438 , 0.00122297,\n",
            "       0.00096388, 0.00110016, 0.00128174, 0.00044218, 0.00085111,\n",
            "       0.00121681, 0.00089394, 0.00057013, 0.00118081, 0.00028299,\n",
            "       0.00157166, 0.00093982, 0.00115427, 0.00188925, 0.00080613,\n",
            "       0.00169504, 0.00119325, 0.00173322, 0.00391   , 0.00118473,\n",
            "       0.00125535, 0.00162819, 0.00163086, 0.00084768, 0.00178244,\n",
            "       0.00089496, 0.00335008, 0.00234249, 0.00063096, 0.00028724,\n",
            "       0.00091007, 0.00120909, 0.00082869, 0.0012142 , 0.00080107,\n",
            "       0.00141857, 0.0018965 , 0.00148099, 0.00094693, 0.00185522,\n",
            "       0.00174012, 0.00235438, 0.00264169, 0.00136106, 0.00250683,\n",
            "       0.00137499, 0.00155147, 0.0003099 , 0.00285589, 0.00065838,\n",
            "       0.0009912 , 0.00077317, 0.00277877, 0.00185085, 0.00365738,\n",
            "       0.00197999, 0.0015902 , 0.00116686, 0.00106834, 0.00131391,\n",
            "       0.00105276, 0.00117778, 0.00048599, 0.00096142, 0.0009135 ,\n",
            "       0.00150757, 0.0019798 , 0.00187249, 0.00075769, 0.00125337,\n",
            "       0.00095567, 0.00152395, 0.00114406, 0.00161048, 0.00163216,\n",
            "       0.00120681, 0.00111014, 0.00907854, 0.00092824, 0.00148427,\n",
            "       0.00089759, 0.00154474, 0.00240816, 0.00154071, 0.00074277,\n",
            "       0.00133528, 0.00205493, 0.00114273, 0.00109628, 0.00089571,\n",
            "       0.00076916, 0.00098702, 0.00175709, 0.00117256, 0.00113441,\n",
            "       0.00109269, 0.00170376, 0.00147715, 0.00048264, 0.00130121,\n",
            "       0.00152899, 0.00125805, 0.00151755, 0.00129409, 0.00104266,\n",
            "       0.00127715, 0.00183394, 0.00107919, 0.00054908, 0.00111626,\n",
            "       0.00090885, 0.00191359, 0.00101536, 0.0011851 , 0.000722  ,\n",
            "       0.00182435, 0.00100523, 0.00111007, 0.00092399, 0.00114808,\n",
            "       0.00106985, 0.00190647, 0.00128589, 0.00102507, 0.00068454,\n",
            "       0.00178822, 0.00139804, 0.00254801, 0.00206055, 0.00162079,\n",
            "       0.00126918, 0.00157285, 0.0030484 , 0.00219701, 0.00134463,\n",
            "       0.00197564, 0.0015653 , 0.0012258 , 0.00483294, 0.00157742,\n",
            "       0.00078792, 0.00121278, 0.00039674, 0.0024403 , 0.00092071,\n",
            "       0.00052944], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block4_layer6/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer6/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 195, 'shape': array([  1,   3,   3, 576], dtype=int32), 'shape_signature': array([  1,   3,   3, 576], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01680658, 0.01942946, 0.00853847, 0.01802433, 0.02316462,\n",
            "       0.02907147, 0.01304638, 0.01592885, 0.02513468, 0.01057185,\n",
            "       0.00505865, 0.01685123, 0.02460303, 0.05041043, 0.01649731,\n",
            "       0.00922529, 0.01332005, 0.00884128, 0.02185723, 0.02649967,\n",
            "       0.012788  , 0.01956719, 0.0088237 , 0.02704627, 0.02472346,\n",
            "       0.02721183, 0.01637595, 0.01559191, 0.01352817, 0.02482761,\n",
            "       0.021114  , 0.01820968, 0.00705888, 0.01706252, 0.01707258,\n",
            "       0.02814766, 0.03673307, 0.01605821, 0.0191751 , 0.03827358,\n",
            "       0.01952512, 0.02829132, 0.01626891, 0.00804609, 0.00758702,\n",
            "       0.03475022, 0.01382515, 0.01599389, 0.01667611, 0.02745124,\n",
            "       0.02453431, 0.02383   , 0.01395659, 0.01272211, 0.03374477,\n",
            "       0.01414756, 0.01393108, 0.01351324, 0.01720689, 0.02056386,\n",
            "       0.01809376, 0.02465851, 0.0151467 , 0.01985205, 0.00961028,\n",
            "       0.02502319, 0.05534018, 0.01251955, 0.01457865, 0.01201217,\n",
            "       0.01657449, 0.01903515, 0.04897569, 0.01324226, 0.01621191,\n",
            "       0.006781  , 0.02080972, 0.02239778, 0.00627727, 0.02000436,\n",
            "       0.01262187, 0.02397297, 0.01751013, 0.01448841, 0.01899363,\n",
            "       0.10072859, 0.00930783, 0.02645584, 0.01300287, 0.01122946,\n",
            "       0.02538079, 0.01692576, 0.0136345 , 0.01874441, 0.02064861,\n",
            "       0.0260035 , 0.02031006, 0.01882602, 0.01429061, 0.02053621,\n",
            "       0.01194202, 0.01512153, 0.02276298, 0.02662295, 0.02144827,\n",
            "       0.12923063, 0.02049956, 0.01453771, 0.02225725, 0.05142995,\n",
            "       0.02189663, 0.01162568, 0.02283818, 0.02145261, 0.01494459,\n",
            "       0.02629609, 0.02913033, 0.01815963, 0.02533479, 0.03556597,\n",
            "       0.01516036, 0.02179382, 0.01740033, 0.02258674, 0.01663554,\n",
            "       0.03375566, 0.02966981, 0.01392516, 0.03119249, 0.01982685,\n",
            "       0.01675756, 0.02166666, 0.01655692, 0.01362589, 0.01351465,\n",
            "       0.0116918 , 0.021525  , 0.01051532, 0.01289732, 0.02628842,\n",
            "       0.01975391, 0.04648427, 0.02246009, 0.02606559, 0.01862521,\n",
            "       0.02016994, 0.03134453, 0.01529136, 0.02022674, 0.02388657,\n",
            "       0.01227431, 0.01123043, 0.02609262, 0.01514447, 0.03674021,\n",
            "       0.01975012, 0.007048  , 0.02883018, 0.02244651, 0.01889768,\n",
            "       0.00233069, 0.02137792, 0.03072357, 0.01555357, 0.02176209,\n",
            "       0.01530171, 0.01275803, 0.01571002, 0.0198439 , 0.01623547,\n",
            "       0.01938104, 0.01297501, 0.08960409, 0.01365335, 0.02833518,\n",
            "       0.01460552, 0.00897987, 0.00601035, 0.01911127, 0.01550277,\n",
            "       0.01894867, 0.0063892 , 0.01110486, 0.02825838, 0.04326529,\n",
            "       0.01796121, 0.01449051, 0.04896126, 0.01951448, 0.01494198,\n",
            "       0.01694322, 0.02666534, 0.02220178, 0.02142792, 0.02892224,\n",
            "       0.01277234, 0.02130844, 0.01277246, 0.01976618, 0.01054053,\n",
            "       0.02482944, 0.01398968, 0.02774504, 0.02806378, 0.02108119,\n",
            "       0.01513266, 0.02083159, 0.01472861, 0.01678883, 0.01539583,\n",
            "       0.02292489, 0.01348145, 0.01107211, 0.01590893, 0.02293419,\n",
            "       0.02729253, 0.04024661, 0.0203288 , 0.01297326, 0.05956791,\n",
            "       0.02580694, 0.0392817 , 0.01918191, 0.05603797, 0.01089214,\n",
            "       0.01363876, 0.01679445, 0.02150902, 0.01634801, 0.01448147,\n",
            "       0.01334699, 0.01223374, 0.01371407, 0.01632825, 0.01109184,\n",
            "       0.03402889, 0.0282896 , 0.01680951, 0.02198238, 0.07003298,\n",
            "       0.01986717, 0.01074522, 0.01925495, 0.03288266, 0.01673559,\n",
            "       0.01433298, 0.04002937, 0.01481969, 0.02354626, 0.0138813 ,\n",
            "       0.01527282, 0.01994601, 0.012555  , 0.01792923, 0.01590379,\n",
            "       0.01428683, 0.01242777, 0.02170104, 0.02223918, 0.01898311,\n",
            "       0.02508816, 0.0176489 , 0.04505116, 0.02032372, 0.02403782,\n",
            "       0.01619314, 0.01550169, 0.01874387, 0.02085384, 0.02189838,\n",
            "       0.0144361 , 0.00710206, 0.01272694, 0.02577113, 0.02901771,\n",
            "       0.0167982 , 0.01355906, 0.02782112, 0.00838454, 0.02182385,\n",
            "       0.01353053, 0.017874  , 0.02002216, 0.02400394, 0.02865693,\n",
            "       0.01317007, 0.02102414, 0.01509661, 0.00981416, 0.01742454,\n",
            "       0.01350961, 0.02504646, 0.01551724, 0.03109717, 0.02100452,\n",
            "       0.05795599, 0.07278344, 0.01488722, 0.00957063, 0.01102335,\n",
            "       0.01062519, 0.03604244, 0.02135065, 0.02822311, 0.01595792,\n",
            "       0.0253792 , 0.03657966, 0.05397664, 0.03514538, 0.02260374,\n",
            "       0.02114567, 0.01079575, 0.00966589, 0.02070144, 0.01511441,\n",
            "       0.01524733, 0.01347745, 0.01845481, 0.00945081, 0.0203097 ,\n",
            "       0.01461334, 0.02865607, 0.01440982, 0.0092528 , 0.00402598,\n",
            "       0.02485586, 0.01898566, 0.01813659, 0.01678918, 0.02016142,\n",
            "       0.04696541, 0.01677934, 0.02161955, 0.03063206, 0.04171449,\n",
            "       0.04354974, 0.01403681, 0.04080824, 0.03130481, 0.02100091,\n",
            "       0.0223359 , 0.03750162, 0.02763472, 0.06711965, 0.00953423,\n",
            "       0.05178965, 0.01426874, 0.011915  , 0.02035555, 0.05173789,\n",
            "       0.03592167, 0.03740177, 0.02266456, 0.00912981, 0.04088865,\n",
            "       0.01458456, 0.04338737, 0.03944546, 0.00697586, 0.01738971,\n",
            "       0.0153371 , 0.02093462, 0.02538843, 0.03351766, 0.01099214,\n",
            "       0.01752785, 0.01527878, 0.013178  , 0.02065878, 0.0173891 ,\n",
            "       0.01801461, 0.00984195, 0.01543265, 0.0202319 , 0.01960942,\n",
            "       0.01770853, 0.02672693, 0.02621033, 0.01362147, 0.03716483,\n",
            "       0.02389486, 0.01564445, 0.02503312, 0.0634973 , 0.01695642,\n",
            "       0.01047047, 0.00410991, 0.01584398, 0.01417314, 0.05410083,\n",
            "       0.01574212, 0.01171527, 0.01100667, 0.02105607, 0.05238294,\n",
            "       0.020305  , 0.02351981, 0.00991618, 0.01540238, 0.02782413,\n",
            "       0.09689407, 0.01828231, 0.01783347, 0.01328823, 0.01078018,\n",
            "       0.02311657, 0.03767481, 0.00519746, 0.03056282, 0.05842839,\n",
            "       0.01512867, 0.01122106, 0.01826048, 0.01771265, 0.00899181,\n",
            "       0.01046138, 0.01153685, 0.0104153 , 0.04875236, 0.01188799,\n",
            "       0.01996656, 0.02092894, 0.02243377, 0.01841424, 0.04727547,\n",
            "       0.01247318, 0.02224146, 0.0199829 , 0.02116991, 0.0179319 ,\n",
            "       0.01413294, 0.01613118, 0.01879358, 0.00648351, 0.01247941,\n",
            "       0.01784165, 0.01310741, 0.00835957, 0.01731375, 0.00414941,\n",
            "       0.02304463, 0.01378018, 0.01692464, 0.0277013 , 0.01181988,\n",
            "       0.02485369, 0.0174962 , 0.02541349, 0.05733075, 0.01737123,\n",
            "       0.01840673, 0.02387347, 0.0239126 , 0.01242919, 0.02613521,\n",
            "       0.0131224 , 0.0491209 , 0.03434703, 0.00925145, 0.00421169,\n",
            "       0.01334395, 0.01772836, 0.01215071, 0.01780332, 0.01174573,\n",
            "       0.02079984, 0.02780764, 0.02171517, 0.01388447, 0.02720231,\n",
            "       0.02551472, 0.03452134, 0.03873406, 0.0199566 , 0.0367566 ,\n",
            "       0.02016098, 0.0227486 , 0.00454397, 0.04187466, 0.00965353,\n",
            "       0.0145335 , 0.0113367 , 0.04074397, 0.02713821, 0.05362659,\n",
            "       0.02903182, 0.02331647, 0.01710916, 0.01566464, 0.01926529,\n",
            "       0.01543612, 0.01726924, 0.00712591, 0.01409684, 0.01339426,\n",
            "       0.02210494, 0.02902906, 0.02745549, 0.01110973, 0.01837762,\n",
            "       0.0140126 , 0.02234505, 0.01677485, 0.0236138 , 0.02393163,\n",
            "       0.017695  , 0.01627754, 0.13311487, 0.01361034, 0.0217633 ,\n",
            "       0.01316103, 0.02264982, 0.03530985, 0.02259083, 0.01089086,\n",
            "       0.01957869, 0.03013052, 0.01675541, 0.01607437, 0.0131334 ,\n",
            "       0.01127785, 0.01447227, 0.0257635 , 0.01719277, 0.01663333,\n",
            "       0.01602164, 0.02498147, 0.02165889, 0.00707673, 0.01907903,\n",
            "       0.02241889, 0.01844632, 0.02225116, 0.01897475, 0.01528806,\n",
            "       0.01872638, 0.02689028, 0.01582374, 0.008051  , 0.01636729,\n",
            "       0.01332612, 0.0280582 , 0.01488787, 0.01737668, 0.01058644,\n",
            "       0.02674972, 0.01473932, 0.01627647, 0.01354815, 0.01683384,\n",
            "       0.0156868 , 0.02795371, 0.01885444, 0.01503017, 0.01003719,\n",
            "       0.02621999, 0.02049882, 0.03736036, 0.03021305, 0.02376501,\n",
            "       0.01860942, 0.02306203, 0.04469742, 0.03221386, 0.01971577,\n",
            "       0.02896799, 0.02295137, 0.01797335, 0.07086343, 0.02312907,\n",
            "       0.01155298, 0.01778252, 0.00581725, 0.03578107, 0.01349996,\n",
            "       0.00776292], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 196, 'shape': array([576], dtype=int32), 'shape_signature': array([576], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.89629776e-04, 2.21059818e-04, 1.84700533e-04, 1.65382691e-04,\n",
            "       1.32836707e-04, 8.77303391e-05, 1.30375396e-04, 2.06329467e-04,\n",
            "       7.86953824e-05, 1.01163772e-04, 1.34170987e-04, 1.30882152e-04,\n",
            "       9.39067831e-05, 1.90315750e-05, 1.54436799e-04, 1.68624843e-04,\n",
            "       1.58148701e-04, 1.41967161e-04, 1.87311249e-04, 4.32665729e-05,\n",
            "       1.08982094e-04, 1.87842757e-04, 1.56474736e-04, 3.24130160e-05,\n",
            "       2.58221662e-05, 1.91487023e-04, 1.86858961e-04, 2.43220449e-04,\n",
            "       2.08696321e-04, 2.17028664e-05, 1.69209045e-04, 1.18754811e-04,\n",
            "       1.37598501e-04, 2.14210653e-04, 1.62947836e-04, 3.99745477e-05,\n",
            "       7.30861866e-05, 1.24898375e-04, 1.40106815e-04, 3.29140967e-05,\n",
            "       1.78838425e-04, 1.63006742e-04, 1.81973010e-04, 8.69022333e-05,\n",
            "       1.66026279e-04, 1.41072916e-04, 1.90100385e-04, 1.81482668e-04,\n",
            "       2.09382837e-04, 4.31054468e-05, 1.44571517e-04, 2.26695047e-04,\n",
            "       1.55842412e-04, 1.19018143e-04, 2.15589698e-05, 2.24087547e-04,\n",
            "       2.02228053e-04, 1.48799343e-04, 2.19241265e-04, 1.11401161e-04,\n",
            "       1.43993704e-04, 1.70965315e-04, 1.21848629e-04, 1.12251735e-04,\n",
            "       2.42996815e-04, 7.08047010e-05, 2.97235529e-05, 2.49111792e-04,\n",
            "       6.33915770e-05, 1.40088872e-04, 1.71601860e-04, 9.28435984e-05,\n",
            "       2.82922811e-05, 1.74268134e-04, 1.42468023e-04, 8.87134302e-05,\n",
            "       1.46944600e-04, 1.66766826e-04, 1.28258165e-04, 1.88771213e-04,\n",
            "       1.23728154e-04, 1.57460832e-04, 1.49221902e-04, 1.53724133e-04,\n",
            "       1.69081846e-04, 2.57703632e-05, 1.81328054e-04, 2.06672950e-04,\n",
            "       2.14264059e-04, 1.31623514e-04, 2.32138031e-04, 1.69737614e-04,\n",
            "       1.76576781e-04, 1.13521033e-04, 1.48880645e-04, 1.15007089e-04,\n",
            "       5.18526831e-05, 1.05756830e-04, 1.62005759e-04, 1.58304334e-04,\n",
            "       1.57080227e-04, 1.71162945e-04, 1.69923194e-04, 6.14764504e-05,\n",
            "       1.57377057e-04, 1.55184189e-05, 1.53695481e-04, 1.15914067e-04,\n",
            "       1.95344168e-04, 1.20068558e-04, 1.40490331e-04, 2.42768685e-04,\n",
            "       1.52600012e-04, 1.01772239e-04, 1.87359037e-04, 2.05195727e-04,\n",
            "       3.19315513e-05, 1.45325655e-04, 1.83028824e-04, 3.57690733e-05,\n",
            "       1.80298914e-04, 1.30127548e-04, 1.94819062e-04, 9.43834093e-05,\n",
            "       1.07427892e-04, 1.59913179e-04, 1.94982626e-04, 1.93945656e-04,\n",
            "       4.05100691e-05, 1.40721444e-04, 1.63817647e-04, 1.45275160e-04,\n",
            "       2.19095353e-04, 2.29173791e-04, 1.33594323e-04, 1.50716049e-04,\n",
            "       8.13852166e-05, 1.54530702e-04, 1.59485178e-04, 9.87252788e-05,\n",
            "       1.14193164e-04, 4.15363502e-05, 5.68984906e-05, 6.41189763e-05,\n",
            "       1.21526347e-04, 1.35101145e-04, 7.86080491e-05, 2.37197746e-04,\n",
            "       8.85789850e-05, 2.58939457e-04, 1.33176480e-04, 2.08265425e-04,\n",
            "       2.13832245e-04, 6.15414756e-05, 3.90945315e-05, 1.61735356e-04,\n",
            "       1.29324850e-04, 1.51515094e-04, 1.59571428e-04, 1.40993972e-04,\n",
            "       8.40993307e-05, 1.36846094e-04, 3.39761827e-05, 2.18148693e-04,\n",
            "       1.13630318e-04, 8.25365787e-05, 2.15556211e-04, 7.71353225e-05,\n",
            "       1.44144637e-04, 1.04317354e-04, 6.20796854e-05, 1.77789057e-04,\n",
            "       1.80152510e-05, 1.18415956e-04, 5.87753057e-05, 1.27791704e-04,\n",
            "       1.01146157e-04, 1.10137480e-04, 1.54301859e-04, 1.83119380e-04,\n",
            "       2.61246430e-04, 8.44378228e-05, 2.02377138e-04, 1.60195064e-04,\n",
            "       5.47484124e-05, 1.52880166e-04, 2.12288796e-04, 4.16246039e-05,\n",
            "       1.74105240e-04, 1.73779365e-04, 1.44890655e-04, 1.85741374e-04,\n",
            "       2.05517863e-04, 2.45612900e-04, 2.03537449e-04, 2.56035972e-04,\n",
            "       1.95476925e-04, 1.59726696e-04, 1.45481739e-04, 1.94478314e-04,\n",
            "       1.60270894e-04, 1.87583282e-04, 1.56672941e-05, 1.87135985e-04,\n",
            "       1.60666692e-04, 1.81469790e-04, 1.21435565e-04, 1.95942295e-04,\n",
            "       1.71636770e-04, 2.18948946e-04, 1.19485841e-04, 1.18604716e-04,\n",
            "       1.08422944e-04, 1.62022552e-04, 1.39605618e-04, 1.68267608e-04,\n",
            "       4.66103993e-05, 1.97194517e-04, 6.53653988e-05, 4.38885727e-05,\n",
            "       5.07681143e-05, 4.77025642e-05, 8.38414417e-05, 2.66556326e-05,\n",
            "       2.09162768e-04, 1.44244827e-04, 1.29180815e-04, 1.74057248e-04,\n",
            "       1.66799189e-04, 8.96057754e-05, 1.17391217e-04, 1.60277312e-04,\n",
            "       1.44594276e-04, 1.99477377e-04, 2.18498652e-04, 3.95757888e-05,\n",
            "       6.75064875e-05, 1.55587404e-04, 1.47659564e-04, 4.90441889e-05,\n",
            "       2.77793035e-04, 1.66578466e-04, 1.79187075e-04, 4.93152947e-05,\n",
            "       1.46811159e-04, 1.22833910e-04, 4.82461837e-05, 1.26120125e-04,\n",
            "       1.32509769e-04, 1.45297512e-04, 1.42882403e-04, 1.40045391e-04,\n",
            "       1.94072461e-04, 1.77280774e-04, 1.35582988e-04, 2.37817425e-04,\n",
            "       1.30882239e-04, 7.87997560e-05, 1.41547469e-04, 1.76525733e-04,\n",
            "       1.39628639e-04, 1.78884860e-04, 3.79755766e-05, 1.74129178e-04,\n",
            "       1.32325673e-04, 1.14943556e-04, 1.57855116e-04, 1.55785558e-04,\n",
            "       1.54470079e-04, 1.71348991e-04, 1.40179254e-04, 1.87991565e-04,\n",
            "       1.63225021e-04, 1.70076339e-04, 1.73123743e-04, 2.05214441e-04,\n",
            "       1.76285292e-04, 1.74042201e-04, 1.92614709e-04, 1.46886770e-04,\n",
            "       1.38115574e-04, 1.55926347e-04, 1.36761155e-04, 1.63866120e-04,\n",
            "       4.66304045e-05, 1.09443994e-04, 1.48464242e-04, 1.91614148e-04,\n",
            "       1.51081214e-04, 1.61327931e-04, 9.40526588e-05, 7.97997054e-05,\n",
            "       8.36430772e-05, 3.88272529e-05, 1.88406630e-04, 2.40787194e-05,\n",
            "       3.36413868e-05, 1.59447314e-04, 7.89096230e-05, 2.24709729e-04,\n",
            "       1.61736360e-04, 3.85744861e-05, 1.07670690e-04, 1.14515926e-04,\n",
            "       1.74377681e-04, 1.62826022e-04, 3.47979949e-05, 3.29314717e-05,\n",
            "       3.51520357e-05, 1.67143837e-04, 1.50601743e-04, 1.88194623e-04,\n",
            "       1.18547163e-04, 1.79691197e-04, 1.39743803e-04, 1.98106383e-04,\n",
            "       1.79496332e-04, 2.01556773e-04, 1.04861108e-04, 1.25795748e-04,\n",
            "       1.45784958e-04, 1.58322015e-04, 1.27935666e-04, 1.39320953e-04,\n",
            "       1.52818291e-04, 2.28993333e-04, 1.74173343e-04, 1.89162049e-04,\n",
            "       1.57869450e-04, 4.59129005e-05, 1.91717354e-05, 1.95893124e-04,\n",
            "       1.88521735e-04, 9.96375311e-05, 1.93592758e-04, 2.99580279e-05,\n",
            "       1.63409728e-04, 2.93297689e-05, 1.16837000e-04, 2.12957224e-04,\n",
            "       1.85923462e-04, 1.11519403e-04, 6.62118182e-05, 2.97517508e-05,\n",
            "       1.37071620e-04, 2.16307817e-05, 1.45825674e-04, 1.56283786e-04,\n",
            "       1.74106041e-04, 3.13248274e-05, 4.60727788e-05, 1.81183001e-04,\n",
            "       1.11702982e-04, 9.30618626e-05, 4.11181245e-05, 1.80237927e-04,\n",
            "       3.04532241e-05, 3.93226474e-05, 1.31327135e-04, 1.56172158e-04,\n",
            "       1.33482434e-04, 1.83551121e-04, 1.28788335e-04, 1.97050918e-04,\n",
            "       1.91435567e-04, 2.47445743e-04, 1.02238177e-04, 1.01013909e-04,\n",
            "       2.06206445e-04, 3.05799884e-04, 2.12629122e-04, 1.32249115e-04,\n",
            "       1.91488944e-04, 2.10343278e-04, 1.37570867e-04, 1.36108967e-04,\n",
            "       1.52233639e-04, 1.38286545e-04, 2.15531225e-04, 5.38922977e-05,\n",
            "       1.89470520e-04, 1.14769959e-04, 3.96041723e-05, 3.42704552e-05,\n",
            "       3.91277717e-05, 2.03924181e-04, 1.05365318e-04, 1.66454498e-04,\n",
            "       1.29278546e-04, 2.70135188e-05, 1.86841571e-04, 9.59200770e-05,\n",
            "       1.35787632e-04, 8.04062802e-05, 2.47799362e-05, 1.54735913e-04,\n",
            "       9.33640622e-05, 1.32207555e-04, 1.90373394e-04, 1.17164309e-04,\n",
            "       1.86246889e-05, 3.06134243e-05, 1.45132915e-04, 2.30867852e-04,\n",
            "       1.47341925e-04, 8.46373659e-05, 3.44151194e-05, 1.57131988e-04,\n",
            "       1.67323989e-04, 2.68332042e-05, 8.40316497e-05, 1.79679715e-04,\n",
            "       1.86982899e-04, 1.00767014e-04, 2.06358643e-04, 1.62671291e-04,\n",
            "       1.19406657e-04, 8.58844287e-05, 6.30523791e-05, 2.30090460e-04,\n",
            "       7.45505822e-05, 2.46743410e-04, 2.20540853e-04, 1.29798369e-04,\n",
            "       2.89326526e-05, 1.46721213e-04, 2.08635785e-04, 1.33143447e-04,\n",
            "       2.06645534e-04, 6.61606246e-05, 1.69340026e-04, 1.96259949e-04,\n",
            "       1.40325981e-04, 1.26386120e-04, 1.67494669e-04, 1.92643914e-04,\n",
            "       1.90879757e-04, 1.93710453e-04, 1.57491508e-04, 1.23888662e-04,\n",
            "       1.84837743e-04, 2.00011738e-04, 1.45202823e-04, 1.95601780e-04,\n",
            "       1.78808114e-04, 1.18821838e-04, 1.38974399e-04, 2.31050682e-04,\n",
            "       5.77296523e-05, 9.19720405e-05, 1.79759285e-04, 8.09126577e-05,\n",
            "       1.64338984e-04, 7.02623875e-05, 1.89090511e-04, 1.46279795e-04,\n",
            "       4.08759661e-05, 1.72500295e-04, 1.00579098e-04, 1.18234231e-04,\n",
            "       2.01333416e-04, 1.64605648e-04, 1.98994938e-04, 1.43936471e-04,\n",
            "       1.11060595e-04, 1.72825748e-04, 4.76486748e-05, 1.03663231e-04,\n",
            "       1.38010830e-04, 1.16490541e-04, 1.62320313e-04, 1.45825179e-04,\n",
            "       3.30243929e-05, 1.84681150e-04, 3.75601776e-05, 2.33892963e-04,\n",
            "       1.68822429e-04, 1.82848991e-04, 5.26878648e-05, 1.93562839e-04,\n",
            "       2.22754868e-04, 1.53413974e-04, 3.34633442e-05, 1.82279255e-04,\n",
            "       3.21501066e-05, 1.81276017e-04, 1.73153065e-04, 1.53865389e-04,\n",
            "       1.39689015e-04, 2.01271090e-04, 2.53907579e-04, 1.35911250e-04,\n",
            "       3.11917742e-04, 1.28975109e-04, 1.58840296e-04, 1.58389259e-04,\n",
            "       1.69455045e-04, 1.69254097e-04, 2.11807492e-04, 1.91688203e-04,\n",
            "       1.61733042e-04, 9.84763174e-05, 1.32195302e-04, 9.00020605e-05,\n",
            "       1.51371627e-04, 2.53915059e-04, 1.17086282e-04, 1.52515495e-05,\n",
            "       9.45864012e-05, 2.09806080e-04, 1.11654925e-04, 1.05249135e-04,\n",
            "       4.07657535e-05, 1.43822748e-04, 1.71409527e-04, 1.05330117e-04,\n",
            "       1.67837119e-04, 1.32788802e-04, 1.91753163e-04, 1.27962077e-04,\n",
            "       1.37750132e-04, 1.17645359e-04, 6.27969566e-05, 1.93378699e-04,\n",
            "       1.84950797e-04, 1.00327088e-04, 1.57897433e-04, 1.04391402e-04,\n",
            "       2.95324688e-04, 1.22045552e-04, 1.88093836e-04, 2.45005882e-04,\n",
            "       1.85574507e-04, 2.61992827e-04, 1.33475129e-04, 1.60441821e-04,\n",
            "       1.20508623e-04, 1.79218856e-04, 2.52852187e-04, 1.96816341e-04,\n",
            "       1.27095511e-04, 2.45497125e-04, 1.45416358e-04, 1.16327690e-04,\n",
            "       1.02841943e-04, 1.21338038e-04, 1.37104580e-04, 1.75682522e-04,\n",
            "       1.26389365e-04, 1.20735851e-04, 2.06180484e-04, 1.38248040e-04,\n",
            "       4.38768067e-04, 1.88688166e-04, 1.10469897e-04, 7.87299359e-05,\n",
            "       8.71951052e-05, 7.26270737e-05, 5.62891291e-05, 2.18358546e-04,\n",
            "       2.41768852e-04, 1.42908277e-04, 2.96745511e-05, 4.21070363e-05,\n",
            "       1.27713240e-04, 1.23353238e-04, 2.04755779e-04, 2.04204247e-04,\n",
            "       2.18679670e-05, 1.00430967e-04, 1.61516829e-04, 1.68235405e-04,\n",
            "       1.39463795e-04, 3.09283714e-05, 2.25555428e-04, 1.73571927e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 197, 'shape': array([576,   1,   1, 144], dtype=int32), 'shape_signature': array([576,   1,   1, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.46824119e-04, 4.04308230e-04, 3.37808771e-04, 3.02477332e-04,\n",
            "       2.42952214e-04, 1.60454758e-04, 2.38450593e-04, 3.77367105e-04,\n",
            "       1.43930229e-04, 1.85023877e-04, 2.45392555e-04, 2.39377434e-04,\n",
            "       1.71751177e-04, 3.48078756e-05, 2.82457797e-04, 3.08407063e-04,\n",
            "       2.89246702e-04, 2.59651395e-04, 3.42583662e-04, 7.91325729e-05,\n",
            "       1.99323229e-04, 3.43555759e-04, 2.86185095e-04, 5.92819124e-05,\n",
            "       4.72275533e-05, 3.50220944e-04, 3.41756444e-04, 4.44839010e-04,\n",
            "       3.81695951e-04, 3.96935429e-05, 3.09475552e-04, 2.17197085e-04,\n",
            "       2.51661317e-04, 3.91781417e-04, 2.98024097e-04, 7.31116088e-05,\n",
            "       1.33671274e-04, 2.28433390e-04, 2.56248924e-04, 6.01983702e-05,\n",
            "       3.27087240e-04, 2.98131839e-04, 3.32820258e-04, 1.58940180e-04,\n",
            "       3.03654408e-04, 2.58015876e-04, 3.47684865e-04, 3.31923453e-04,\n",
            "       3.82951577e-04, 7.88378748e-05, 2.64414644e-04, 4.14614799e-04,\n",
            "       2.85028596e-04, 2.17678709e-04, 3.94303643e-05, 4.09845816e-04,\n",
            "       3.69865797e-04, 2.72147154e-04, 4.00982186e-04, 2.03747593e-04,\n",
            "       2.63357855e-04, 3.12687684e-04, 2.22855539e-04, 2.05303251e-04,\n",
            "       4.44429985e-04, 1.29498541e-04, 5.43630085e-05, 4.55614005e-04,\n",
            "       1.15940275e-04, 2.56216095e-04, 3.13851895e-04, 1.69806663e-04,\n",
            "       5.17452791e-05, 3.18728387e-04, 2.60567467e-04, 1.62252778e-04,\n",
            "       2.68754899e-04, 3.05008842e-04, 2.34578285e-04, 3.45253851e-04,\n",
            "       2.26293094e-04, 2.87988601e-04, 2.72919977e-04, 2.81154353e-04,\n",
            "       3.09242925e-04, 4.71328094e-05, 3.31640651e-04, 3.77995311e-04,\n",
            "       3.91879090e-04, 2.40733338e-04, 4.24569764e-04, 3.10442294e-04,\n",
            "       3.22950800e-04, 2.07624747e-04, 2.72295845e-04, 2.10342667e-04,\n",
            "       9.48361703e-05, 1.93424377e-04, 2.96301063e-04, 2.89531337e-04,\n",
            "       2.87292496e-04, 3.13049153e-04, 3.10781703e-04, 1.12437599e-04,\n",
            "       2.87835399e-04, 2.83824738e-05, 2.81101966e-04, 2.12001498e-04,\n",
            "       3.57275479e-04, 2.19599868e-04, 2.56950356e-04, 4.44012752e-04,\n",
            "       2.79098400e-04, 1.86136735e-04, 3.42671061e-04, 3.75293544e-04,\n",
            "       5.84013396e-05, 2.65793933e-04, 3.34751297e-04, 6.54199903e-05,\n",
            "       3.29758419e-04, 2.37997287e-04, 3.56315082e-04, 1.72622909e-04,\n",
            "       1.96480672e-04, 2.92473851e-04, 3.56614240e-04, 3.54717689e-04,\n",
            "       7.40910546e-05, 2.57373031e-04, 2.99614941e-04, 2.65701587e-04,\n",
            "       4.00715304e-04, 4.19148302e-04, 2.44337862e-04, 2.75652710e-04,\n",
            "       1.48849809e-04, 2.82629539e-04, 2.91691045e-04, 1.80563991e-04,\n",
            "       2.08854035e-04, 7.59680697e-05, 1.04064718e-04, 1.17270662e-04,\n",
            "       2.22266099e-04, 2.47093762e-04, 1.43770507e-04, 4.33823763e-04,\n",
            "       1.62006880e-04, 4.73588356e-04, 2.43573639e-04, 3.80907877e-04,\n",
            "       3.91089328e-04, 1.12556532e-04, 7.15021015e-05, 2.95806531e-04,\n",
            "       2.36529188e-04, 2.77114130e-04, 2.91848788e-04, 2.57871492e-04,\n",
            "       1.53813802e-04, 2.50285200e-04, 6.21408763e-05, 3.98983917e-04,\n",
            "       2.07824618e-04, 1.50955602e-04, 3.94242379e-04, 1.41076947e-04,\n",
            "       2.63633905e-04, 1.90791645e-04, 1.13540882e-04, 3.25167988e-04,\n",
            "       3.29490649e-05, 2.16577333e-04, 1.07497326e-04, 2.33725150e-04,\n",
            "       1.84991659e-04, 2.01436385e-04, 2.82210996e-04, 3.34916927e-04,\n",
            "       4.77807713e-04, 1.54432884e-04, 3.70138470e-04, 2.92989396e-04,\n",
            "       1.00132325e-04, 2.79610773e-04, 3.88266431e-04, 7.61294868e-05,\n",
            "       3.18430481e-04, 3.17834463e-04, 2.64998351e-04, 3.39712424e-04,\n",
            "       3.75882722e-04, 4.49214684e-04, 3.72260634e-04, 4.68277984e-04,\n",
            "       3.57518293e-04, 2.92132783e-04, 2.66079413e-04, 3.55691882e-04,\n",
            "       2.93128076e-04, 3.43081192e-04, 2.86547602e-05, 3.42263113e-04,\n",
            "       2.93851976e-04, 3.31899879e-04, 2.22100061e-04, 3.58369434e-04,\n",
            "       3.13915749e-04, 4.00447549e-04, 2.18534100e-04, 2.16922563e-04,\n",
            "       1.98300579e-04, 2.96331797e-04, 2.55332241e-04, 3.07753711e-04,\n",
            "       8.52482772e-05, 3.60659702e-04, 1.19550306e-04, 8.02701761e-05,\n",
            "       9.28525405e-05, 8.72457967e-05, 1.53342131e-04, 4.87519246e-05,\n",
            "       3.82549071e-04, 2.63817143e-04, 2.36265754e-04, 3.18342703e-04,\n",
            "       3.05068039e-04, 1.63884833e-04, 2.14703134e-04, 2.93139834e-04,\n",
            "       2.64456263e-04, 3.64834937e-04, 3.99623968e-04, 7.23822959e-05,\n",
            "       1.23466263e-04, 2.84562208e-04, 2.70062534e-04, 8.96995625e-05,\n",
            "       5.08070691e-04, 3.04664340e-04, 3.27724905e-04, 9.01954045e-05,\n",
            "       2.68510863e-04, 2.24657575e-04, 8.82400491e-05, 2.30667909e-04,\n",
            "       2.42354261e-04, 2.65742448e-04, 2.61325331e-04, 2.56136584e-04,\n",
            "       3.54949589e-04, 3.24238383e-04, 2.47975055e-04, 4.34957125e-04,\n",
            "       2.39377594e-04, 1.44121121e-04, 2.58883811e-04, 3.22857435e-04,\n",
            "       2.55374354e-04, 3.27172165e-04, 6.94555783e-05, 3.18474253e-04,\n",
            "       2.42017573e-04, 2.10226470e-04, 2.88709736e-04, 2.84924608e-04,\n",
            "       2.82518653e-04, 3.13389406e-04, 2.56381405e-04, 3.43827909e-04,\n",
            "       2.98531057e-04, 3.11061798e-04, 3.16635356e-04, 3.75327771e-04,\n",
            "       3.22417676e-04, 3.18315171e-04, 3.52283445e-04, 2.68649135e-04,\n",
            "       2.52607017e-04, 2.85182119e-04, 2.50129844e-04, 2.99703592e-04,\n",
            "       8.52848607e-05, 2.00168026e-04, 2.71534256e-04, 3.50453454e-04,\n",
            "       2.76320585e-04, 2.95061356e-04, 1.72017986e-04, 1.45949991e-04,\n",
            "       1.52979337e-04, 7.10132590e-05, 3.44587053e-04, 4.40388685e-05,\n",
            "       6.15285462e-05, 2.91621807e-04, 1.44322068e-04, 4.10983746e-04,\n",
            "       2.95808364e-04, 7.05509592e-05, 1.96924739e-04, 2.09444363e-04,\n",
            "       3.18928738e-04, 2.97801307e-04, 6.36439290e-05, 6.02301479e-05,\n",
            "       6.42914529e-05, 3.05698370e-04, 2.75443657e-04, 3.44199303e-04,\n",
            "       2.16817309e-04, 3.28646915e-04, 2.55584979e-04, 3.62327468e-04,\n",
            "       3.28290538e-04, 3.68638051e-04, 1.91786137e-04, 2.30074627e-04,\n",
            "       2.66633986e-04, 2.89563672e-04, 2.33988438e-04, 2.54811603e-04,\n",
            "       2.79497617e-04, 4.18818265e-04, 3.18555016e-04, 3.45968670e-04,\n",
            "       2.88735959e-04, 8.39725835e-05, 3.50642222e-05, 3.58279503e-04,\n",
            "       3.44797561e-04, 1.82232456e-04, 3.54072254e-04, 5.47918535e-05,\n",
            "       2.98868865e-04, 5.36427979e-05, 2.13689491e-04, 3.89488967e-04,\n",
            "       3.40045459e-04, 2.03963849e-04, 1.21098361e-04, 5.44145842e-05,\n",
            "       2.50697689e-04, 3.95617026e-05, 2.66708434e-04, 2.85835849e-04,\n",
            "       3.18431936e-04, 5.72916688e-05, 8.42649897e-05, 3.31375370e-04,\n",
            "       2.04299606e-04, 1.70205865e-04, 7.52031556e-05, 3.29646864e-04,\n",
            "       5.56975465e-05, 7.19193122e-05, 2.40191279e-04, 2.85631686e-04,\n",
            "       2.44133218e-04, 3.35706543e-04, 2.35547937e-04, 3.60397069e-04,\n",
            "       3.50126851e-04, 4.52566863e-04, 1.86988924e-04, 1.84749792e-04,\n",
            "       3.77142103e-04, 5.59293898e-04, 3.88888875e-04, 2.41877555e-04,\n",
            "       3.50224465e-04, 3.84708168e-04, 2.51610792e-04, 2.48937024e-04,\n",
            "       2.78428313e-04, 2.52919737e-04, 3.94196686e-04, 9.85665320e-05,\n",
            "       3.46532848e-04, 2.09908976e-04, 7.24342099e-05, 6.26790861e-05,\n",
            "       7.15628921e-05, 3.72967945e-04, 1.92708321e-04, 3.04437621e-04,\n",
            "       2.36444495e-04, 4.94064807e-05, 3.41724633e-04, 1.75433408e-04,\n",
            "       2.48349330e-04, 1.47059385e-04, 4.53213615e-05, 2.83004862e-04,\n",
            "       1.70758576e-04, 2.41801536e-04, 3.48184170e-04, 2.14288128e-04,\n",
            "       3.40636980e-05, 5.59905420e-05, 2.65441427e-04, 4.22246667e-04,\n",
            "       2.69481592e-04, 1.54797846e-04, 6.29436690e-05, 2.87387171e-04,\n",
            "       3.06027883e-04, 4.90766943e-05, 1.53690024e-04, 3.28625931e-04,\n",
            "       3.41983105e-04, 1.84298231e-04, 3.77420452e-04, 2.97518302e-04,\n",
            "       2.18389279e-04, 1.57078670e-04, 1.15319905e-04, 4.20824857e-04,\n",
            "       1.36349583e-04, 4.51282336e-04, 4.03359067e-04, 2.37395245e-04,\n",
            "       5.29164899e-05, 2.68346339e-04, 3.81585240e-04, 2.43513234e-04,\n",
            "       3.77945165e-04, 1.21004741e-04, 3.09715106e-04, 3.58950405e-04,\n",
            "       2.56649771e-04, 2.31154394e-04, 3.06340051e-04, 3.52336850e-04,\n",
            "       3.49110283e-04, 3.54287506e-04, 2.88044714e-04, 2.26586650e-04,\n",
            "       3.38059734e-04, 3.65812273e-04, 2.65569281e-04, 3.57746641e-04,\n",
            "       3.27031797e-04, 2.17319670e-04, 2.54177779e-04, 4.22581070e-04,\n",
            "       1.05584877e-04, 1.68212631e-04, 3.28771450e-04, 1.47985527e-04,\n",
            "       3.00568441e-04, 1.28506668e-04, 3.45837849e-04, 2.67538999e-04,\n",
            "       7.47602608e-05, 3.15495097e-04, 1.83954544e-04, 2.16244967e-04,\n",
            "       3.68229550e-04, 3.01056163e-04, 3.63952568e-04, 2.63253169e-04,\n",
            "       2.03124713e-04, 3.16090329e-04, 8.71472294e-05, 1.89595274e-04,\n",
            "       2.52415455e-04, 2.13055842e-04, 2.96876387e-04, 2.66707531e-04,\n",
            "       6.04000925e-05, 3.37773323e-04, 6.86958374e-05, 4.27779451e-04,\n",
            "       3.08768445e-04, 3.34422395e-04, 9.63636776e-05, 3.54017509e-04,\n",
            "       4.07408399e-04, 2.80587090e-04, 6.12029180e-05, 3.33380362e-04,\n",
            "       5.88010626e-05, 3.31545481e-04, 3.16688995e-04, 2.81412707e-04,\n",
            "       2.55484774e-04, 3.68115550e-04, 4.64385288e-04, 2.48575408e-04,\n",
            "       5.70483215e-04, 2.35889544e-04, 2.90511583e-04, 2.89686664e-04,\n",
            "       3.09925468e-04, 3.09557945e-04, 3.87386157e-04, 3.50588904e-04,\n",
            "       2.95802281e-04, 1.80108647e-04, 2.41779111e-04, 1.64609621e-04,\n",
            "       2.76851730e-04, 4.64398967e-04, 2.14145417e-04, 2.78943826e-05,\n",
            "       1.72994172e-04, 3.83725652e-04, 2.04211712e-04, 1.92495820e-04,\n",
            "       7.45586876e-05, 2.63045193e-04, 3.13500146e-04, 1.92643929e-04,\n",
            "       3.06966365e-04, 2.42864597e-04, 3.50707705e-04, 2.34036750e-04,\n",
            "       2.51938647e-04, 2.15167951e-04, 1.14852737e-04, 3.53680749e-04,\n",
            "       3.38266487e-04, 1.83493627e-04, 2.88787123e-04, 1.90927065e-04,\n",
            "       5.40135254e-04, 2.23215698e-04, 3.44014959e-04, 4.48104489e-04,\n",
            "       3.39407241e-04, 4.79172799e-04, 2.44119859e-04, 2.93440709e-04,\n",
            "       2.20404720e-04, 3.27783026e-04, 4.62455006e-04, 3.59968020e-04,\n",
            "       2.32451828e-04, 4.49002924e-04, 2.65959825e-04, 2.12757994e-04,\n",
            "       1.88093181e-04, 2.21921684e-04, 2.50757963e-04, 3.21315252e-04,\n",
            "       2.31160331e-04, 2.20820308e-04, 3.77094606e-04, 2.52849306e-04,\n",
            "       8.02486611e-04, 3.45101958e-04, 2.02044350e-04, 1.43993428e-04,\n",
            "       1.59475836e-04, 1.32831570e-04, 1.02950224e-04, 3.99367738e-04,\n",
            "       4.42184100e-04, 2.61372654e-04, 5.42733869e-05, 7.70118277e-05,\n",
            "       2.33581624e-04, 2.25607393e-04, 3.74488882e-04, 3.73480172e-04,\n",
            "       3.99955061e-05, 1.83683616e-04, 2.95406848e-04, 3.07694805e-04,\n",
            "       2.55072868e-04, 5.65665650e-05, 4.12530499e-04, 3.17455066e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/rezero/mul', 'index': 198, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.008881947956979275, 127), 'quantization_parameters': {'scales': array([0.00888195], dtype=float32), 'zero_points': array([127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 199, 'shape': array([144], dtype=int32), 'shape_signature': array([144], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00024267, 0.0004235 , 0.0006546 , 0.00045561, 0.00030379,\n",
            "       0.00027347, 0.00038116, 0.00028095, 0.00077197, 0.00031222,\n",
            "       0.00036384, 0.00066987, 0.00029986, 0.00052633, 0.00045397,\n",
            "       0.00028206, 0.00022724, 0.00039052, 0.00040213, 0.00025858,\n",
            "       0.00034971, 0.00047947, 0.0002981 , 0.00026009, 0.00036478,\n",
            "       0.00055168, 0.00041531, 0.00024739, 0.00029702, 0.00044854,\n",
            "       0.00025021, 0.00029989, 0.00046458, 0.00024861, 0.00044248,\n",
            "       0.00025865, 0.00032128, 0.0003018 , 0.00043548, 0.0004194 ,\n",
            "       0.00036163, 0.00039129, 0.00038767, 0.00034724, 0.00050365,\n",
            "       0.00028028, 0.00044472, 0.00035173, 0.00041883, 0.00029447,\n",
            "       0.00033028, 0.00031233, 0.00032738, 0.00056738, 0.00029367,\n",
            "       0.00027626, 0.00041431, 0.0003767 , 0.00050236, 0.00033284,\n",
            "       0.00043706, 0.00040481, 0.00024172, 0.00055448, 0.0004844 ,\n",
            "       0.00117891, 0.00033768, 0.00055166, 0.00042776, 0.00039245,\n",
            "       0.00030145, 0.000298  , 0.00048061, 0.00024946, 0.0003979 ,\n",
            "       0.00040627, 0.00057063, 0.00051192, 0.00050054, 0.0004375 ,\n",
            "       0.00053021, 0.00049252, 0.0003603 , 0.00038392, 0.00036825,\n",
            "       0.0002857 , 0.00027414, 0.00035109, 0.00033453, 0.00042839,\n",
            "       0.00040134, 0.00041664, 0.00054946, 0.00048801, 0.00034737,\n",
            "       0.00036157, 0.00036964, 0.0002453 , 0.00035645, 0.00043221,\n",
            "       0.00038555, 0.00032367, 0.00046324, 0.0002875 , 0.00035657,\n",
            "       0.00038444, 0.00041153, 0.00052832, 0.00051604, 0.00025363,\n",
            "       0.00035414, 0.00046338, 0.00036386, 0.00060798, 0.00033601,\n",
            "       0.00037948, 0.00039926, 0.00021767, 0.00038186, 0.00045524,\n",
            "       0.00059693, 0.00030196, 0.00027239, 0.00054078, 0.00024353,\n",
            "       0.00039836, 0.00036366, 0.00042673, 0.00067906, 0.00052075,\n",
            "       0.00034501, 0.00054522, 0.00022259, 0.00036947, 0.00029688,\n",
            "       0.00103262, 0.00068026, 0.00028297, 0.00065426, 0.00030834,\n",
            "       0.00036725, 0.0004273 , 0.00040911, 0.00076263], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 200, 'shape': array([144,   1,   1, 480], dtype=int32), 'shape_signature': array([144,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00516849, 0.00901987, 0.01394197, 0.00970371, 0.00647026,\n",
            "       0.00582445, 0.00811804, 0.00598378, 0.01644173, 0.00664982,\n",
            "       0.00774912, 0.01426708, 0.00638644, 0.01120989, 0.00966893,\n",
            "       0.00600744, 0.00483995, 0.00831735, 0.00856468, 0.00550724,\n",
            "       0.00744828, 0.01021196, 0.00634912, 0.00553943, 0.00776918,\n",
            "       0.01174982, 0.00884547, 0.00526908, 0.00632604, 0.00955312,\n",
            "       0.00532905, 0.00638714, 0.00989482, 0.00529503, 0.00942421,\n",
            "       0.00550876, 0.00684285, 0.0064278 , 0.00927504, 0.00893256,\n",
            "       0.00770206, 0.00833385, 0.00825671, 0.00739571, 0.01072702,\n",
            "       0.00596955, 0.00947188, 0.00749131, 0.0089205 , 0.00627174,\n",
            "       0.00703454, 0.00665211, 0.00697267, 0.0120843 , 0.0062548 ,\n",
            "       0.00588391, 0.00882412, 0.00802303, 0.01069938, 0.00708894,\n",
            "       0.00930875, 0.00862173, 0.00514823, 0.01180951, 0.01031685,\n",
            "       0.02510882, 0.00719196, 0.01174957, 0.00911057, 0.00835854,\n",
            "       0.00642032, 0.00634691, 0.01023612, 0.00531317, 0.00847473,\n",
            "       0.0086528 , 0.0121535 , 0.01090299, 0.01066062, 0.009318  ,\n",
            "       0.01129271, 0.01048994, 0.00767382, 0.00817696, 0.00784322,\n",
            "       0.00608498, 0.0058388 , 0.00747755, 0.007125  , 0.00912406,\n",
            "       0.00854793, 0.00887371, 0.01170253, 0.0103938 , 0.0073985 ,\n",
            "       0.0077008 , 0.00787266, 0.0052246 , 0.00759172, 0.00920546,\n",
            "       0.0082117 , 0.00689374, 0.00986621, 0.00612332, 0.00759431,\n",
            "       0.00818802, 0.00876497, 0.01125234, 0.01099093, 0.00540192,\n",
            "       0.00754271, 0.00986935, 0.00774971, 0.0129491 , 0.00715647,\n",
            "       0.0080824 , 0.00850363, 0.00463601, 0.00813302, 0.00969597,\n",
            "       0.01271368, 0.0064313 , 0.00580146, 0.01151771, 0.0051869 ,\n",
            "       0.00848447, 0.00774532, 0.00908875, 0.01446285, 0.01109114,\n",
            "       0.00734812, 0.01161222, 0.00474071, 0.00786914, 0.00632301,\n",
            "       0.02199305, 0.01448837, 0.00602689, 0.01393467, 0.00656714,\n",
            "       0.00782185, 0.00910077, 0.00871345, 0.01624284], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 201, 'shape': array([480], dtype=int32), 'shape_signature': array([480], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.02493677e-05, 4.73347718e-05, 5.15923512e-06, 1.44895948e-05,\n",
            "       4.08862470e-05, 5.05159369e-05, 2.68085587e-05, 3.77701144e-05,\n",
            "       3.12811135e-05, 1.08968678e-04, 3.31670562e-05, 3.20552172e-05,\n",
            "       1.29583332e-05, 3.36648809e-05, 5.98516681e-06, 4.20537654e-05,\n",
            "       3.02394674e-05, 1.87377973e-05, 2.02250358e-05, 4.92363906e-05,\n",
            "       2.45490792e-05, 4.11634537e-05, 4.62263633e-05, 3.91190224e-05,\n",
            "       4.34784997e-05, 2.60827183e-05, 5.23869676e-05, 6.21477229e-05,\n",
            "       7.82114294e-05, 5.27270386e-05, 7.57730668e-05, 2.28254066e-05,\n",
            "       3.41412015e-05, 3.86289285e-05, 3.67554057e-05, 3.40612460e-05,\n",
            "       7.45185480e-06, 5.35866675e-05, 3.54220319e-05, 5.42279986e-06,\n",
            "       4.68625512e-05, 1.55066155e-05, 4.15492323e-05, 3.97795375e-05,\n",
            "       4.76477180e-05, 3.04542045e-05, 2.59015233e-05, 4.24880091e-05,\n",
            "       4.43927529e-05, 2.76490900e-05, 4.52157365e-05, 3.07428163e-05,\n",
            "       3.62245009e-05, 2.62757258e-05, 4.22868907e-05, 4.11556684e-05,\n",
            "       5.44710238e-05, 7.94666485e-05, 1.66623777e-05, 4.71777057e-05,\n",
            "       4.62673270e-05, 3.42628373e-05, 4.16588009e-05, 3.07794166e-04,\n",
            "       3.81244790e-05, 4.62195167e-05, 7.58208698e-05, 4.55170994e-05,\n",
            "       5.09286838e-05, 3.74228766e-05, 3.92570983e-05, 4.55597510e-05,\n",
            "       5.57727399e-05, 4.54893379e-05, 5.72810814e-06, 2.48542765e-05,\n",
            "       3.77042015e-05, 3.24638713e-05, 1.31341192e-04, 1.73832123e-05,\n",
            "       4.31669905e-05, 3.24202738e-05, 4.10497705e-05, 7.79820948e-06,\n",
            "       5.13886844e-05, 5.37406504e-06, 7.76463185e-06, 3.82848593e-05,\n",
            "       3.99323544e-05, 3.95028655e-05, 4.62660573e-05, 3.33311946e-05,\n",
            "       3.07218470e-05, 4.21015029e-05, 2.19216636e-05, 7.40083715e-06,\n",
            "       3.28940332e-05, 5.47825402e-05, 3.88128101e-05, 5.25996165e-06,\n",
            "       5.27917728e-05, 3.74144583e-05, 2.93610465e-05, 3.33192620e-05,\n",
            "       3.39042417e-05, 3.72411523e-05, 2.30554979e-05, 4.99956368e-05,\n",
            "       7.43005239e-06, 1.17572717e-05, 2.02152169e-05, 4.42247620e-05,\n",
            "       4.68410035e-05, 6.10563666e-06, 3.71511596e-05, 3.41724772e-05,\n",
            "       4.11682413e-05, 3.59131336e-05, 1.67403778e-05, 7.72380226e-05,\n",
            "       3.49665493e-06, 3.61474340e-05, 4.35663133e-05, 4.62440803e-05,\n",
            "       4.02785663e-05, 4.50229782e-05, 2.10781618e-05, 5.91231765e-05,\n",
            "       4.79402734e-05, 1.25448332e-05, 3.26476147e-05, 4.05269093e-05,\n",
            "       3.86559441e-05, 1.21902431e-05, 9.18936712e-06, 7.26563758e-06,\n",
            "       5.08566554e-05, 2.83810768e-05, 1.00099613e-04, 3.86756437e-05,\n",
            "       3.51666640e-05, 3.78396107e-05, 3.00542324e-05, 3.78027762e-05,\n",
            "       9.78086609e-06, 4.45931482e-06, 3.19198116e-05, 4.96995563e-05,\n",
            "       3.59949445e-05, 4.65352714e-05, 5.57049543e-06, 2.19540416e-05,\n",
            "       9.55718206e-05, 3.70898269e-05, 3.85999811e-05, 3.63778781e-06,\n",
            "       3.86165157e-05, 2.73220940e-05, 4.10056018e-05, 4.08337291e-05,\n",
            "       1.89873754e-05, 3.46229644e-05, 1.07355199e-05, 4.63498554e-06,\n",
            "       3.57459612e-05, 4.66465281e-05, 3.74705087e-05, 3.24219291e-05,\n",
            "       3.55129814e-05, 3.21201696e-06, 1.83760003e-05, 1.98383714e-05,\n",
            "       2.94803940e-05, 1.40259826e-05, 3.86233405e-05, 3.28406422e-05,\n",
            "       5.14791063e-05, 4.11407964e-05, 4.27770792e-05, 4.54719047e-05,\n",
            "       4.91233459e-06, 2.08733509e-05, 1.08556806e-05, 5.00911028e-06,\n",
            "       3.51864510e-05, 1.51199811e-05, 4.25674625e-06, 4.24974314e-05,\n",
            "       3.57961108e-05, 1.09050061e-05, 6.27635454e-05, 3.85328676e-05,\n",
            "       3.99954988e-05, 6.69152769e-06, 7.03881506e-06, 5.37545793e-06,\n",
            "       4.48928222e-05, 4.04812308e-05, 1.76998328e-05, 8.28344710e-05,\n",
            "       4.41839511e-05, 3.32287818e-05, 1.66149330e-05, 3.05761168e-05,\n",
            "       3.97624935e-05, 2.12711457e-05, 3.38631908e-05, 6.59839179e-06,\n",
            "       3.75232121e-05, 5.15916781e-06, 4.37132949e-05, 3.30258372e-05,\n",
            "       4.39658252e-05, 3.61546408e-05, 4.27925152e-05, 4.43535864e-05,\n",
            "       3.21488587e-05, 2.60337474e-05, 5.99930790e-05, 4.83496988e-05,\n",
            "       4.26114639e-06, 2.21193804e-05, 2.33033334e-05, 4.08147025e-06,\n",
            "       1.21377025e-05, 1.33068088e-05, 4.76239438e-05, 3.74132578e-05,\n",
            "       4.19494463e-05, 3.93398368e-05, 3.83484221e-05, 9.13857093e-06,\n",
            "       4.24632562e-05, 1.38351006e-05, 1.70204821e-05, 3.94504241e-05,\n",
            "       5.86082115e-06, 8.51308323e-06, 5.32471240e-05, 2.68485128e-05,\n",
            "       3.00832562e-05, 4.52708673e-06, 4.72608044e-05, 3.76296339e-05,\n",
            "       4.18815762e-05, 4.40625008e-05, 3.18143975e-05, 4.63342658e-05,\n",
            "       3.61952589e-05, 1.83648626e-05, 1.18654325e-05, 4.92336476e-05,\n",
            "       3.36750563e-05, 3.00064439e-05, 3.20559993e-05, 3.74439951e-05,\n",
            "       5.21492548e-05, 4.14457718e-05, 3.21550433e-05, 1.03287557e-05,\n",
            "       4.36514420e-05, 3.14779827e-05, 3.97158983e-05, 6.31607372e-06,\n",
            "       3.33878124e-05, 2.38715274e-05, 4.48674546e-05, 3.57313074e-05,\n",
            "       6.68363718e-05, 4.48157807e-05, 3.38985519e-05, 3.77293218e-05,\n",
            "       4.59785588e-05, 5.11913868e-06, 2.39410110e-05, 4.17396805e-05,\n",
            "       1.75679415e-05, 8.41454857e-06, 3.43870706e-05, 4.39666619e-05,\n",
            "       4.09921195e-05, 4.67982682e-05, 3.75363816e-05, 3.41372834e-05,\n",
            "       2.77539202e-05, 4.92547042e-05, 3.50804075e-05, 4.18890158e-05,\n",
            "       5.75556078e-05, 3.41383129e-05, 3.30464572e-05, 3.46464803e-05,\n",
            "       2.95227492e-05, 5.09168749e-05, 5.34759010e-06, 3.53038522e-05,\n",
            "       3.92357397e-05, 5.61272172e-05, 3.73525472e-05, 3.72586292e-05,\n",
            "       3.70979542e-05, 3.27572525e-05, 2.81104967e-05, 3.21809021e-05,\n",
            "       1.64598241e-04, 4.54162619e-05, 2.43406885e-05, 2.12142659e-05,\n",
            "       1.61449188e-05, 4.79875453e-05, 5.25603209e-05, 2.50464564e-05,\n",
            "       2.95449845e-05, 8.66991104e-05, 4.52466811e-05, 3.32546151e-05,\n",
            "       1.73988774e-05, 3.77873439e-05, 4.80217313e-05, 3.88714398e-05,\n",
            "       3.04218829e-05, 3.61185848e-05, 1.95859593e-05, 5.28268793e-05,\n",
            "       3.15425314e-05, 2.76257379e-05, 4.54601541e-05, 5.07772675e-05,\n",
            "       3.12635202e-05, 4.22041994e-05, 1.84017772e-05, 4.76457353e-05,\n",
            "       2.49142904e-05, 4.30696309e-06, 4.03054219e-05, 2.47903936e-05,\n",
            "       6.02360296e-06, 3.59644800e-05, 4.75143788e-05, 1.23746959e-05,\n",
            "       8.88803879e-06, 3.23097665e-05, 2.09743339e-05, 1.78506671e-05,\n",
            "       5.81208005e-05, 1.20751038e-05, 4.33049572e-05, 3.84159612e-05,\n",
            "       9.87430849e-06, 4.77838985e-05, 5.17342887e-05, 7.41060503e-05,\n",
            "       2.70808396e-05, 4.97914298e-05, 3.93886148e-05, 2.98219547e-05,\n",
            "       3.32296404e-05, 3.70917296e-05, 3.53290161e-05, 9.53803465e-06,\n",
            "       1.68833812e-05, 3.67826215e-05, 1.37535302e-04, 4.62476164e-05,\n",
            "       2.79904307e-05, 3.01462551e-05, 6.66944652e-06, 1.78395821e-05,\n",
            "       5.62934565e-06, 3.41931445e-05, 3.94492417e-05, 1.24650294e-04,\n",
            "       4.90402708e-05, 3.26226036e-05, 5.86787428e-06, 6.89098988e-06,\n",
            "       3.69059417e-05, 7.19502714e-05, 4.05384308e-05, 4.04958228e-05,\n",
            "       1.38998466e-05, 3.56551609e-05, 4.60714837e-05, 3.24373104e-05,\n",
            "       5.11677572e-05, 4.71520107e-05, 3.11940275e-05, 3.64576990e-05,\n",
            "       4.52072845e-06, 6.33715172e-05, 3.18020138e-05, 5.49054021e-05,\n",
            "       4.38096795e-05, 4.50612097e-05, 5.13359773e-05, 2.44394596e-05,\n",
            "       5.03084630e-06, 1.06328325e-05, 5.87313189e-05, 4.13108792e-05,\n",
            "       6.10896022e-05, 5.58020511e-05, 3.00615793e-05, 3.36981611e-05,\n",
            "       5.23644921e-05, 3.61679013e-05, 9.33614137e-05, 3.13510318e-05,\n",
            "       5.01177165e-05, 4.72730426e-05, 4.20637662e-05, 4.31100998e-05,\n",
            "       3.76747630e-05, 3.74426854e-05, 4.80509661e-05, 4.74412518e-05,\n",
            "       4.21319783e-05, 7.17652711e-06, 2.42668684e-05, 2.53403578e-05,\n",
            "       4.04134516e-05, 3.53265932e-05, 5.61184424e-06, 2.98090581e-05,\n",
            "       5.08446865e-05, 4.80823201e-06, 4.25410108e-05, 7.10316044e-06,\n",
            "       4.91240025e-05, 4.46916965e-05, 3.79361918e-05, 2.64976879e-05,\n",
            "       3.18504171e-05, 2.79708020e-05, 3.90131027e-05, 4.17284537e-05,\n",
            "       1.80547613e-05, 3.43727334e-05, 4.04646344e-05, 4.41088087e-05,\n",
            "       1.44733640e-05, 3.21078733e-06, 9.90055378e-06, 4.62481294e-05,\n",
            "       4.38562492e-05, 4.12949485e-05, 1.83323828e-05, 4.35286565e-05,\n",
            "       4.28642270e-05, 8.37416883e-06, 3.41980522e-05, 5.17763192e-06,\n",
            "       4.98407826e-05, 4.47227139e-05, 5.34221363e-05, 3.56308628e-05,\n",
            "       3.56042874e-05, 1.76688027e-05, 3.21615480e-05, 3.16377846e-05,\n",
            "       1.52090970e-05, 4.46727099e-05, 1.01261448e-05, 3.91151189e-05,\n",
            "       3.10246696e-06, 4.76956229e-05, 2.41043708e-05, 4.51769802e-06,\n",
            "       3.65967644e-05, 2.73385176e-05, 6.67119184e-06, 5.02393914e-06,\n",
            "       4.14406386e-05, 5.00680690e-05, 4.84619022e-06, 5.16870277e-05,\n",
            "       2.34946656e-05, 3.46012202e-05, 5.43242968e-05, 7.98918245e-06],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 202, 'shape': array([480,   1,   1, 240], dtype=int32), 'shape_signature': array([480,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.1037786e-04, 1.4334216e-03, 1.5623524e-04, 4.3878311e-04,\n",
            "       1.2381433e-03, 1.5297557e-03, 8.1183383e-04, 1.1437786e-03,\n",
            "       9.4727456e-04, 3.2998587e-03, 1.0043859e-03, 9.7071647e-04,\n",
            "       3.9241248e-04, 1.0194613e-03, 1.8124662e-04, 1.2734989e-03,\n",
            "       9.1573078e-04, 5.6742987e-04, 6.1246741e-04, 1.4910076e-03,\n",
            "       7.4341084e-04, 1.2465379e-03, 1.3998561e-03, 1.1846271e-03,\n",
            "       1.3166436e-03, 7.8985345e-04, 1.5864155e-03, 1.8819969e-03,\n",
            "       2.3684483e-03, 1.5967137e-03, 2.2946082e-03, 6.9121347e-04,\n",
            "       1.0338855e-03, 1.1697857e-03, 1.1130505e-03, 1.0314643e-03,\n",
            "       2.2566180e-04, 1.6227455e-03, 1.0726724e-03, 1.6421668e-04,\n",
            "       1.4191215e-03, 4.6958119e-04, 1.2582203e-03, 1.2046292e-03,\n",
            "       1.4428985e-03, 9.2223356e-04, 7.8436639e-04, 1.2866489e-03,\n",
            "       1.3443296e-03, 8.3728734e-04, 1.3692516e-03, 9.3097350e-04,\n",
            "       1.0969733e-03, 7.9569820e-04, 1.2805585e-03, 1.2463022e-03,\n",
            "       1.6495262e-03, 2.4064595e-03, 5.0458073e-04, 1.4286652e-03,\n",
            "       1.4010966e-03, 1.0375690e-03, 1.2615382e-03, 9.3208188e-03,\n",
            "       1.1545097e-03, 1.3996487e-03, 2.2960557e-03, 1.3783778e-03,\n",
            "       1.5422548e-03, 1.1332633e-03, 1.1888084e-03, 1.3796693e-03,\n",
            "       1.6889456e-03, 1.3775370e-03, 1.7346221e-04, 7.5265300e-04,\n",
            "       1.1417826e-03, 9.8309154e-04, 3.9773574e-03, 5.2640948e-04,\n",
            "       1.3072102e-03, 9.8177139e-04, 1.2430953e-03, 2.3615033e-04,\n",
            "       1.5561848e-03, 1.6274085e-04, 2.3513351e-04, 1.1593665e-03,\n",
            "       1.2092569e-03, 1.1962509e-03, 1.4010582e-03, 1.0093565e-03,\n",
            "       9.3033846e-04, 1.2749445e-03, 6.6384574e-04, 2.2411685e-04,\n",
            "       9.9611806e-04, 1.6589597e-03, 1.1753542e-03, 1.5928550e-04,\n",
            "       1.5986740e-03, 1.1330084e-03, 8.8912988e-04, 1.0089951e-03,\n",
            "       1.0267098e-03, 1.1277603e-03, 6.9818122e-04, 1.5139997e-03,\n",
            "       2.2500157e-04, 3.5604119e-04, 6.1217003e-04, 1.3392423e-03,\n",
            "       1.4184690e-03, 1.8489477e-04, 1.1250350e-03, 1.0348327e-03,\n",
            "       1.2466828e-03, 1.0875444e-03, 5.0694274e-04, 2.3389708e-03,\n",
            "       1.0588793e-04, 1.0946395e-03, 1.3193028e-03, 1.4003926e-03,\n",
            "       1.2197412e-03, 1.3634145e-03, 6.3830230e-04, 1.7904056e-03,\n",
            "       1.4517579e-03, 3.7989061e-04, 9.8865584e-04, 1.2272616e-03,\n",
            "       1.1706039e-03, 3.6915269e-04, 2.7827825e-04, 2.2002266e-04,\n",
            "       1.5400735e-03, 8.5945381e-04, 3.0312801e-03, 1.1712004e-03,\n",
            "       1.0649393e-03, 1.1458831e-03, 9.1012137e-04, 1.1447677e-03,\n",
            "       2.9619041e-04, 1.3503981e-04, 9.6661603e-04, 1.5050336e-03,\n",
            "       1.0900218e-03, 1.4092106e-03, 1.6868928e-04, 6.6482625e-04,\n",
            "       2.8941666e-03, 1.1231777e-03, 1.1689091e-03, 1.1016180e-04,\n",
            "       1.1694098e-03, 8.2738500e-04, 1.2417577e-03, 1.2365530e-03,\n",
            "       5.7498779e-04, 1.0484746e-03, 3.2509983e-04, 1.4035958e-04,\n",
            "       1.0824819e-03, 1.4125798e-03, 1.1347057e-03, 9.8182145e-04,\n",
            "       1.0754267e-03, 9.7268341e-05, 5.5647374e-04, 6.0075818e-04,\n",
            "       8.9274405e-04, 4.2474372e-04, 1.1696166e-03, 9.9450117e-04,\n",
            "       1.5589230e-03, 1.2458517e-03, 1.2954026e-03, 1.3770091e-03,\n",
            "       1.4875844e-04, 6.3210010e-04, 3.2873862e-04, 1.5168906e-04,\n",
            "       1.0655385e-03, 4.5787287e-04, 1.2890549e-04, 1.2869342e-03,\n",
            "       1.0840006e-03, 3.3023232e-04, 1.9006456e-03, 1.1668768e-03,\n",
            "       1.2111691e-03, 2.0263709e-04, 2.1315386e-04, 1.6278304e-04,\n",
            "       1.3594730e-03, 1.2258784e-03, 5.3599756e-04, 2.5084461e-03,\n",
            "       1.3380065e-03, 1.0062550e-03, 5.0314394e-04, 9.2592544e-04,\n",
            "       1.2041131e-03, 6.4414635e-04, 1.0254667e-03, 1.9981670e-04,\n",
            "       1.1363018e-03, 1.5623320e-04, 1.3237537e-03, 1.0001094e-03,\n",
            "       1.3314011e-03, 1.0948578e-03, 1.2958702e-03, 1.3431435e-03,\n",
            "       9.7355217e-04, 7.8837050e-04, 1.8167485e-03, 1.4641563e-03,\n",
            "       1.2903874e-04, 6.6983316e-04, 7.0568634e-04, 1.2359768e-04,\n",
            "       3.6756162e-04, 4.0296523e-04, 1.4421785e-03, 1.1329721e-03,\n",
            "       1.2703398e-03, 1.1913140e-03, 1.1612913e-03, 2.7674000e-04,\n",
            "       1.2858993e-03, 4.1896332e-04, 5.1542505e-04, 1.1946628e-03,\n",
            "       1.7748111e-04, 2.5779859e-04, 1.6124633e-03, 8.1304373e-04,\n",
            "       9.1100030e-04, 1.3709212e-04, 1.4311817e-03, 1.1395245e-03,\n",
            "       1.2682845e-03, 1.3343287e-03, 9.6342375e-04, 1.4031237e-03,\n",
            "       1.0960879e-03, 5.5613642e-04, 3.5931656e-04, 1.4909246e-03,\n",
            "       1.0197695e-03, 9.0867421e-04, 9.7074010e-04, 1.1339028e-03,\n",
            "       1.5792169e-03, 1.2550872e-03, 9.7373949e-04, 3.1278195e-04,\n",
            "       1.3218807e-03, 9.5323625e-04, 1.2027021e-03, 1.9126736e-04,\n",
            "       1.0110709e-03, 7.2289276e-04, 1.3587048e-03, 1.0820382e-03,\n",
            "       2.0239814e-03, 1.3571399e-03, 1.0265375e-03, 1.1425433e-03,\n",
            "       1.3923519e-03, 1.5502101e-04, 7.2499691e-04, 1.2639875e-03,\n",
            "       5.3200359e-04, 2.5481472e-04, 1.0413311e-03, 1.3314264e-03,\n",
            "       1.2413494e-03, 1.4171749e-03, 1.1367005e-03, 1.0337669e-03,\n",
            "       8.4046187e-04, 1.4915622e-03, 1.0623272e-03, 1.2685098e-03,\n",
            "       1.7429355e-03, 1.0337981e-03, 1.0007338e-03, 1.0491867e-03,\n",
            "       8.9402666e-04, 1.5418972e-03, 1.6193913e-04, 1.0690937e-03,\n",
            "       1.1881616e-03, 1.6996801e-03, 1.1311335e-03, 1.1282895e-03,\n",
            "       1.1234238e-03, 9.9197589e-04, 8.5125992e-04, 9.7452255e-04,\n",
            "       4.9844687e-03, 1.3753241e-03, 7.3710020e-04, 6.4242387e-04,\n",
            "       4.8891071e-04, 1.4531893e-03, 1.5916651e-03, 7.5847271e-04,\n",
            "       8.9470000e-04, 2.6254775e-03, 1.3701888e-03, 1.0070374e-03,\n",
            "       5.2688387e-04, 1.1443003e-03, 1.4542246e-03, 1.1771297e-03,\n",
            "       9.2125480e-04, 1.0937660e-03, 5.9311447e-04, 1.5997371e-03,\n",
            "       9.5519098e-04, 8.3658018e-04, 1.3766533e-03, 1.5376695e-03,\n",
            "       9.4674178e-04, 1.2780544e-03, 5.5725430e-04, 1.4428385e-03,\n",
            "       7.5447035e-04, 1.3042620e-04, 1.2205543e-03, 7.5071846e-04,\n",
            "       1.8241057e-04, 1.0890992e-03, 1.4388607e-03, 3.7473842e-04,\n",
            "       2.6915324e-04, 9.7842491e-04, 6.3515810e-04, 5.4056523e-04,\n",
            "       1.7600510e-03, 3.6566597e-04, 1.3113882e-03, 1.1633366e-03,\n",
            "       2.9902009e-04, 1.4470224e-03, 1.5666506e-03, 2.2441265e-03,\n",
            "       8.2007918e-04, 1.5078157e-03, 1.1927910e-03, 9.0308738e-04,\n",
            "       1.0062811e-03, 1.1232353e-03, 1.0698558e-03, 2.8883683e-04,\n",
            "       5.1127328e-04, 1.1138747e-03, 4.1649314e-03, 1.4004997e-03,\n",
            "       8.4762403e-04, 9.1290806e-04, 2.0196842e-04, 5.4022955e-04,\n",
            "       1.7047142e-04, 1.0354585e-03, 1.1946270e-03, 3.7747396e-03,\n",
            "       1.4850687e-03, 9.8789844e-04, 1.7769470e-04, 2.0867733e-04,\n",
            "       1.1176092e-03, 2.1788438e-03, 1.2276105e-03, 1.2263203e-03,\n",
            "       4.2092399e-04, 1.0797322e-03, 1.3951659e-03, 9.8228722e-04,\n",
            "       1.5494946e-03, 1.4278871e-03, 9.4463740e-04, 1.1040352e-03,\n",
            "       1.3689957e-04, 1.9190565e-03, 9.6304878e-04, 1.6626803e-03,\n",
            "       1.3266725e-03, 1.3645722e-03, 1.5545887e-03, 7.4009126e-04,\n",
            "       1.5234729e-04, 3.2199020e-04, 1.7785392e-03, 1.2510023e-03,\n",
            "       1.8499541e-03, 1.6898331e-03, 9.1034384e-04, 1.0204691e-03,\n",
            "       1.5857348e-03, 1.0952593e-03, 2.8272297e-03, 9.4939186e-04,\n",
            "       1.5176965e-03, 1.4315523e-03, 1.2738017e-03, 1.3054875e-03,\n",
            "       1.1408911e-03, 1.1338632e-03, 1.4551099e-03, 1.4366461e-03,\n",
            "       1.2758673e-03, 2.1732415e-04, 7.3486473e-04, 7.6737284e-04,\n",
            "       1.2238258e-03, 1.0697823e-03, 1.6994143e-04, 9.0269686e-04,\n",
            "       1.5397111e-03, 1.4560594e-04, 1.2882539e-03, 2.1510242e-04,\n",
            "       1.4876042e-03, 1.3533824e-03, 1.1488078e-03, 8.0241985e-04,\n",
            "       9.6451462e-04, 8.4702962e-04, 1.1814196e-03, 1.2636476e-03,\n",
            "       5.4674578e-04, 1.0408970e-03, 1.2253758e-03, 1.3357310e-03,\n",
            "       4.3829161e-04, 9.7231103e-05, 2.9981486e-04, 1.4005152e-03,\n",
            "       1.3280828e-03, 1.2505199e-03, 5.5515289e-04, 1.3181624e-03,\n",
            "       1.2980418e-03, 2.5359189e-04, 1.0356072e-03, 1.5679235e-04,\n",
            "       1.5093102e-03, 1.3543216e-03, 1.6177631e-03, 1.0789965e-03,\n",
            "       1.0781917e-03, 5.3505792e-04, 9.7393646e-04, 9.5807551e-04,\n",
            "       4.6057155e-04, 1.3528074e-03, 3.0664634e-04, 1.1845089e-03,\n",
            "       9.3950875e-05, 1.4443492e-03, 7.2994386e-04, 1.3680781e-04,\n",
            "       1.1082465e-03, 8.2788238e-04, 2.0202127e-04, 1.5213812e-04,\n",
            "       1.2549318e-03, 1.5161930e-03, 1.4675541e-04, 1.5652194e-03,\n",
            "       7.1148039e-04, 1.0478161e-03, 1.6450828e-03, 2.4193349e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 203, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([8.58873245e-05, 3.01771197e-05, 1.24766710e-04, 1.43565863e-04,\n",
            "       1.36884133e-04, 1.35270777e-04, 2.13442545e-04, 3.22158419e-04,\n",
            "       1.68656101e-04, 1.03199971e-04, 4.04488746e-05, 9.60088728e-05,\n",
            "       3.92193651e-05, 7.03664409e-05, 1.13863360e-04, 2.78351417e-05,\n",
            "       3.31928095e-05, 1.72726577e-04, 7.42632838e-05, 9.04855187e-05,\n",
            "       4.44614452e-05, 4.25953767e-05, 1.29550419e-04, 6.42668310e-05,\n",
            "       3.93015434e-05, 9.42210609e-05, 1.33745998e-04, 6.78199358e-05,\n",
            "       1.08503002e-04, 3.69935115e-05, 9.44224885e-05, 7.30132961e-05,\n",
            "       7.01030367e-05, 8.43950547e-05, 9.72240450e-05, 8.87406204e-05,\n",
            "       2.63585534e-04, 1.28868618e-04, 1.39428332e-04, 7.41751574e-05,\n",
            "       3.38830141e-05, 1.07582833e-03, 1.35175665e-04, 2.30073740e-04,\n",
            "       9.43407867e-05, 2.53050785e-05, 1.37719180e-04, 4.71281019e-05,\n",
            "       4.04765669e-05, 2.04783195e-04, 1.06444182e-04, 4.30602522e-05,\n",
            "       4.84034608e-05, 5.38487075e-05, 5.03805277e-05, 1.66566591e-04,\n",
            "       8.80469670e-05, 5.01831091e-05, 4.52874083e-05, 9.82906786e-05,\n",
            "       4.78826878e-05, 1.78118862e-04, 7.71935884e-05, 1.30808432e-04,\n",
            "       6.93497859e-05, 1.25074803e-04, 3.60300110e-05, 3.87550273e-04,\n",
            "       5.82699649e-05, 6.60483565e-05, 1.11987276e-04, 1.45697326e-04,\n",
            "       1.07081447e-04, 3.77731958e-05, 1.99698829e-04, 1.33677910e-04,\n",
            "       1.19067292e-04, 1.53098968e-04, 1.09957851e-04, 8.45244795e-04,\n",
            "       5.56918239e-05, 1.17061070e-04, 3.21370972e-05, 1.09785120e-04,\n",
            "       4.44153666e-05, 2.10230864e-04, 8.38455380e-05, 1.56942086e-04,\n",
            "       7.52976048e-05, 1.46346370e-04, 8.11104546e-05, 1.08375942e-04,\n",
            "       1.20616431e-04, 2.68738979e-04, 6.06218928e-05, 2.66993884e-04,\n",
            "       2.88624469e-05, 4.28633139e-05, 1.24986400e-04, 3.16769911e-05,\n",
            "       1.09282220e-04, 1.34690708e-04, 1.71472697e-04, 1.99235350e-04,\n",
            "       1.58002556e-04, 1.28913802e-04, 1.46661274e-04, 3.41643427e-05,\n",
            "       3.26418449e-05, 7.99385307e-05, 9.58540404e-05, 5.51676858e-05,\n",
            "       1.23117454e-04, 1.05687810e-04, 1.40642922e-04, 2.37317916e-04,\n",
            "       6.24430759e-05, 3.35300210e-05, 1.37318013e-04, 4.76227033e-05,\n",
            "       1.24154991e-04, 5.43056012e-05, 5.35214240e-05, 1.02711871e-04,\n",
            "       3.97608164e-05, 2.58619373e-04, 9.79365796e-05, 2.95438622e-05,\n",
            "       2.78234365e-04, 1.46022096e-04, 6.73348768e-05, 1.47098021e-04,\n",
            "       4.02845108e-05, 2.69576576e-05, 7.73487845e-05, 1.20074757e-04,\n",
            "       7.69374383e-05, 1.14244322e-04, 9.55340001e-05, 1.17176642e-04,\n",
            "       1.83683398e-04, 8.75411133e-05, 4.27152008e-05, 9.53756316e-05,\n",
            "       1.03993174e-04, 3.49785150e-05, 3.49173133e-05, 9.02350657e-05,\n",
            "       1.26744271e-04, 4.24086429e-05, 8.72994933e-05, 6.77778589e-05,\n",
            "       1.37622861e-04, 2.19010137e-04, 2.17903784e-04, 1.24122962e-04,\n",
            "       2.81325832e-04, 1.28842890e-04, 6.27097397e-05, 2.59200733e-05,\n",
            "       2.40567490e-04, 1.28723579e-04, 1.95819783e-04, 1.36734365e-04,\n",
            "       1.28898901e-04, 1.30144530e-04, 1.45073747e-04, 1.00010817e-04,\n",
            "       4.33856112e-05, 3.82691760e-05, 7.08383668e-05, 2.70095130e-04,\n",
            "       2.61680281e-04, 5.52872261e-05, 9.44294094e-04, 3.99384626e-05,\n",
            "       2.86611248e-05, 3.85462954e-05, 9.74468130e-05, 2.47320917e-04,\n",
            "       1.09931701e-04, 1.77324822e-04, 3.01650143e-04, 6.29840506e-05,\n",
            "       3.76422176e-05, 8.87863425e-05, 3.06237962e-05, 1.11077687e-04,\n",
            "       1.04564926e-04, 1.49435597e-04, 2.39379791e-04, 4.08821506e-05,\n",
            "       4.60498704e-05, 4.94708547e-05, 1.12629343e-04, 1.35988928e-04,\n",
            "       1.71530337e-04, 1.71988242e-04, 8.96656275e-05, 5.80248961e-05,\n",
            "       9.21724059e-05, 1.72589789e-04, 1.61450764e-04, 2.66918680e-04,\n",
            "       1.67703663e-04, 7.72019775e-05, 1.21943827e-04, 1.55818721e-04,\n",
            "       3.58820718e-04, 1.18117227e-04, 2.62727146e-04, 3.20147410e-05,\n",
            "       4.00035060e-05, 3.68404057e-04, 1.53786663e-04, 1.11613888e-04,\n",
            "       1.25401988e-04, 6.84257757e-05, 1.26950283e-04, 1.29366526e-04,\n",
            "       1.47027415e-04, 5.99944979e-05, 1.88817619e-04, 1.53236411e-04,\n",
            "       1.28156113e-04, 5.59035216e-05, 2.00907438e-04, 2.77238141e-05,\n",
            "       8.56827755e-05, 4.23127749e-05, 9.24264750e-05, 4.34907779e-05,\n",
            "       1.13788396e-04, 9.82443235e-05, 1.35132592e-04, 7.72998101e-05,\n",
            "       1.45148209e-04, 1.02761820e-04, 1.16521296e-04, 1.17268588e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 204, 'shape': array([240,   1,   1, 960], dtype=int32), 'shape_signature': array([240,   1,   1, 960], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.0009886 , 0.00034735, 0.00143612, 0.0016525 , 0.0015756 ,\n",
            "       0.00155702, 0.00245682, 0.00370818, 0.0019413 , 0.00118788,\n",
            "       0.00046558, 0.0011051 , 0.00045143, 0.00080995, 0.00131062,\n",
            "       0.00032039, 0.00038206, 0.00198816, 0.0008548 , 0.00104153,\n",
            "       0.00051177, 0.00049029, 0.00149118, 0.00073974, 0.00045238,\n",
            "       0.00108452, 0.00153947, 0.00078064, 0.00124892, 0.00042581,\n",
            "       0.00108684, 0.00084041, 0.00080692, 0.00097142, 0.00111909,\n",
            "       0.00102144, 0.00303398, 0.00148333, 0.00160488, 0.00085379,\n",
            "       0.00039001, 0.01238325, 0.00155593, 0.00264825, 0.0010859 ,\n",
            "       0.00029127, 0.00158521, 0.00054246, 0.0004659 , 0.00235714,\n",
            "       0.00122522, 0.00049564, 0.00055714, 0.00061982, 0.0005799 ,\n",
            "       0.00191725, 0.00101346, 0.00057763, 0.00052128, 0.00113137,\n",
            "       0.00055115, 0.00205022, 0.00088853, 0.00150566, 0.00079825,\n",
            "       0.00143966, 0.00041472, 0.00446087, 0.00067071, 0.00076024,\n",
            "       0.00128902, 0.00167704, 0.00123255, 0.00043479, 0.00229862,\n",
            "       0.00153869, 0.00137052, 0.00176223, 0.00126566, 0.00972913,\n",
            "       0.00064104, 0.00134742, 0.00036991, 0.00126367, 0.00051124,\n",
            "       0.00241985, 0.0009651 , 0.00180647, 0.00086671, 0.00168451,\n",
            "       0.00093362, 0.00124745, 0.00138835, 0.0030933 , 0.00069778,\n",
            "       0.00307321, 0.00033222, 0.00049338, 0.00143865, 0.00036462,\n",
            "       0.00125789, 0.00155035, 0.00197372, 0.00229328, 0.00181868,\n",
            "       0.00148385, 0.00168813, 0.00039325, 0.00037572, 0.00092013,\n",
            "       0.00110332, 0.000635  , 0.00141713, 0.00121651, 0.00161886,\n",
            "       0.00273163, 0.00071875, 0.00038594, 0.00158059, 0.00054816,\n",
            "       0.00142908, 0.00062508, 0.00061605, 0.00118226, 0.00045766,\n",
            "       0.00297682, 0.00112729, 0.00034006, 0.0032026 , 0.00168078,\n",
            "       0.00077505, 0.00169316, 0.00046369, 0.00031029, 0.00089032,\n",
            "       0.00138211, 0.00088558, 0.001315  , 0.00109964, 0.00134875,\n",
            "       0.00211428, 0.00100764, 0.00049167, 0.00109781, 0.00119701,\n",
            "       0.00040262, 0.00040191, 0.00103864, 0.00145888, 0.00048814,\n",
            "       0.00100485, 0.00078015, 0.0015841 , 0.0025209 , 0.00250817,\n",
            "       0.00142871, 0.00323818, 0.00148304, 0.00072182, 0.00029835,\n",
            "       0.00276904, 0.00148166, 0.00225397, 0.00157387, 0.00148368,\n",
            "       0.00149802, 0.00166986, 0.00115117, 0.00049939, 0.00044049,\n",
            "       0.00081538, 0.00310891, 0.00301205, 0.00063638, 0.01086923,\n",
            "       0.00045971, 0.0003299 , 0.00044368, 0.00112165, 0.00284677,\n",
            "       0.00126536, 0.00204108, 0.00347212, 0.00072497, 0.00043328,\n",
            "       0.00102197, 0.00035249, 0.00127855, 0.00120359, 0.00172007,\n",
            "       0.00275536, 0.00047057, 0.00053005, 0.00056943, 0.00129641,\n",
            "       0.00156529, 0.00197439, 0.00197966, 0.00103209, 0.00066789,\n",
            "       0.00106094, 0.00198658, 0.00185837, 0.00307235, 0.00193034,\n",
            "       0.00088863, 0.00140363, 0.00179354, 0.00413018, 0.00135958,\n",
            "       0.0030241 , 0.0003685 , 0.00046046, 0.00424049, 0.00177015,\n",
            "       0.00128472, 0.00144343, 0.00078761, 0.00146125, 0.00148906,\n",
            "       0.00169235, 0.00069056, 0.00217337, 0.00176382, 0.00147513,\n",
            "       0.00064347, 0.00231253, 0.00031911, 0.00098625, 0.00048704,\n",
            "       0.00106387, 0.0005006 , 0.00130975, 0.00113083, 0.00155543,\n",
            "       0.00088975, 0.00167072, 0.00118283, 0.00134121, 0.00134981],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 205, 'shape': array([480], dtype=int32), 'shape_signature': array([480], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00795424, 0.00100657, 0.00101642, 0.00303199, 0.00088456,\n",
            "       0.00155332, 0.00377295, 0.00219936, 0.00141263, 0.00671289,\n",
            "       0.00097823, 0.00118457, 0.00339124, 0.0065183 , 0.00162083,\n",
            "       0.00206058, 0.01389888, 0.00415683, 0.002148  , 0.00465868,\n",
            "       0.00343958, 0.00087505, 0.00103635, 0.00231936, 0.00606197,\n",
            "       0.0028649 , 0.00496781, 0.00648788, 0.00573895, 0.0060333 ,\n",
            "       0.03160416, 0.00385081, 0.00170529, 0.0059807 , 0.0025296 ,\n",
            "       0.00621009, 0.00109298, 0.00133778, 0.00100081, 0.0012104 ,\n",
            "       0.00170327, 0.00097809, 0.00103921, 0.0020233 , 0.00128493,\n",
            "       0.00067941, 0.01270385, 0.00093708, 0.01453576, 0.00621223,\n",
            "       0.0009862 , 0.00139874, 0.00443392, 0.00232429, 0.00134311,\n",
            "       0.00882604, 0.00143167, 0.01187416, 0.00057433, 0.00521956,\n",
            "       0.00084825, 0.00226945, 0.00119977, 0.00947965, 0.00139809,\n",
            "       0.00677942, 0.00708678, 0.00097302, 0.00113285, 0.00433367,\n",
            "       0.00155677, 0.00208571, 0.00333407, 0.00337207, 0.00139235,\n",
            "       0.00661977, 0.00966618, 0.00489901, 0.00945102, 0.00263357,\n",
            "       0.00172626, 0.00297306, 0.00100867, 0.00167973, 0.00679234,\n",
            "       0.00195211, 0.00295278, 0.00461574, 0.00152821, 0.00059491,\n",
            "       0.00100439, 0.00224476, 0.00215233, 0.00106162, 0.00212477,\n",
            "       0.00161818, 0.00082906, 0.00402893, 0.00165606, 0.00170543,\n",
            "       0.00732   , 0.00118048, 0.00095523, 0.00106445, 0.00090832,\n",
            "       0.0021884 , 0.00359439, 0.00203992, 0.00221682, 0.00310637,\n",
            "       0.00436463, 0.00204324, 0.00150899, 0.00159605, 0.00420159,\n",
            "       0.00983728, 0.00064037, 0.00496795, 0.00122406, 0.00159979,\n",
            "       0.00124213, 0.00140747, 0.01677893, 0.00389972, 0.00296302,\n",
            "       0.00108185, 0.0008965 , 0.00934887, 0.00485186, 0.0030326 ,\n",
            "       0.00873855, 0.00561151, 0.00468523, 0.00340251, 0.00267494,\n",
            "       0.00076324, 0.00995474, 0.0010959 , 0.00796299, 0.0063542 ,\n",
            "       0.00554376, 0.00094863, 0.00134071, 0.01003866, 0.00198095,\n",
            "       0.00104967, 0.00549726, 0.00623173, 0.00135827, 0.00624481,\n",
            "       0.00092569, 0.00096174, 0.00287933, 0.00169677, 0.00336952,\n",
            "       0.00082205, 0.00275049, 0.0010252 , 0.00137879, 0.0012719 ,\n",
            "       0.00666781, 0.00542316, 0.00273374, 0.00112842, 0.00155157,\n",
            "       0.0117194 , 0.01226552, 0.00469239, 0.00184053, 0.00137543,\n",
            "       0.00116316, 0.00586507, 0.00535755, 0.00510247, 0.00125666,\n",
            "       0.00137142, 0.00375988, 0.00220933, 0.0012529 , 0.01334232,\n",
            "       0.00093459, 0.00698657, 0.0055565 , 0.0008275 , 0.01188622,\n",
            "       0.00140149, 0.00171997, 0.00234941, 0.00194698, 0.0028338 ,\n",
            "       0.01301828, 0.00811449, 0.00125475, 0.00269196, 0.00174454,\n",
            "       0.00111749, 0.0014378 , 0.00318276, 0.00667824, 0.00141895,\n",
            "       0.00424192, 0.00214314, 0.00121915, 0.00348731, 0.00096166,\n",
            "       0.00148892, 0.00196925, 0.00165741, 0.00165798, 0.00131782,\n",
            "       0.00212592, 0.00276382, 0.00288854, 0.00140255, 0.00163649,\n",
            "       0.00798096, 0.00113498, 0.00608133, 0.0056881 , 0.00113163,\n",
            "       0.00128063, 0.00196299, 0.00416802, 0.00105412, 0.00197793,\n",
            "       0.00288581, 0.0044992 , 0.00256419, 0.00118833, 0.00145878,\n",
            "       0.00123069, 0.003297  , 0.00108557, 0.0079678 , 0.00178778,\n",
            "       0.00134547, 0.00205971, 0.00204026, 0.00145349, 0.00102423,\n",
            "       0.00136988, 0.00101283, 0.00143625, 0.00975243, 0.00119211,\n",
            "       0.00106178, 0.00400205, 0.00204115, 0.00170908, 0.00186189,\n",
            "       0.00346779, 0.00130351, 0.00110674, 0.00124197, 0.00113805,\n",
            "       0.00175181, 0.00288941, 0.00073636, 0.00332664, 0.00347205,\n",
            "       0.00138119, 0.00181595, 0.00597049, 0.00159837, 0.00290408,\n",
            "       0.003695  , 0.00147711, 0.00367098, 0.00591584, 0.00123751,\n",
            "       0.00123237, 0.00570362, 0.00102395, 0.00139932, 0.00335636,\n",
            "       0.00387265, 0.00581201, 0.00300689, 0.00754036, 0.00120546,\n",
            "       0.00222783, 0.00211653, 0.00165342, 0.00793716, 0.00301722,\n",
            "       0.0014972 , 0.00702181, 0.00138594, 0.00328117, 0.00451515,\n",
            "       0.00139588, 0.0031366 , 0.0014574 , 0.0013852 , 0.00200421,\n",
            "       0.00235412, 0.00130998, 0.00135395, 0.01052943, 0.00190007,\n",
            "       0.00181763, 0.00314397, 0.00729578, 0.00201829, 0.03213798,\n",
            "       0.00069064, 0.00413073, 0.00158609, 0.00106892, 0.00104461,\n",
            "       0.00574885, 0.00259175, 0.00437232, 0.00557784, 0.003939  ,\n",
            "       0.00151041, 0.00724818, 0.00225524, 0.0015814 , 0.00177017,\n",
            "       0.00701796, 0.00346082, 0.00065764, 0.00108806, 0.00108064,\n",
            "       0.00103239, 0.00138119, 0.00731492, 0.00119282, 0.00100843,\n",
            "       0.00191498, 0.00912273, 0.00540582, 0.00100529, 0.00228294,\n",
            "       0.00899868, 0.00140781, 0.00105433, 0.00814536, 0.00229142,\n",
            "       0.00347915, 0.00434866, 0.00287796, 0.00369848, 0.0047114 ,\n",
            "       0.00451951, 0.00160915, 0.00140324, 0.0022245 , 0.00073036,\n",
            "       0.0035728 , 0.00206265, 0.0012535 , 0.00721017, 0.00171655,\n",
            "       0.00101991, 0.00135685, 0.00119449, 0.00198423, 0.00082856,\n",
            "       0.00122685, 0.00072169, 0.00025036, 0.0046287 , 0.00118226,\n",
            "       0.00077588, 0.00146038, 0.00174454, 0.00214544, 0.00465134,\n",
            "       0.00212504, 0.00663401, 0.00306032, 0.00189298, 0.0015165 ,\n",
            "       0.00162158, 0.00342547, 0.00310221, 0.00075154, 0.00130803,\n",
            "       0.00257071, 0.00110866, 0.00585884, 0.0009003 , 0.00112034,\n",
            "       0.00132974, 0.00102819, 0.00184155, 0.00134888, 0.00465024,\n",
            "       0.01587861, 0.00447261, 0.00247844, 0.01335303, 0.00216101,\n",
            "       0.00082403, 0.00078252, 0.00231069, 0.00642705, 0.00126243,\n",
            "       0.01522664, 0.0012552 , 0.00372043, 0.00072092, 0.00113038,\n",
            "       0.00191552, 0.00267049, 0.00238371, 0.00399908, 0.00091471,\n",
            "       0.01125284, 0.00133271, 0.00472338, 0.00160006, 0.00191211,\n",
            "       0.00126243, 0.00244811, 0.00283229, 0.00302757, 0.00221263,\n",
            "       0.00366297, 0.00146553, 0.00105907, 0.00087345, 0.00063969,\n",
            "       0.00144974, 0.00164845, 0.00112138, 0.00180422, 0.00169163,\n",
            "       0.00141565, 0.00321789, 0.00303661, 0.00941324, 0.00203265,\n",
            "       0.00136619, 0.00076001, 0.00064634, 0.00279916, 0.00518393,\n",
            "       0.00099794, 0.00109508, 0.0009652 , 0.00516501, 0.01833159,\n",
            "       0.00220335, 0.00111683, 0.000984  , 0.00218975, 0.00133818,\n",
            "       0.00125484, 0.00112578, 0.00112198, 0.00137789, 0.00087663,\n",
            "       0.00315791, 0.00158353, 0.00147636, 0.00352781, 0.00088546,\n",
            "       0.00551934, 0.0086843 , 0.00489776, 0.00225826, 0.00103123,\n",
            "       0.00553616, 0.00296086, 0.00134787, 0.00106572, 0.00261182,\n",
            "       0.00148851, 0.00106561, 0.00097693, 0.00106491, 0.00107466,\n",
            "       0.00089766, 0.00756807, 0.00204365, 0.00662486, 0.00138547],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul', 'index': 206, 'shape': array([  1,   3,   1, 480], dtype=int32), 'shape_signature': array([  1,   3,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.06637156, 0.00839896, 0.00848117, 0.02529943, 0.0073809 ,\n",
            "       0.01296118, 0.03148219, 0.01835182, 0.01178725, 0.05601354,\n",
            "       0.00816249, 0.00988429, 0.02829712, 0.05438986, 0.01352448,\n",
            "       0.01719384, 0.11597468, 0.03468532, 0.0179233 , 0.03887283,\n",
            "       0.02870045, 0.0073016 , 0.00864749, 0.01935318, 0.05058217,\n",
            "       0.02390523, 0.04145227, 0.05413604, 0.04788679, 0.0503429 ,\n",
            "       0.2637107 , 0.03213185, 0.01422923, 0.04990401, 0.0211074 ,\n",
            "       0.05181812, 0.00912   , 0.01116266, 0.00835094, 0.01009982,\n",
            "       0.01421241, 0.00816134, 0.00867138, 0.01688274, 0.0107217 ,\n",
            "       0.00566914, 0.1060032 , 0.00781917, 0.12128893, 0.05183596,\n",
            "       0.00822901, 0.01167135, 0.03699742, 0.01939428, 0.01120712,\n",
            "       0.073646  , 0.01194608, 0.09908012, 0.00479228, 0.04355289,\n",
            "       0.00707798, 0.0189367 , 0.01001105, 0.07909985, 0.01166593,\n",
            "       0.05656868, 0.05913335, 0.00811905, 0.00945274, 0.0361609 ,\n",
            "       0.01298992, 0.01740354, 0.02782003, 0.02813711, 0.01161799,\n",
            "       0.05523656, 0.08065635, 0.04087822, 0.07886097, 0.02197497,\n",
            "       0.01440419, 0.02480774, 0.00841651, 0.01401599, 0.05667644,\n",
            "       0.01628874, 0.0246385 , 0.03851458, 0.01275166, 0.00496402,\n",
            "       0.00838079, 0.0187307 , 0.01795943, 0.00885836, 0.01772943,\n",
            "       0.01350237, 0.00691781, 0.03361808, 0.01381843, 0.01423043,\n",
            "       0.06107935, 0.0098501 , 0.00797058, 0.00888193, 0.00757919,\n",
            "       0.01826041, 0.02999225, 0.01702143, 0.01849754, 0.02592008,\n",
            "       0.03641921, 0.01704913, 0.0125913 , 0.01331769, 0.03505882,\n",
            "       0.08208402, 0.0053434 , 0.04145348, 0.01021376, 0.01334891,\n",
            "       0.01036455, 0.01174422, 0.14000632, 0.03253995, 0.024724  ,\n",
            "       0.00902717, 0.00748057, 0.07800863, 0.04048479, 0.02530456,\n",
            "       0.07291596, 0.04682342, 0.03909439, 0.02839115, 0.0223202 ,\n",
            "       0.00636861, 0.08306409, 0.00914437, 0.06644458, 0.05302058,\n",
            "       0.04625808, 0.00791553, 0.01118714, 0.08376431, 0.01652939,\n",
            "       0.00875864, 0.04587012, 0.05199865, 0.01133367, 0.05210776,\n",
            "       0.00772413, 0.00802497, 0.02402565, 0.01415814, 0.02811586,\n",
            "       0.0068593 , 0.02295058, 0.00855447, 0.01150483, 0.010613  ,\n",
            "       0.05563735, 0.04525176, 0.02281078, 0.00941571, 0.01294656,\n",
            "       0.09778872, 0.1023457 , 0.03915415, 0.01535767, 0.01147683,\n",
            "       0.00970565, 0.0489392 , 0.04470433, 0.04257594, 0.0104858 ,\n",
            "       0.01144336, 0.03137311, 0.01843503, 0.01045439, 0.11133063,\n",
            "       0.00779841, 0.05829713, 0.04636439, 0.0069048 , 0.09918071,\n",
            "       0.0116943 , 0.01435176, 0.01960388, 0.01624598, 0.02364573,\n",
            "       0.10862681, 0.06770872, 0.01046988, 0.02246216, 0.01455672,\n",
            "       0.00932453, 0.01199725, 0.02655748, 0.05572443, 0.01183994,\n",
            "       0.0353953 , 0.01788277, 0.01017282, 0.02909872, 0.00802429,\n",
            "       0.01242382, 0.01643174, 0.01382971, 0.01383446, 0.01099613,\n",
            "       0.01773903, 0.02306183, 0.02410245, 0.01170309, 0.01365519,\n",
            "       0.0665945 , 0.00947048, 0.05074368, 0.04746253, 0.00944255,\n",
            "       0.01068584, 0.01637956, 0.0347787 , 0.00879577, 0.01650416,\n",
            "       0.02407974, 0.03754215, 0.02139601, 0.00991564, 0.01217234,\n",
            "       0.01026908, 0.02751073, 0.00905822, 0.0664847 , 0.01491754,\n",
            "       0.01122686, 0.01718662, 0.01702428, 0.01212815, 0.00854636,\n",
            "       0.01143049, 0.00845121, 0.01198435, 0.08137602, 0.00994716,\n",
            "       0.0088597 , 0.03339383, 0.01703175, 0.01426082, 0.01553596,\n",
            "       0.02893586, 0.01087676, 0.00923487, 0.01036319, 0.00949609,\n",
            "       0.01461742, 0.02410974, 0.00614432, 0.02775809, 0.02897141,\n",
            "       0.01152485, 0.01515261, 0.04981879, 0.01333706, 0.02423218,\n",
            "       0.03083174, 0.01232524, 0.0306313 , 0.04936277, 0.01032597,\n",
            "       0.0102831 , 0.04759204, 0.00854399, 0.01167617, 0.02800609,\n",
            "       0.03231405, 0.04849644, 0.02509001, 0.0629181 , 0.01005853,\n",
            "       0.01858945, 0.01766068, 0.01379646, 0.06622909, 0.02517617,\n",
            "       0.01249294, 0.05859121, 0.01156454, 0.02737866, 0.03767519,\n",
            "       0.0116475 , 0.02617232, 0.01216082, 0.01155833, 0.01672349,\n",
            "       0.01964317, 0.01093067, 0.0112976 , 0.08785944, 0.01585449,\n",
            "       0.01516665, 0.02623384, 0.06087729, 0.01684095, 0.2681649 ,\n",
            "       0.0057628 , 0.03446753, 0.01323459, 0.00891923, 0.00871637,\n",
            "       0.04796945, 0.02162599, 0.03648343, 0.04654246, 0.03286769,\n",
            "       0.01260311, 0.06048008, 0.01881814, 0.01319552, 0.01477059,\n",
            "       0.05855909, 0.02887767, 0.0054875 , 0.00907895, 0.00901704,\n",
            "       0.00861447, 0.01152492, 0.06103695, 0.00995309, 0.00841453,\n",
            "       0.01597893, 0.07612166, 0.04510709, 0.0083883 , 0.01904928,\n",
            "       0.07508655, 0.01174698, 0.00879749, 0.06796635, 0.01912004,\n",
            "       0.02903063, 0.03628594, 0.02401424, 0.03086076, 0.03931279,\n",
            "       0.03771159, 0.01342703, 0.01170889, 0.01856159, 0.00609422,\n",
            "       0.02981205, 0.01721111, 0.01045939, 0.06016293, 0.01432317,\n",
            "       0.00851035, 0.01132176, 0.00996707, 0.01655677, 0.00691364,\n",
            "       0.01023707, 0.00602192, 0.00208907, 0.03862267, 0.00986499,\n",
            "       0.00647409, 0.01218566, 0.01455679, 0.01790196, 0.03881162,\n",
            "       0.01773171, 0.05535538, 0.02553582, 0.01579539, 0.01265398,\n",
            "       0.01353076, 0.0285827 , 0.0258854 , 0.00627095, 0.01091441,\n",
            "       0.02145042, 0.00925085, 0.04888722, 0.00751222, 0.00934828,\n",
            "       0.01109555, 0.00857943, 0.01536625, 0.01125528, 0.03880243,\n",
            "       0.13249391, 0.03732023, 0.02068056, 0.11142007, 0.01803181,\n",
            "       0.00687584, 0.00652952, 0.01928083, 0.05362844, 0.01053394,\n",
            "       0.12705375, 0.01047358, 0.0310439 , 0.00601552, 0.00943207,\n",
            "       0.0159834 , 0.02228307, 0.01989007, 0.03336902, 0.0076325 ,\n",
            "       0.09389569, 0.01112039, 0.03941272, 0.01335118, 0.01595497,\n",
            "       0.0105339 , 0.02042742, 0.02363314, 0.02526257, 0.01846254,\n",
            "       0.03056448, 0.01222866, 0.00883706, 0.00728824, 0.00533771,\n",
            "       0.01209686, 0.01375497, 0.00935701, 0.01505474, 0.01411523,\n",
            "       0.01181243, 0.02685068, 0.02533804, 0.07854576, 0.01696081,\n",
            "       0.01139973, 0.00634163, 0.00539317, 0.02335668, 0.04325559,\n",
            "       0.008327  , 0.00913758, 0.0080538 , 0.04309774, 0.15296201,\n",
            "       0.01838512, 0.00931904, 0.00821066, 0.01827166, 0.01116602,\n",
            "       0.01047059, 0.0093937 , 0.00936202, 0.01149736, 0.00731476,\n",
            "       0.02635017, 0.01321322, 0.01231897, 0.02943666, 0.00738844,\n",
            "       0.04605434, 0.0724633 , 0.04086775, 0.01884332, 0.00860472,\n",
            "       0.0461947 , 0.02470596, 0.01124689, 0.00889259, 0.02179347,\n",
            "       0.0124204 , 0.00889162, 0.00815165, 0.0088858 , 0.00896712,\n",
            "       0.00749026, 0.06314933, 0.01705259, 0.05527901, 0.01156059],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 207, 'shape': array([480], dtype=int32), 'shape_signature': array([480], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.07989418e-04, 4.25970618e-04, 3.66899476e-04, 7.38279923e-05,\n",
            "       9.12534248e-04, 7.68237107e-04, 3.44747939e-04, 9.20011313e-04,\n",
            "       5.38751949e-04, 2.19331516e-04, 5.41508140e-04, 4.17806092e-04,\n",
            "       2.96399492e-04, 4.48291801e-04, 1.81792988e-04, 7.78706046e-04,\n",
            "       1.82593780e-04, 1.04916951e-04, 2.85310758e-04, 7.75599387e-04,\n",
            "       2.49431032e-04, 7.42076256e-04, 5.20446047e-04, 8.79039639e-04,\n",
            "       3.27313814e-04, 3.07815382e-04, 3.24416964e-04, 1.54565976e-04,\n",
            "       1.04227685e-04, 1.24239392e-04, 2.47300399e-04, 7.57745802e-05,\n",
            "       4.87596437e-04, 1.26052080e-04, 5.24323026e-04, 4.24838130e-04,\n",
            "       6.55113952e-04, 2.28609453e-04, 2.49560660e-04, 8.67396011e-04,\n",
            "       1.02806475e-03, 2.07076198e-04, 5.40582580e-04, 9.30187991e-04,\n",
            "       8.13462131e-04, 6.74177252e-04, 3.84474872e-04, 6.20282022e-04,\n",
            "       1.65940161e-04, 1.78381626e-04, 6.26530207e-04, 3.67059023e-04,\n",
            "       3.71192145e-04, 3.26946378e-04, 9.05031688e-04, 5.47755277e-04,\n",
            "       7.36290182e-04, 1.08157226e-04, 6.01338455e-04, 2.69783370e-04,\n",
            "       3.91759357e-04, 3.39977589e-04, 7.38537638e-04, 1.80435192e-04,\n",
            "       7.90736871e-04, 7.23135134e-04, 9.01001113e-05, 6.32131763e-04,\n",
            "       2.66859832e-04, 1.08832457e-04, 6.25649292e-04, 3.84028186e-04,\n",
            "       1.49817773e-04, 1.61155884e-04, 5.33481129e-04, 1.65016696e-04,\n",
            "       1.38773990e-04, 2.79913453e-04, 5.83807050e-05, 5.80475375e-04,\n",
            "       6.13348268e-04, 7.60806259e-04, 4.13427391e-04, 3.30494426e-04,\n",
            "       1.02623351e-04, 2.05955512e-04, 2.35950502e-04, 6.31245552e-04,\n",
            "       5.86758892e-04, 3.38268525e-04, 7.80567760e-04, 5.49271004e-04,\n",
            "       7.57642032e-04, 5.62742003e-04, 5.42669382e-04, 2.32149119e-04,\n",
            "       5.10169368e-04, 4.75140492e-04, 7.41213036e-04, 2.85890797e-04,\n",
            "       3.99383716e-04, 6.68760680e-04, 5.43874397e-04, 7.02060701e-04,\n",
            "       5.91039076e-04, 2.80885375e-04, 1.54339767e-04, 1.39603461e-03,\n",
            "       2.44222378e-04, 1.00601952e-04, 1.64935293e-04, 5.99936466e-04,\n",
            "       2.79178930e-04, 2.12146959e-04, 2.74656428e-04, 4.99846821e-04,\n",
            "       2.88186333e-04, 5.94049343e-04, 2.92921934e-04, 5.91960270e-04,\n",
            "       2.76095088e-04, 4.99996298e-04, 4.00920922e-04, 1.19610957e-03,\n",
            "       6.49363908e-04, 1.19517441e-03, 6.11791795e-04, 2.29557205e-04,\n",
            "       4.44528618e-04, 9.89506443e-05, 1.44115154e-04, 1.29006512e-04,\n",
            "       9.10904128e-05, 7.09469241e-05, 1.46387290e-04, 4.57828864e-04,\n",
            "       6.51546754e-04, 2.60847883e-04, 5.58168278e-04, 2.02832030e-04,\n",
            "       7.45996222e-05, 4.85279772e-04, 6.50697271e-04, 1.17973919e-04,\n",
            "       3.24166846e-04, 5.66273695e-04, 5.00346127e-04, 3.33814532e-04,\n",
            "       5.08226105e-04, 6.22049789e-04, 2.62291054e-04, 6.40214654e-04,\n",
            "       7.37470284e-04, 5.34062798e-04, 6.53400610e-04, 3.07379814e-04,\n",
            "       4.70684841e-04, 9.96212009e-04, 5.51976555e-04, 4.39620635e-04,\n",
            "       3.55157856e-04, 7.59617906e-05, 1.04174644e-04, 3.74669471e-04,\n",
            "       5.76950610e-04, 2.19321868e-04, 1.89363578e-04, 7.32559012e-04,\n",
            "       7.15985254e-04, 4.80648043e-04, 3.45342793e-04, 1.22890269e-04,\n",
            "       7.19051168e-04, 2.50609242e-04, 4.23685735e-04, 3.21010652e-04,\n",
            "       7.28555664e-04, 5.08384604e-04, 4.64523968e-04, 5.44374816e-05,\n",
            "       3.34563141e-04, 1.42289777e-04, 2.15162188e-04, 2.98563333e-04,\n",
            "       3.11573851e-04, 1.24716456e-03, 4.31703287e-04, 5.41004061e-04,\n",
            "       9.07582813e-04, 2.57764244e-04, 2.02345516e-04, 8.68660572e-05,\n",
            "       5.75172540e-04, 1.22335565e-04, 3.63005733e-04, 3.19354323e-04,\n",
            "       7.61155214e-04, 2.03983407e-04, 7.98951369e-04, 2.15737862e-04,\n",
            "       3.11225333e-04, 4.07050800e-04, 3.09042574e-04, 3.25884495e-04,\n",
            "       3.94488947e-04, 2.49840494e-04, 5.83139306e-04, 3.86315864e-04,\n",
            "       5.18992252e-04, 4.36479197e-04, 8.49783828e-04, 4.60248557e-04,\n",
            "       8.31600104e-04, 5.40175242e-04, 1.79891125e-04, 8.33699421e-04,\n",
            "       4.18866199e-04, 1.02458766e-03, 6.83008111e-05, 6.98521151e-04,\n",
            "       4.22265468e-04, 1.85236422e-04, 1.41282188e-04, 3.94682895e-04,\n",
            "       9.56454169e-05, 1.66905811e-04, 2.81203887e-04, 5.47292468e-04,\n",
            "       2.23754541e-04, 5.08656958e-04, 3.22638865e-04, 1.39866956e-04,\n",
            "       7.25560240e-04, 1.15667375e-04, 2.24116608e-04, 4.05693572e-04,\n",
            "       6.71214715e-04, 1.91511877e-04, 5.35985047e-04, 3.58933146e-04,\n",
            "       4.71223175e-04, 2.47544493e-04, 9.22338164e-04, 4.69083840e-04,\n",
            "       1.03677437e-03, 6.37954567e-04, 7.17516174e-04, 4.30589193e-04,\n",
            "       4.37559182e-04, 4.66431578e-04, 2.67833966e-04, 6.41527295e-04,\n",
            "       5.69921511e-04, 6.33157848e-04, 6.19726721e-04, 5.11240505e-04,\n",
            "       6.22424181e-04, 4.59524686e-04, 6.18661812e-04, 7.78702451e-05,\n",
            "       8.34401522e-04, 5.28158329e-04, 2.01672825e-04, 3.09929223e-04,\n",
            "       4.83354554e-04, 1.13265174e-04, 2.57805310e-04, 4.82728996e-04,\n",
            "       2.08747515e-04, 4.00328921e-04, 4.47149418e-04, 7.88029647e-05,\n",
            "       6.79280027e-04, 5.69665222e-04, 6.47792418e-04, 7.01951678e-04,\n",
            "       3.91123089e-04, 4.06448991e-04, 3.29619186e-04, 5.55804698e-04,\n",
            "       1.10252970e-03, 1.80703690e-04, 7.10879860e-04, 5.58199012e-04,\n",
            "       4.76426358e-04, 8.44200724e-04, 6.22970983e-04, 7.22459867e-04,\n",
            "       1.03317259e-04, 7.58698268e-04, 5.27433469e-04, 6.11211173e-04,\n",
            "       4.53052198e-04, 5.88871131e-04, 2.46856041e-04, 6.72872528e-04,\n",
            "       4.89307626e-04, 4.70712548e-04, 5.13692867e-05, 2.90368713e-04,\n",
            "       6.64751162e-04, 9.83657199e-04, 4.26228100e-04, 3.52072675e-04,\n",
            "       6.01790904e-04, 5.53655962e-04, 1.09588444e-04, 3.38116166e-04,\n",
            "       8.81942688e-05, 5.85571339e-04, 1.91277824e-04, 2.58153130e-04,\n",
            "       4.49918938e-04, 7.19963500e-05, 1.97229587e-04, 5.51939302e-04,\n",
            "       2.53051141e-04, 4.66899626e-04, 6.62371458e-04, 5.78345149e-04,\n",
            "       7.29774532e-04, 7.94629625e-04, 3.36333847e-04, 7.17700284e-04,\n",
            "       5.98981977e-04, 7.66989717e-04, 4.89792030e-04, 5.59283595e-04,\n",
            "       6.10062794e-04, 1.08824449e-03, 4.30437387e-04, 1.02877582e-03,\n",
            "       7.86844466e-04, 3.50916263e-04, 4.54848108e-04, 2.70330638e-04,\n",
            "       8.35638028e-04, 3.87650565e-04, 6.69185363e-04, 1.09375687e-04,\n",
            "       1.57333925e-04, 7.46101869e-05, 3.02695087e-04, 3.44580912e-04,\n",
            "       2.29257625e-04, 8.67233757e-05, 7.20138778e-04, 5.22137037e-04,\n",
            "       2.62888963e-04, 6.10809424e-04, 3.69450310e-04, 3.52746458e-04,\n",
            "       5.79632004e-04, 2.14548243e-04, 9.05492227e-04, 6.15561439e-04,\n",
            "       2.57814303e-04, 6.30700728e-04, 2.09481019e-04, 2.12474071e-04,\n",
            "       5.51798672e-04, 3.85151856e-04, 1.02486974e-03, 2.75156286e-04,\n",
            "       8.83702014e-04, 6.45619701e-04, 5.01181756e-04, 4.55224217e-04,\n",
            "       2.37955159e-04, 6.17649348e-04, 9.85131948e-04, 2.84151029e-04,\n",
            "       1.30624656e-04, 6.62433507e-04, 3.48042086e-04, 3.34628334e-04,\n",
            "       3.07801500e-04, 6.77215517e-04, 3.41318606e-04, 1.05116563e-03,\n",
            "       3.36815516e-04, 5.38631692e-04, 6.20725506e-04, 7.06743856e-04,\n",
            "       2.54579820e-04, 4.72315791e-04, 3.27999849e-04, 6.06297108e-04,\n",
            "       5.72183228e-04, 9.50688336e-05, 7.96973589e-04, 9.22610416e-05,\n",
            "       2.01625342e-04, 2.07300312e-04, 6.58761302e-04, 2.73511279e-04,\n",
            "       4.61537944e-04, 2.89745192e-04, 4.65989229e-04, 3.99357436e-04,\n",
            "       2.45263334e-04, 9.97910625e-04, 1.52941182e-04, 4.76619782e-04,\n",
            "       3.96220217e-04, 8.96483194e-04, 2.39665434e-03, 2.43526971e-04,\n",
            "       9.03176697e-05, 2.72272242e-04, 3.44972650e-04, 6.24665758e-04,\n",
            "       7.14730631e-05, 4.22435987e-04, 1.01854245e-03, 4.49985819e-04,\n",
            "       5.79568383e-04, 1.49935018e-04, 2.17940949e-04, 2.26433185e-04,\n",
            "       4.19841381e-04, 6.73796050e-04, 3.13012366e-04, 5.58149477e-04,\n",
            "       5.34307852e-04, 4.00780031e-04, 5.28966659e-04, 3.22191423e-04,\n",
            "       6.03244524e-04, 8.84221226e-04, 4.78466070e-04, 2.17892448e-04,\n",
            "       1.07795221e-03, 2.04040232e-04, 4.47291706e-04, 7.62867450e-04,\n",
            "       7.46206497e-04, 8.66659277e-04, 4.82182542e-04, 8.11842765e-05,\n",
            "       6.04337663e-04, 6.40289101e-04, 6.45230815e-04, 6.40977581e-04,\n",
            "       2.38760680e-04, 9.94879752e-04, 2.47575605e-04, 1.12115068e-03,\n",
            "       5.32590842e-04, 6.24464825e-04, 7.07425817e-04, 4.79709153e-04,\n",
            "       7.04059261e-04, 5.50021476e-04, 4.72613930e-04, 9.17366706e-04,\n",
            "       5.82507346e-04, 2.40153662e-04, 1.74047818e-04, 5.28198085e-04,\n",
            "       9.75757372e-04, 4.92399267e-04, 1.69917577e-04, 1.35646173e-04,\n",
            "       2.89460178e-04, 6.16878213e-04, 8.79409345e-05, 2.44184805e-04,\n",
            "       5.21528884e-04, 5.11684280e-04, 2.91562756e-04, 3.39899765e-04,\n",
            "       5.01601433e-04, 5.13272244e-04, 3.05218011e-04, 3.55765049e-04,\n",
            "       5.85071044e-04, 6.90812652e-04, 2.96681537e-04, 4.96952969e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 208, 'shape': array([  1,   3,   3, 480], dtype=int32), 'shape_signature': array([  1,   3,   3, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00461946, 0.00946085, 0.00814887, 0.00163973, 0.02026747,\n",
            "       0.01706262, 0.00765688, 0.02043353, 0.01196573, 0.00487137,\n",
            "       0.01202694, 0.00927951, 0.00658306, 0.0099566 , 0.00403764,\n",
            "       0.01729513, 0.00405542, 0.00233021, 0.00633678, 0.01722613,\n",
            "       0.00553989, 0.01648158, 0.01155915, 0.01952355, 0.00726967,\n",
            "       0.00683661, 0.00720533, 0.00343292, 0.00231491, 0.00275937,\n",
            "       0.00549256, 0.00168296, 0.01082956, 0.00279963, 0.01164526,\n",
            "       0.00943569, 0.01455014, 0.00507744, 0.00554276, 0.01926494,\n",
            "       0.02283341, 0.00459918, 0.01200639, 0.02065956, 0.01806707,\n",
            "       0.01497354, 0.00853922, 0.01377652, 0.00368555, 0.00396187,\n",
            "       0.01391529, 0.00815241, 0.00824421, 0.00726151, 0.02010084,\n",
            "       0.01216569, 0.01635307, 0.00240218, 0.01335578, 0.00599191,\n",
            "       0.00870101, 0.00755093, 0.01640299, 0.00400748, 0.01756234,\n",
            "       0.0160609 , 0.00200113, 0.0140397 , 0.00592698, 0.00241718,\n",
            "       0.01389573, 0.0085293 , 0.00332747, 0.00357929, 0.01184866,\n",
            "       0.00366504, 0.00308218, 0.0062169 , 0.00129664, 0.01289241,\n",
            "       0.01362252, 0.01689758, 0.00918226, 0.00734031, 0.00227927,\n",
            "       0.00457429, 0.00524048, 0.01402002, 0.01303197, 0.00751297,\n",
            "       0.01733648, 0.01219936, 0.0168273 , 0.01249855, 0.01205274,\n",
            "       0.00515605, 0.01133091, 0.01055291, 0.01646241, 0.00634966,\n",
            "       0.00887035, 0.01485324, 0.0120795 , 0.01559283, 0.01312703,\n",
            "       0.00623849, 0.0034279 , 0.03100605, 0.0054242 , 0.00223438,\n",
            "       0.00366323, 0.01332464, 0.00620059, 0.0047118 , 0.00610014,\n",
            "       0.01110164, 0.00640064, 0.01319389, 0.00650582, 0.01314749,\n",
            "       0.0061321 , 0.01110496, 0.00890449, 0.0265657 , 0.01442243,\n",
            "       0.02654493, 0.01358795, 0.00509849, 0.00987302, 0.0021977 ,\n",
            "       0.00320081, 0.00286525, 0.00202313, 0.00157574, 0.00325127,\n",
            "       0.01016842, 0.01447091, 0.00579346, 0.01239697, 0.00450492,\n",
            "       0.00165686, 0.01077811, 0.01445204, 0.00262021, 0.00719977,\n",
            "       0.01257699, 0.01111273, 0.00741405, 0.01128775, 0.01381578,\n",
            "       0.00582551, 0.01421923, 0.01637928, 0.01186158, 0.01451209,\n",
            "       0.00682693, 0.01045395, 0.02212596, 0.01225945, 0.00976401,\n",
            "       0.00788809, 0.00168712, 0.00231373, 0.00832144, 0.01281413,\n",
            "       0.00487116, 0.00420578, 0.0162702 , 0.0159021 , 0.01067524,\n",
            "       0.00767009, 0.0027294 , 0.01597019, 0.00556605, 0.0094101 ,\n",
            "       0.00712968, 0.01618129, 0.01129127, 0.01031712, 0.00120906,\n",
            "       0.00743068, 0.00316027, 0.00477877, 0.00663112, 0.00692008,\n",
            "       0.02769964, 0.00958817, 0.01201575, 0.0201575 , 0.00572497,\n",
            "       0.00449411, 0.0019293 , 0.01277463, 0.00271708, 0.00806239,\n",
            "       0.00709289, 0.01690533, 0.00453049, 0.01774478, 0.00479156,\n",
            "       0.00691234, 0.00904064, 0.00686386, 0.00723792, 0.00876164,\n",
            "       0.00554898, 0.01295158, 0.00858011, 0.01152686, 0.00969424,\n",
            "       0.01887378, 0.01022216, 0.01846991, 0.01199734, 0.0039954 ,\n",
            "       0.01851654, 0.00930306, 0.02275619, 0.00151697, 0.01551422,\n",
            "       0.00937855, 0.00411412, 0.00313789, 0.00876594, 0.00212429,\n",
            "       0.00370699, 0.00624556, 0.01215542, 0.00496961, 0.01129732,\n",
            "       0.00716584, 0.00310646, 0.01611476, 0.00256898, 0.00497765,\n",
            "       0.00901049, 0.01490774, 0.0042535 , 0.01190428, 0.00797194,\n",
            "       0.01046591, 0.00549799, 0.02048521, 0.01041839, 0.02302685,\n",
            "       0.01416903, 0.0159361 , 0.00956342, 0.00971823, 0.01035949,\n",
            "       0.00594862, 0.01424838, 0.01265801, 0.01406249, 0.01376419,\n",
            "       0.0113547 , 0.0138241 , 0.01020608, 0.01374053, 0.00172951,\n",
            "       0.01853213, 0.01173044, 0.00447917, 0.00688356, 0.01073535,\n",
            "       0.00251563, 0.00572588, 0.01072145, 0.0046363 , 0.00889134,\n",
            "       0.00993123, 0.00175022, 0.01508687, 0.01265232, 0.01438753,\n",
            "       0.01559041, 0.00868688, 0.00902727, 0.00732087, 0.01234447,\n",
            "       0.02448728, 0.00401345, 0.01578871, 0.01239765, 0.01058147,\n",
            "       0.01874977, 0.01383624, 0.0160459 , 0.00229469, 0.01685076,\n",
            "       0.01171434, 0.01357506, 0.01006233, 0.01307888, 0.00548269,\n",
            "       0.01494456, 0.01086757, 0.01045457, 0.00114092, 0.00644911,\n",
            "       0.01476418, 0.02184712, 0.00946656, 0.00781957, 0.01336583,\n",
            "       0.01229675, 0.00243397, 0.00750959, 0.0019588 , 0.01300559,\n",
            "       0.0042483 , 0.0057336 , 0.00999274, 0.00159905, 0.00438049,\n",
            "       0.01225862, 0.00562029, 0.01036988, 0.01471133, 0.0128451 ,\n",
            "       0.01620836, 0.0176488 , 0.00747   , 0.01594019, 0.01330344,\n",
            "       0.01703491, 0.01087832, 0.01242174, 0.01354955, 0.02417001,\n",
            "       0.00956005, 0.0228492 , 0.01747589, 0.00779388, 0.01010222,\n",
            "       0.00600407, 0.0185596 , 0.00860975, 0.01486267, 0.00242924,\n",
            "       0.0034944 , 0.0016571 , 0.00672289, 0.00765317, 0.00509183,\n",
            "       0.00192613, 0.01599435, 0.01159671, 0.00583879, 0.01356613,\n",
            "       0.00820552, 0.00783453, 0.01287368, 0.00476514, 0.02011106,\n",
            "       0.01367167, 0.00572608, 0.01400792, 0.00465259, 0.00471907,\n",
            "       0.0122555 , 0.00855426, 0.02276245, 0.00611125, 0.0196271 ,\n",
            "       0.01433927, 0.01113129, 0.01011057, 0.00528501, 0.01371805,\n",
            "       0.02187987, 0.00631102, 0.00290119, 0.01471271, 0.00773005,\n",
            "       0.00743213, 0.0068363 , 0.01504102, 0.00758072, 0.02334648,\n",
            "       0.0074807 , 0.01196306, 0.01378637, 0.01569684, 0.00565424,\n",
            "       0.01049018, 0.00728491, 0.01346591, 0.01270824, 0.00211149,\n",
            "       0.01770085, 0.00204913, 0.00447812, 0.00460416, 0.01463115,\n",
            "       0.00607471, 0.0102508 , 0.00643527, 0.01034966, 0.00886976,\n",
            "       0.00544732, 0.02216369, 0.00339684, 0.01058577, 0.00880009,\n",
            "       0.01991097, 0.05322991, 0.00540876, 0.00200596, 0.00604719,\n",
            "       0.00766187, 0.01387388, 0.00158742, 0.00938234, 0.02262192,\n",
            "       0.00999423, 0.01287227, 0.00333007, 0.00484049, 0.0050291 ,\n",
            "       0.00932471, 0.01496507, 0.00695203, 0.01239655, 0.01186703,\n",
            "       0.00890136, 0.0117484 , 0.0071559 , 0.01339811, 0.01963863,\n",
            "       0.01062677, 0.00483941, 0.02394142, 0.00453175, 0.00993439,\n",
            "       0.01694335, 0.01657331, 0.01924858, 0.01070932, 0.00180311,\n",
            "       0.01342239, 0.01422088, 0.01433063, 0.01423617, 0.0053029 ,\n",
            "       0.02209637, 0.00549868, 0.02490086, 0.01182889, 0.01386942,\n",
            "       0.01571199, 0.01065438, 0.01563722, 0.01221603, 0.0104968 ,\n",
            "       0.0203748 , 0.01293754, 0.00533383, 0.00386562, 0.01173133,\n",
            "       0.02167166, 0.01093623, 0.00377388, 0.00301271, 0.00642894,\n",
            "       0.01370092, 0.00195318, 0.00542337, 0.0115832 , 0.01136455,\n",
            "       0.00647564, 0.0075492 , 0.01114061, 0.01139982, 0.00677892,\n",
            "       0.00790157, 0.01299448, 0.01534301, 0.00658932, 0.01103737],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 209, 'shape': array([480], dtype=int32), 'shape_signature': array([480], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([5.64971560e-05, 1.24657556e-04, 7.50338222e-05, 1.65877384e-04,\n",
            "       1.18119278e-04, 1.37266383e-04, 5.17350491e-05, 1.39300173e-04,\n",
            "       1.11185036e-04, 9.12908363e-05, 1.61809745e-04, 1.42219404e-04,\n",
            "       6.60461737e-05, 6.14924138e-05, 9.09774099e-05, 9.73641145e-05,\n",
            "       5.65107948e-05, 2.38220979e-04, 1.01995574e-04, 4.32712586e-05,\n",
            "       8.51695004e-05, 1.18837350e-04, 1.14130155e-04, 1.26312007e-04,\n",
            "       7.66530502e-05, 1.07960332e-04, 4.23995225e-05, 5.53764621e-05,\n",
            "       1.17054100e-04, 1.46969571e-04, 2.40993759e-05, 7.74870277e-05,\n",
            "       9.73815331e-05, 1.10113477e-04, 5.50581353e-05, 4.01342440e-05,\n",
            "       1.32809102e-04, 1.47733677e-04, 1.47642626e-04, 1.30031971e-04,\n",
            "       6.93211914e-05, 1.60952841e-04, 8.92737153e-05, 7.79389229e-05,\n",
            "       9.21538740e-05, 8.76881822e-05, 1.33524245e-05, 1.53325949e-04,\n",
            "       5.33516250e-05, 7.86524106e-05, 1.45779457e-04, 1.18231779e-04,\n",
            "       8.36394393e-05, 9.29396410e-05, 1.12291767e-04, 2.37689201e-05,\n",
            "       1.10490844e-04, 7.68476893e-05, 1.30435321e-04, 7.32112749e-05,\n",
            "       1.32111498e-04, 1.11603149e-04, 9.87238454e-05, 1.30479326e-04,\n",
            "       1.10658693e-04, 3.17596605e-05, 5.99568884e-05, 1.50697029e-04,\n",
            "       1.27624517e-04, 1.31605935e-04, 1.20175922e-04, 8.20336136e-05,\n",
            "       8.00716662e-05, 8.66268529e-05, 1.05878709e-04, 8.00129710e-05,\n",
            "       5.92478573e-05, 1.08150336e-04, 1.52180597e-04, 5.78230174e-05,\n",
            "       1.47192142e-04, 1.11866924e-04, 1.03612067e-04, 5.99280102e-05,\n",
            "       1.19802382e-04, 1.22488709e-04, 6.64158506e-05, 9.71515983e-05,\n",
            "       1.01458449e-04, 1.31564011e-04, 9.34601267e-05, 9.80998666e-05,\n",
            "       1.33550653e-04, 1.40276621e-04, 9.84115250e-05, 9.57310767e-05,\n",
            "       1.19068442e-04, 5.27894736e-05, 8.84859473e-05, 1.04201405e-04,\n",
            "       6.21491490e-05, 1.22550453e-04, 1.18051626e-04, 1.15439732e-04,\n",
            "       1.20187309e-04, 8.52958401e-05, 1.57649905e-04, 5.68260439e-05,\n",
            "       1.19287550e-04, 6.19910134e-05, 5.98495899e-05, 1.21768375e-04,\n",
            "       1.18001357e-04, 6.82227983e-05, 3.62507126e-05, 2.67841951e-05,\n",
            "       1.54830326e-04, 4.63405340e-05, 9.51597322e-05, 1.04835708e-04,\n",
            "       8.78671053e-05, 1.63529839e-04, 1.70344192e-05, 6.80137164e-05,\n",
            "       1.16729032e-04, 8.57649793e-05, 6.75650444e-05, 4.23131205e-05,\n",
            "       5.78227009e-05, 1.36822055e-04, 4.86647659e-05, 7.37180962e-05,\n",
            "       2.14588275e-04, 1.12525639e-04, 8.47723641e-05, 1.03672595e-04,\n",
            "       2.71245663e-05, 1.04365361e-04, 8.50617289e-05, 3.93129048e-05,\n",
            "       1.45858692e-04, 1.92214662e-04, 8.61329027e-05, 9.03580658e-05,\n",
            "       1.50796521e-04, 1.14147733e-04, 7.49583342e-05, 3.71440183e-05,\n",
            "       9.61902333e-05, 3.49975162e-05, 7.53446657e-05, 6.54279138e-05,\n",
            "       3.65177621e-05, 5.82583416e-05, 9.96150411e-05, 8.74510370e-05,\n",
            "       6.51590599e-05, 9.12880787e-05, 1.24381710e-04, 8.56134284e-05,\n",
            "       3.43550382e-05, 2.23869967e-04, 6.74373514e-05, 8.64372050e-05,\n",
            "       9.87265303e-05, 1.19627854e-04, 5.65038354e-05, 4.04168713e-05,\n",
            "       5.43658243e-05, 7.82160423e-05, 1.03741579e-04, 7.63963471e-05,\n",
            "       3.22190535e-05, 1.74582645e-04, 1.97843096e-04, 1.22362952e-04,\n",
            "       1.09596891e-04, 1.34431481e-04, 1.19937926e-04, 1.57820672e-04,\n",
            "       9.75800431e-05, 6.35855249e-05, 1.27882740e-04, 9.64684514e-05,\n",
            "       4.81982024e-05, 1.77643946e-04, 7.94609732e-05, 7.65614022e-05,\n",
            "       1.31725130e-04, 1.29894339e-04, 8.44825045e-05, 4.94510932e-05,\n",
            "       1.03226223e-04, 1.03251848e-04, 6.06214198e-05, 1.34638016e-04,\n",
            "       1.17369978e-04, 9.48857778e-05, 3.37996753e-05, 1.90751132e-04,\n",
            "       6.06963222e-05, 9.54323041e-05, 8.84208639e-05, 8.55271355e-05,\n",
            "       1.26436178e-04, 1.08979701e-04, 1.16688068e-04, 1.21109377e-04,\n",
            "       9.98357209e-05, 8.62930901e-05, 8.21213034e-05, 8.57442355e-05,\n",
            "       8.46329713e-05, 1.35551614e-04, 7.17811927e-05, 2.72108227e-05,\n",
            "       1.04007115e-04, 3.32691125e-05, 1.10999215e-04, 1.05067105e-04,\n",
            "       1.04425591e-04, 1.11809553e-04, 1.09358982e-04, 8.56479601e-05,\n",
            "       1.60690208e-04, 7.32739791e-05, 4.45430524e-05, 7.41117692e-05,\n",
            "       1.15289091e-04, 9.02034226e-05, 1.04446364e-04, 1.16999465e-04,\n",
            "       1.08152570e-04, 7.79433831e-05, 9.92893547e-05, 1.07122796e-04,\n",
            "       1.35316906e-04, 6.88513974e-05, 1.10588175e-04, 1.44488324e-04,\n",
            "       8.70760778e-05, 8.96135680e-05, 1.27220803e-04, 3.13882083e-05,\n",
            "       1.39692216e-04, 9.41606850e-05, 6.15777681e-05, 8.37987391e-05,\n",
            "       7.61260235e-05, 7.22542100e-05, 1.31381719e-04, 1.20433921e-04,\n",
            "       8.63115129e-05, 1.35066613e-04, 1.17381525e-04, 1.21237317e-04,\n",
            "       1.02262231e-04, 1.18845717e-04, 8.26187825e-05, 1.07266635e-04,\n",
            "       1.18110846e-04, 1.34169677e-04, 6.98369622e-05, 8.89848670e-05,\n",
            "       5.16411310e-05, 2.47752410e-04, 8.21568901e-05, 6.60793812e-05,\n",
            "       8.22412912e-05, 1.18245021e-04, 1.32933652e-04, 1.54595677e-04,\n",
            "       1.19207645e-04, 7.41877739e-05, 8.06508615e-05, 9.31048417e-05,\n",
            "       6.54903852e-05, 1.00267207e-04, 5.46649389e-05, 1.13456197e-04,\n",
            "       1.07139422e-04, 1.21625933e-04, 1.29553591e-04, 2.51525344e-05,\n",
            "       5.88058392e-05, 1.16235118e-04, 5.74348669e-05, 1.23021833e-04,\n",
            "       1.78284463e-04, 4.11008041e-05, 1.26343177e-04, 4.69775659e-05,\n",
            "       1.19788769e-04, 1.19644326e-04, 1.13818503e-04, 7.55042929e-05,\n",
            "       1.10070025e-04, 5.62144050e-05, 1.07792366e-04, 1.92743042e-04,\n",
            "       1.01088452e-04, 5.67006609e-05, 4.28731983e-05, 1.17993346e-04,\n",
            "       1.01811347e-05, 1.23019228e-04, 9.72007765e-05, 1.33068781e-04,\n",
            "       1.22302343e-04, 1.19499353e-04, 3.75192321e-05, 8.09006742e-05,\n",
            "       1.00702040e-04, 1.07880631e-04, 7.90895137e-05, 1.03244573e-04,\n",
            "       2.36687833e-04, 8.58854619e-05, 8.52601370e-05, 1.27388368e-04,\n",
            "       3.25206856e-05, 8.05956442e-05, 9.63535131e-05, 1.02384991e-04,\n",
            "       1.18271026e-04, 9.81220801e-05, 1.21739991e-04, 1.32785017e-05,\n",
            "       9.31711693e-05, 1.49256201e-04, 1.18874435e-04, 1.56949427e-05,\n",
            "       4.32687484e-05, 8.58215353e-05, 1.00208541e-04, 5.51101584e-05,\n",
            "       9.58784804e-05, 1.22765981e-04, 2.27275013e-05, 1.12850248e-04,\n",
            "       1.14160350e-04, 1.36563278e-04, 9.31949617e-05, 9.97386815e-05,\n",
            "       5.51255143e-05, 1.32147514e-04, 1.18844233e-04, 1.29666310e-04,\n",
            "       5.66520685e-05, 1.59024872e-04, 6.77061907e-05, 1.37476425e-04,\n",
            "       8.00235357e-05, 4.23430720e-05, 1.38103904e-04, 2.00161652e-04,\n",
            "       1.10781701e-04, 1.39080759e-04, 2.15558874e-04, 6.06073118e-05,\n",
            "       1.10261753e-04, 1.60928583e-04, 4.90426937e-05, 3.85598905e-05,\n",
            "       9.57110969e-05, 1.08980632e-04, 6.09210365e-05, 1.11514048e-04,\n",
            "       7.96897803e-05, 4.28806270e-05, 5.93105651e-05, 1.10463072e-04,\n",
            "       8.16988322e-05, 1.49623273e-04, 5.07974109e-05, 6.37285339e-05,\n",
            "       7.51878688e-05, 9.21648607e-05, 1.37242823e-04, 4.02103979e-05,\n",
            "       1.14424991e-04, 1.24315993e-04, 2.43804770e-05, 1.70041021e-04,\n",
            "       1.94152832e-04, 1.12621477e-04, 1.31030640e-04, 1.14346112e-04,\n",
            "       1.09496592e-04, 1.27277672e-04, 1.27764961e-05, 8.40503053e-05,\n",
            "       1.03153172e-04, 9.31291070e-05, 1.49887579e-04, 8.19571505e-05,\n",
            "       1.37967610e-04, 7.40031974e-05, 2.37914173e-05, 1.34156508e-04,\n",
            "       1.90677092e-05, 5.73390062e-05, 1.33798894e-04, 1.23637205e-04,\n",
            "       1.57474438e-04, 6.76392519e-05, 1.18870703e-05, 9.07791255e-05,\n",
            "       1.55862974e-04, 1.35286566e-04, 6.23677770e-05, 8.85762420e-05,\n",
            "       2.50775105e-04, 9.12463875e-05, 6.77574790e-05, 1.81585070e-04,\n",
            "       1.15661773e-04, 9.69613684e-05, 9.08071888e-05, 1.15983872e-04,\n",
            "       4.60197734e-05, 1.13666341e-04, 9.64357969e-05, 1.31920562e-04,\n",
            "       1.48180116e-04, 9.24023407e-05, 1.23620077e-04, 1.05387371e-04,\n",
            "       8.61642038e-05, 1.38187155e-04, 8.35262399e-05, 1.40146629e-04,\n",
            "       8.47460396e-05, 3.66603927e-05, 1.01103928e-04, 1.01092854e-04,\n",
            "       8.49105782e-05, 1.03531085e-04, 1.11476009e-04, 1.03039703e-04,\n",
            "       1.28564381e-04, 1.04533741e-04, 1.17239055e-04, 3.71377319e-05,\n",
            "       6.74295225e-05, 1.50198728e-04, 1.40429416e-04, 5.88500880e-05,\n",
            "       9.45498105e-05, 7.50023755e-05, 9.75389121e-05, 8.32493824e-05,\n",
            "       1.02197853e-04, 1.27826468e-04, 9.62062768e-05, 1.00133853e-04,\n",
            "       1.34124886e-04, 1.09735411e-04, 1.22219324e-04, 1.56720096e-04,\n",
            "       8.93511460e-05, 3.64400512e-05, 1.20341807e-04, 1.06472973e-04,\n",
            "       9.60697143e-05, 5.90472519e-05, 2.82646419e-04, 9.86693994e-05,\n",
            "       1.00044628e-04, 5.25774340e-05, 7.95531814e-05, 7.23519188e-05,\n",
            "       1.47031082e-04, 9.29938615e-05, 1.18506352e-04, 1.61351636e-04,\n",
            "       2.62953145e-05, 7.06410210e-05, 4.64139302e-05, 5.92639262e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 210, 'shape': array([480,   1,   1, 144], dtype=int32), 'shape_signature': array([480,   1,   1, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.19453187e-04, 2.63566239e-04, 1.58645678e-04, 3.50718212e-04,\n",
            "       2.49742210e-04, 2.90225347e-04, 1.09384557e-04, 2.94525438e-04,\n",
            "       2.35080981e-04, 1.93018233e-04, 3.42117914e-04, 3.00697633e-04,\n",
            "       1.39642885e-04, 1.30014771e-04, 1.92355554e-04, 2.05859105e-04,\n",
            "       1.19482022e-04, 5.03675896e-04, 2.15651497e-04, 9.14893826e-05,\n",
            "       1.80075760e-04, 2.51260441e-04, 2.41307920e-04, 2.67064286e-04,\n",
            "       1.62069235e-04, 2.28262914e-04, 8.96462516e-05, 1.17083684e-04,\n",
            "       2.47490068e-04, 3.10741016e-04, 5.09538440e-05, 1.63832534e-04,\n",
            "       2.05895936e-04, 2.32815364e-04, 1.16410636e-04, 8.48567215e-05,\n",
            "       2.80801236e-04, 3.12356598e-04, 3.12164077e-04, 2.74929480e-04,\n",
            "       1.46567327e-04, 3.40306171e-04, 1.88753387e-04, 1.64787984e-04,\n",
            "       1.94842971e-04, 1.85401062e-04, 2.82313267e-05, 3.24180437e-04,\n",
            "       1.12802525e-04, 1.66296537e-04, 3.08224728e-04, 2.49980076e-04,\n",
            "       1.76840724e-04, 1.96504334e-04, 2.37420973e-04, 5.02551557e-05,\n",
            "       2.33613246e-04, 1.62480777e-04, 2.75782280e-04, 1.54792215e-04,\n",
            "       2.79326254e-04, 2.35965010e-04, 2.08734011e-04, 2.75875325e-04,\n",
            "       2.33968123e-04, 6.71501548e-05, 1.26768180e-04, 3.18622071e-04,\n",
            "       2.69839336e-04, 2.78257357e-04, 2.54090613e-04, 1.73445485e-04,\n",
            "       1.69297302e-04, 1.83157070e-04, 2.23861702e-04, 1.69173203e-04,\n",
            "       1.25269056e-04, 2.28664649e-04, 3.21758795e-04, 1.22256490e-04,\n",
            "       3.11211596e-04, 2.36522712e-04, 2.19069290e-04, 1.26707120e-04,\n",
            "       2.53300823e-04, 2.58980581e-04, 1.40424498e-04, 2.05409771e-04,\n",
            "       2.14515851e-04, 2.78168707e-04, 1.97604808e-04, 2.07414720e-04,\n",
            "       2.82369117e-04, 2.96589977e-04, 2.08073659e-04, 2.02406329e-04,\n",
            "       2.51749036e-04, 1.11613954e-04, 1.87087804e-04, 2.20315342e-04,\n",
            "       1.31403329e-04, 2.59111141e-04, 2.49599165e-04, 2.44076786e-04,\n",
            "       2.54114682e-04, 1.80342890e-04, 3.33322678e-04, 1.20148565e-04,\n",
            "       2.52212310e-04, 1.31068969e-04, 1.26541316e-04, 2.57457577e-04,\n",
            "       2.49492878e-04, 1.44244972e-04, 7.66456869e-05, 5.66304188e-05,\n",
            "       3.27361195e-04, 9.79788165e-05, 2.01198331e-04, 2.21656461e-04,\n",
            "       1.85779369e-04, 3.45754757e-04, 3.60162485e-05, 1.43802899e-04,\n",
            "       2.46802781e-04, 1.81334792e-04, 1.42854275e-04, 8.94635668e-05,\n",
            "       1.22255820e-04, 2.89285905e-04, 1.02892991e-04, 1.55863803e-04,\n",
            "       4.53708752e-04, 2.37915447e-04, 1.79236085e-04, 2.19197260e-04,\n",
            "       5.73500729e-05, 2.20661997e-04, 1.79847892e-04, 8.31201469e-05,\n",
            "       3.08392249e-04, 4.06403706e-04, 1.82112708e-04, 1.91046056e-04,\n",
            "       3.18832434e-04, 2.41345086e-04, 1.58486073e-04, 7.85344237e-05,\n",
            "       2.03377145e-04, 7.39960233e-05, 1.59302901e-04, 1.38335687e-04,\n",
            "       7.72103158e-05, 1.23176898e-04, 2.10618280e-04, 1.84899662e-04,\n",
            "       1.37767245e-04, 1.93012413e-04, 2.62982998e-04, 1.81014373e-04,\n",
            "       7.26376165e-05, 4.73333232e-04, 1.42584293e-04, 1.82756092e-04,\n",
            "       2.08739686e-04, 2.52931815e-04, 1.19467310e-04, 8.54542886e-05,\n",
            "       1.14946866e-04, 1.65373916e-04, 2.19343114e-04, 1.61526492e-04,\n",
            "       6.81214588e-05, 3.69123940e-04, 4.18304029e-04, 2.58714688e-04,\n",
            "       2.31723141e-04, 2.84231472e-04, 2.53587408e-04, 3.33683740e-04,\n",
            "       2.06315643e-04, 1.34440284e-04, 2.70385324e-04, 2.03965377e-04,\n",
            "       1.01906524e-04, 3.75596515e-04, 1.68006096e-04, 1.61875461e-04,\n",
            "       2.78509367e-04, 2.74638471e-04, 1.78623231e-04, 1.04555540e-04,\n",
            "       2.18253495e-04, 2.18307672e-04, 1.28173211e-04, 2.84668145e-04,\n",
            "       2.48157943e-04, 2.00619106e-04, 7.14634007e-05, 4.03309357e-04,\n",
            "       1.28331580e-04, 2.01774630e-04, 1.86950187e-04, 1.80831921e-04,\n",
            "       2.67326803e-04, 2.30418198e-04, 2.46716168e-04, 2.56064232e-04,\n",
            "       2.11084873e-04, 1.82451389e-04, 1.73630891e-04, 1.81290932e-04,\n",
            "       1.78941365e-04, 2.86599767e-04, 1.51768560e-04, 5.75324448e-05,\n",
            "       2.19904541e-04, 7.03416226e-05, 2.34688094e-04, 2.22145711e-04,\n",
            "       2.20789341e-04, 2.36401422e-04, 2.31220110e-04, 1.81087380e-04,\n",
            "       3.39750870e-04, 1.54924797e-04, 9.41783583e-05, 1.56696158e-04,\n",
            "       2.43758273e-04, 1.90719089e-04, 2.20833259e-04, 2.47374555e-04,\n",
            "       2.28669378e-04, 1.64797428e-04, 2.09929683e-04, 2.26492106e-04,\n",
            "       2.86103517e-04, 1.45574028e-04, 2.33819024e-04, 3.05494876e-04,\n",
            "       1.84106873e-04, 1.89471946e-04, 2.68985750e-04, 6.63647807e-05,\n",
            "       2.95354344e-04, 1.99086018e-04, 1.30195243e-04, 1.77177528e-04,\n",
            "       1.60954936e-04, 1.52768684e-04, 2.77783285e-04, 2.54636107e-04,\n",
            "       1.82490345e-04, 2.85574322e-04, 2.48182361e-04, 2.56334752e-04,\n",
            "       2.16215296e-04, 2.51278136e-04, 1.74682718e-04, 2.26796226e-04,\n",
            "       2.49724369e-04, 2.83677917e-04, 1.47657833e-04, 1.88142672e-04,\n",
            "       1.09185989e-04, 5.23828377e-04, 1.73706139e-04, 1.39713098e-04,\n",
            "       1.73884589e-04, 2.50008074e-04, 2.81064567e-04, 3.26865062e-04,\n",
            "       2.52043363e-04, 1.56856855e-04, 1.70521904e-04, 1.96853623e-04,\n",
            "       1.38467774e-04, 2.11997176e-04, 1.15579292e-04, 2.39882953e-04,\n",
            "       2.26527249e-04, 2.57156411e-04, 2.73918035e-04, 5.31805599e-05,\n",
            "       1.24334489e-04, 2.45758478e-04, 1.21435813e-04, 2.60107772e-04,\n",
            "       3.76950775e-04, 8.69003416e-05, 2.67130177e-04, 9.93257054e-05,\n",
            "       2.53272039e-04, 2.52966653e-04, 2.40648980e-04, 1.59640404e-04,\n",
            "       2.32723498e-04, 1.18855358e-04, 2.27907789e-04, 4.07520885e-04,\n",
            "       2.13733554e-04, 1.19883465e-04, 9.06477508e-05, 2.49475939e-04,\n",
            "       2.15261989e-05, 2.60102272e-04, 2.05513759e-04, 2.81350280e-04,\n",
            "       2.58586544e-04, 2.52660131e-04, 7.93277432e-05, 1.71050080e-04,\n",
            "       2.12916551e-04, 2.28094403e-04, 1.67220715e-04, 2.18292291e-04,\n",
            "       5.00434311e-04, 1.81589538e-04, 1.80267394e-04, 2.69340060e-04,\n",
            "       6.87592037e-05, 1.70405154e-04, 2.03722360e-04, 2.16474858e-04,\n",
            "       2.50063051e-04, 2.07461693e-04, 2.57397565e-04, 2.80750301e-05,\n",
            "       1.96993860e-04, 3.15575686e-04, 2.51338846e-04, 3.31841657e-05,\n",
            "       9.14840712e-05, 1.81454379e-04, 2.11873135e-04, 1.16520627e-04,\n",
            "       2.02718002e-04, 2.59566819e-04, 4.80532581e-05, 2.38601773e-04,\n",
            "       2.41371759e-04, 2.88738753e-04, 1.97044166e-04, 2.10879705e-04,\n",
            "       1.16553092e-04, 2.79402419e-04, 2.51274992e-04, 2.74156366e-04,\n",
            "       1.19780721e-04, 3.36229801e-04, 1.43152705e-04, 2.90669443e-04,\n",
            "       1.69195540e-04, 8.95268968e-05, 2.91996141e-04, 4.23206220e-04,\n",
            "       2.34228210e-04, 2.94061523e-04, 4.55760892e-04, 1.28143380e-04,\n",
            "       2.33128871e-04, 3.40254861e-04, 1.03692051e-04, 8.15280291e-05,\n",
            "       2.02364099e-04, 2.30420163e-04, 1.28806700e-04, 2.35776621e-04,\n",
            "       1.68489874e-04, 9.06634596e-05, 1.25401639e-04, 2.33554514e-04,\n",
            "       1.72737651e-04, 3.16351798e-04, 1.07402091e-04, 1.34742644e-04,\n",
            "       1.58971379e-04, 1.94866210e-04, 2.90175551e-04, 8.50177312e-05,\n",
            "       2.41931295e-04, 2.62844056e-04, 5.15481843e-05, 3.59521509e-04,\n",
            "       4.10501641e-04, 2.38118082e-04, 2.77040992e-04, 2.41764516e-04,\n",
            "       2.31511076e-04, 2.69106007e-04, 2.70136279e-05, 1.77709429e-04,\n",
            "       2.18099041e-04, 1.96904934e-04, 3.16910620e-04, 1.73283814e-04,\n",
            "       2.91707984e-04, 1.56466602e-04, 5.03027222e-05, 2.83650064e-04,\n",
            "       4.03152808e-05, 1.21233134e-04, 2.82893976e-04, 2.61408888e-04,\n",
            "       3.32951691e-04, 1.43011173e-04, 2.51330966e-05, 1.91936313e-04,\n",
            "       3.29544535e-04, 2.86039372e-04, 1.31865570e-04, 1.87278711e-04,\n",
            "       5.30219346e-04, 1.92924257e-04, 1.43261132e-04, 3.83929320e-04,\n",
            "       2.44546245e-04, 2.05007571e-04, 1.91995656e-04, 2.45227275e-04,\n",
            "       9.73006245e-05, 2.40327267e-04, 2.03896343e-04, 2.78922555e-04,\n",
            "       3.13300494e-04, 1.95368310e-04, 2.61372654e-04, 2.22822855e-04,\n",
            "       1.82178890e-04, 2.92172161e-04, 1.76601374e-04, 2.96315120e-04,\n",
            "       1.79180424e-04, 7.75118824e-05, 2.13766267e-04, 2.13742853e-04,\n",
            "       1.79528317e-04, 2.18898072e-04, 2.35696192e-04, 2.17859124e-04,\n",
            "       2.71826517e-04, 2.21018010e-04, 2.47881137e-04, 7.85211305e-05,\n",
            "       1.42567733e-04, 3.17568483e-04, 2.96913029e-04, 1.24428043e-04,\n",
            "       1.99908754e-04, 1.58579176e-04, 2.06228680e-04, 1.76016008e-04,\n",
            "       2.16079177e-04, 2.70266319e-04, 2.03411066e-04, 2.11715218e-04,\n",
            "       2.83583213e-04, 2.32016013e-04, 2.58411019e-04, 3.31356772e-04,\n",
            "       1.88917111e-04, 7.70460101e-05, 2.54441344e-04, 2.25118172e-04,\n",
            "       2.03122327e-04, 1.24844912e-04, 5.97605598e-04, 2.08618891e-04,\n",
            "       2.11526567e-04, 1.11165631e-04, 1.68201048e-04, 1.52975263e-04,\n",
            "       3.10871081e-04, 1.96618988e-04, 2.50560610e-04, 3.41149338e-04,\n",
            "       5.55967672e-05, 1.49357875e-04, 9.81339981e-05, 1.25303035e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/rezero/mul', 'index': 211, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.008088294416666031, -128), 'quantization_parameters': {'scales': array([0.00808829], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 212, 'shape': array([144], dtype=int32), 'shape_signature': array([144], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00016149, 0.00035161, 0.00047746, 0.00034054, 0.00022111,\n",
            "       0.00021638, 0.00022102, 0.00021266, 0.00045728, 0.00016936,\n",
            "       0.00043798, 0.00029013, 0.00030323, 0.00038144, 0.00033152,\n",
            "       0.00016099, 0.00020102, 0.00038637, 0.00032739, 0.00020702,\n",
            "       0.00017888, 0.00021985, 0.00025418, 0.00019479, 0.00021843,\n",
            "       0.00029219, 0.00033664, 0.0001907 , 0.00017487, 0.00037131,\n",
            "       0.00017317, 0.00023483, 0.00041781, 0.00017483, 0.00065998,\n",
            "       0.00021702, 0.0001863 , 0.00027624, 0.00029016, 0.00034713,\n",
            "       0.00024696, 0.00038898, 0.00039061, 0.00014679, 0.00034331,\n",
            "       0.00018411, 0.00026328, 0.00023645, 0.0003064 , 0.00019982,\n",
            "       0.00025135, 0.00025948, 0.0001966 , 0.0004578 , 0.00028085,\n",
            "       0.0001601 , 0.0002007 , 0.00036455, 0.00031576, 0.00024097,\n",
            "       0.00034894, 0.00023849, 0.00019876, 0.00036082, 0.00028964,\n",
            "       0.00064561, 0.00022774, 0.00040576, 0.00031877, 0.0003396 ,\n",
            "       0.0001956 , 0.00022539, 0.00040557, 0.00017953, 0.00031157,\n",
            "       0.00038728, 0.00033336, 0.00037389, 0.00033691, 0.00036751,\n",
            "       0.00036854, 0.00030544, 0.00051085, 0.00024517, 0.00025094,\n",
            "       0.00017566, 0.00017118, 0.00026096, 0.000154  , 0.00033816,\n",
            "       0.00031407, 0.00014354, 0.00042648, 0.0003452 , 0.00022054,\n",
            "       0.00029705, 0.00023114, 0.00021367, 0.00034032, 0.00038615,\n",
            "       0.00023427, 0.00029593, 0.00036411, 0.00015179, 0.00027057,\n",
            "       0.00025615, 0.00018194, 0.000374  , 0.00037683, 0.00016115,\n",
            "       0.00026992, 0.0003734 , 0.00031632, 0.00034448, 0.00020037,\n",
            "       0.00033063, 0.0004184 , 0.00015387, 0.0003458 , 0.00030666,\n",
            "       0.0004101 , 0.000277  , 0.00034874, 0.00052978, 0.00021117,\n",
            "       0.00030285, 0.00019946, 0.00023479, 0.00038532, 0.00027403,\n",
            "       0.00032791, 0.00045781, 0.0001874 , 0.00035788, 0.00024002,\n",
            "       0.00043712, 0.00028617, 0.0003491 , 0.00031185, 0.0003198 ,\n",
            "       0.00031043, 0.00028681, 0.00030231, 0.00041565], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 213, 'shape': array([144,   1,   1, 480], dtype=int32), 'shape_signature': array([144,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00478699, 0.0104227 , 0.01415357, 0.01009478, 0.0065543 ,\n",
            "       0.00641424, 0.00655185, 0.00630405, 0.01355521, 0.00502025,\n",
            "       0.012983  , 0.00860037, 0.00898877, 0.01130697, 0.00982722,\n",
            "       0.00477216, 0.00595898, 0.01145326, 0.0097048 , 0.00613677,\n",
            "       0.00530248, 0.00651704, 0.00753478, 0.00577433, 0.00647494,\n",
            "       0.00866151, 0.00997911, 0.00565286, 0.00518375, 0.01100691,\n",
            "       0.00513333, 0.00696108, 0.01238511, 0.00518238, 0.01956379,\n",
            "       0.00643325, 0.00552253, 0.00818852, 0.00860133, 0.01029015,\n",
            "       0.00732058, 0.01153057, 0.01157884, 0.00435124, 0.01017686,\n",
            "       0.00545763, 0.00780455, 0.00700919, 0.00908282, 0.00592342,\n",
            "       0.00745071, 0.00769172, 0.00582772, 0.01357077, 0.00832529,\n",
            "       0.00474579, 0.00594949, 0.01080651, 0.00936026, 0.00714298,\n",
            "       0.0103438 , 0.00706948, 0.00589186, 0.01069595, 0.00858582,\n",
            "       0.01913793, 0.00675097, 0.01202798, 0.00944935, 0.01006691,\n",
            "       0.0057983 , 0.00668137, 0.01202235, 0.00532179, 0.00923595,\n",
            "       0.01148013, 0.00988198, 0.01108326, 0.0099872 , 0.01089424,\n",
            "       0.01092468, 0.00905408, 0.01514312, 0.00726771, 0.00743863,\n",
            "       0.00520715, 0.00507433, 0.00773573, 0.00456497, 0.01002415,\n",
            "       0.00930997, 0.00425509, 0.01264218, 0.01023277, 0.00653765,\n",
            "       0.00880538, 0.00685179, 0.00633393, 0.01008807, 0.01144684,\n",
            "       0.00694444, 0.0087722 , 0.01079343, 0.00449963, 0.00802052,\n",
            "       0.00759317, 0.0053932 , 0.01108665, 0.01117045, 0.00477688,\n",
            "       0.00800115, 0.01106883, 0.00937663, 0.01021163, 0.00593947,\n",
            "       0.00980088, 0.01240264, 0.0045613 , 0.01025057, 0.0090903 ,\n",
            "       0.01215668, 0.00821109, 0.01033776, 0.01570451, 0.00625962,\n",
            "       0.00897744, 0.00591276, 0.00695981, 0.01142202, 0.00812303,\n",
            "       0.00972031, 0.013571  , 0.00555504, 0.01060869, 0.0071149 ,\n",
            "       0.01295768, 0.00848311, 0.01034853, 0.00924425, 0.00947986,\n",
            "       0.00920227, 0.00850182, 0.0089615 , 0.01232122], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block4_layer4/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block4_layer4/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block4_layer4/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer4/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 214, 'shape': array([480], dtype=int32), 'shape_signature': array([480], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([5.34722531e-05, 6.56554621e-05, 6.67366476e-05, 6.62291422e-05,\n",
            "       6.23163724e-05, 4.37174021e-05, 4.78295115e-05, 5.59824002e-05,\n",
            "       4.98346089e-05, 5.05928074e-05, 7.04730846e-05, 4.91228893e-05,\n",
            "       1.34371381e-04, 8.16273387e-05, 4.93220323e-05, 4.12771769e-05,\n",
            "       4.92518811e-05, 5.97762737e-05, 1.32761619e-04, 3.71060778e-05,\n",
            "       2.83993086e-05, 4.99276830e-05, 1.36809453e-04, 7.47573285e-05,\n",
            "       4.36171249e-05, 3.91803515e-05, 2.85791375e-05, 6.01013489e-05,\n",
            "       4.37203926e-05, 5.99600753e-05, 3.29571667e-05, 4.61055715e-05,\n",
            "       4.36957853e-05, 4.82010328e-05, 4.82092655e-05, 6.62765597e-05,\n",
            "       5.69354233e-05, 4.01401849e-05, 6.36675613e-05, 5.62802015e-05,\n",
            "       4.51094274e-05, 7.38294038e-05, 5.09930651e-05, 3.76711396e-05,\n",
            "       5.55223778e-05, 4.77866888e-05, 5.76001476e-05, 5.03839656e-05,\n",
            "       4.60873052e-05, 5.08135017e-05, 6.34320895e-05, 7.33943161e-05,\n",
            "       3.97384756e-05, 5.41963709e-05, 6.01385982e-05, 9.40451719e-05,\n",
            "       6.51446462e-05, 6.72839378e-05, 4.92275794e-05, 6.63219107e-05,\n",
            "       6.08604896e-05, 7.45002835e-05, 4.08944106e-05, 4.97077635e-05,\n",
            "       5.41385380e-05, 5.03076808e-05, 4.70368723e-05, 5.45486473e-05,\n",
            "       5.23455128e-05, 6.65320185e-05, 7.46567530e-05, 6.42561863e-05,\n",
            "       2.53498329e-05, 9.16772624e-05, 5.50999284e-05, 3.37430574e-05,\n",
            "       5.65556547e-05, 5.13537343e-05, 4.86234821e-05, 5.69650692e-05,\n",
            "       4.35054208e-05, 3.53229843e-05, 5.79004845e-05, 5.59615255e-05,\n",
            "       6.13118609e-05, 4.95688982e-05, 8.28080083e-05, 4.58085706e-05,\n",
            "       4.09089698e-05, 4.80743183e-05, 5.35177605e-05, 4.11249093e-05,\n",
            "       6.51333103e-05, 7.47835584e-05, 6.11784635e-05, 1.03512488e-04,\n",
            "       5.34588107e-05, 4.49840481e-05, 1.58568102e-04, 5.56878949e-05,\n",
            "       5.14557323e-05, 3.56244673e-05, 5.21030997e-05, 9.48580273e-05,\n",
            "       5.98591178e-05, 4.46783160e-05, 4.13264606e-05, 6.43136664e-05,\n",
            "       4.55541085e-05, 7.12509645e-05, 5.97665821e-05, 9.84614962e-05,\n",
            "       5.52192905e-05, 3.02806002e-05, 7.25626232e-05, 6.70043737e-05,\n",
            "       3.76986100e-05, 5.69884178e-05, 7.21713513e-05, 5.70381162e-05,\n",
            "       4.85603705e-05, 6.82393584e-05, 4.36188093e-05, 4.53256944e-05,\n",
            "       5.48814678e-05, 5.65030459e-05, 4.74570079e-05, 5.13906343e-05,\n",
            "       5.58857137e-05, 6.83908802e-05, 3.86134961e-05, 5.40842884e-05,\n",
            "       6.42743762e-05, 5.22935261e-05, 4.64105760e-05, 5.03336050e-05,\n",
            "       5.89556039e-05, 5.04927884e-05, 5.16097862e-05, 3.16093610e-05,\n",
            "       4.91968312e-05, 7.16939976e-05, 4.98783447e-05, 5.31260885e-05,\n",
            "       5.78988474e-05, 1.17702533e-04, 6.68514040e-05, 4.92248400e-05,\n",
            "       5.67669231e-05, 7.33537745e-05, 4.51962915e-05, 5.34396058e-05,\n",
            "       5.39851171e-05, 1.64129669e-04, 6.42343875e-05, 4.97213332e-05,\n",
            "       4.65493322e-05, 4.32284469e-05, 7.16378345e-05, 4.15574505e-05,\n",
            "       5.76135426e-05, 4.32783600e-05, 3.97590957e-05, 3.90671776e-05,\n",
            "       4.80892813e-05, 5.55807892e-05, 4.66204001e-05, 4.12815498e-05,\n",
            "       5.57515086e-05, 1.34985428e-04, 4.57946335e-05, 4.85886594e-05,\n",
            "       5.58974498e-05, 6.26396577e-05, 2.73116257e-05, 6.88263099e-05,\n",
            "       4.83431540e-05, 5.98390689e-05, 4.85599812e-05, 5.80448359e-05,\n",
            "       1.06045329e-04, 4.14173810e-05, 5.10850005e-05, 4.42983728e-05,\n",
            "       4.90400489e-05, 3.91852009e-05, 5.34459832e-05, 7.28861414e-05,\n",
            "       5.40224028e-05, 6.54078904e-05, 1.29874563e-04, 7.35228823e-05,\n",
            "       5.62894602e-05, 5.45742296e-05, 4.54830479e-05, 3.06010770e-05,\n",
            "       4.74332846e-05, 8.53507372e-05, 4.23312049e-05, 6.69531219e-05,\n",
            "       5.46645351e-05, 3.85524108e-05, 5.86305869e-05, 4.87777179e-05,\n",
            "       5.36321859e-05, 5.07706354e-05, 5.74947553e-05, 3.68703586e-05,\n",
            "       1.19806238e-04, 6.89021399e-05, 3.18894345e-05, 5.51330668e-05,\n",
            "       5.98187944e-05, 5.76547973e-05, 6.26521505e-05, 6.14971286e-05,\n",
            "       5.26284566e-05, 6.02335604e-05, 1.22905767e-04, 6.20592473e-05,\n",
            "       5.65900118e-05, 3.67280445e-05, 4.92265572e-05, 5.14246203e-05,\n",
            "       7.36078364e-05, 6.93363254e-05, 4.70034283e-05, 6.04335364e-05,\n",
            "       5.24220450e-05, 5.21847833e-05, 5.04687268e-05, 5.02035546e-05,\n",
            "       5.38441345e-05, 6.25805187e-05, 5.95254096e-05, 1.65353020e-04,\n",
            "       5.08427329e-05, 4.40349722e-05, 7.19754607e-05, 3.09076022e-05,\n",
            "       6.26838664e-05, 9.05708876e-05, 5.35456165e-05, 5.42154303e-05,\n",
            "       4.90553648e-05, 4.74399458e-05, 5.57177154e-05, 6.57839264e-05,\n",
            "       6.80422745e-05, 4.62361495e-05, 4.88282712e-05, 6.72717069e-05,\n",
            "       5.22116316e-05, 4.55055233e-05, 4.75284178e-05, 6.90443121e-05,\n",
            "       5.33892635e-05, 6.68769717e-05, 5.68341638e-05, 5.38622626e-05,\n",
            "       5.52713718e-05, 4.16185212e-05, 3.86418724e-05, 2.56375624e-05,\n",
            "       6.17022670e-05, 8.17454202e-05, 4.42225573e-05, 1.00422818e-04,\n",
            "       6.28337584e-05, 3.92229413e-05, 5.43045862e-05, 4.83573203e-05,\n",
            "       5.74670958e-05, 6.00350359e-05, 6.23782616e-05, 6.19166094e-05,\n",
            "       5.91036187e-05, 6.32449592e-05, 4.43436984e-05, 7.18734882e-05,\n",
            "       5.71389064e-05, 4.22673256e-05, 4.99848466e-05, 7.19154195e-05,\n",
            "       6.01725405e-05, 6.30389768e-05, 5.04147574e-05, 1.16945768e-04,\n",
            "       6.19880884e-05, 2.01324467e-04, 5.83215624e-05, 4.58817158e-05,\n",
            "       4.95404674e-05, 6.10599964e-05, 6.18881677e-05, 6.06675567e-05,\n",
            "       5.83103938e-05, 6.60133446e-05, 6.22708249e-05, 4.43411773e-05,\n",
            "       3.76797507e-05, 6.53418974e-05, 4.97002547e-05, 4.45378973e-05,\n",
            "       7.09965752e-05, 1.04541388e-04, 4.96922985e-05, 5.03509618e-05,\n",
            "       5.48284479e-05, 6.13799857e-05, 1.41785058e-04, 4.25823455e-05,\n",
            "       5.27963493e-05, 2.21341310e-04, 9.37340155e-05, 5.42424423e-05,\n",
            "       5.92549550e-05, 5.40080582e-05, 4.77636859e-05, 8.42775771e-05,\n",
            "       5.18960878e-05, 4.14945243e-05, 4.26577244e-05, 5.19661880e-05,\n",
            "       5.25278010e-05, 6.87559514e-05, 5.08549674e-05, 4.32763918e-05,\n",
            "       4.70591076e-05, 6.20274150e-05, 4.72025058e-05, 6.65367479e-05,\n",
            "       1.75656940e-04, 9.28649315e-05, 3.56393502e-05, 1.04178900e-04,\n",
            "       4.53086759e-05, 3.89348388e-05, 4.45764781e-05, 1.09031724e-04,\n",
            "       7.46774604e-05, 5.91820644e-05, 9.91334600e-05, 5.51327503e-05,\n",
            "       5.40757428e-05, 6.24811291e-05, 4.41400225e-05, 5.70652046e-05,\n",
            "       5.60438348e-05, 5.83886649e-05, 5.21752299e-05, 7.03607875e-05,\n",
            "       3.43369647e-05, 5.13082960e-05, 4.46294653e-05, 1.73340406e-04,\n",
            "       1.87428988e-04, 5.26860931e-05, 4.66977399e-05, 6.40833168e-05,\n",
            "       2.85562764e-05, 4.15864561e-05, 5.62360328e-05, 6.01811807e-05,\n",
            "       4.33717905e-05, 5.21077673e-05, 3.96833966e-05, 4.60405463e-05,\n",
            "       4.05684223e-05, 4.75878733e-05, 5.36559019e-05, 4.12936897e-05,\n",
            "       5.28533528e-05, 5.67339557e-05, 5.45034127e-05, 8.29993442e-05,\n",
            "       4.79454175e-05, 5.06531396e-05, 4.03598642e-05, 8.24832387e-05,\n",
            "       5.12974402e-05, 4.11951296e-05, 3.74817246e-05, 5.39191060e-05,\n",
            "       5.46425181e-05, 6.48059213e-05, 4.28174171e-05, 4.28283565e-05,\n",
            "       4.86614335e-05, 3.62116953e-05, 5.56786254e-05, 4.05132414e-05,\n",
            "       4.87562866e-05, 5.42753842e-05, 6.46239278e-05, 4.72882202e-05,\n",
            "       6.53380266e-05, 7.63338539e-05, 7.42079574e-05, 5.02567163e-05,\n",
            "       2.36452070e-05, 6.40451981e-05, 5.97707076e-05, 5.27570410e-05,\n",
            "       4.72584034e-05, 6.62681923e-05, 3.50656446e-05, 5.94772500e-05,\n",
            "       5.19484056e-05, 9.61932019e-05, 5.86359602e-05, 4.45820551e-05,\n",
            "       4.16696530e-05, 4.69003826e-05, 4.77290960e-05, 2.11108490e-04,\n",
            "       5.59838154e-05, 5.76151397e-05, 1.69587627e-04, 4.14528367e-05,\n",
            "       6.47669949e-05, 6.30644936e-05, 5.11131802e-05, 4.34124995e-05,\n",
            "       4.99252419e-05, 5.74774313e-05, 6.47225388e-05, 5.25555261e-05,\n",
            "       5.33299135e-05, 5.16048058e-05, 6.38945494e-05, 7.27623847e-05,\n",
            "       6.06545400e-05, 6.00054227e-05, 5.17340413e-05, 3.90422319e-05,\n",
            "       5.39139110e-05, 6.58614881e-05, 1.08061417e-04, 5.70297852e-05,\n",
            "       5.74767801e-05, 4.20542310e-05, 6.21741056e-05, 5.96078680e-05,\n",
            "       5.57542080e-05, 5.37493106e-05, 6.28034613e-05, 4.04523780e-05,\n",
            "       3.97442964e-05, 5.49634387e-05, 5.04035706e-05, 4.77401118e-05,\n",
            "       7.53402346e-05, 4.95500208e-05, 5.46645642e-05, 6.65372936e-05,\n",
            "       4.79119772e-05, 1.14519724e-04, 4.61295240e-05, 7.69114340e-05,\n",
            "       3.78458753e-05, 5.35328400e-05, 1.84509390e-05, 9.32476541e-05,\n",
            "       4.55991394e-05, 6.48115092e-05, 6.97016076e-05, 6.66237829e-05,\n",
            "       4.04086641e-05, 5.95076417e-05, 4.06147192e-05, 6.82222089e-05,\n",
            "       5.88095027e-05, 2.49321805e-04, 1.20203760e-04, 5.89382726e-05,\n",
            "       4.72474385e-05, 5.24735478e-05, 5.17024528e-05, 3.76149546e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 215, 'shape': array([480,   1,   1, 240], dtype=int32), 'shape_signature': array([480,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00131109, 0.00160981, 0.00163632, 0.00162388, 0.00152794,\n",
            "       0.00107191, 0.00117273, 0.00137264, 0.0012219 , 0.00124049,\n",
            "       0.00172793, 0.00120445, 0.00329466, 0.00200143, 0.00120933,\n",
            "       0.00101208, 0.00120761, 0.00146566, 0.00325519, 0.00090981,\n",
            "       0.00069632, 0.00122418, 0.00335444, 0.00183298, 0.00106945,\n",
            "       0.00096067, 0.00070073, 0.00147363, 0.00107198, 0.00147016,\n",
            "       0.00080808, 0.00113046, 0.00107138, 0.00118184, 0.00118205,\n",
            "       0.00162504, 0.001396  , 0.0009842 , 0.00156107, 0.00137994,\n",
            "       0.00110604, 0.00181023, 0.0012503 , 0.00092366, 0.00136136,\n",
            "       0.00117168, 0.0014123 , 0.00123537, 0.00113002, 0.0012459 ,\n",
            "       0.00155529, 0.00179956, 0.00097435, 0.00132884, 0.00147454,\n",
            "       0.0023059 , 0.00159729, 0.00164974, 0.00120701, 0.00162615,\n",
            "       0.00149224, 0.00182668, 0.00100269, 0.00121879, 0.00132743,\n",
            "       0.0012335 , 0.0011533 , 0.00133748, 0.00128346, 0.0016313 ,\n",
            "       0.00183051, 0.0015755 , 0.00062155, 0.00224784, 0.001351  ,\n",
            "       0.00082735, 0.00138669, 0.00125914, 0.0011922 , 0.00139673,\n",
            "       0.00106671, 0.00086609, 0.00141967, 0.00137212, 0.00150331,\n",
            "       0.00121538, 0.00203037, 0.00112318, 0.00100305, 0.00117874,\n",
            "       0.0013122 , 0.00100834, 0.00159701, 0.00183362, 0.00150004,\n",
            "       0.00253803, 0.00131076, 0.00110297, 0.00388794, 0.00136541,\n",
            "       0.00126165, 0.00087348, 0.00127752, 0.00232583, 0.00146769,\n",
            "       0.00109547, 0.00101329, 0.00157691, 0.00111694, 0.00174701,\n",
            "       0.00146542, 0.00241418, 0.00135392, 0.00074245, 0.00177917,\n",
            "       0.00164288, 0.00092433, 0.0013973 , 0.00176957, 0.00139852,\n",
            "       0.00119065, 0.00167316, 0.00106949, 0.00111134, 0.00134564,\n",
            "       0.0013854 , 0.0011636 , 0.00126005, 0.00137026, 0.00167688,\n",
            "       0.00094677, 0.0013261 , 0.00157595, 0.00128219, 0.00113794,\n",
            "       0.00123413, 0.00144554, 0.00123804, 0.00126542, 0.00077503,\n",
            "       0.00120626, 0.00175787, 0.00122297, 0.0013026 , 0.00141962,\n",
            "       0.00288595, 0.00163913, 0.00120695, 0.00139187, 0.00179857,\n",
            "       0.00110817, 0.00131029, 0.00132366, 0.0040243 , 0.00157497,\n",
            "       0.00121912, 0.00114135, 0.00105992, 0.00175649, 0.00101895,\n",
            "       0.00141263, 0.00106114, 0.00097486, 0.00095789, 0.0011791 ,\n",
            "       0.00136279, 0.00114309, 0.00101218, 0.00136697, 0.00330972,\n",
            "       0.00112284, 0.00119135, 0.00137055, 0.00153587, 0.00066966,\n",
            "       0.00168756, 0.00118533, 0.0014672 , 0.00119064, 0.0014232 ,\n",
            "       0.00260013, 0.00101551, 0.00125256, 0.00108615, 0.00120242,\n",
            "       0.00096078, 0.00131044, 0.0017871 , 0.00132458, 0.00160374,\n",
            "       0.0031844 , 0.00180271, 0.00138016, 0.00133811, 0.0011152 ,\n",
            "       0.00075031, 0.00116302, 0.00209272, 0.00103792, 0.00164163,\n",
            "       0.00134032, 0.00094527, 0.00143757, 0.00119598, 0.00131501,\n",
            "       0.00124485, 0.00140972, 0.00090403, 0.00293754, 0.00168942,\n",
            "       0.0007819 , 0.00135181, 0.0014667 , 0.00141364, 0.00153617,\n",
            "       0.00150785, 0.0012904 , 0.00147687, 0.00301353, 0.00152163,\n",
            "       0.00138753, 0.00090054, 0.00120699, 0.00126088, 0.00180479,\n",
            "       0.00170006, 0.00115248, 0.00148177, 0.00128534, 0.00127952,\n",
            "       0.00123745, 0.00123094, 0.00132021, 0.00153442, 0.00145951,\n",
            "       0.0040543 , 0.00124662, 0.0010797 , 0.00176477, 0.00075783,\n",
            "       0.00153695, 0.00222071, 0.00131289, 0.00132931, 0.00120279,\n",
            "       0.00116318, 0.00136615, 0.00161296, 0.00166833, 0.00113367,\n",
            "       0.00119722, 0.00164944, 0.00128018, 0.00111575, 0.00116535,\n",
            "       0.0016929 , 0.00130905, 0.00163976, 0.00139352, 0.00132065,\n",
            "       0.0013552 , 0.00102045, 0.00094746, 0.00062861, 0.00151288,\n",
            "       0.00200432, 0.0010843 , 0.00246227, 0.00154062, 0.00096171,\n",
            "       0.0013315 , 0.00118568, 0.00140904, 0.001472  , 0.00152946,\n",
            "       0.00151814, 0.00144916, 0.00155071, 0.00108727, 0.00176227,\n",
            "       0.00140099, 0.00103635, 0.00122558, 0.0017633 , 0.00147537,\n",
            "       0.00154566, 0.00123612, 0.0028674 , 0.00151989, 0.00493629,\n",
            "       0.00142999, 0.00112498, 0.00121469, 0.00149713, 0.00151744,\n",
            "       0.00148751, 0.00142972, 0.00161858, 0.00152682, 0.0010872 ,\n",
            "       0.00092387, 0.00160212, 0.0012186 , 0.00109203, 0.00174077,\n",
            "       0.00256326, 0.00121841, 0.00123456, 0.00134434, 0.00150498,\n",
            "       0.00347644, 0.00104408, 0.00129452, 0.00542708, 0.00229827,\n",
            "       0.00132997, 0.00145288, 0.00132423, 0.00117112, 0.00206641,\n",
            "       0.00127244, 0.00101741, 0.00104593, 0.00127416, 0.00128793,\n",
            "       0.00168583, 0.00124692, 0.0010611 , 0.00115384, 0.00152085,\n",
            "       0.00115736, 0.00163142, 0.00430694, 0.00227696, 0.00087384,\n",
            "       0.00255437, 0.00111093, 0.00095465, 0.00109297, 0.00267335,\n",
            "       0.00183102, 0.00145109, 0.00243066, 0.0013518 , 0.00132589,\n",
            "       0.00153198, 0.00108227, 0.00139918, 0.00137414, 0.00143163,\n",
            "       0.00127929, 0.00172518, 0.00084191, 0.00125803, 0.00109427,\n",
            "       0.00425014, 0.00459558, 0.00129181, 0.00114498, 0.00157126,\n",
            "       0.00070017, 0.00101966, 0.00137885, 0.00147559, 0.00106344,\n",
            "       0.00127763, 0.000973  , 0.00112887, 0.0009947 , 0.00116681,\n",
            "       0.00131559, 0.00101248, 0.00129591, 0.00139106, 0.00133637,\n",
            "       0.00203507, 0.00117558, 0.00124197, 0.00098959, 0.00202241,\n",
            "       0.00125776, 0.00101007, 0.00091902, 0.00132205, 0.00133978,\n",
            "       0.00158898, 0.00104984, 0.00105011, 0.00119313, 0.00088788,\n",
            "       0.00136519, 0.00099335, 0.00119546, 0.00133078, 0.00158452,\n",
            "       0.00115946, 0.00160203, 0.00187163, 0.00181951, 0.00123225,\n",
            "       0.00057976, 0.00157033, 0.00146552, 0.00129355, 0.00115873,\n",
            "       0.00162483, 0.00085978, 0.00145833, 0.00127373, 0.00235857,\n",
            "       0.0014377 , 0.00109311, 0.0010217 , 0.00114995, 0.00117027,\n",
            "       0.00517618, 0.00137267, 0.00141267, 0.00415813, 0.00101638,\n",
            "       0.00158803, 0.00154628, 0.00125325, 0.00106443, 0.00122412,\n",
            "       0.00140929, 0.00158694, 0.00128861, 0.0013076 , 0.0012653 ,\n",
            "       0.00156663, 0.00178406, 0.00148719, 0.00147128, 0.00126847,\n",
            "       0.00095728, 0.00132192, 0.00161486, 0.00264956, 0.00139832,\n",
            "       0.00140928, 0.00103113, 0.00152445, 0.00146153, 0.00136704,\n",
            "       0.00131788, 0.00153988, 0.00099185, 0.00097449, 0.00134765,\n",
            "       0.00123585, 0.00117054, 0.00184727, 0.00121492, 0.00134032,\n",
            "       0.00163143, 0.00117476, 0.00280792, 0.00113105, 0.0018858 ,\n",
            "       0.00092795, 0.00131257, 0.0004524 , 0.00228634, 0.00111805,\n",
            "       0.00158912, 0.00170902, 0.00163355, 0.00099078, 0.00145907,\n",
            "       0.00099583, 0.00167274, 0.00144195, 0.00611313, 0.00294728,\n",
            "       0.00144511, 0.00115846, 0.0012866 , 0.0012677 , 0.00092228],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 216, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.58906623e-04, 1.15373172e-04, 2.63323745e-04, 1.57392715e-04,\n",
            "       1.71172491e-04, 1.80054194e-04, 2.34748441e-04, 2.22068033e-04,\n",
            "       1.57220406e-04, 1.70285362e-04, 1.01032783e-04, 2.44945084e-04,\n",
            "       7.83930009e-05, 1.41649507e-04, 1.43953454e-04, 9.47931840e-05,\n",
            "       1.48162449e-04, 1.11212612e-04, 3.24475142e-04, 8.43882299e-05,\n",
            "       1.38573843e-04, 1.80916366e-04, 1.86451405e-04, 1.35438808e-04,\n",
            "       1.29385080e-04, 1.46290651e-04, 2.18013272e-04, 1.37982541e-04,\n",
            "       1.39006428e-04, 1.62685275e-04, 2.50603305e-04, 1.51048574e-04,\n",
            "       1.40260454e-04, 1.81502968e-04, 1.54284557e-04, 1.20758690e-04,\n",
            "       1.31860506e-04, 1.22360376e-04, 1.58127848e-04, 1.12490212e-04,\n",
            "       1.00591409e-04, 6.57616692e-05, 1.59282150e-04, 3.39516555e-04,\n",
            "       1.82989621e-04, 1.10635032e-04, 1.35244438e-04, 1.26629195e-04,\n",
            "       1.56226000e-04, 1.92029198e-04, 1.50473934e-04, 1.94581517e-04,\n",
            "       1.31186025e-04, 1.16120398e-04, 2.03371994e-04, 2.07988458e-04,\n",
            "       1.01253099e-04, 1.43638579e-04, 2.28808873e-04, 2.06900819e-04,\n",
            "       1.29258318e-04, 2.24404095e-04, 1.38226489e-04, 1.27839900e-04,\n",
            "       1.35632086e-04, 1.53750050e-04, 1.91416722e-04, 1.49942760e-04,\n",
            "       1.12974565e-04, 1.88241713e-04, 2.24106421e-04, 1.58428418e-04,\n",
            "       2.05550969e-04, 6.05208843e-05, 2.24447227e-04, 2.95786711e-04,\n",
            "       1.66130092e-04, 1.66205849e-04, 1.26277184e-04, 2.26727308e-04,\n",
            "       2.17704917e-04, 1.23670281e-04, 1.41606855e-04, 5.13819905e-05,\n",
            "       1.64386074e-04, 3.33465287e-04, 1.51752480e-04, 1.58024690e-04,\n",
            "       6.16824909e-05, 1.10188885e-04, 2.12263665e-04, 2.33823725e-04,\n",
            "       4.58606431e-04, 1.39385505e-04, 2.51339050e-04, 1.70797473e-04,\n",
            "       2.41373986e-04, 4.20907134e-04, 1.66125013e-04, 1.54441179e-04,\n",
            "       1.63956007e-04, 1.90698673e-04, 1.75562440e-04, 1.46701641e-04,\n",
            "       1.62799799e-04, 1.26263723e-04, 1.97476766e-04, 1.34192538e-04,\n",
            "       1.41069133e-04, 1.63021235e-04, 1.21296216e-04, 1.05047016e-04,\n",
            "       2.11618419e-04, 3.37982288e-04, 1.23672362e-04, 1.65219579e-04,\n",
            "       1.37716386e-04, 2.89485266e-04, 2.79018917e-04, 1.87929152e-04,\n",
            "       1.08528795e-04, 6.13687225e-05, 1.62884884e-04, 1.28326399e-04,\n",
            "       2.16303481e-04, 1.59688891e-04, 1.04071463e-04, 1.81207099e-04,\n",
            "       1.25457271e-04, 1.53597197e-04, 7.45713041e-05, 2.93250603e-04,\n",
            "       1.56341164e-04, 2.40035297e-04, 1.66448051e-04, 1.75445675e-04,\n",
            "       1.42085104e-04, 2.31699654e-04, 2.04206124e-04, 1.58775307e-04,\n",
            "       1.74957575e-04, 1.91723331e-04, 1.11111585e-04, 2.15604814e-04,\n",
            "       1.33475609e-04, 1.53521847e-04, 1.81836935e-04, 7.17066723e-05,\n",
            "       4.49144805e-04, 1.32686720e-04, 1.55547037e-04, 1.39041207e-04,\n",
            "       3.54105723e-04, 1.46366903e-04, 1.61936827e-04, 2.22266288e-04,\n",
            "       1.44206089e-04, 1.51211425e-04, 1.35668641e-04, 1.42710735e-04,\n",
            "       2.79662170e-04, 6.36397817e-05, 1.35259514e-04, 6.34993412e-05,\n",
            "       2.06197263e-04, 4.66797792e-04, 1.72414191e-04, 1.63437915e-04,\n",
            "       1.45604950e-04, 1.49803673e-04, 1.48855324e-04, 1.34981674e-04,\n",
            "       2.29600904e-04, 1.51120257e-04, 3.40247556e-04, 1.48585197e-04,\n",
            "       1.13592585e-04, 1.24527491e-04, 1.48246952e-04, 1.67565202e-04,\n",
            "       2.40993730e-04, 1.43290963e-04, 1.32318703e-04, 1.22648678e-04,\n",
            "       2.02918396e-04, 1.89262311e-04, 5.78682520e-05, 1.85936922e-04,\n",
            "       1.36184870e-04, 1.66347265e-04, 1.87132857e-04, 1.76022964e-04,\n",
            "       2.32915118e-04, 1.43167592e-04, 1.82309988e-04, 1.51196364e-04,\n",
            "       1.88439386e-04, 1.50083622e-04, 1.94324602e-04, 2.12121871e-04,\n",
            "       5.64999973e-05, 1.93230590e-04, 1.39992364e-04, 1.24045517e-04,\n",
            "       1.89580605e-04, 1.50123276e-04, 1.70200627e-04, 2.40658075e-04,\n",
            "       1.62833487e-04, 1.81560972e-04, 1.79687049e-04, 1.31781300e-04,\n",
            "       3.61582002e-04, 2.50850775e-04, 1.31842360e-04, 1.42946054e-04,\n",
            "       1.75707464e-04, 3.03696434e-04, 1.23643011e-04, 1.13476533e-04,\n",
            "       2.13456718e-04, 6.46694098e-05, 2.23663155e-04, 1.70420928e-04,\n",
            "       1.90793464e-04, 1.42250457e-04, 1.12769427e-04, 1.53354922e-04,\n",
            "       1.36642586e-04, 1.99489587e-04, 2.89019052e-04, 1.55654168e-04,\n",
            "       1.78776783e-04, 2.30588645e-04, 1.34264366e-04, 1.40594813e-04,\n",
            "       1.65323770e-04, 2.20452857e-04, 2.99601612e-04, 1.45400918e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 217, 'shape': array([240,   1,   1, 960], dtype=int32), 'shape_signature': array([240,   1,   1, 960], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00146163, 0.00106121, 0.00242206, 0.0014477 , 0.00157445,\n",
            "       0.00165615, 0.00215922, 0.00204259, 0.00144612, 0.00156629,\n",
            "       0.0009293 , 0.00225301, 0.00072106, 0.0013029 , 0.00132409,\n",
            "       0.00087191, 0.0013628 , 0.00102294, 0.00298453, 0.00077621,\n",
            "       0.00127461, 0.00166408, 0.00171499, 0.00124577, 0.00119009,\n",
            "       0.00134559, 0.00200529, 0.00126917, 0.00127859, 0.00149639,\n",
            "       0.00230506, 0.00138935, 0.00129012, 0.00166947, 0.00141911,\n",
            "       0.00111074, 0.00121286, 0.00112548, 0.00145447, 0.00103469,\n",
            "       0.00092524, 0.00060488, 0.00146508, 0.00312289, 0.00168315,\n",
            "       0.00101763, 0.00124398, 0.00116474, 0.00143697, 0.00176629,\n",
            "       0.00138406, 0.00178977, 0.00120665, 0.00106808, 0.00187062,\n",
            "       0.00191309, 0.00093133, 0.00132119, 0.00210459, 0.00190308,\n",
            "       0.00118892, 0.00206408, 0.00127141, 0.00117588, 0.00124755,\n",
            "       0.0014142 , 0.00176066, 0.00137918, 0.00103914, 0.00173145,\n",
            "       0.00206134, 0.00145723, 0.00189067, 0.00055667, 0.00206447,\n",
            "       0.00272066, 0.00152807, 0.00152877, 0.0011615 , 0.00208545,\n",
            "       0.00200246, 0.00113752, 0.00130251, 0.00047261, 0.00151203,\n",
            "       0.00306723, 0.00139582, 0.00145352, 0.00056736, 0.00101352,\n",
            "       0.00195241, 0.00215072, 0.00421828, 0.00128207, 0.00231183,\n",
            "       0.001571  , 0.00222017, 0.00387152, 0.00152802, 0.00142056,\n",
            "       0.00150807, 0.00175405, 0.00161483, 0.00134937, 0.00149744,\n",
            "       0.00116138, 0.0018164 , 0.00123431, 0.00129756, 0.00149948,\n",
            "       0.00111569, 0.00096623, 0.00194647, 0.00310877, 0.00113754,\n",
            "       0.0015197 , 0.00126672, 0.0026627 , 0.00256643, 0.00172858,\n",
            "       0.00099825, 0.00056447, 0.00149822, 0.00118035, 0.00198957,\n",
            "       0.00146882, 0.00095725, 0.00166675, 0.00115396, 0.00141279,\n",
            "       0.00068591, 0.00269733, 0.00143803, 0.00220785, 0.001531  ,\n",
            "       0.00161376, 0.0013069 , 0.00213118, 0.0018783 , 0.00146042,\n",
            "       0.00160927, 0.00176348, 0.00102201, 0.00198314, 0.00122771,\n",
            "       0.0014121 , 0.00167254, 0.00065956, 0.00413125, 0.00122046,\n",
            "       0.00143073, 0.00127891, 0.00325708, 0.00134629, 0.0014895 ,\n",
            "       0.00204441, 0.00132641, 0.00139085, 0.00124789, 0.00131266,\n",
            "       0.00257234, 0.00058536, 0.00124412, 0.00058407, 0.00189661,\n",
            "       0.00429362, 0.00158587, 0.00150331, 0.00133928, 0.0013779 ,\n",
            "       0.00136918, 0.00124157, 0.00211188, 0.00139001, 0.00312961,\n",
            "       0.00136669, 0.00104483, 0.00114541, 0.00136358, 0.00154127,\n",
            "       0.00221667, 0.001318  , 0.00121707, 0.00112813, 0.00186645,\n",
            "       0.00174084, 0.00053227, 0.00171025, 0.00125263, 0.00153007,\n",
            "       0.00172125, 0.00161907, 0.00214236, 0.00131686, 0.00167689,\n",
            "       0.00139071, 0.00173327, 0.00138047, 0.0017874 , 0.0019511 ,\n",
            "       0.00051969, 0.00177734, 0.00128765, 0.00114098, 0.00174377,\n",
            "       0.00138084, 0.00156551, 0.00221358, 0.00149775, 0.00167   ,\n",
            "       0.00165277, 0.00121213, 0.00332584, 0.00230733, 0.00121269,\n",
            "       0.00131482, 0.00161616, 0.00279341, 0.00113727, 0.00104376,\n",
            "       0.00196338, 0.00059483, 0.00205726, 0.00156754, 0.00175493,\n",
            "       0.00130842, 0.00103726, 0.00141056, 0.00125684, 0.00183491,\n",
            "       0.00265841, 0.00143171, 0.0016444 , 0.00212096, 0.00123497,\n",
            "       0.0012932 , 0.00152065, 0.00202773, 0.00275575, 0.0013374 ],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 218, 'shape': array([480], dtype=int32), 'shape_signature': array([480], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([6.7239022e-04, 7.0588477e-04, 1.9846766e-03, 1.0936247e-03,\n",
            "       1.2222666e-03, 7.6927425e-04, 6.2832911e-04, 7.8639301e-04,\n",
            "       5.5827951e-04, 7.4425520e-04, 1.3347694e-03, 7.8905787e-04,\n",
            "       8.4542838e-04, 4.2052584e-04, 7.6833199e-04, 8.7494764e-04,\n",
            "       5.5889809e-04, 4.6348420e-04, 1.4540444e-03, 8.0486079e-04,\n",
            "       1.5230477e-03, 7.8301283e-04, 8.1616151e-04, 4.5019260e-04,\n",
            "       6.3470984e-04, 6.3214259e-04, 6.8176212e-04, 1.4963927e-03,\n",
            "       1.1615501e-03, 6.6408492e-04, 1.0117390e-03, 6.0650613e-04,\n",
            "       7.0122670e-04, 5.9731776e-04, 7.4814353e-04, 5.2518159e-04,\n",
            "       5.9735292e-04, 1.5747134e-04, 5.5489724e-04, 5.4402585e-04,\n",
            "       1.0290249e-03, 1.0752346e-03, 6.5153127e-04, 4.7092047e-04,\n",
            "       4.0270176e-04, 2.6897257e-04, 6.4704166e-04, 6.1095564e-04,\n",
            "       5.8705336e-04, 6.8434572e-04, 1.0488061e-03, 8.6029450e-04,\n",
            "       6.9105509e-04, 1.4238947e-03, 7.9351722e-04, 4.1402446e-04,\n",
            "       8.9403806e-04, 2.2399999e-04, 6.0235121e-04, 4.7753498e-04,\n",
            "       9.2952972e-04, 9.1585662e-04, 6.3789176e-04, 6.3484191e-04,\n",
            "       7.3611166e-04, 5.4886081e-04, 7.4850605e-04, 6.4389914e-04,\n",
            "       8.1897748e-04, 4.3471935e-04, 7.0871820e-04, 7.6673354e-04,\n",
            "       1.2709361e-03, 5.4840010e-04, 9.1753423e-04, 9.8109699e-04,\n",
            "       8.4518339e-04, 5.7948980e-04, 8.4390666e-04, 7.3298323e-04,\n",
            "       8.3404250e-04, 5.3049246e-04, 3.3648108e-04, 5.2879099e-04,\n",
            "       5.9188379e-04, 4.7569742e-04, 1.2270757e-03, 1.3783472e-03,\n",
            "       7.5547182e-04, 1.4183464e-03, 8.0578594e-04, 6.5464270e-04,\n",
            "       1.0682003e-03, 5.8912486e-04, 5.6699559e-04, 4.5187604e-03,\n",
            "       8.1951258e-04, 9.7429520e-04, 1.4435605e-03, 6.3732144e-04,\n",
            "       8.5533189e-04, 1.0247555e-03, 1.5189697e-03, 4.3537966e-03,\n",
            "       7.5585581e-04, 7.6702528e-04, 9.0988580e-04, 1.1222980e-03,\n",
            "       7.6765212e-04, 1.0078289e-03, 8.2067132e-04, 2.9844081e-04,\n",
            "       7.2974002e-04, 5.1953056e-04, 5.3491601e-04, 9.5081783e-04,\n",
            "       6.1575603e-04, 7.6155644e-04, 5.7896873e-04, 7.7951991e-04,\n",
            "       4.5026274e-04, 3.9966434e-04, 7.2674127e-04, 1.4343279e-03,\n",
            "       8.3697430e-04, 6.6051172e-04, 3.4119078e-04, 1.4534892e-03,\n",
            "       1.0149701e-03, 7.9275016e-04, 3.8039187e-04, 6.0805248e-04,\n",
            "       8.6474611e-04, 7.9418812e-04, 6.3306716e-04, 1.4511272e-03,\n",
            "       5.3050875e-04, 6.7859568e-04, 8.6294109e-04, 4.4972007e-04,\n",
            "       7.6229859e-04, 4.2982804e-04, 6.2516157e-04, 1.1828312e-03,\n",
            "       1.0739937e-03, 8.8764733e-04, 2.4705569e-04, 8.9521339e-04,\n",
            "       5.6667585e-04, 8.8785845e-04, 7.9981697e-04, 1.3279042e-03,\n",
            "       6.6221377e-04, 7.0493657e-04, 7.0498552e-04, 7.3952321e-04,\n",
            "       7.0538971e-04, 6.9989043e-04, 3.8992640e-04, 9.5984200e-04,\n",
            "       5.2899314e-04, 7.1766914e-04, 1.2920039e-03, 6.0042128e-04,\n",
            "       1.0426422e-03, 7.4223714e-04, 7.8647229e-04, 1.5079356e-03,\n",
            "       6.2713353e-04, 1.2884686e-03, 1.2006470e-03, 9.3980873e-04,\n",
            "       1.2239054e-03, 5.6019280e-04, 1.0722004e-03, 9.6987328e-04,\n",
            "       5.8108836e-04, 6.0701603e-04, 5.5855932e-04, 6.4513966e-04,\n",
            "       9.1430050e-04, 1.0333473e-03, 1.1455858e-03, 6.9759274e-04,\n",
            "       6.1474700e-04, 2.4261828e-04, 5.7292409e-04, 8.7949622e-04,\n",
            "       6.3728058e-04, 1.1317637e-03, 4.6165072e-04, 1.3516934e-03,\n",
            "       5.4404233e-04, 8.1555825e-04, 2.5914237e-03, 7.4540247e-04,\n",
            "       8.3260570e-04, 6.5946457e-04, 6.6748267e-04, 1.3131563e-03,\n",
            "       7.5174583e-04, 4.3662373e-04, 5.4209505e-04, 1.5883485e-03,\n",
            "       8.4805477e-04, 1.1279226e-03, 8.6670270e-04, 7.4486807e-04,\n",
            "       3.9863333e-04, 1.0085837e-03, 2.9873478e-04, 9.2674175e-04,\n",
            "       1.2414597e-03, 7.0959039e-04, 1.3302553e-03, 8.3581446e-04,\n",
            "       1.6046767e-03, 6.2699587e-04, 1.2111568e-03, 9.0829690e-04,\n",
            "       7.4686273e-04, 2.6019712e-04, 3.6860173e-04, 6.7210500e-04,\n",
            "       9.4735395e-04, 6.3932041e-04, 7.2622014e-04, 7.9394743e-04,\n",
            "       1.0812462e-03, 9.5419114e-04, 8.7961613e-04, 1.0075287e-03,\n",
            "       5.1438221e-04, 5.8799685e-04, 5.7073013e-04, 8.1028999e-04,\n",
            "       6.8338483e-04, 1.0604147e-03, 1.6165808e-03, 9.9633692e-04,\n",
            "       7.1625988e-04, 2.1983946e-04, 1.1443290e-03, 6.7812647e-04,\n",
            "       8.3796144e-04, 9.9455181e-04, 7.3379843e-04, 6.3990289e-04,\n",
            "       1.2477809e-03, 5.3209363e-04, 7.0127920e-04, 1.0063520e-03,\n",
            "       8.2077429e-04, 6.4202480e-04, 1.4274415e-03, 1.0661453e-03,\n",
            "       1.1581369e-03, 4.7982848e-04, 7.1591412e-04, 1.5227916e-03,\n",
            "       1.0490399e-03, 1.1696824e-03, 7.6641102e-04, 1.0425400e-03,\n",
            "       7.2039745e-04, 7.6137448e-04, 3.8462944e-04, 3.8463625e-04,\n",
            "       1.3319202e-03, 3.2265187e-04, 5.8736623e-04, 9.5727685e-04,\n",
            "       7.2571961e-04, 6.7924272e-04, 6.5072911e-04, 3.8889141e-04,\n",
            "       5.8728427e-04, 1.0513162e-03, 4.9910863e-04, 7.5611210e-04,\n",
            "       5.4404954e-04, 6.7730097e-04, 1.0800117e-03, 6.4745120e-04,\n",
            "       1.1746945e-03, 5.8286166e-04, 5.0204404e-04, 1.8861836e-04,\n",
            "       8.6130830e-04, 6.1109895e-04, 7.3650409e-04, 8.1878301e-04,\n",
            "       9.0235565e-04, 5.9549196e-04, 1.0191774e-03, 7.3862833e-04,\n",
            "       5.0887570e-04, 6.6887058e-04, 1.1351594e-03, 7.2658330e-04,\n",
            "       9.4497285e-04, 5.6543516e-04, 6.1059592e-04, 4.8890157e-04,\n",
            "       5.2921631e-04, 6.4634642e-04, 7.3375215e-04, 1.2155387e-03,\n",
            "       4.6833907e-03, 5.6059303e-04, 1.4129205e-04, 6.3950859e-04,\n",
            "       7.7039230e-04, 1.7637769e-03, 3.7909418e-04, 7.6251931e-04,\n",
            "       7.5715035e-04, 7.4323529e-04, 7.2669156e-04, 4.8253464e-04,\n",
            "       8.1606134e-04, 4.5026888e-04, 9.6023688e-04, 8.9244265e-04,\n",
            "       6.4730196e-04, 1.6181549e-03, 5.9063348e-04, 6.1653665e-04,\n",
            "       4.8691159e-04, 6.1166740e-04, 9.0303208e-04, 4.8446871e-04,\n",
            "       2.8251854e-03, 2.1508458e-04, 8.5635990e-04, 1.3233335e-03,\n",
            "       5.9066707e-04, 2.9905722e-04, 7.0521550e-04, 1.4792865e-03,\n",
            "       8.5640250e-04, 7.8310963e-04, 1.0291039e-03, 7.4111862e-04,\n",
            "       8.6924160e-04, 5.5275817e-04, 6.3058489e-04, 5.5328739e-04,\n",
            "       7.2369032e-04, 1.8096352e-03, 6.0239271e-04, 2.8457612e-04,\n",
            "       5.8237842e-04, 6.4020150e-04, 6.0731213e-04, 6.1582000e-04,\n",
            "       3.4319033e-04, 6.0739653e-04, 1.4550004e-03, 2.1922572e-03,\n",
            "       1.2522993e-03, 1.2764654e-03, 5.3245958e-04, 9.4419997e-04,\n",
            "       8.0405426e-04, 5.8326154e-04, 6.4226618e-04, 5.3445483e-04,\n",
            "       1.2289472e-03, 9.4533048e-04, 1.1878673e-03, 9.5509714e-04,\n",
            "       8.2125823e-04, 4.2212778e-04, 7.7559939e-04, 5.7281839e-04,\n",
            "       8.8222057e-04, 7.0076232e-04, 7.2393718e-04, 1.0568162e-03,\n",
            "       1.2332073e-03, 9.3021675e-04, 1.3894073e-03, 1.8224363e-03,\n",
            "       3.9212429e-04, 1.7847039e-03, 4.0291954e-04, 5.1343639e-04,\n",
            "       7.4968714e-04, 3.9366755e-04, 6.8316428e-04, 1.2144033e-03,\n",
            "       8.0750458e-04, 3.7616963e-04, 7.5601682e-04, 1.0769519e-03,\n",
            "       7.1598613e-04, 9.2455564e-04, 7.2272751e-04, 9.2717755e-04,\n",
            "       1.4415574e-03, 8.3787047e-04, 9.6783892e-04, 1.0714482e-03,\n",
            "       7.1235292e-04, 1.3901293e-03, 7.5721921e-04, 7.8898220e-04,\n",
            "       1.6309823e-03, 4.5082069e-04, 6.7298481e-04, 5.5683672e-04,\n",
            "       6.5489777e-04, 7.3246466e-04, 5.7587173e-04, 3.2573609e-04,\n",
            "       6.5517513e-04, 6.0572469e-04, 8.5067609e-04, 1.0116870e-03,\n",
            "       7.2834000e-04, 6.9711410e-04, 5.5364147e-04, 2.2952894e-03,\n",
            "       1.1588064e-03, 9.9347439e-04, 6.6191849e-04, 6.5680395e-04,\n",
            "       6.0167327e-04, 6.4552465e-04, 1.0341246e-03, 1.0492987e-03,\n",
            "       6.6717126e-04, 2.1556685e-04, 6.3135772e-04, 5.2464596e-04,\n",
            "       5.9432240e-04, 1.0664964e-03, 5.6652443e-05, 6.5141742e-04,\n",
            "       1.9061619e-03, 6.3461537e-04, 3.1037189e-04, 5.5235374e-04,\n",
            "       1.1859738e-03, 6.9342327e-04, 8.3038711e-04, 2.0239565e-03,\n",
            "       5.9459719e-04, 9.0149516e-04, 1.1565005e-03, 1.6685780e-03,\n",
            "       5.3979742e-04, 3.1582560e-04, 6.9631793e-04, 1.1102966e-03,\n",
            "       6.6119072e-04, 5.6861719e-04, 8.0277212e-04, 5.6264346e-04,\n",
            "       8.7808492e-04, 1.0599908e-03, 8.7918801e-04, 1.2278691e-03,\n",
            "       6.8111328e-04, 1.1029700e-03, 4.0084656e-04, 5.1294791e-04,\n",
            "       2.1289669e-03, 8.6908322e-04, 8.2857849e-04, 8.8271336e-04,\n",
            "       5.9030019e-04, 5.5124809e-04, 2.2104211e-04, 2.8974863e-04,\n",
            "       2.3606389e-03, 1.0062407e-03, 1.0230799e-03, 5.2695599e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block4_layer4/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer4/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 219, 'shape': array([  1,   5,   5, 480], dtype=int32), 'shape_signature': array([  1,   5,   5, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01252422, 0.01314811, 0.03696742, 0.02037031, 0.02276645,\n",
            "       0.01432882, 0.01170352, 0.01464769, 0.01039875, 0.01386281,\n",
            "       0.02486197, 0.01469732, 0.0157473 , 0.00783289, 0.01431127,\n",
            "       0.01629714, 0.01041027, 0.00863305, 0.02708364, 0.01499167,\n",
            "       0.02836892, 0.01458472, 0.01520217, 0.00838548, 0.01182237,\n",
            "       0.01177455, 0.01269879, 0.02787244, 0.02163552, 0.01236952,\n",
            "       0.01884508, 0.01129704, 0.01306134, 0.01112589, 0.01393523,\n",
            "       0.00978225, 0.01112655, 0.00293313, 0.01033575, 0.01013325,\n",
            "       0.01916705, 0.02002777, 0.01213569, 0.00877156, 0.00750089,\n",
            "       0.00501   , 0.01205207, 0.01137992, 0.0109347 , 0.01274691,\n",
            "       0.0195355 , 0.01602421, 0.01287188, 0.02652206, 0.01478038,\n",
            "       0.00771179, 0.01665273, 0.00417232, 0.01121965, 0.00889477,\n",
            "       0.01731381, 0.01705913, 0.01188164, 0.01182483, 0.01371112,\n",
            "       0.01022331, 0.01394199, 0.01199353, 0.01525462, 0.00809726,\n",
            "       0.01320088, 0.0142815 , 0.02367299, 0.01021473, 0.01709038,\n",
            "       0.01827432, 0.01574274, 0.01079382, 0.01571896, 0.01365285,\n",
            "       0.01553523, 0.00988117, 0.00626744, 0.00984948, 0.01102468,\n",
            "       0.00886054, 0.02285603, 0.02567367, 0.01407173, 0.02641872,\n",
            "       0.01500891, 0.01219365, 0.01989675, 0.01097329, 0.0105611 ,\n",
            "       0.08416832, 0.01526458, 0.01814763, 0.02688836, 0.01187102,\n",
            "       0.01593177, 0.01908753, 0.02829297, 0.08109564, 0.01407889,\n",
            "       0.01428693, 0.01694791, 0.02090439, 0.01429861, 0.01877224,\n",
            "       0.01528617, 0.00555888, 0.01359244, 0.00967699, 0.00996357,\n",
            "       0.01771033, 0.01146933, 0.01418507, 0.01078411, 0.01451966,\n",
            "       0.00838678, 0.00744432, 0.01353659, 0.02671639, 0.01558983,\n",
            "       0.01230297, 0.00635516, 0.0270733 , 0.01890526, 0.0147661 ,\n",
            "       0.00708534, 0.01132584, 0.01610712, 0.01479288, 0.01179177,\n",
            "       0.0270293 , 0.00988148, 0.01263981, 0.0160735 , 0.00837667,\n",
            "       0.01419889, 0.00800616, 0.01164452, 0.02203191, 0.02000466,\n",
            "       0.01653369, 0.00460176, 0.01667462, 0.01055514, 0.01653762,\n",
            "       0.01489773, 0.0247341 , 0.01233467, 0.01313044, 0.01313136,\n",
            "       0.01377467, 0.01313888, 0.01303645, 0.00726293, 0.01787842,\n",
            "       0.00985325, 0.01336761, 0.02406541, 0.0111837 , 0.01942069,\n",
            "       0.01382522, 0.01464916, 0.02808744, 0.01168125, 0.02399956,\n",
            "       0.02236375, 0.01750527, 0.02279697, 0.01043439, 0.01997125,\n",
            "       0.01806527, 0.0108236 , 0.01130653, 0.01040396, 0.01201664,\n",
            "       0.01703014, 0.01924756, 0.02133816, 0.01299365, 0.01145054,\n",
            "       0.00451911, 0.01067152, 0.01638187, 0.01187025, 0.0210807 ,\n",
            "       0.0085989 , 0.02517721, 0.01013356, 0.01519093, 0.04826894,\n",
            "       0.01388418, 0.01550846, 0.01228346, 0.01243281, 0.0244594 ,\n",
            "       0.01400233, 0.00813274, 0.01009729, 0.02958525, 0.01579622,\n",
            "       0.02100916, 0.01614357, 0.01387422, 0.00742511, 0.0187863 ,\n",
            "       0.00556436, 0.01726188, 0.02312395, 0.01321713, 0.02477789,\n",
            "       0.01556823, 0.02988938, 0.01167869, 0.02255951, 0.01691832,\n",
            "       0.01391138, 0.00484654, 0.00686573, 0.01251891, 0.01764581,\n",
            "       0.01190825, 0.01352688, 0.0147884 , 0.02013974, 0.01777316,\n",
            "       0.0163841 , 0.01876665, 0.0095811 , 0.01095228, 0.01063066,\n",
            "       0.0150928 , 0.01272901, 0.01975173, 0.03011111, 0.01855819,\n",
            "       0.01334136, 0.00409482, 0.02131475, 0.01263107, 0.01560822,\n",
            "       0.01852494, 0.01366804, 0.0119191 , 0.02324169, 0.009911  ,\n",
            "       0.01306232, 0.01874473, 0.01528809, 0.01195862, 0.02658812,\n",
            "       0.01985847, 0.02157194, 0.00893749, 0.01333492, 0.02836415,\n",
            "       0.01953986, 0.02178699, 0.01427549, 0.01941879, 0.01341842,\n",
            "       0.01418168, 0.00716427, 0.0071644 , 0.0248089 , 0.00600985,\n",
            "       0.01094053, 0.01783064, 0.01351756, 0.01265186, 0.01212075,\n",
            "       0.00724365, 0.010939  , 0.01958225, 0.00929661, 0.01408366,\n",
            "       0.01013369, 0.01261569, 0.02011675, 0.0120597 , 0.02188035,\n",
            "       0.01085663, 0.00935128, 0.00351328, 0.01604309, 0.01138259,\n",
            "       0.01371843, 0.015251  , 0.01680765, 0.01109188, 0.01898362,\n",
            "       0.013758  , 0.00947853, 0.01245866, 0.02114395, 0.01353365,\n",
            "       0.01760146, 0.01053203, 0.01137322, 0.00910649, 0.0098574 ,\n",
            "       0.01203912, 0.01366717, 0.02264113, 0.0872348 , 0.01044184,\n",
            "       0.00263176, 0.01191176, 0.01434965, 0.03285285, 0.00706117,\n",
            "       0.014203  , 0.014103  , 0.01384381, 0.01353566, 0.00898789,\n",
            "       0.0152003 , 0.0083869 , 0.01788577, 0.01662301, 0.01205692,\n",
            "       0.03014043, 0.01100139, 0.01148387, 0.00906942, 0.01139317,\n",
            "       0.01682025, 0.00902392, 0.05262309, 0.00400626, 0.01595092,\n",
            "       0.02464896, 0.01100201, 0.00557037, 0.01313564, 0.02755381,\n",
            "       0.01595171, 0.01458653, 0.01916852, 0.01380439, 0.01619086,\n",
            "       0.01029591, 0.01174554, 0.01030576, 0.01347976, 0.03370702,\n",
            "       0.01122042, 0.00530063, 0.01084762, 0.01192466, 0.01131205,\n",
            "       0.01147052, 0.00639241, 0.01131362, 0.02710145, 0.0408339 ,\n",
            "       0.02332585, 0.02377598, 0.00991782, 0.01758706, 0.01497665,\n",
            "       0.01086407, 0.01196312, 0.00995498, 0.02289089, 0.01760812,\n",
            "       0.02212571, 0.01779004, 0.0152971 , 0.00786273, 0.01444664,\n",
            "       0.01066956, 0.01643261, 0.01305269, 0.01348436, 0.0196847 ,\n",
            "       0.02297023, 0.01732661, 0.02587968, 0.03394546, 0.00730387,\n",
            "       0.03324264, 0.00750495, 0.00956348, 0.01396399, 0.00733262,\n",
            "       0.0127249 , 0.02261999, 0.01504092, 0.00700669, 0.01408189,\n",
            "       0.02005976, 0.01333626, 0.01722116, 0.01346183, 0.01727   ,\n",
            "       0.02685105, 0.01560653, 0.01802737, 0.01995724, 0.01326858,\n",
            "       0.02589313, 0.01410428, 0.01469591, 0.03037936, 0.00839717,\n",
            "       0.0125353 , 0.01037187, 0.0121984 , 0.01364319, 0.01072643,\n",
            "       0.0060673 , 0.01220357, 0.01128248, 0.01584505, 0.01884411,\n",
            "       0.01356637, 0.01298474, 0.01031236, 0.04275302, 0.02158441,\n",
            "       0.01850487, 0.01232917, 0.01223391, 0.01120702, 0.01202381,\n",
            "       0.01926204, 0.01954468, 0.01242701, 0.00401524, 0.01175993,\n",
            "       0.00977228, 0.0110701 , 0.01986501, 0.00105523, 0.01213357,\n",
            "       0.03550497, 0.01182061, 0.00578112, 0.01028837, 0.02209044,\n",
            "       0.01291599, 0.01546714, 0.03769906, 0.01107522, 0.01679163,\n",
            "       0.02154146, 0.03107963, 0.01005449, 0.0058827 , 0.01296991,\n",
            "       0.02068085, 0.01231562, 0.0105913 , 0.01495277, 0.01048003,\n",
            "       0.01635558, 0.01974383, 0.01637612, 0.0228708 , 0.0126867 ,\n",
            "       0.02054438, 0.00746634, 0.00955438, 0.03965503, 0.01618791,\n",
            "       0.01543345, 0.01644179, 0.01099518, 0.01026778, 0.00411722,\n",
            "       0.00539698, 0.04397025, 0.01874266, 0.01905631, 0.0098153 ],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 220, 'shape': array([480], dtype=int32), 'shape_signature': array([480], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.07847503e-04, 8.43749003e-05, 1.41262964e-04, 1.20682518e-04,\n",
            "       8.03576695e-05, 1.50288528e-04, 1.51208485e-04, 1.67130594e-04,\n",
            "       1.65456411e-04, 1.64053010e-04, 1.51492000e-04, 1.56145674e-04,\n",
            "       1.54000096e-04, 2.39768226e-04, 2.25501630e-04, 1.22753641e-04,\n",
            "       1.51716755e-04, 2.05786928e-04, 4.13891648e-05, 7.11749963e-05,\n",
            "       2.81703960e-05, 8.80021835e-05, 4.23496531e-05, 1.55151865e-04,\n",
            "       2.01885647e-04, 1.65536956e-04, 2.04217547e-04, 8.17254113e-05,\n",
            "       1.83315700e-04, 1.15904651e-04, 1.46119812e-04, 7.80254340e-05,\n",
            "       1.33706417e-04, 1.11623027e-04, 9.21100145e-05, 1.23341495e-04,\n",
            "       1.61314922e-04, 1.73560489e-04, 1.49080966e-04, 1.63983321e-04,\n",
            "       1.53703993e-04, 1.67661608e-04, 1.70703381e-04, 7.11101966e-05,\n",
            "       1.91682222e-04, 1.00748475e-04, 1.90693652e-04, 9.92227797e-05,\n",
            "       8.19278212e-05, 9.64327119e-05, 9.38996673e-05, 1.31425011e-04,\n",
            "       9.39132078e-05, 1.45055805e-04, 9.83927603e-05, 1.18681965e-04,\n",
            "       1.31061577e-04, 1.68783023e-04, 1.08863824e-04, 1.26248298e-04,\n",
            "       1.88381193e-04, 1.66131707e-04, 1.62487937e-04, 1.67136182e-04,\n",
            "       1.59266972e-04, 1.29671040e-04, 1.19997327e-04, 1.54639187e-04,\n",
            "       1.57929317e-04, 1.76543064e-04, 8.10464408e-05, 1.15510775e-04,\n",
            "       4.55668851e-05, 1.29120031e-04, 1.61379707e-04, 3.72877621e-05,\n",
            "       1.39587210e-04, 1.29072621e-04, 1.59500545e-04, 1.31199311e-04,\n",
            "       9.91047491e-05, 4.12103582e-05, 1.14648748e-04, 1.34783884e-04,\n",
            "       1.20125871e-04, 1.53700967e-04, 8.45073882e-05, 7.33550478e-05,\n",
            "       7.36159564e-05, 1.34959031e-04, 1.91917410e-04, 1.74405053e-04,\n",
            "       1.89512240e-04, 1.19894008e-04, 1.48931736e-04, 1.98676553e-05,\n",
            "       1.21236117e-04, 9.88096435e-05, 1.64428871e-04, 1.44741076e-04,\n",
            "       1.17950716e-04, 4.67562204e-05, 1.73438617e-04, 1.50167798e-05,\n",
            "       1.36906310e-04, 2.11343431e-04, 1.36029092e-04, 1.22993486e-04,\n",
            "       1.69549297e-04, 4.92299296e-05, 1.31566689e-04, 5.68306496e-05,\n",
            "       2.03488322e-04, 1.27306688e-04, 1.18608492e-04, 1.30861794e-04,\n",
            "       1.15511779e-04, 1.17179559e-04, 2.19010995e-04, 1.35157941e-04,\n",
            "       1.01281141e-04, 1.16408395e-04, 1.85688696e-04, 1.50374573e-04,\n",
            "       1.91308121e-04, 9.63834173e-05, 2.03193325e-04, 1.01763399e-04,\n",
            "       1.22179030e-04, 1.13272137e-04, 1.65002159e-04, 1.03557664e-04,\n",
            "       1.46751263e-04, 1.69585634e-04, 1.63374352e-04, 9.64815190e-05,\n",
            "       1.50213644e-04, 1.85575220e-04, 1.85186582e-04, 9.73354399e-05,\n",
            "       1.34001471e-04, 1.32576446e-04, 1.06783271e-04, 1.18712742e-04,\n",
            "       1.70524188e-04, 7.97252214e-05, 2.11283113e-04, 1.29433334e-04,\n",
            "       1.67895472e-04, 1.64156576e-04, 1.17147167e-04, 1.23868085e-04,\n",
            "       1.84312914e-04, 1.36018702e-04, 1.46430757e-04, 1.37219686e-04,\n",
            "       1.59312083e-04, 1.93893837e-04, 9.01706444e-05, 1.42432778e-04,\n",
            "       1.41575845e-04, 1.67788108e-04, 1.55251400e-04, 1.59750110e-04,\n",
            "       1.32000612e-04, 2.13430016e-04, 8.90860392e-05, 1.81409618e-04,\n",
            "       1.29128210e-04, 1.77337104e-04, 1.60995492e-04, 1.30547880e-04,\n",
            "       8.66347400e-05, 1.30235057e-04, 4.29290267e-05, 1.18984877e-04,\n",
            "       2.00890849e-04, 1.01239319e-04, 1.79849812e-04, 1.31303692e-04,\n",
            "       9.19004524e-05, 1.10893459e-04, 1.55633534e-04, 1.15626659e-04,\n",
            "       1.36509494e-04, 1.96778798e-04, 1.38356336e-04, 1.88029750e-04,\n",
            "       1.16553085e-04, 1.32684479e-04, 7.65311706e-05, 1.86062578e-04,\n",
            "       1.51167653e-04, 1.35330003e-04, 2.21528044e-05, 8.46326293e-05,\n",
            "       1.87425554e-04, 6.03214248e-05, 1.32757050e-04, 1.61033357e-04,\n",
            "       9.87589956e-05, 1.38586489e-04, 1.25969804e-04, 1.25214225e-04,\n",
            "       1.70016719e-04, 9.71684058e-05, 1.68937389e-04, 7.66331577e-05,\n",
            "       7.09668748e-05, 1.36595161e-04, 1.03010505e-04, 1.34731134e-04,\n",
            "       1.54355817e-04, 1.49066313e-04, 1.09611530e-04, 1.40075208e-04,\n",
            "       1.44354999e-04, 2.53523467e-04, 8.62700908e-05, 1.73648456e-04,\n",
            "       1.33272901e-04, 1.90788094e-04, 1.63203251e-04, 1.19713048e-04,\n",
            "       1.37675423e-04, 2.04639757e-04, 1.61832999e-04, 1.38938034e-04,\n",
            "       9.47297740e-05, 1.56611131e-04, 1.42065910e-04, 1.18940632e-04,\n",
            "       1.19634475e-04, 9.71880800e-05, 1.65437406e-04, 1.54434529e-04,\n",
            "       1.73084496e-04, 6.76640921e-05, 9.77708260e-05, 4.62802200e-05,\n",
            "       1.81127441e-04, 8.58294297e-05, 1.79342009e-04, 1.35549388e-04,\n",
            "       1.37341805e-04, 1.73977955e-04, 1.24475773e-04, 1.13218615e-04,\n",
            "       1.31034671e-04, 1.35374110e-04, 1.27190433e-04, 9.32681141e-05,\n",
            "       1.24318947e-04, 1.33768146e-04, 1.26050960e-04, 1.13654307e-04,\n",
            "       1.44380043e-04, 1.49039741e-04, 1.71060907e-04, 1.31141423e-04,\n",
            "       1.11253765e-04, 1.98978654e-04, 1.33137117e-04, 2.62772664e-05,\n",
            "       1.07625354e-04, 1.18003569e-04, 1.15050971e-04, 1.40819931e-04,\n",
            "       1.63280594e-04, 1.53023182e-04, 1.20647252e-04, 1.72662156e-04,\n",
            "       1.65732272e-04, 1.02692429e-04, 1.24614351e-04, 1.14110444e-04,\n",
            "       9.23992702e-05, 6.40235230e-05, 1.55780814e-04, 1.85286030e-04,\n",
            "       1.20697812e-04, 1.58698371e-04, 7.03324768e-05, 1.49345069e-04,\n",
            "       1.03546416e-04, 2.15629902e-04, 1.46571503e-04, 1.41659140e-04,\n",
            "       1.09010893e-04, 1.96843233e-04, 1.75559297e-04, 9.59257668e-05,\n",
            "       1.46305480e-04, 1.25891849e-04, 3.80879974e-05, 1.42562611e-04,\n",
            "       1.16844050e-04, 1.36541159e-04, 1.67721111e-04, 1.44983991e-04,\n",
            "       1.07566964e-04, 1.77428636e-04, 2.10786631e-04, 2.16260829e-04,\n",
            "       1.43439145e-04, 1.89066603e-04, 8.84586843e-05, 9.20547682e-05,\n",
            "       2.06437035e-05, 1.11522466e-04, 5.06431352e-05, 1.12077396e-04,\n",
            "       1.33827896e-04, 1.40546608e-05, 1.25005652e-04, 1.17563286e-04,\n",
            "       1.17061034e-04, 1.33648704e-04, 1.39150026e-04, 8.11189166e-05,\n",
            "       1.79050068e-04, 1.77581154e-04, 6.11583237e-05, 1.36599134e-04,\n",
            "       1.65015474e-04, 5.10216742e-05, 1.30991160e-04, 9.30948081e-05,\n",
            "       1.38475414e-04, 1.20641518e-04, 1.29971653e-04, 1.65047881e-04,\n",
            "       1.65904985e-05, 7.73528154e-05, 6.81564197e-05, 1.34262300e-04,\n",
            "       1.23100763e-04, 1.48553809e-04, 1.15575895e-04, 4.20369361e-05,\n",
            "       1.64945392e-04, 1.15090472e-04, 9.61650949e-05, 2.09502818e-04,\n",
            "       1.36512273e-04, 1.55261543e-04, 1.60137526e-04, 1.73934997e-04,\n",
            "       1.17484124e-04, 2.11281749e-05, 1.49124520e-04, 1.74742308e-04,\n",
            "       1.47915722e-04, 1.26733779e-04, 1.32256057e-04, 2.05642355e-04,\n",
            "       5.43800779e-05, 1.49157888e-04, 1.58207549e-04, 4.60304618e-05,\n",
            "       2.10779181e-05, 8.57958730e-05, 1.09763911e-04, 1.61850214e-04,\n",
            "       9.01809981e-05, 1.19737102e-04, 1.54327761e-04, 1.48004867e-04,\n",
            "       6.53638053e-05, 1.23718200e-04, 1.16200245e-04, 1.39499884e-04,\n",
            "       1.29693886e-04, 8.14561499e-05, 1.41814875e-04, 7.20581738e-05,\n",
            "       1.44322141e-04, 1.17868178e-04, 7.84531076e-05, 1.23266975e-04,\n",
            "       1.46628969e-04, 1.59557516e-04, 2.33202500e-05, 6.90648667e-05,\n",
            "       2.20276241e-04, 1.31360095e-04, 1.76245070e-04, 1.30153509e-04,\n",
            "       1.60507232e-04, 1.58825555e-04, 1.80002302e-04, 7.67131714e-05,\n",
            "       1.17910196e-04, 1.23127087e-04, 1.42516161e-04, 1.48968116e-04,\n",
            "       1.26611194e-04, 2.23978728e-04, 1.02603561e-04, 6.83319740e-05,\n",
            "       3.00410229e-05, 1.51273154e-04, 1.05113482e-04, 1.16112140e-04,\n",
            "       9.06993446e-05, 1.49514337e-04, 9.80173354e-05, 9.33470656e-05,\n",
            "       4.37604212e-05, 1.35059017e-04, 1.17558848e-04, 1.10890731e-04,\n",
            "       1.32743211e-04, 1.56146678e-04, 1.26634099e-04, 5.54277722e-05,\n",
            "       1.19198761e-04, 1.73357243e-04, 1.43084078e-04, 1.50678883e-04,\n",
            "       1.53618777e-04, 1.60801443e-04, 1.36435498e-04, 4.15551476e-05,\n",
            "       1.90139210e-04, 1.71478285e-04, 1.44602251e-04, 8.58137209e-05,\n",
            "       1.55722533e-04, 1.12455680e-04, 1.92756808e-04, 1.56614071e-04,\n",
            "       1.55146539e-04, 1.68007624e-04, 1.24276630e-04, 1.45069745e-04,\n",
            "       1.59704243e-04, 1.67758422e-04, 1.33850990e-04, 1.48377774e-04,\n",
            "       2.21538430e-05, 1.38577889e-04, 1.21047196e-04, 1.94882567e-04,\n",
            "       2.75036837e-05, 1.52091437e-04, 1.35953334e-04, 2.41081689e-05,\n",
            "       1.75367895e-04, 1.20885299e-04, 1.78767485e-04, 1.16700881e-04,\n",
            "       1.12034548e-04, 2.33305618e-04, 1.32573550e-04, 1.54303794e-04,\n",
            "       7.28164014e-05, 1.60499578e-04, 1.20611476e-04, 6.29955102e-05,\n",
            "       1.25861960e-04, 1.46157239e-04, 3.38494137e-05, 1.03683793e-04,\n",
            "       1.52450521e-04, 3.56680066e-05, 9.53614217e-05, 1.81550422e-04,\n",
            "       3.66863351e-05, 7.53962013e-05, 1.44772814e-04, 1.38866017e-04,\n",
            "       1.42446908e-04, 1.86945326e-04, 5.76893945e-05, 1.58116643e-04,\n",
            "       3.53913165e-05, 1.35209906e-04, 1.60473661e-04, 1.32317800e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 221, 'shape': array([480,   1,   1, 144], dtype=int32), 'shape_signature': array([480,   1,   1, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.61100329e-04, 2.04272830e-04, 3.41999636e-04, 2.92174082e-04,\n",
            "       1.94547058e-04, 3.63850646e-04, 3.66077875e-04, 4.04625520e-04,\n",
            "       4.00572288e-04, 3.97174648e-04, 3.66764260e-04, 3.78030876e-04,\n",
            "       3.72836395e-04, 5.80482243e-04, 5.45942632e-04, 2.97188293e-04,\n",
            "       3.67308414e-04, 4.98213049e-04, 1.00203753e-04, 1.72315675e-04,\n",
            "       6.82009268e-05, 2.13054518e-04, 1.02529106e-04, 3.75624862e-04,\n",
            "       4.88767982e-04, 4.00767312e-04, 4.94413543e-04, 1.97858375e-04,\n",
            "       4.43809899e-04, 2.80606793e-04, 3.53758136e-04, 1.88900667e-04,\n",
            "       3.23705113e-04, 2.70240911e-04, 2.22999646e-04, 2.98611500e-04,\n",
            "       3.90545698e-04, 4.20192402e-04, 3.60927108e-04, 3.97005933e-04,\n",
            "       3.72119539e-04, 4.05911123e-04, 4.13275295e-04, 1.72158791e-04,\n",
            "       4.64065350e-04, 2.43913470e-04, 4.61672025e-04, 2.40219742e-04,\n",
            "       1.98348411e-04, 2.33464947e-04, 2.27332421e-04, 3.18181788e-04,\n",
            "       2.27365192e-04, 3.51182156e-04, 2.38210254e-04, 2.87330709e-04,\n",
            "       3.17301921e-04, 4.08626074e-04, 2.63560854e-04, 3.05648922e-04,\n",
            "       4.56073525e-04, 4.02207195e-04, 3.93385591e-04, 4.04639053e-04,\n",
            "       3.85587598e-04, 3.13935423e-04, 2.90515221e-04, 3.74383642e-04,\n",
            "       3.82349099e-04, 4.27413237e-04, 1.96214576e-04, 2.79653206e-04,\n",
            "       1.10318069e-04, 3.12601420e-04, 3.90702538e-04, 9.02741958e-05,\n",
            "       3.37942591e-04, 3.12486634e-04, 3.86153057e-04, 3.17635364e-04,\n",
            "       2.39933986e-04, 9.97708557e-05, 2.77566229e-04, 3.26313690e-04,\n",
            "       2.90826429e-04, 3.72112205e-04, 2.04593569e-04, 1.77593596e-04,\n",
            "       1.78225266e-04, 3.26737703e-04, 4.64634737e-04, 4.22237092e-04,\n",
            "       4.58811817e-04, 2.90265074e-04, 3.60565842e-04, 4.80998751e-05,\n",
            "       2.93514342e-04, 2.39219531e-04, 3.98084609e-04, 3.50420189e-04,\n",
            "       2.85560352e-04, 1.13197464e-04, 4.19897318e-04, 3.63558356e-05,\n",
            "       3.31452087e-04, 5.11665421e-04, 3.29328352e-04, 2.97768973e-04,\n",
            "       4.10481240e-04, 1.19186356e-04, 3.18524806e-04, 1.37587806e-04,\n",
            "       4.92648105e-04, 3.08211282e-04, 2.87152827e-04, 3.16818245e-04,\n",
            "       2.79655651e-04, 2.83693371e-04, 5.30228717e-04, 3.27219284e-04,\n",
            "       2.45203060e-04, 2.81826360e-04, 4.49554936e-04, 3.64058942e-04,\n",
            "       4.63159638e-04, 2.33345607e-04, 4.91933897e-04, 2.46370619e-04,\n",
            "       2.95797159e-04, 2.74233433e-04, 3.99472541e-04, 2.50714569e-04,\n",
            "       3.55286873e-04, 4.10569221e-04, 3.95531591e-04, 2.33583109e-04,\n",
            "       3.63669329e-04, 4.49280225e-04, 4.48339328e-04, 2.35650470e-04,\n",
            "       3.24419438e-04, 3.20969441e-04, 2.58523796e-04, 2.87405215e-04,\n",
            "       4.12841444e-04, 1.93015891e-04, 5.11519378e-04, 3.13359924e-04,\n",
            "       4.06477309e-04, 3.97425378e-04, 2.83614936e-04, 2.99886393e-04,\n",
            "       4.46224149e-04, 3.29303206e-04, 3.54510936e-04, 3.32210795e-04,\n",
            "       3.85696796e-04, 4.69419698e-04, 2.18304398e-04, 3.44831758e-04,\n",
            "       3.42757121e-04, 4.06217383e-04, 3.75865813e-04, 3.86757252e-04,\n",
            "       3.19575338e-04, 5.16717089e-04, 2.15678563e-04, 4.39195224e-04,\n",
            "       3.12621210e-04, 4.29335632e-04, 3.89772351e-04, 3.16058256e-04,\n",
            "       2.09743928e-04, 3.15300917e-04, 1.03931779e-04, 2.88064068e-04,\n",
            "       4.86359582e-04, 2.45101808e-04, 4.35418944e-04, 3.17888102e-04,\n",
            "       2.22492294e-04, 2.68474629e-04, 3.76790966e-04, 2.79933767e-04,\n",
            "       3.30491399e-04, 4.76404239e-04, 3.34962620e-04, 4.55222675e-04,\n",
            "       2.82176654e-04, 3.21230997e-04, 1.85283046e-04, 4.50460124e-04,\n",
            "       3.65979009e-04, 3.27635847e-04, 5.36322514e-05, 2.04896787e-04,\n",
            "       4.53759916e-04, 1.46039019e-04, 3.21406696e-04, 3.89864028e-04,\n",
            "       2.39096917e-04, 3.35519842e-04, 3.04974674e-04, 3.03145411e-04,\n",
            "       4.11612884e-04, 2.35246087e-04, 4.08999796e-04, 1.85529949e-04,\n",
            "       1.71811800e-04, 3.30698822e-04, 2.49389879e-04, 3.26185982e-04,\n",
            "       3.73697607e-04, 3.60891630e-04, 2.65371054e-04, 3.39124061e-04,\n",
            "       3.49485490e-04, 6.13783894e-04, 2.08861107e-04, 4.20405355e-04,\n",
            "       3.22655571e-04, 4.61900665e-04, 3.95117357e-04, 2.89826974e-04,\n",
            "       3.33314121e-04, 4.95435728e-04, 3.91799986e-04, 3.36370926e-04,\n",
            "       2.29342113e-04, 3.79157747e-04, 3.43943568e-04, 2.87956937e-04,\n",
            "       2.89636751e-04, 2.35293715e-04, 4.00526274e-04, 3.73888179e-04,\n",
            "       4.19040007e-04, 1.63815712e-04, 2.36704538e-04, 1.12045062e-04,\n",
            "       4.38512099e-04, 2.07794263e-04, 4.34189540e-04, 3.28166992e-04,\n",
            "       3.32506432e-04, 4.21203062e-04, 3.01357592e-04, 2.74103862e-04,\n",
            "       3.17236787e-04, 3.27742629e-04, 3.07929819e-04, 2.25803422e-04,\n",
            "       3.00977932e-04, 3.23854561e-04, 3.05171154e-04, 2.75158673e-04,\n",
            "       3.49546113e-04, 3.60827311e-04, 4.14140872e-04, 3.17495229e-04,\n",
            "       2.69346929e-04, 4.81730123e-04, 3.22326843e-04, 6.36176337e-05,\n",
            "       2.60562490e-04, 2.85688293e-04, 2.78540014e-04, 3.40927043e-04,\n",
            "       3.95304611e-04, 3.70471273e-04, 2.92088691e-04, 4.18017502e-04,\n",
            "       4.01240162e-04, 2.48619821e-04, 3.01693100e-04, 2.76262988e-04,\n",
            "       2.23699928e-04, 1.55001850e-04, 3.77147546e-04, 4.48580104e-04,\n",
            "       2.92211102e-04, 3.84210987e-04, 1.70275918e-04, 3.61566519e-04,\n",
            "       2.50687328e-04, 5.22043032e-04, 3.54851683e-04, 3.42958781e-04,\n",
            "       2.63916911e-04, 4.76560235e-04, 4.25031525e-04, 2.32237639e-04,\n",
            "       3.54207616e-04, 3.04785935e-04, 9.22115796e-05, 3.45146080e-04,\n",
            "       2.82881083e-04, 3.30568058e-04, 4.06055158e-04, 3.51008290e-04,\n",
            "       2.60421133e-04, 4.29557229e-04, 5.10317390e-04, 5.23570518e-04,\n",
            "       3.47268186e-04, 4.57732909e-04, 2.14159722e-04, 2.22865885e-04,\n",
            "       4.99786984e-05, 2.69997458e-04, 1.22607744e-04, 2.71340949e-04,\n",
            "       3.23999237e-04, 3.40265324e-05, 3.02640459e-04, 2.84622365e-04,\n",
            "       2.83406407e-04, 3.23565386e-04, 3.36884172e-04, 1.96390043e-04,\n",
            "       4.33482754e-04, 4.29926469e-04, 1.48065155e-04, 3.30708426e-04,\n",
            "       3.99504788e-04, 1.23524194e-04, 3.17131460e-04, 2.25383847e-04,\n",
            "       3.35250923e-04, 2.92074808e-04, 3.14663193e-04, 3.99583252e-04,\n",
            "       4.01658290e-05, 1.87272250e-04, 1.65007645e-04, 3.25050933e-04,\n",
            "       2.98028666e-04, 3.59650847e-04, 2.79810862e-04, 1.01772013e-04,\n",
            "       3.99335113e-04, 2.78635649e-04, 2.32817052e-04, 5.07209275e-04,\n",
            "       3.30498151e-04, 3.75890377e-04, 3.87695211e-04, 4.21099074e-04,\n",
            "       2.84430716e-04, 5.11516082e-05, 3.61032580e-04, 4.23053600e-04,\n",
            "       3.58106045e-04, 3.06824280e-04, 3.20193765e-04, 4.97863046e-04,\n",
            "       1.31654931e-04, 3.61113343e-04, 3.83022707e-04, 1.11440393e-04,\n",
            "       5.10299360e-05, 2.07713019e-04, 2.65739975e-04, 3.91841633e-04,\n",
            "       2.18329471e-04, 2.89885211e-04, 3.73629679e-04, 3.58321879e-04,\n",
            "       1.58246694e-04, 2.99523497e-04, 2.81322427e-04, 3.37731180e-04,\n",
            "       3.13990720e-04, 1.97206493e-04, 3.43335822e-04, 1.74453860e-04,\n",
            "       3.49405949e-04, 2.85360526e-04, 1.89936080e-04, 2.98431085e-04,\n",
            "       3.54990800e-04, 3.86291009e-04, 5.64586517e-05, 1.67207021e-04,\n",
            "       5.33291895e-04, 3.18024657e-04, 4.26691782e-04, 3.15103476e-04,\n",
            "       3.88590270e-04, 3.84518906e-04, 4.35788097e-04, 1.85723664e-04,\n",
            "       2.85462243e-04, 2.98092404e-04, 3.45033623e-04, 3.60653910e-04,\n",
            "       3.06527480e-04, 5.42255642e-04, 2.48404656e-04, 1.65432662e-04,\n",
            "       7.27297374e-05, 3.66234424e-04, 2.54481216e-04, 2.81109125e-04,\n",
            "       2.19584399e-04, 3.61976301e-04, 2.37301356e-04, 2.25994561e-04,\n",
            "       1.05944600e-04, 3.26979789e-04, 2.84611626e-04, 2.68468022e-04,\n",
            "       3.21373198e-04, 3.78033321e-04, 3.06582951e-04, 1.34191418e-04,\n",
            "       2.88581883e-04, 4.19700315e-04, 3.46408575e-04, 3.64795706e-04,\n",
            "       3.71913222e-04, 3.89302557e-04, 3.30312265e-04, 1.00605597e-04,\n",
            "       4.60329698e-04, 4.15151328e-04, 3.50084068e-04, 2.07756224e-04,\n",
            "       3.77006450e-04, 2.72256788e-04, 4.66666941e-04, 3.79164878e-04,\n",
            "       3.75611940e-04, 4.06748819e-04, 3.00875487e-04, 3.51215887e-04,\n",
            "       3.86646221e-04, 4.06145497e-04, 3.24055116e-04, 3.59224679e-04,\n",
            "       5.36347652e-05, 3.35499004e-04, 2.93056975e-04, 4.71813430e-04,\n",
            "       6.65868065e-05, 3.68215522e-04, 3.29144939e-04, 5.83662149e-05,\n",
            "       4.24568134e-04, 2.92665005e-04, 4.32798581e-04, 2.82534485e-04,\n",
            "       2.71237222e-04, 5.64836198e-04, 3.20962426e-04, 3.73571645e-04,\n",
            "       1.76289526e-04, 3.88571731e-04, 2.92002078e-04, 1.52513021e-04,\n",
            "       3.04713583e-04, 3.53848736e-04, 8.19499110e-05, 2.51019927e-04,\n",
            "       3.69084853e-04, 8.63527457e-05, 2.30871345e-04, 4.39536117e-04,\n",
            "       8.88181312e-05, 1.82535267e-04, 3.50497023e-04, 3.36196594e-04,\n",
            "       3.44865985e-04, 4.52597276e-04, 1.39666838e-04, 3.82802624e-04,\n",
            "       8.56828774e-05, 3.27345071e-04, 3.88508983e-04, 3.20343272e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/rezero/mul', 'index': 222, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.006478710565716028, 127), 'quantization_parameters': {'scales': array([0.00647871], dtype=float32), 'zero_points': array([127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 223, 'shape': array([144], dtype=int32), 'shape_signature': array([144], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([9.59638928e-05, 1.90699473e-04, 3.16639489e-04, 2.59322522e-04,\n",
            "       1.49469313e-04, 1.60145821e-04, 1.58035939e-04, 1.18808101e-04,\n",
            "       2.85331102e-04, 1.34109985e-04, 2.71718745e-04, 1.94061577e-04,\n",
            "       1.45266909e-04, 2.47676013e-04, 2.11069026e-04, 8.52025987e-05,\n",
            "       1.22081212e-04, 1.93904110e-04, 2.31924045e-04, 1.24085389e-04,\n",
            "       9.11851603e-05, 1.20124896e-04, 1.60111143e-04, 9.46128930e-05,\n",
            "       1.30574088e-04, 2.05913588e-04, 1.75481880e-04, 1.24533908e-04,\n",
            "       1.00498080e-04, 2.09878795e-04, 8.07889810e-05, 1.23296559e-04,\n",
            "       2.21466704e-04, 1.42187462e-04, 2.18983507e-04, 1.12132147e-04,\n",
            "       1.52648194e-04, 1.23370774e-04, 2.01780262e-04, 2.06146389e-04,\n",
            "       1.68536833e-04, 1.99693022e-04, 2.27810757e-04, 1.05605992e-04,\n",
            "       2.01912408e-04, 1.65048594e-04, 1.73502427e-04, 1.28654501e-04,\n",
            "       1.95881075e-04, 1.69797830e-04, 1.75904206e-04, 1.18993812e-04,\n",
            "       1.21367782e-04, 2.40844558e-04, 1.64148572e-04, 8.48653726e-05,\n",
            "       1.87111786e-04, 2.61573266e-04, 1.74666609e-04, 1.79693641e-04,\n",
            "       2.01245392e-04, 2.31375350e-04, 1.30948087e-04, 2.23137831e-04,\n",
            "       1.93242551e-04, 1.97610512e-04, 1.00619160e-04, 3.11663345e-04,\n",
            "       2.32168910e-04, 2.00180744e-04, 1.72399436e-04, 1.69160310e-04,\n",
            "       1.79645504e-04, 1.10041728e-04, 1.99221060e-04, 1.80486575e-04,\n",
            "       1.88135498e-04, 2.25030191e-04, 2.29857120e-04, 1.87016965e-04,\n",
            "       2.59916123e-04, 2.56247964e-04, 3.77313641e-04, 1.75736757e-04,\n",
            "       1.54029156e-04, 1.38235599e-04, 9.69943139e-05, 1.72540138e-04,\n",
            "       1.29740234e-04, 1.66540805e-04, 1.75248875e-04, 8.77018829e-05,\n",
            "       2.96456914e-04, 2.97994848e-04, 1.69888401e-04, 2.57503474e-04,\n",
            "       1.18817792e-04, 1.07112988e-04, 3.33534321e-04, 1.94227701e-04,\n",
            "       1.06451480e-04, 2.14272979e-04, 3.40873725e-04, 9.57113516e-05,\n",
            "       2.31283251e-04, 1.65572666e-04, 1.34398608e-04, 1.99517803e-04,\n",
            "       1.84897261e-04, 8.68854768e-05, 1.58146868e-04, 1.92737265e-04,\n",
            "       2.44206167e-04, 3.21999833e-04, 1.16300886e-04, 3.08974297e-04,\n",
            "       1.56138485e-04, 1.03307197e-04, 1.85568104e-04, 2.04942684e-04,\n",
            "       2.47572025e-04, 2.22124421e-04, 1.78081187e-04, 2.30170233e-04,\n",
            "       1.16513991e-04, 1.44468577e-04, 1.04572369e-04, 1.53330824e-04,\n",
            "       1.92713880e-04, 1.88478982e-04, 2.01316710e-04, 1.81242154e-04,\n",
            "       1.25135397e-04, 2.22958042e-04, 1.73273394e-04, 2.79355474e-04,\n",
            "       2.42394221e-04, 2.80911074e-04, 1.40247445e-04, 1.69844134e-04,\n",
            "       1.92194901e-04, 1.83534517e-04, 2.08383208e-04, 2.78347492e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 224, 'shape': array([144,   1,   1, 480], dtype=int32), 'shape_signature': array([144,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.0050924 , 0.01011961, 0.01680272, 0.01376115, 0.0079317 ,\n",
            "       0.00849826, 0.0083863 , 0.00630464, 0.01514131, 0.00711665,\n",
            "       0.01441896, 0.01029802, 0.0077087 , 0.01314312, 0.01120054,\n",
            "       0.00452134, 0.00647833, 0.01028967, 0.01230723, 0.00658469,\n",
            "       0.00483881, 0.00637452, 0.00849642, 0.00502071, 0.00692901,\n",
            "       0.01092696, 0.00931208, 0.00660849, 0.00533301, 0.01113738,\n",
            "       0.00428713, 0.00654283, 0.0117523 , 0.00754529, 0.01162053,\n",
            "       0.00595038, 0.00810039, 0.00654676, 0.01070762, 0.01093931,\n",
            "       0.00894354, 0.01059686, 0.01208895, 0.00560406, 0.01071464,\n",
            "       0.00875843, 0.00920704, 0.00682715, 0.01039458, 0.00901045,\n",
            "       0.00933449, 0.0063145 , 0.00644047, 0.0127806 , 0.00871067,\n",
            "       0.00450345, 0.00992923, 0.01388058, 0.00926882, 0.00953558,\n",
            "       0.01067924, 0.01227811, 0.00694886, 0.01184098, 0.01025456,\n",
            "       0.01048635, 0.00533943, 0.01653865, 0.01232022, 0.01062274,\n",
            "       0.00914851, 0.00897662, 0.00953303, 0.00583945, 0.01057182,\n",
            "       0.00957766, 0.00998355, 0.0119414 , 0.01219754, 0.0099242 ,\n",
            "       0.01379265, 0.01359799, 0.02002244, 0.0093256 , 0.00817367,\n",
            "       0.00733558, 0.00514708, 0.00915597, 0.00688476, 0.00883761,\n",
            "       0.00929972, 0.00465397, 0.01573171, 0.01581332, 0.00901526,\n",
            "       0.01366462, 0.00630516, 0.00568403, 0.01769925, 0.01030684,\n",
            "       0.00564893, 0.01137056, 0.01808872, 0.005079  , 0.01227322,\n",
            "       0.00878624, 0.00713196, 0.01058756, 0.00981171, 0.00461064,\n",
            "       0.00839218, 0.01022775, 0.01295899, 0.01708717, 0.00617159,\n",
            "       0.01639596, 0.00828561, 0.00548207, 0.00984731, 0.01087544,\n",
            "       0.0131376 , 0.0117872 , 0.00945001, 0.01221416, 0.0061829 ,\n",
            "       0.00766633, 0.00554921, 0.00813662, 0.01022651, 0.01000178,\n",
            "       0.01068302, 0.00961775, 0.0066404 , 0.01183144, 0.00919488,\n",
            "       0.01482421, 0.01286283, 0.01490676, 0.00744234, 0.00901291,\n",
            "       0.01019897, 0.0097394 , 0.01105801, 0.01477072], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block4_layer3/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block4_layer3/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block4_layer3/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer3/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 225, 'shape': array([480], dtype=int32), 'shape_signature': array([480], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([4.29541687e-05, 3.51794879e-05, 5.84770678e-05, 3.75382115e-05,\n",
            "       4.04917591e-05, 3.07497066e-05, 5.20471549e-05, 1.76780413e-05,\n",
            "       2.95377413e-05, 4.47450075e-05, 3.84965861e-05, 3.03612069e-05,\n",
            "       4.86436584e-05, 2.66130610e-05, 3.87794753e-05, 2.22741655e-05,\n",
            "       5.06280776e-05, 2.51632409e-05, 1.67915387e-05, 2.92360673e-05,\n",
            "       3.52531242e-05, 3.28495116e-05, 2.31397680e-05, 4.39411269e-05,\n",
            "       4.09426975e-05, 3.92222100e-05, 2.46919917e-05, 5.99296909e-05,\n",
            "       4.49309737e-05, 4.01045945e-05, 4.36975060e-05, 3.77903161e-05,\n",
            "       4.42978089e-05, 3.33835123e-05, 5.82477442e-05, 2.91771157e-05,\n",
            "       1.55875587e-05, 3.82044745e-05, 1.36582705e-04, 3.92743132e-05,\n",
            "       2.95415830e-05, 3.25161345e-05, 3.37496567e-05, 2.91239321e-05,\n",
            "       3.06858237e-05, 2.84480138e-05, 3.47185378e-05, 5.34782812e-05,\n",
            "       4.99554953e-05, 5.91086500e-05, 5.29488971e-05, 3.33202042e-05,\n",
            "       3.56681594e-05, 3.45921799e-05, 6.33708769e-05, 1.86431807e-05,\n",
            "       5.23412018e-05, 5.04000418e-05, 1.58630501e-05, 4.28067651e-05,\n",
            "       2.75566963e-05, 2.76974624e-05, 3.59332953e-05, 1.37231051e-04,\n",
            "       3.52972747e-05, 1.91902927e-05, 3.37630736e-05, 3.84581435e-05,\n",
            "       4.57308597e-05, 2.10817525e-05, 4.24140344e-05, 2.73137885e-05,\n",
            "       4.83570584e-05, 2.27907003e-05, 2.45746614e-05, 2.15937671e-05,\n",
            "       2.47395437e-05, 3.12028351e-05, 5.67658208e-05, 2.30890091e-05,\n",
            "       3.65299020e-05, 4.51834458e-05, 1.62649321e-05, 3.22178785e-05,\n",
            "       6.58300050e-05, 3.85860185e-05, 4.20872020e-05, 3.87709151e-05,\n",
            "       2.78823391e-05, 2.82312012e-05, 3.47487039e-05, 3.28151218e-05,\n",
            "       3.02214467e-05, 2.98038922e-05, 2.73728983e-05, 2.95042482e-05,\n",
            "       2.44145376e-05, 1.87219193e-05, 3.08699491e-05, 4.13065100e-05,\n",
            "       2.96151029e-05, 3.67634166e-05, 3.60616541e-05, 2.97013667e-05,\n",
            "       5.50617951e-05, 3.09349307e-05, 3.90000241e-05, 1.54244808e-05,\n",
            "       4.55147529e-05, 1.40452767e-05, 1.57611823e-04, 3.01644304e-05,\n",
            "       1.19954475e-05, 3.39078688e-05, 3.88010012e-05, 3.14512290e-05,\n",
            "       5.40283472e-05, 4.49651125e-05, 3.83439801e-05, 1.71160173e-05,\n",
            "       5.08263729e-05, 3.76553253e-05, 4.55713343e-05, 2.67957075e-05,\n",
            "       4.53791399e-05, 3.04305322e-05, 4.75091438e-05, 1.51863233e-05,\n",
            "       4.90659368e-05, 4.55248228e-05, 2.80161748e-05, 4.07619555e-05,\n",
            "       4.35428883e-05, 3.40981569e-05, 7.66807061e-05, 4.87646757e-05,\n",
            "       1.56726644e-04, 3.08252420e-05, 1.75733512e-05, 3.31867850e-05,\n",
            "       5.25447540e-05, 4.12913359e-05, 4.77061949e-05, 3.22145424e-05,\n",
            "       3.02015014e-05, 2.95877562e-05, 1.80465922e-05, 4.24309692e-05,\n",
            "       4.91346182e-05, 3.69919617e-05, 6.13479642e-05, 8.65255497e-05,\n",
            "       7.15644928e-05, 4.25764374e-05, 6.06604735e-05, 3.79835983e-05,\n",
            "       2.97373881e-05, 2.44551156e-05, 1.66101090e-05, 3.49856055e-05,\n",
            "       3.01040909e-05, 3.36617704e-05, 5.01010363e-05, 2.28528788e-05,\n",
            "       3.66540262e-05, 1.93149663e-05, 5.36113257e-05, 2.56578642e-05,\n",
            "       2.52700538e-05, 5.23490489e-05, 3.34674623e-05, 3.56903838e-05,\n",
            "       3.45454464e-05, 3.11977528e-05, 4.92494073e-05, 3.74765259e-05,\n",
            "       2.81130451e-05, 2.94776255e-05, 2.51008241e-05, 3.90033965e-05,\n",
            "       3.49464171e-05, 4.37380586e-05, 2.84049383e-05, 4.78312249e-05,\n",
            "       1.19474971e-04, 4.86217759e-05, 2.90245207e-05, 5.97673425e-05,\n",
            "       3.37057390e-05, 4.11774963e-05, 4.25306280e-05, 3.67316279e-05,\n",
            "       2.06720979e-05, 2.61646601e-05, 2.42692713e-05, 3.26267982e-05,\n",
            "       4.36962182e-05, 4.54125584e-05, 2.03324489e-05, 4.81767092e-05,\n",
            "       4.72811917e-05, 4.30159562e-05, 9.52427145e-05, 3.60479644e-05,\n",
            "       2.34015370e-05, 2.63056081e-05, 3.37068777e-05, 2.94514812e-05,\n",
            "       1.90738065e-05, 2.23020088e-05, 3.94234412e-05, 6.12698204e-05,\n",
            "       3.72819923e-05, 4.15839713e-05, 5.19698078e-05, 3.62285027e-05,\n",
            "       1.62999877e-05, 5.59843720e-05, 4.53087378e-05, 4.46324120e-05,\n",
            "       3.80620622e-05, 4.45091937e-05, 2.76015489e-05, 5.68166906e-05,\n",
            "       4.32375455e-05, 3.89766319e-05, 4.62954958e-05, 3.61071980e-05,\n",
            "       3.13234887e-05, 1.96247074e-05, 2.48093729e-05, 4.81494753e-05,\n",
            "       4.32855304e-05, 2.73629903e-05, 5.23414747e-05, 4.24941136e-05,\n",
            "       5.16927030e-05, 5.09395395e-05, 1.63047607e-05, 3.59665537e-05,\n",
            "       2.13994044e-05, 4.28206658e-05, 4.85928176e-05, 5.16100372e-05,\n",
            "       3.29970899e-05, 3.61075108e-05, 3.64504995e-05, 4.13988237e-05,\n",
            "       3.98635893e-05, 3.71841124e-05, 4.85224919e-05, 2.84101407e-05,\n",
            "       4.93754851e-05, 4.33748901e-05, 3.29247159e-05, 1.95280081e-05,\n",
            "       6.65663320e-05, 4.56046328e-05, 3.66527420e-05, 2.11891584e-05,\n",
            "       3.24623179e-05, 4.22537269e-05, 4.70159976e-05, 4.21110017e-05,\n",
            "       4.01699581e-05, 3.34633041e-05, 5.57101630e-05, 3.15619654e-05,\n",
            "       2.48794568e-05, 2.41325361e-05, 9.76836600e-05, 3.89892375e-05,\n",
            "       3.46346496e-05, 5.24337047e-05, 7.22239565e-05, 3.60301528e-05,\n",
            "       2.48128454e-05, 3.33681455e-05, 2.94456295e-05, 3.70318994e-05,\n",
            "       2.67791329e-05, 3.84536288e-05, 2.33250576e-05, 2.09091122e-05,\n",
            "       4.19585049e-05, 4.81013412e-05, 3.40402803e-05, 5.52758938e-05,\n",
            "       4.73200198e-05, 3.40594779e-05, 4.10796747e-05, 5.03012125e-05,\n",
            "       2.26884513e-05, 4.43465797e-05, 1.89238290e-05, 2.66549723e-05,\n",
            "       3.38268546e-05, 2.14438751e-05, 1.84080473e-05, 4.50843800e-05,\n",
            "       3.03050456e-05, 3.63131148e-05, 2.00623144e-05, 2.85026927e-05,\n",
            "       4.82978649e-05, 3.51960480e-05, 3.30062539e-05, 5.06314391e-05,\n",
            "       4.49016152e-05, 4.85390337e-05, 3.69450281e-05, 2.86194772e-05,\n",
            "       2.81191915e-05, 2.33973024e-05, 2.86419890e-05, 5.07815603e-05,\n",
            "       4.09220593e-05, 4.40822769e-05, 3.79000776e-05, 4.57613969e-05,\n",
            "       2.50551602e-05, 2.13762360e-05, 2.14409374e-05, 4.08184023e-05,\n",
            "       2.14195370e-05, 1.23179081e-04, 3.99764722e-05, 2.51366109e-05,\n",
            "       2.63807669e-05, 3.88643057e-05, 5.66822382e-05, 2.83494428e-05,\n",
            "       3.53407995e-05, 3.23350432e-05, 4.34635404e-05, 4.31920307e-05,\n",
            "       1.48440749e-05, 2.49689983e-05, 3.87372456e-05, 3.26050576e-05,\n",
            "       4.32543420e-05, 2.94782403e-05, 3.72391187e-05, 2.27761393e-05,\n",
            "       6.68579814e-05, 4.12840054e-05, 6.22817606e-05, 5.05418066e-05,\n",
            "       4.02179321e-05, 2.97849947e-05, 4.77482536e-05, 3.50505943e-05,\n",
            "       3.98131961e-05, 3.90276800e-05, 2.95207137e-05, 2.63746606e-05,\n",
            "       6.11024516e-05, 1.30609214e-05, 4.43658355e-05, 2.07593894e-05,\n",
            "       3.83081569e-05, 2.30867463e-05, 1.89232360e-05, 3.58771249e-05,\n",
            "       5.62737368e-05, 4.12171175e-05, 2.28170156e-05, 2.25569565e-05,\n",
            "       2.61389541e-05, 3.53073410e-05, 4.44018333e-05, 6.80212906e-05,\n",
            "       4.43214594e-05, 4.03438207e-05, 2.80781824e-05, 3.66660825e-05,\n",
            "       3.53416362e-05, 4.12769587e-05, 2.45883821e-05, 2.10840353e-05,\n",
            "       3.09778552e-05, 2.29301422e-05, 4.44794096e-05, 1.97829049e-05,\n",
            "       3.11231452e-05, 3.90332498e-05, 3.71038586e-05, 3.29666291e-05,\n",
            "       3.26605041e-05, 2.83126719e-05, 2.28893350e-05, 6.29821297e-05,\n",
            "       4.11431938e-05, 5.79647422e-05, 3.65900960e-05, 2.58205910e-05,\n",
            "       3.52392490e-05, 4.58903414e-05, 2.86558152e-05, 2.28724512e-05,\n",
            "       4.02839869e-05, 4.84698539e-05, 2.21522296e-05, 4.63087235e-05,\n",
            "       4.55810805e-05, 3.72792310e-05, 2.49619043e-05, 6.49919457e-05,\n",
            "       3.44876571e-05, 4.11999536e-05, 4.56738780e-05, 4.61144118e-05,\n",
            "       4.10559442e-05, 4.89056547e-05, 3.06456423e-05, 4.22841913e-05,\n",
            "       1.67843627e-05, 2.32649327e-05, 1.08459739e-04, 4.19263342e-05,\n",
            "       3.95301395e-05, 1.43373545e-05, 4.21284713e-05, 3.07264345e-05,\n",
            "       3.22680717e-05, 3.14682002e-05, 3.22687083e-05, 4.75300440e-05,\n",
            "       4.30644250e-05, 4.24463578e-05, 3.55445554e-05, 3.57692043e-05,\n",
            "       3.30257899e-05, 3.92286383e-05, 3.83976476e-05, 2.83251156e-05,\n",
            "       4.61493619e-05, 3.48275316e-05, 3.59419646e-05, 4.18684722e-05,\n",
            "       1.83274060e-05, 2.44991916e-05, 7.33768102e-05, 2.00660816e-05,\n",
            "       2.53276285e-05, 2.68376189e-05, 5.00564202e-05, 7.46028163e-05,\n",
            "       3.36122539e-05, 4.30738364e-05, 7.11632383e-05, 2.73525293e-05,\n",
            "       3.28677488e-05, 4.98299851e-05, 3.17145059e-05, 3.12819102e-05,\n",
            "       1.89922030e-05, 3.69984518e-05, 3.49602124e-05, 3.69436784e-05,\n",
            "       2.65319777e-05, 6.68891807e-05, 5.50195618e-05, 6.27159752e-05,\n",
            "       4.44226062e-05, 3.62065366e-05, 3.31080701e-05, 2.19078756e-05,\n",
            "       3.09056231e-05, 3.14524441e-05, 6.83077160e-05, 4.46164631e-05,\n",
            "       2.05617234e-05, 2.29653506e-05, 3.45320368e-05, 3.24213215e-05,\n",
            "       4.56492889e-05, 5.27468474e-05, 3.53788855e-05, 3.26349182e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 226, 'shape': array([480,   1,   1, 240], dtype=int32), 'shape_signature': array([480,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00137433, 0.00112558, 0.00187099, 0.00120105, 0.00129555,\n",
            "       0.00098385, 0.00166526, 0.00056561, 0.00094507, 0.00143163,\n",
            "       0.00123171, 0.00097142, 0.00155637, 0.00085149, 0.00124076,\n",
            "       0.00071267, 0.00161986, 0.00080511, 0.00053725, 0.00093542,\n",
            "       0.00112793, 0.00105103, 0.00074036, 0.00140591, 0.00130997,\n",
            "       0.00125493, 0.00079003, 0.00191747, 0.00143758, 0.00128316,\n",
            "       0.00139811, 0.00120911, 0.00141732, 0.00106812, 0.00186365,\n",
            "       0.00093353, 0.00049873, 0.00122236, 0.00437   , 0.00125659,\n",
            "       0.00094519, 0.00104036, 0.00107983, 0.00093183, 0.0009818 ,\n",
            "       0.0009102 , 0.00111083, 0.00171105, 0.00159834, 0.0018912 ,\n",
            "       0.00169412, 0.00106609, 0.00114121, 0.00110679, 0.00202757,\n",
            "       0.00059649, 0.00167467, 0.00161256, 0.00050754, 0.00136961,\n",
            "       0.00088168, 0.00088619, 0.0011497 , 0.00439075, 0.00112935,\n",
            "       0.000614  , 0.00108026, 0.00123048, 0.00146317, 0.00067452,\n",
            "       0.00135705, 0.00087391, 0.0015472 , 0.00072919, 0.00078627,\n",
            "       0.0006909 , 0.00079155, 0.00099834, 0.00181624, 0.00073874,\n",
            "       0.00116878, 0.00144566, 0.0005204 , 0.00103082, 0.00210625,\n",
            "       0.00123457, 0.00134659, 0.00124049, 0.0008921 , 0.00090327,\n",
            "       0.00111179, 0.00104993, 0.00096694, 0.00095358, 0.0008758 ,\n",
            "       0.000944  , 0.00078115, 0.00059901, 0.00098769, 0.00132161,\n",
            "       0.00094754, 0.00117626, 0.0011538 , 0.0009503 , 0.00176172,\n",
            "       0.00098977, 0.00124782, 0.00049351, 0.00145626, 0.00044938,\n",
            "       0.00504284, 0.00096512, 0.0003838 , 0.00108489, 0.00124145,\n",
            "       0.00100629, 0.00172865, 0.00143867, 0.00122683, 0.00054763,\n",
            "       0.0016262 , 0.00120479, 0.00145807, 0.00085734, 0.00145192,\n",
            "       0.00097363, 0.00152007, 0.00048589, 0.00156988, 0.00145658,\n",
            "       0.00089639, 0.00130419, 0.00139317, 0.00109098, 0.00245342,\n",
            "       0.00156024, 0.00501451, 0.00098626, 0.00056226, 0.00106182,\n",
            "       0.00168118, 0.00132113, 0.00152637, 0.00103071, 0.00096631,\n",
            "       0.00094667, 0.00057741, 0.00135759, 0.00157208, 0.00118357,\n",
            "       0.00196285, 0.00276841, 0.00228973, 0.00136225, 0.00194085,\n",
            "       0.0012153 , 0.00095146, 0.00078245, 0.00053145, 0.00111937,\n",
            "       0.00096319, 0.00107702, 0.001603  , 0.00073118, 0.00117276,\n",
            "       0.00061799, 0.00171531, 0.00082093, 0.00080852, 0.00167492,\n",
            "       0.0010708 , 0.00114192, 0.00110529, 0.00099818, 0.00157575,\n",
            "       0.00119907, 0.00089948, 0.00094315, 0.00080311, 0.00124792,\n",
            "       0.00111812, 0.00139941, 0.00090882, 0.00153037, 0.00382264,\n",
            "       0.00155567, 0.00092865, 0.00191227, 0.00107842, 0.00131749,\n",
            "       0.00136078, 0.00117524, 0.00066141, 0.00083715, 0.0007765 ,\n",
            "       0.0010439 , 0.00139807, 0.00145299, 0.00065054, 0.00154143,\n",
            "       0.00151278, 0.00137631, 0.00304732, 0.00115336, 0.00074874,\n",
            "       0.00084166, 0.00107846, 0.00094231, 0.00061027, 0.00071356,\n",
            "       0.00126136, 0.00196035, 0.00119285, 0.00133049, 0.00166279,\n",
            "       0.00115914, 0.00052152, 0.00179124, 0.00144967, 0.00142803,\n",
            "       0.00121781, 0.00142408, 0.00088312, 0.00181787, 0.0013834 ,\n",
            "       0.00124707, 0.00148124, 0.00115526, 0.0010022 , 0.0006279 ,\n",
            "       0.00079378, 0.00154056, 0.00138493, 0.00087549, 0.00167468,\n",
            "       0.00135961, 0.00165392, 0.00162983, 0.00052168, 0.00115076,\n",
            "       0.00068468, 0.00137006, 0.00155474, 0.00165128, 0.00105575,\n",
            "       0.00115527, 0.00116624, 0.00132457, 0.00127545, 0.00118972,\n",
            "       0.00155249, 0.00090899, 0.00157978, 0.00138779, 0.00105344,\n",
            "       0.0006248 , 0.00212981, 0.00145913, 0.00117271, 0.00067795,\n",
            "       0.00103864, 0.00135192, 0.00150429, 0.00134735, 0.00128525,\n",
            "       0.00107067, 0.00178246, 0.00100983, 0.00079603, 0.00077213,\n",
            "       0.00312542, 0.00124747, 0.00110815, 0.00167763, 0.00231083,\n",
            "       0.0011528 , 0.00079389, 0.00106762, 0.00094212, 0.00118485,\n",
            "       0.00085681, 0.00123033, 0.00074629, 0.00066899, 0.00134247,\n",
            "       0.00153902, 0.00108913, 0.00176857, 0.00151402, 0.00108974,\n",
            "       0.00131436, 0.0016094 , 0.00072592, 0.00141888, 0.00060547,\n",
            "       0.00085283, 0.0010823 , 0.0006861 , 0.00058897, 0.00144249,\n",
            "       0.00096962, 0.00116185, 0.0006419 , 0.00091195, 0.0015453 ,\n",
            "       0.00112611, 0.00105604, 0.00161997, 0.00143664, 0.00155302,\n",
            "       0.00118207, 0.00091569, 0.00089968, 0.0007486 , 0.00091641,\n",
            "       0.00162477, 0.00130931, 0.00141043, 0.00121262, 0.00146415,\n",
            "       0.00080165, 0.00068394, 0.00068601, 0.001306  , 0.00068532,\n",
            "       0.00394115, 0.00127906, 0.00080425, 0.00084406, 0.00124347,\n",
            "       0.00181356, 0.00090705, 0.00113074, 0.00103457, 0.00139063,\n",
            "       0.00138194, 0.00047494, 0.00079889, 0.00123941, 0.00104321,\n",
            "       0.00138393, 0.00094316, 0.00119148, 0.00072873, 0.00213914,\n",
            "       0.00132089, 0.00199272, 0.0016171 , 0.00128678, 0.00095298,\n",
            "       0.00152772, 0.00112145, 0.00127383, 0.0012487 , 0.00094452,\n",
            "       0.00084386, 0.00195499, 0.00041789, 0.0014195 , 0.0006642 ,\n",
            "       0.00122568, 0.00073867, 0.00060545, 0.0011479 , 0.00180049,\n",
            "       0.00131875, 0.00073004, 0.00072172, 0.00083632, 0.00112967,\n",
            "       0.00142065, 0.00217636, 0.00141808, 0.00129081, 0.00089837,\n",
            "       0.00117314, 0.00113077, 0.00132067, 0.00078671, 0.00067459,\n",
            "       0.00099115, 0.00073366, 0.00142313, 0.00063296, 0.00099579,\n",
            "       0.00124888, 0.00118715, 0.00105478, 0.00104498, 0.00090587,\n",
            "       0.00073235, 0.00201513, 0.00131639, 0.0018546 , 0.00117071,\n",
            "       0.00082614, 0.00112749, 0.00146827, 0.00091685, 0.00073181,\n",
            "       0.0012889 , 0.00155081, 0.00070877, 0.00148166, 0.00145838,\n",
            "       0.00119276, 0.00079866, 0.00207944, 0.00110344, 0.0013182 ,\n",
            "       0.00146135, 0.00147544, 0.0013136 , 0.00156475, 0.00098052,\n",
            "       0.00135289, 0.00053702, 0.00074437, 0.0034702 , 0.00134145,\n",
            "       0.00126478, 0.00045873, 0.00134791, 0.0009831 , 0.00103243,\n",
            "       0.00100683, 0.00103245, 0.00152074, 0.00137786, 0.00135808,\n",
            "       0.00113726, 0.00114445, 0.00105667, 0.00125513, 0.00122854,\n",
            "       0.00090627, 0.00147656, 0.00111432, 0.00114997, 0.00133959,\n",
            "       0.00058639, 0.00078386, 0.00234771, 0.00064202, 0.00081036,\n",
            "       0.00085868, 0.00160157, 0.00238694, 0.00107543, 0.00137816,\n",
            "       0.00227689, 0.00087515, 0.00105161, 0.00159432, 0.00101471,\n",
            "       0.00100087, 0.00060766, 0.00118378, 0.00111856, 0.00118202,\n",
            "       0.0008489 , 0.00214014, 0.00176037, 0.00200662, 0.00142131,\n",
            "       0.00115844, 0.0010593 , 0.00070095, 0.00098883, 0.00100633,\n",
            "       0.00218552, 0.00142752, 0.00065788, 0.00073478, 0.00110486,\n",
            "       0.00103733, 0.00146056, 0.00168765, 0.00113196, 0.00104416],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 227, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.38618622e-06, 3.91141884e-06, 1.58658422e-05, 1.43564910e-06,\n",
            "       3.74176452e-05, 1.81741780e-05, 2.46950567e-05, 6.18210697e-06,\n",
            "       5.93212280e-06, 3.30177354e-05, 3.40340630e-05, 4.26311772e-06,\n",
            "       4.38041316e-05, 3.78461518e-05, 3.23882668e-05, 7.17563016e-05,\n",
            "       1.25046954e-05, 9.07303638e-06, 2.97529664e-06, 9.11119878e-06,\n",
            "       5.30710713e-06, 7.14426187e-06, 5.30349826e-06, 9.63106959e-06,\n",
            "       1.61879984e-06, 5.66323479e-06, 9.53015915e-05, 1.09710898e-04,\n",
            "       5.85400194e-05, 7.08595107e-05, 3.82459475e-05, 7.09052131e-07,\n",
            "       4.45781507e-06, 8.59296222e-07, 2.21873506e-05, 8.27689437e-05,\n",
            "       4.24782138e-06, 1.48139907e-05, 2.47882599e-06, 1.20443419e-05,\n",
            "       6.31718967e-06, 8.23096125e-05, 4.04145749e-06, 1.73474200e-05,\n",
            "       2.88416359e-05, 2.53024837e-06, 1.60849468e-05, 2.45090469e-05,\n",
            "       3.83764700e-06, 3.53379619e-06, 1.92199859e-05, 1.40663515e-05,\n",
            "       3.67447637e-06, 3.11416698e-05, 5.63754020e-06, 9.08293805e-06,\n",
            "       1.26696232e-05, 9.20773527e-06, 2.55979467e-05, 2.81616462e-06,\n",
            "       3.25185611e-05, 1.91911240e-05, 3.65913693e-05, 3.68140063e-05,\n",
            "       6.00744934e-05, 6.86676722e-05, 1.14839233e-04, 6.39267228e-06,\n",
            "       5.23917151e-05, 1.49141497e-05, 3.71686147e-05, 1.21258608e-06,\n",
            "       3.36027078e-05, 1.00278612e-05, 7.51261541e-05, 8.50818615e-05,\n",
            "       3.59374644e-05, 5.74109035e-05, 2.93650714e-06, 8.97055270e-06,\n",
            "       8.34979437e-05, 2.24850082e-05, 3.73009498e-05, 6.40259123e-06,\n",
            "       2.70627811e-06, 1.45701770e-05, 1.43383122e-05, 3.09545794e-05,\n",
            "       7.96791210e-06, 3.07986875e-06, 1.32258447e-06, 6.20500305e-06,\n",
            "       1.95037901e-05, 3.42511112e-06, 1.30776443e-05, 8.64821413e-05,\n",
            "       4.24005520e-06, 3.13688111e-06, 1.17114928e-06, 3.40916677e-06,\n",
            "       1.22764141e-05, 4.90083730e-05, 6.37021822e-06, 2.72972875e-06,\n",
            "       1.32242567e-05, 1.02312561e-05, 1.32075093e-05, 2.78969787e-06,\n",
            "       1.67954513e-05, 4.58915974e-06, 5.74178512e-06, 3.71619608e-05,\n",
            "       2.68620897e-06, 5.92748765e-05, 5.55755651e-05, 3.37157894e-06,\n",
            "       6.24356790e-06, 9.23400057e-06, 4.70169789e-06, 7.60431703e-06,\n",
            "       3.58389007e-05, 5.84527152e-05, 3.04110072e-05, 7.28705572e-06,\n",
            "       3.40700558e-06, 9.27435103e-05, 9.44795465e-05, 1.57893373e-05,\n",
            "       3.81212994e-05, 2.94485790e-06, 1.15248304e-05, 1.06394800e-05,\n",
            "       1.15166040e-05, 5.96001883e-05, 1.12040419e-04, 4.25355029e-06,\n",
            "       2.01301486e-06, 1.75298646e-05, 3.89434172e-06, 4.85041928e-05,\n",
            "       1.13589958e-04, 1.55643811e-05, 3.41253472e-05, 8.32552032e-05,\n",
            "       2.74470258e-05, 7.69781036e-06, 1.57981708e-06, 3.95133611e-06,\n",
            "       2.35796499e-04, 3.89205616e-06, 6.57114651e-05, 1.10576811e-05,\n",
            "       1.30437293e-05, 4.64446712e-05, 1.64830835e-05, 2.22927501e-05,\n",
            "       2.94685742e-06, 4.55619011e-06, 5.32839158e-06, 5.13493287e-05,\n",
            "       1.81095296e-04, 7.77071091e-06, 9.77300260e-06, 8.81755659e-06,\n",
            "       8.12244252e-06, 6.75233059e-06, 3.69775307e-06, 8.52928952e-06,\n",
            "       2.14845409e-06, 9.60242687e-06, 1.11231057e-04, 2.72763305e-06,\n",
            "       1.44472915e-05, 6.62769162e-06, 1.40263428e-05, 3.65952997e-06,\n",
            "       2.94000783e-05, 6.09085364e-05, 1.05698664e-05, 6.74150488e-06,\n",
            "       6.26941483e-06, 9.55649557e-06, 1.94403106e-06, 1.77285438e-05,\n",
            "       3.38446662e-05, 1.03695247e-05, 3.07385599e-05, 4.07345260e-06,\n",
            "       2.43579452e-05, 2.18906716e-05, 8.85502595e-05, 1.55044074e-06,\n",
            "       1.93467822e-05, 4.58241584e-06, 3.50856062e-05, 5.41517920e-06,\n",
            "       5.39686916e-05, 2.90718253e-06, 3.61990606e-05, 9.13921758e-05,\n",
            "       2.35491298e-05, 2.83186728e-05, 2.10177641e-05, 8.13587394e-06,\n",
            "       1.79176768e-05, 1.02690046e-05, 5.15814418e-06, 9.96635208e-06,\n",
            "       8.46881812e-05, 1.28035563e-05, 1.44235619e-05, 3.19208834e-06,\n",
            "       8.75732712e-06, 6.65920161e-05, 2.80837503e-05, 4.27129817e-06,\n",
            "       8.49576554e-06, 2.68163581e-06, 2.27795522e-06, 6.86885096e-06,\n",
            "       1.63305940e-05, 1.04239587e-06, 1.75076621e-05, 7.01007093e-06,\n",
            "       1.43273704e-04, 2.08650658e-06, 7.88061661e-05, 6.62553248e-06,\n",
            "       2.19049525e-06, 9.42552379e-06, 9.67427877e-06, 1.15713274e-05,\n",
            "       6.03514272e-05, 1.73357580e-06, 1.06350035e-05, 6.92362164e-06,\n",
            "       8.69072210e-06, 7.80289702e-06, 3.11470535e-06, 6.05327368e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 228, 'shape': array([240,   1,   1, 960], dtype=int32), 'shape_signature': array([240,   1,   1, 960], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([5.66922390e-05, 9.29294984e-05, 3.76948825e-04, 3.41088889e-05,\n",
            "       8.88987677e-04, 4.31791472e-04, 5.86717855e-04, 1.46877675e-04,\n",
            "       1.40938428e-04, 7.84452364e-04, 8.08598765e-04, 1.01285339e-04,\n",
            "       1.04072108e-03, 8.99168313e-04, 7.69497128e-04, 1.70482311e-03,\n",
            "       2.97092978e-04, 2.15561857e-04, 7.06886276e-05, 2.16468543e-04,\n",
            "       1.26088984e-04, 1.69737046e-04, 1.26003244e-04, 2.28819903e-04,\n",
            "       3.84602790e-05, 1.34550050e-04, 2.26422423e-03, 2.60656793e-03,\n",
            "       1.39082386e-03, 1.68351666e-03, 9.08666931e-04, 1.68460247e-05,\n",
            "       1.05911058e-04, 2.04156022e-05, 5.27138473e-04, 1.96646713e-03,\n",
            "       1.00921927e-04, 3.51958413e-04, 5.88932235e-05, 2.86155671e-04,\n",
            "       1.50087042e-04, 1.95555412e-03, 9.60190227e-05, 4.12148918e-04,\n",
            "       6.85234438e-04, 6.01149404e-05, 3.82154423e-04, 5.82298555e-04,\n",
            "       9.11767929e-05, 8.39577478e-05, 4.56638314e-04, 3.34195618e-04,\n",
            "       8.73000972e-05, 7.39879790e-04, 1.33939582e-04, 2.15797118e-04,\n",
            "       3.01011431e-04, 2.18762114e-04, 6.08169183e-04, 6.69078872e-05,\n",
            "       7.72592728e-04, 4.55952599e-04, 8.69356561e-04, 8.74646066e-04,\n",
            "       1.42728072e-03, 1.63144188e-03, 2.72840960e-03, 1.51880391e-04,\n",
            "       1.24474929e-03, 3.54338030e-04, 8.83071101e-04, 2.88092433e-05,\n",
            "       7.98350375e-04, 2.38247085e-04, 1.78488588e-03, 2.02141865e-03,\n",
            "       8.53820762e-04, 1.36399781e-03, 6.97670475e-05, 2.13127001e-04,\n",
            "       1.98378717e-03, 5.34210412e-04, 8.86215188e-04, 1.52116059e-04,\n",
            "       6.42971499e-05, 3.46165762e-04, 3.40656989e-04, 7.35434820e-04,\n",
            "       1.89305749e-04, 7.31731052e-05, 3.14226418e-05, 1.47421655e-04,\n",
            "       4.63381090e-04, 8.13755541e-05, 3.10705393e-04, 2.05468712e-03,\n",
            "       1.00737416e-04, 7.45276338e-05, 2.78247662e-05, 8.09967387e-05,\n",
            "       2.91669363e-04, 1.16436614e-03, 1.51346918e-04, 6.48542991e-05,\n",
            "       3.14188685e-04, 2.43079441e-04, 3.13790806e-04, 6.62790771e-05,\n",
            "       3.99034965e-04, 1.09031622e-04, 1.36416289e-04, 8.82913009e-04,\n",
            "       6.38203346e-05, 1.40828302e-03, 1.32039282e-03, 8.01037095e-05,\n",
            "       1.48337902e-04, 2.19386129e-04, 1.11705354e-04, 1.80667281e-04,\n",
            "       8.51479068e-04, 1.38874969e-03, 7.22520344e-04, 1.73129622e-04,\n",
            "       8.09453923e-05, 2.20344798e-03, 2.24469369e-03, 3.75131203e-04,\n",
            "       9.05705441e-04, 6.99654483e-05, 2.73812853e-04, 2.52778234e-04,\n",
            "       2.73617392e-04, 1.41601195e-03, 2.66191387e-03, 1.01058038e-04,\n",
            "       4.78262409e-05, 4.16483526e-04, 9.25237691e-05, 1.15238759e-03,\n",
            "       2.69872858e-03, 3.69786576e-04, 8.10767582e-04, 1.97801995e-03,\n",
            "       6.52100542e-04, 1.82888529e-04, 3.75341078e-05, 9.38778758e-05,\n",
            "       5.60217444e-03, 9.24694759e-05, 1.56120677e-03, 2.62714078e-04,\n",
            "       3.09899624e-04, 1.10345636e-03, 3.91613576e-04, 5.29642624e-04,\n",
            "       7.00129531e-05, 1.08248307e-04, 1.26594663e-04, 1.21998379e-03,\n",
            "       4.30255523e-03, 1.84620541e-04, 2.32192018e-04, 2.09492035e-04,\n",
            "       1.92977168e-04, 1.60425348e-04, 8.78531209e-05, 2.02643248e-04,\n",
            "       5.10440768e-05, 2.28139397e-04, 2.64268462e-03, 6.48045097e-05,\n",
            "       3.43246182e-04, 1.57464106e-04, 3.33245058e-04, 8.69449941e-05,\n",
            "       6.98502176e-04, 1.44709635e-03, 2.51124322e-04, 1.60168143e-04,\n",
            "       1.48951978e-04, 2.27048135e-04, 4.61872878e-05, 4.21203877e-04,\n",
            "       8.04098963e-04, 2.46364507e-04, 7.30302476e-04, 9.67791857e-05,\n",
            "       5.78708597e-04, 5.20089816e-04, 2.10382254e-03, 3.68361689e-05,\n",
            "       4.59650793e-04, 1.08871398e-04, 8.33581900e-04, 1.28656611e-04,\n",
            "       1.28221593e-03, 6.90703382e-05, 8.60035885e-04, 2.17134226e-03,\n",
            "       5.59492328e-04, 6.72809605e-04, 4.99350834e-04, 1.93296277e-04,\n",
            "       4.25697363e-04, 2.43976305e-04, 1.22549842e-04, 2.36785709e-04,\n",
            "       2.01206538e-03, 3.04193469e-04, 3.42682411e-04, 7.58392780e-05,\n",
            "       2.08061072e-04, 1.58212730e-03, 6.67228189e-04, 1.01479694e-04,\n",
            "       2.01846779e-04, 6.37116827e-05, 5.41208319e-05, 1.63193690e-04,\n",
            "       3.87990644e-04, 2.47657772e-05, 4.15956049e-04, 1.66548867e-04,\n",
            "       3.40397051e-03, 4.95722961e-05, 1.87231752e-03, 1.57412811e-04,\n",
            "       5.20429130e-05, 2.23936440e-04, 2.29846497e-04, 2.74917547e-04,\n",
            "       1.43386028e-03, 4.11871843e-05, 2.52671889e-04, 1.64494966e-04,\n",
            "       2.06478639e-04, 1.85385245e-04, 7.40007745e-05, 1.43816788e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 229, 'shape': array([480], dtype=int32), 'shape_signature': array([480], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([8.21275404e-04, 5.79268381e-04, 5.52212412e-04, 7.87565426e-04,\n",
            "       5.95031190e-04, 2.63633701e-04, 9.08432063e-04, 6.64523803e-04,\n",
            "       2.91354489e-04, 3.98879871e-04, 7.93548184e-04, 2.63753027e-04,\n",
            "       8.59647058e-04, 7.07140076e-04, 6.41504710e-04, 2.87107367e-04,\n",
            "       7.34313508e-04, 4.30965360e-04, 1.73720735e-04, 6.62481063e-04,\n",
            "       6.93656446e-04, 2.59658787e-03, 9.51340131e-04, 4.73421765e-04,\n",
            "       5.99089952e-04, 2.92081590e-04, 1.05253188e-03, 3.82691418e-04,\n",
            "       3.74601834e-04, 2.87237752e-04, 4.21035074e-04, 3.54377262e-04,\n",
            "       4.66025114e-04, 1.12332858e-03, 2.96612096e-04, 8.34907260e-05,\n",
            "       6.31547999e-04, 2.96027632e-04, 4.60453593e-04, 4.82375384e-04,\n",
            "       1.99167582e-04, 3.70521826e-04, 3.55038501e-04, 4.13486792e-04,\n",
            "       1.29668522e-04, 5.29984420e-04, 7.03432248e-04, 6.38004101e-04,\n",
            "       5.05554723e-04, 3.80658865e-04, 1.78309681e-04, 6.39989972e-04,\n",
            "       2.52435915e-04, 4.31347697e-04, 2.18236702e-04, 1.25385798e-03,\n",
            "       5.72975667e-04, 3.95844865e-04, 1.49357234e-04, 5.51350764e-04,\n",
            "       3.40118859e-04, 1.98596070e-04, 5.90995653e-04, 3.74057330e-04,\n",
            "       1.34746559e-04, 6.20786624e-04, 3.06113914e-04, 5.65433584e-04,\n",
            "       3.61533195e-04, 4.71140433e-04, 3.20999563e-04, 5.79404237e-04,\n",
            "       3.34293174e-04, 2.64304836e-04, 2.26995457e-04, 3.04141169e-04,\n",
            "       6.52499555e-04, 4.43839876e-04, 5.82621666e-04, 9.64576175e-05,\n",
            "       4.60136274e-04, 5.65505819e-04, 3.92989576e-04, 1.90168526e-03,\n",
            "       3.75975505e-04, 1.08021847e-03, 7.11793429e-04, 7.10868044e-04,\n",
            "       5.03164541e-04, 5.00571739e-04, 1.21044263e-03, 6.69690780e-04,\n",
            "       2.20072165e-04, 2.23355353e-04, 4.27113235e-04, 5.70067612e-04,\n",
            "       5.82154142e-04, 4.38873511e-04, 9.62603837e-04, 3.56146309e-04,\n",
            "       2.81158427e-04, 4.12873225e-04, 5.15797699e-04, 6.43134699e-04,\n",
            "       3.01377411e-04, 5.14829240e-04, 4.13753180e-04, 8.36654392e-04,\n",
            "       2.79289525e-04, 4.75129607e-04, 1.70222018e-04, 3.97678028e-04,\n",
            "       1.30914873e-03, 9.41700651e-04, 4.68605285e-04, 4.59506526e-04,\n",
            "       1.14407460e-03, 4.38555260e-04, 4.40283096e-04, 4.05688275e-04,\n",
            "       1.33672974e-03, 2.70828226e-04, 3.28216556e-04, 5.73471247e-04,\n",
            "       4.07302869e-04, 6.77651318e-04, 4.30998596e-04, 5.34805586e-04,\n",
            "       4.99854272e-04, 4.76749206e-04, 4.03477956e-04, 7.37610157e-04,\n",
            "       4.23193444e-04, 4.16761992e-04, 2.90557393e-04, 6.08828617e-04,\n",
            "       2.36201100e-04, 3.86345113e-04, 1.28835079e-03, 5.28076838e-04,\n",
            "       3.04961664e-04, 7.02632591e-04, 1.73284137e-03, 1.90656559e-04,\n",
            "       6.45160675e-04, 4.94470412e-04, 1.73123859e-04, 9.10814328e-04,\n",
            "       4.97295172e-04, 4.49568674e-04, 5.80755121e-04, 7.67330348e-04,\n",
            "       1.08049491e-04, 5.86745969e-04, 7.80013972e-04, 2.88423063e-04,\n",
            "       5.39772795e-04, 1.56175962e-03, 1.49909349e-04, 9.85623919e-04,\n",
            "       2.88333686e-04, 3.78766388e-04, 1.98158232e-04, 1.38437026e-03,\n",
            "       5.33990737e-04, 5.91843796e-04, 3.22650681e-04, 2.58672866e-04,\n",
            "       3.57352401e-04, 3.78390978e-04, 2.89889431e-04, 3.35632678e-04,\n",
            "       6.08495146e-04, 2.52610800e-04, 5.56743063e-04, 3.32276337e-04,\n",
            "       3.50134913e-04, 6.96255302e-04, 3.08117975e-04, 4.44004836e-04,\n",
            "       3.41873238e-04, 4.85693425e-04, 4.75435198e-04, 2.68763630e-04,\n",
            "       3.06618429e-04, 3.33164440e-04, 5.27133874e-04, 1.83010113e-03,\n",
            "       8.47841497e-04, 2.21650349e-03, 3.37480800e-04, 4.55700996e-04,\n",
            "       2.98945495e-04, 4.79820679e-04, 8.12285871e-04, 1.90964376e-04,\n",
            "       3.09398340e-04, 4.68221609e-04, 6.34544354e-04, 1.01300701e-03,\n",
            "       6.19988830e-04, 6.04994013e-04, 4.14968759e-04, 4.00626566e-04,\n",
            "       2.55489082e-04, 2.28847406e-04, 7.41607975e-04, 5.99839492e-04,\n",
            "       7.06444553e-04, 8.90065217e-04, 3.50702234e-04, 1.14139565e-03,\n",
            "       3.89873225e-04, 9.38820129e-04, 5.91865974e-04, 1.37372408e-03,\n",
            "       1.52716215e-03, 8.82486172e-04, 3.29011527e-04, 4.20896627e-04,\n",
            "       3.59338941e-04, 6.05587556e-04, 4.85059660e-04, 2.30347694e-04,\n",
            "       4.08307678e-04, 4.87377518e-04, 6.64815423e-04, 6.12086907e-04,\n",
            "       3.23814456e-04, 7.59431976e-04, 6.16489153e-04, 3.91202950e-04,\n",
            "       2.94740603e-04, 5.09362260e-04, 4.26450570e-04, 4.05671570e-04,\n",
            "       5.29420213e-04, 5.40390727e-04, 9.35171556e-04, 2.62485177e-04,\n",
            "       9.10122471e-04, 2.73232989e-04, 1.72405358e-04, 6.50054542e-04,\n",
            "       1.00129528e-03, 4.85520141e-04, 1.07195333e-03, 7.67190591e-04,\n",
            "       2.34384890e-04, 4.58222610e-04, 3.78114753e-04, 9.93680791e-04,\n",
            "       6.59305369e-04, 2.48338125e-04, 4.20503435e-04, 9.27201065e-04,\n",
            "       6.25110522e-04, 3.45128181e-04, 6.51338254e-04, 1.17969641e-03,\n",
            "       3.81356396e-04, 4.57899558e-04, 2.79482396e-04, 1.03706552e-03,\n",
            "       4.90849954e-04, 4.57007118e-04, 1.21405837e-03, 3.48874572e-04,\n",
            "       2.44638417e-04, 6.71223330e-04, 3.90683243e-04, 5.69433440e-04,\n",
            "       3.96001240e-04, 8.97227495e-04, 7.96593842e-04, 1.67258421e-03,\n",
            "       3.24084162e-04, 3.01521970e-04, 3.15085694e-04, 3.39016435e-04,\n",
            "       6.82096346e-04, 4.12453664e-04, 4.06103121e-04, 3.82223778e-04,\n",
            "       5.00592054e-04, 5.45525691e-04, 1.20859221e-03, 4.21621837e-04,\n",
            "       5.29171375e-04, 6.69643516e-04, 7.96182256e-04, 5.00798109e-04,\n",
            "       7.74891465e-04, 5.68720920e-04, 4.67987440e-04, 6.15989207e-04,\n",
            "       2.77517218e-04, 4.08525346e-04, 9.73357353e-04, 5.71389392e-04,\n",
            "       3.96902789e-04, 3.44130793e-04, 1.49163639e-03, 1.04396453e-03,\n",
            "       2.49861594e-04, 6.61305559e-04, 6.00687345e-04, 1.14143209e-03,\n",
            "       7.63265125e-04, 1.48130488e-03, 2.54510465e-04, 4.15857270e-04,\n",
            "       2.75731960e-04, 8.70773045e-04, 6.49322988e-04, 2.52442260e-04,\n",
            "       2.87841249e-04, 4.79899230e-04, 4.58499126e-04, 6.00971107e-04,\n",
            "       4.58437862e-04, 3.02167813e-04, 1.17291999e-03, 1.42976176e-03,\n",
            "       2.45705887e-04, 2.12404018e-04, 6.35326025e-04, 4.22518904e-04,\n",
            "       1.02039764e-03, 4.54287219e-04, 9.46764427e-04, 5.04803262e-04,\n",
            "       4.13027592e-04, 7.55327055e-04, 2.20717557e-04, 5.77791303e-04,\n",
            "       2.17866807e-04, 1.65720048e-04, 5.14743733e-04, 5.96031954e-04,\n",
            "       1.38115650e-03, 7.67957943e-04, 2.48915574e-04, 2.87574716e-04,\n",
            "       8.79520958e-04, 2.73100042e-04, 3.37090518e-04, 7.02633813e-04,\n",
            "       3.98229953e-04, 4.98477835e-04, 9.73355956e-04, 4.01146768e-04,\n",
            "       6.11337658e-04, 3.24421737e-04, 1.19536126e-03, 1.02333399e-03,\n",
            "       5.29545476e-04, 2.05348304e-04, 1.45079044e-03, 6.72657567e-04,\n",
            "       4.42366058e-04, 2.82018300e-04, 9.86286788e-04, 1.30921183e-03,\n",
            "       3.19269195e-04, 1.53161655e-03, 1.53436209e-03, 2.74670892e-04,\n",
            "       2.55582476e-04, 1.09583791e-03, 6.06954738e-04, 5.80304244e-04,\n",
            "       5.23425348e-04, 6.73952280e-04, 7.07168714e-04, 2.19679408e-04,\n",
            "       9.57286858e-04, 3.62305873e-04, 2.92141078e-04, 1.23513339e-03,\n",
            "       3.78246215e-04, 3.57129291e-04, 6.64420950e-04, 7.46843056e-04,\n",
            "       3.05702444e-04, 3.73511575e-04, 4.18081123e-04, 4.03844548e-04,\n",
            "       4.14971990e-04, 3.73694493e-04, 1.71077016e-04, 4.20340017e-04,\n",
            "       4.51284286e-04, 6.18434162e-04, 7.83274183e-04, 8.47310410e-04,\n",
            "       5.29988203e-04, 8.05303105e-04, 3.32955504e-04, 4.81238007e-04,\n",
            "       4.01906931e-04, 5.01922856e-04, 1.05597882e-03, 7.38771341e-04,\n",
            "       6.20890874e-04, 3.63031315e-04, 9.84010636e-04, 7.10484164e-04,\n",
            "       7.40823743e-04, 2.41177229e-04, 1.56492332e-03, 5.73800062e-04,\n",
            "       4.10564244e-04, 6.78909884e-04, 2.77332467e-04, 5.35388244e-04,\n",
            "       3.09617870e-04, 4.12806723e-04, 8.72325385e-04, 1.01321377e-03,\n",
            "       7.44651246e-04, 1.10509747e-04, 5.08136756e-04, 3.61721002e-04,\n",
            "       4.82118863e-04, 3.73145973e-04, 4.57272545e-04, 1.87335405e-04,\n",
            "       1.37236807e-03, 3.97957803e-04, 3.37994396e-04, 4.89304191e-04,\n",
            "       2.97808030e-04, 7.97570567e-04, 5.78010920e-04, 4.35103342e-04,\n",
            "       7.79044407e-04, 3.64634325e-04, 5.62472676e-04, 8.16533749e-04,\n",
            "       3.94625153e-04, 2.20857808e-04, 1.44959151e-04, 1.10952195e-03,\n",
            "       1.15143135e-03, 7.12776266e-04, 2.02090960e-04, 3.23407236e-04,\n",
            "       2.92670797e-04, 2.26575043e-03, 9.12372605e-04, 6.88246626e-04,\n",
            "       4.24399186e-04, 9.94672300e-04, 2.76350067e-04, 2.68707139e-04,\n",
            "       4.20649070e-04, 4.79152135e-04, 7.61438510e-04, 7.01406039e-04,\n",
            "       2.62633839e-04, 1.19226155e-04, 5.32301608e-04, 4.72833024e-04,\n",
            "       5.43726375e-04, 6.36118348e-04, 3.94640345e-04, 5.20866306e-04,\n",
            "       3.90365341e-04, 6.32899173e-04, 4.84550750e-04, 5.05415082e-04,\n",
            "       6.13621320e-04, 1.29440421e-04, 4.95439279e-04, 4.94877459e-04,\n",
            "       2.16500659e-04, 1.90230960e-03, 4.01386875e-04, 7.32097193e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block4_layer3/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer3/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 230, 'shape': array([  1,   5,   5, 480], dtype=int32), 'shape_signature': array([  1,   5,   5, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.02091264, 0.01475026, 0.01406132, 0.02005426, 0.01515164,\n",
            "       0.00671307, 0.02313196, 0.01692117, 0.00741894, 0.01015692,\n",
            "       0.0202066 , 0.0067161 , 0.02188972, 0.01800634, 0.01633503,\n",
            "       0.00731079, 0.01869827, 0.01097393, 0.00442356, 0.01686916,\n",
            "       0.017663  , 0.0661185 , 0.02422455, 0.01205503, 0.01525499,\n",
            "       0.00743745, 0.02680126, 0.0097447 , 0.00953871, 0.00731411,\n",
            "       0.01072107, 0.00902372, 0.01186668, 0.028604  , 0.00755281,\n",
            "       0.00212598, 0.01608149, 0.00753793, 0.01172481, 0.01228302,\n",
            "       0.00507153, 0.00943482, 0.00904056, 0.01052887, 0.00330183,\n",
            "       0.01349532, 0.01791192, 0.01624589, 0.01287325, 0.00969295,\n",
            "       0.00454041, 0.01629645, 0.00642793, 0.01098367, 0.00555709,\n",
            "       0.03192775, 0.01459003, 0.01007964, 0.00380317, 0.01403938,\n",
            "       0.00866065, 0.00505697, 0.01504888, 0.00952485, 0.00343113,\n",
            "       0.01580747, 0.00779477, 0.01439798, 0.00920594, 0.01199694,\n",
            "       0.00817381, 0.01475372, 0.00851231, 0.00673016, 0.00578012,\n",
            "       0.00774453, 0.01661499, 0.01130177, 0.01483565, 0.00245616,\n",
            "       0.01171673, 0.01439982, 0.01000693, 0.04842377, 0.00957369,\n",
            "       0.02750626, 0.01812483, 0.01810127, 0.01281239, 0.01274636,\n",
            "       0.03082224, 0.01705274, 0.00560383, 0.00568743, 0.01087584,\n",
            "       0.01451598, 0.01482375, 0.0111753 , 0.02451137, 0.00906877,\n",
            "       0.00715931, 0.01051324, 0.01313407, 0.01637653, 0.00767416,\n",
            "       0.01310941, 0.01053565, 0.02130424, 0.00711172, 0.01209851,\n",
            "       0.00433447, 0.01012632, 0.03333565, 0.0239791 , 0.01193238,\n",
            "       0.01170069, 0.02913227, 0.0111672 , 0.0112112 , 0.01033029,\n",
            "       0.03403796, 0.00689626, 0.00835758, 0.01460265, 0.0103714 ,\n",
            "       0.01725545, 0.01097478, 0.01361808, 0.01272809, 0.01213976,\n",
            "       0.01027401, 0.01878222, 0.01077603, 0.01061226, 0.00739864,\n",
            "       0.01550297, 0.00601453, 0.00983774, 0.03280606, 0.01344674,\n",
            "       0.00776542, 0.01789156, 0.04412439, 0.0048548 , 0.01642812,\n",
            "       0.012591  , 0.00440836, 0.02319262, 0.01266293, 0.01144764,\n",
            "       0.01478812, 0.019539  , 0.00275133, 0.01494067, 0.01986197,\n",
            "       0.00734429, 0.01374456, 0.03976804, 0.00381723, 0.02509754,\n",
            "       0.00734202, 0.00964476, 0.00504582, 0.03525106, 0.01359733,\n",
            "       0.01507048, 0.00821585, 0.00658674, 0.00909948, 0.0096352 ,\n",
            "       0.00738163, 0.00854642, 0.01549448, 0.00643238, 0.01417669,\n",
            "       0.00846095, 0.0089157 , 0.01772917, 0.0078458 , 0.01130597,\n",
            "       0.00870533, 0.01236751, 0.0121063 , 0.00684369, 0.00780761,\n",
            "       0.00848357, 0.01342273, 0.04660098, 0.0215891 , 0.05644018,\n",
            "       0.00859348, 0.01160379, 0.00761223, 0.01221797, 0.02068373,\n",
            "       0.00486264, 0.0078784 , 0.01192261, 0.01615779, 0.02579481,\n",
            "       0.01578715, 0.01540533, 0.0105666 , 0.0102014 , 0.00650567,\n",
            "       0.00582728, 0.01888402, 0.01527408, 0.01798863, 0.02266427,\n",
            "       0.00893014, 0.02906405, 0.00992758, 0.02390575, 0.01507104,\n",
            "       0.03497997, 0.03888706, 0.02247128, 0.00837782, 0.01071755,\n",
            "       0.00915007, 0.01542044, 0.01235137, 0.00586548, 0.01039699,\n",
            "       0.01241039, 0.0169286 , 0.01558594, 0.00824548, 0.01933788,\n",
            "       0.01569804, 0.00996144, 0.00750516, 0.0129702 , 0.01085897,\n",
            "       0.01032986, 0.01348095, 0.0137603 , 0.02381284, 0.00668382,\n",
            "       0.023175  , 0.0069575 , 0.00439006, 0.01655274, 0.02549659,\n",
            "       0.01236309, 0.0272958 , 0.01953544, 0.00596829, 0.011668  ,\n",
            "       0.00962817, 0.0253027 , 0.01678829, 0.00632358, 0.01070753,\n",
            "       0.02360989, 0.01591757, 0.00878821, 0.01658542, 0.03003933,\n",
            "       0.00971071, 0.01165977, 0.00711663, 0.02640743, 0.01249881,\n",
            "       0.01163705, 0.03091431, 0.00888361, 0.00622938, 0.01709177,\n",
            "       0.00994821, 0.01449983, 0.01008362, 0.02284665, 0.02028415,\n",
            "       0.04259003, 0.00825235, 0.00767784, 0.00802322, 0.00863258,\n",
            "       0.01736864, 0.01050256, 0.01034085, 0.0097328 , 0.01274688,\n",
            "       0.01389105, 0.03077512, 0.01073601, 0.01347461, 0.01705154,\n",
            "       0.02027367, 0.01275213, 0.01973153, 0.01448169, 0.01191665,\n",
            "       0.01568531, 0.00706659, 0.01040253, 0.02478519, 0.01454964,\n",
            "       0.01010658, 0.00876281, 0.03798245, 0.0265831 , 0.00636238,\n",
            "       0.01683923, 0.01529567, 0.02906498, 0.01943548, 0.03771937,\n",
            "       0.00648075, 0.01058923, 0.00702113, 0.02217302, 0.01653411,\n",
            "       0.00642809, 0.00732948, 0.01221997, 0.01167504, 0.01530289,\n",
            "       0.01167348, 0.00769428, 0.02986678, 0.03640689, 0.00625656,\n",
            "       0.00540857, 0.01617769, 0.01075886, 0.02598301, 0.01156779,\n",
            "       0.02410804, 0.01285411, 0.01051717, 0.01923335, 0.00562027,\n",
            "       0.01471265, 0.00554768, 0.00421983, 0.01310723, 0.01517712,\n",
            "       0.03516923, 0.01955498, 0.00633829, 0.00732269, 0.02239578,\n",
            "       0.00695411, 0.00858354, 0.01789159, 0.01014037, 0.01269304,\n",
            "       0.02478516, 0.01021464, 0.01556686, 0.00826095, 0.03043821,\n",
            "       0.02605778, 0.01348414, 0.00522891, 0.03694236, 0.01712829,\n",
            "       0.01126424, 0.0071812 , 0.02511442, 0.03333726, 0.00812975,\n",
            "       0.03900049, 0.0390704 , 0.00699411, 0.00650805, 0.02790399,\n",
            "       0.01545526, 0.01477664, 0.0133283 , 0.01716126, 0.01800707,\n",
            "       0.00559383, 0.02437598, 0.00922562, 0.00743897, 0.03145095,\n",
            "       0.00963151, 0.0090938 , 0.01691855, 0.01901732, 0.00778429,\n",
            "       0.00951095, 0.01064585, 0.01028334, 0.01056668, 0.00951561,\n",
            "       0.00435624, 0.01070337, 0.01149133, 0.01574757, 0.01994499,\n",
            "       0.02157558, 0.01349541, 0.02050592, 0.00847825, 0.01225406,\n",
            "       0.010234  , 0.01278077, 0.02688903, 0.01881178, 0.01581012,\n",
            "       0.00924409, 0.02505646, 0.01809149, 0.01886405, 0.00614124,\n",
            "       0.0398486 , 0.01461102, 0.01045445, 0.0172875 , 0.00706189,\n",
            "       0.01363292, 0.00788399, 0.01051155, 0.02221255, 0.02580008,\n",
            "       0.01896151, 0.00281398, 0.012939  , 0.00921072, 0.01227649,\n",
            "       0.00950164, 0.01164381, 0.00477024, 0.03494544, 0.01013344,\n",
            "       0.00860656, 0.01245945, 0.00758327, 0.02030903, 0.01471824,\n",
            "       0.0110793 , 0.01983728, 0.00928491, 0.01432258, 0.0207919 ,\n",
            "       0.01004858, 0.00562384, 0.00369118, 0.02825243, 0.0293196 ,\n",
            "       0.01814986, 0.00514597, 0.00823512, 0.00745245, 0.05769419,\n",
            "       0.0232323 , 0.01752524, 0.01080673, 0.02532795, 0.00703687,\n",
            "       0.00684225, 0.01071124, 0.01220094, 0.01938897, 0.01786033,\n",
            "       0.00668761, 0.00303593, 0.01355432, 0.01204003, 0.01384524,\n",
            "       0.01619787, 0.01004897, 0.01326314, 0.00994011, 0.0161159 ,\n",
            "       0.01233841, 0.01286969, 0.01562501, 0.00329602, 0.01261567,\n",
            "       0.01260137, 0.00551289, 0.04843967, 0.01022076, 0.01864184],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 231, 'shape': array([480], dtype=int32), 'shape_signature': array([480], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([6.01661377e-05, 6.73414397e-05, 1.71279622e-04, 1.36703384e-04,\n",
            "       1.23533697e-04, 1.06193947e-04, 6.62533785e-05, 1.00710487e-04,\n",
            "       1.40746284e-04, 7.97243702e-05, 1.38210598e-04, 1.41366909e-04,\n",
            "       4.77484791e-05, 3.75358832e-05, 1.23670150e-04, 1.44906429e-04,\n",
            "       5.84150766e-05, 9.61227997e-05, 1.33116817e-04, 8.70465956e-05,\n",
            "       8.51390432e-05, 3.17237682e-05, 6.81266611e-05, 1.48995023e-04,\n",
            "       8.90564261e-05, 1.01540063e-04, 3.48391368e-05, 1.87599391e-04,\n",
            "       2.01989969e-04, 1.36385323e-04, 1.03878905e-04, 1.36940813e-04,\n",
            "       1.48998646e-04, 4.71406856e-05, 1.01274716e-04, 1.42678167e-04,\n",
            "       2.25891908e-05, 1.32404981e-04, 6.02661748e-05, 9.12130272e-05,\n",
            "       1.42594596e-04, 1.16819094e-04, 1.22631129e-04, 1.22710306e-04,\n",
            "       1.19741140e-04, 1.18463751e-04, 1.25056336e-04, 8.09961493e-05,\n",
            "       1.34823887e-04, 1.58418945e-04, 1.08186425e-04, 8.90471347e-05,\n",
            "       1.37966752e-04, 1.06216699e-04, 1.87853162e-04, 1.79133694e-05,\n",
            "       4.58424547e-05, 1.25665421e-04, 1.20265722e-04, 9.42987463e-05,\n",
            "       1.06618951e-04, 1.46588165e-04, 1.19069278e-04, 4.55451882e-05,\n",
            "       1.07610176e-04, 3.44472101e-05, 1.17595038e-04, 1.25680031e-04,\n",
            "       1.40027216e-04, 5.58461143e-05, 1.09962595e-04, 9.58039236e-05,\n",
            "       1.35842420e-04, 9.95689479e-05, 1.20708028e-04, 1.24184357e-04,\n",
            "       1.30554108e-04, 7.34377536e-05, 1.68553946e-04, 1.96612629e-04,\n",
            "       1.16941781e-04, 1.24628234e-04, 6.74995463e-05, 3.13557866e-05,\n",
            "       9.95914233e-05, 5.03396404e-05, 1.58834257e-04, 7.43890705e-05,\n",
            "       1.07014108e-04, 4.37720810e-05, 7.43448472e-05, 1.00494653e-04,\n",
            "       1.09425462e-04, 1.13645474e-04, 9.80581390e-05, 8.99889637e-05,\n",
            "       1.15128874e-04, 8.93266042e-05, 3.07431801e-05, 1.15399162e-04,\n",
            "       7.27214792e-05, 1.86311838e-04, 1.02241560e-04, 1.02750717e-04,\n",
            "       1.12364840e-04, 8.49855787e-05, 1.01014841e-04, 2.10411108e-05,\n",
            "       9.99816912e-05, 5.81627137e-05, 1.16536037e-04, 1.54508904e-04,\n",
            "       2.27252985e-05, 6.44926258e-05, 1.54658526e-04, 1.17507130e-04,\n",
            "       1.21105986e-04, 1.41009761e-04, 8.57734049e-05, 8.31376819e-05,\n",
            "       4.90191087e-05, 1.52808789e-04, 1.32195448e-04, 7.29590683e-05,\n",
            "       1.46278981e-04, 6.00810781e-05, 1.47926869e-04, 4.43974277e-05,\n",
            "       1.21187782e-04, 8.20343048e-05, 8.23625232e-05, 1.21010788e-04,\n",
            "       1.23910155e-04, 1.32514542e-04, 1.08947468e-04, 9.17520956e-05,\n",
            "       5.99892373e-05, 1.02113554e-04, 2.63135862e-05, 1.10027300e-04,\n",
            "       1.30198212e-04, 5.49565957e-05, 1.83259926e-05, 1.44122227e-04,\n",
            "       4.14252863e-05, 1.33409791e-04, 9.27966175e-05, 8.92101743e-05,\n",
            "       1.52819339e-04, 1.20623976e-04, 1.36717805e-04, 5.28427918e-05,\n",
            "       1.19045857e-04, 8.25649695e-05, 9.78087701e-05, 1.51882457e-04,\n",
            "       8.06436947e-05, 1.22917598e-04, 1.47714178e-04, 5.69133845e-05,\n",
            "       1.03552775e-04, 5.81257991e-05, 1.16034600e-04, 1.90467108e-05,\n",
            "       6.94168120e-05, 6.14562668e-05, 1.53054425e-04, 1.43173573e-04,\n",
            "       4.55695517e-05, 1.55641930e-04, 7.53519489e-05, 1.38002841e-04,\n",
            "       1.10403300e-04, 1.26072264e-04, 1.10851397e-04, 1.15082243e-04,\n",
            "       5.09601705e-05, 8.50305005e-05, 1.44786114e-04, 8.61543886e-05,\n",
            "       1.24942337e-04, 1.22361089e-04, 8.32238729e-05, 1.26189436e-04,\n",
            "       1.15475756e-04, 1.64027122e-04, 5.44614122e-05, 1.89685288e-05,\n",
            "       8.26272881e-05, 2.12310006e-05, 8.52056692e-05, 1.05425410e-04,\n",
            "       1.16876494e-04, 1.05336097e-04, 3.29673821e-05, 1.15447765e-04,\n",
            "       1.43766170e-04, 1.17335403e-04, 5.60727713e-05, 5.82558896e-05,\n",
            "       9.00788436e-05, 9.22551772e-05, 9.99235635e-05, 6.99886878e-05,\n",
            "       1.21073186e-04, 1.27082385e-04, 1.20786266e-04, 9.51994371e-05,\n",
            "       3.14808713e-05, 3.06806396e-05, 9.62217600e-05, 4.01284706e-05,\n",
            "       1.06742096e-04, 4.42273558e-05, 9.21862156e-05, 2.52281443e-05,\n",
            "       3.20244690e-05, 4.26552106e-05, 1.24713450e-04, 6.13357115e-05,\n",
            "       9.06159185e-05, 9.73885544e-05, 1.41793964e-04, 1.41955141e-04,\n",
            "       1.18196695e-04, 1.17176634e-04, 1.00910009e-04, 1.18312848e-04,\n",
            "       1.03730374e-04, 4.37860363e-05, 4.96801513e-05, 1.08919769e-04,\n",
            "       1.03565908e-04, 1.08472530e-04, 1.50751395e-04, 8.47158735e-05,\n",
            "       5.73210491e-05, 5.55028928e-05, 2.68535932e-05, 1.23819264e-04,\n",
            "       4.28490675e-05, 1.19622011e-04, 1.03329046e-04, 1.21014011e-04,\n",
            "       6.16910256e-05, 9.73975984e-05, 4.72843167e-05, 8.24665258e-05,\n",
            "       1.29414126e-04, 1.21259829e-04, 1.49402622e-04, 5.54218313e-05,\n",
            "       6.97041032e-05, 1.70778265e-04, 1.20960452e-04, 4.26550068e-05,\n",
            "       1.40770353e-04, 1.27865220e-04, 1.33772613e-04, 3.01372238e-05,\n",
            "       1.17384421e-04, 1.44048681e-04, 9.06377172e-05, 8.83028042e-05,\n",
            "       9.44624990e-05, 8.83852044e-05, 1.28523316e-04, 8.24273957e-05,\n",
            "       1.13302362e-04, 1.12663576e-04, 1.47557788e-04, 8.16733809e-05,\n",
            "       1.10743284e-04, 9.29989837e-05, 8.26479300e-05, 1.78705923e-05,\n",
            "       1.39655487e-04, 1.16035240e-04, 1.30455912e-04, 1.49086030e-04,\n",
            "       7.90375998e-05, 1.24916100e-04, 8.01906208e-05, 1.56789189e-04,\n",
            "       1.46070117e-04, 1.45911938e-04, 2.09621612e-05, 9.31550894e-05,\n",
            "       8.61867229e-05, 1.24166269e-04, 6.09664276e-05, 1.72356114e-04,\n",
            "       3.46975103e-05, 1.34119691e-04, 5.94953090e-05, 2.33574392e-05,\n",
            "       1.34095651e-04, 9.60784018e-05, 2.77980198e-05, 1.34778500e-04,\n",
            "       7.07132785e-05, 1.79218972e-04, 2.43689228e-05, 5.13075684e-05,\n",
            "       1.08168009e-04, 5.03518604e-05, 1.00997422e-04, 9.25481800e-05,\n",
            "       5.44958893e-05, 2.74355116e-05, 1.64015393e-04, 1.03233324e-04,\n",
            "       1.41398850e-04, 3.18454877e-05, 1.01895654e-04, 1.08262029e-04,\n",
            "       9.29698799e-05, 8.90511947e-05, 1.39739146e-04, 5.36824846e-05,\n",
            "       8.67900599e-05, 1.21205194e-04, 3.13450109e-05, 4.60430092e-05,\n",
            "       1.30012631e-04, 1.22512545e-04, 9.92921705e-05, 6.81752717e-05,\n",
            "       5.35511717e-05, 1.33895650e-04, 7.74861328e-05, 1.13490678e-04,\n",
            "       1.02752791e-04, 1.22639714e-04, 1.69884021e-04, 6.86089188e-05,\n",
            "       1.03497820e-04, 1.02323516e-04, 8.54098398e-05, 1.15002003e-04,\n",
            "       7.08217558e-05, 8.02535724e-05, 1.13610025e-04, 1.01140053e-04,\n",
            "       7.52432170e-05, 1.80864925e-04, 8.30776335e-05, 1.47879808e-04,\n",
            "       9.66022417e-05, 2.91507808e-04, 1.76592512e-05, 1.02634680e-04,\n",
            "       1.13182439e-04, 1.36034345e-04, 3.51833442e-05, 3.70720118e-05,\n",
            "       1.29978798e-04, 1.14911629e-04, 4.64081968e-05, 3.84935120e-05,\n",
            "       1.26681785e-04, 1.25261999e-04, 3.41985979e-05, 5.84653208e-05,\n",
            "       9.24843262e-05, 3.71891110e-05, 2.65790040e-05, 9.50857502e-05,\n",
            "       1.04262392e-04, 4.86690151e-05, 1.44439487e-04, 1.26379193e-04,\n",
            "       9.02130560e-05, 8.79905710e-05, 8.80059888e-05, 1.32714646e-04,\n",
            "       7.61810370e-05, 1.58666473e-04, 1.38756775e-04, 2.50432458e-05,\n",
            "       1.11932466e-04, 8.16271204e-05, 8.09520570e-05, 2.83441968e-05,\n",
            "       1.63168166e-04, 1.08197120e-04, 1.57565722e-04, 1.05461440e-04,\n",
            "       1.01092890e-04, 9.71758709e-05, 1.08744418e-04, 8.46310868e-05,\n",
            "       1.27928419e-04, 1.23094680e-04, 7.11640532e-05, 1.04796876e-04,\n",
            "       7.88876569e-05, 7.11293396e-05, 9.62436388e-05, 6.04831512e-05,\n",
            "       9.12811374e-05, 1.78041024e-04, 4.00320532e-05, 1.07844193e-04,\n",
            "       1.95142580e-04, 1.12043599e-04, 2.74643153e-05, 1.24459795e-04,\n",
            "       1.03015678e-04, 1.16994881e-04, 2.75003367e-05, 1.30824046e-04,\n",
            "       1.22874786e-04, 9.53650015e-05, 1.26410028e-04, 8.49550343e-05,\n",
            "       1.03080922e-04, 1.32722460e-04, 8.13172010e-05, 3.98272168e-05,\n",
            "       7.42083794e-05, 1.25590726e-04, 1.92753927e-04, 1.20858065e-04,\n",
            "       1.79856419e-04, 1.04312247e-04, 1.49710220e-04, 1.23567530e-04,\n",
            "       6.32194788e-05, 1.38042597e-04, 1.27861538e-04, 1.09790359e-04,\n",
            "       1.52141452e-04, 5.28924720e-05, 9.84439175e-05, 7.50941035e-05,\n",
            "       6.22028820e-05, 1.12172092e-04, 8.57846317e-05, 3.90356254e-05,\n",
            "       4.87111938e-05, 1.12882663e-04, 6.99744051e-05, 2.87694074e-05,\n",
            "       2.52740228e-05, 7.76296365e-05, 1.29473367e-04, 1.34725196e-04,\n",
            "       2.74199338e-05, 2.41865582e-05, 7.34034547e-05, 1.72032072e-04,\n",
            "       1.18293392e-04, 5.55171173e-05, 4.47220846e-05, 1.03074352e-04,\n",
            "       9.77869786e-05, 9.89839027e-05, 6.03535918e-05, 5.78873151e-05,\n",
            "       1.14319562e-04, 1.33897600e-04, 1.51463915e-04, 1.34256683e-04,\n",
            "       1.87135432e-04, 1.15117240e-04, 1.07309505e-04, 8.05606032e-05,\n",
            "       1.33570065e-04, 1.11267356e-04, 1.05232088e-04, 1.33067675e-04,\n",
            "       3.01732180e-05, 1.12368703e-04, 1.20727724e-04, 8.92041207e-05,\n",
            "       1.23498452e-04, 1.89802140e-05, 1.12639682e-04, 7.54328794e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 232, 'shape': array([480,   1,   1, 144], dtype=int32), 'shape_signature': array([480,   1,   1, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.56442795e-04, 1.75099864e-04, 4.45357873e-04, 3.55453405e-04,\n",
            "       3.21209867e-04, 2.76123377e-04, 1.72270724e-04, 2.61865411e-04,\n",
            "       3.65965680e-04, 2.07297722e-04, 3.59372440e-04, 3.67579429e-04,\n",
            "       1.24154642e-04, 9.76000520e-05, 3.21564672e-04, 3.76782817e-04,\n",
            "       1.51889719e-04, 2.49936595e-04, 3.46127694e-04, 2.26336822e-04,\n",
            "       2.21376846e-04, 8.24875096e-05, 1.77141585e-04, 3.87413893e-04,\n",
            "       2.31562750e-04, 2.64022441e-04, 9.05880297e-05, 4.87792189e-04,\n",
            "       5.25210286e-04, 3.54626391e-04, 2.70103861e-04, 3.56070756e-04,\n",
            "       3.87423323e-04, 1.22574274e-04, 2.63332506e-04, 3.70988913e-04,\n",
            "       5.87359646e-05, 3.44276777e-04, 1.56702910e-04, 2.37170287e-04,\n",
            "       3.70771624e-04, 3.03750683e-04, 3.18863022e-04, 3.19068902e-04,\n",
            "       3.11348529e-04, 3.08027084e-04, 3.25168978e-04, 2.10604572e-04,\n",
            "       3.50566377e-04, 4.11917776e-04, 2.81304179e-04, 2.31538579e-04,\n",
            "       3.58738384e-04, 2.76182545e-04, 4.88452031e-04, 4.65779849e-05,\n",
            "       1.19198638e-04, 3.26752721e-04, 3.12712538e-04, 2.45193718e-04,\n",
            "       2.77228479e-04, 3.81155638e-04, 3.09601572e-04, 1.18425691e-04,\n",
            "       2.79805827e-04, 8.95689445e-05, 3.05768277e-04, 3.26790701e-04,\n",
            "       3.64095991e-04, 1.45209953e-04, 2.85922550e-04, 2.49107456e-04,\n",
            "       3.53214768e-04, 2.58897198e-04, 3.13862605e-04, 3.22901702e-04,\n",
            "       3.39464197e-04, 1.90951381e-04, 4.38270596e-04, 5.11228223e-04,\n",
            "       3.04069690e-04, 3.24055844e-04, 1.75510970e-04, 8.15306921e-05,\n",
            "       2.58955639e-04, 1.30892135e-04, 4.12997673e-04, 1.93424974e-04,\n",
            "       2.78255960e-04, 1.13815295e-04, 1.93309985e-04, 2.61304202e-04,\n",
            "       2.84525915e-04, 2.95498699e-04, 2.54968822e-04, 2.33987506e-04,\n",
            "       2.99355801e-04, 2.32265258e-04, 7.99378031e-05, 3.00058600e-04,\n",
            "       1.89088940e-04, 4.84444347e-04, 2.65846465e-04, 2.67170370e-04,\n",
            "       2.92168814e-04, 2.20977803e-04, 2.62656773e-04, 5.47106793e-05,\n",
            "       2.59970402e-04, 1.51233529e-04, 3.03014676e-04, 4.01750964e-04,\n",
            "       5.90898708e-05, 1.67692444e-04, 4.02140024e-04, 3.05539696e-04,\n",
            "       3.14897363e-04, 3.66650784e-04, 2.23026305e-04, 2.16172950e-04,\n",
            "       1.27458508e-04, 3.97330354e-04, 3.43731954e-04, 1.89706712e-04,\n",
            "       3.80351674e-04, 1.56221620e-04, 3.84636485e-04, 1.15441311e-04,\n",
            "       3.15110054e-04, 2.13303967e-04, 2.14157393e-04, 3.14649835e-04,\n",
            "       3.22188716e-04, 3.44561675e-04, 2.83283036e-04, 2.38571971e-04,\n",
            "       1.55982823e-04, 2.65513634e-04, 6.84200641e-05, 2.86090799e-04,\n",
            "       3.38538783e-04, 1.42897043e-04, 4.76508831e-05, 3.74743744e-04,\n",
            "       1.07713204e-04, 3.46889487e-04, 2.41287911e-04, 2.31962520e-04,\n",
            "       3.97357799e-04, 3.13644065e-04, 3.55490920e-04, 1.37400770e-04,\n",
            "       3.09540657e-04, 2.14683780e-04, 2.54320417e-04, 3.94921721e-04,\n",
            "       2.09688122e-04, 3.19607905e-04, 3.84083454e-04, 1.47985047e-04,\n",
            "       2.69255863e-04, 1.51137545e-04, 3.01710854e-04, 4.95248787e-05,\n",
            "       1.80496208e-04, 1.59797361e-04, 3.97969066e-04, 3.72277078e-04,\n",
            "       1.18489043e-04, 4.04697028e-04, 1.95928646e-04, 3.58832243e-04,\n",
            "       2.87068455e-04, 3.27810587e-04, 2.88233598e-04, 2.99234554e-04,\n",
            "       1.32505622e-04, 2.21094611e-04, 3.76469950e-04, 2.24016927e-04,\n",
            "       3.24872584e-04, 3.18160863e-04, 2.16397049e-04, 3.28115246e-04,\n",
            "       3.00257758e-04, 4.26500046e-04, 1.41609475e-04, 4.93215884e-05,\n",
            "       2.14845830e-04, 5.52044257e-05, 2.21550086e-04, 2.74125050e-04,\n",
            "       3.03899928e-04, 2.73892831e-04, 8.57211271e-05, 3.00184969e-04,\n",
            "       3.73817922e-04, 3.05093185e-04, 1.45799306e-04, 1.51475804e-04,\n",
            "       2.34221210e-04, 2.39880072e-04, 2.59819266e-04, 1.81983196e-04,\n",
            "       3.14812089e-04, 3.30437091e-04, 3.14066041e-04, 2.47535674e-04,\n",
            "       8.18559347e-05, 7.97751854e-05, 2.50193902e-04, 1.04341249e-04,\n",
            "       2.77548679e-04, 1.14999086e-04, 2.39700763e-04, 6.55977201e-05,\n",
            "       8.32693840e-05, 1.10911227e-04, 3.24277440e-04, 1.59483898e-04,\n",
            "       2.35617699e-04, 2.53227772e-04, 3.68689827e-04, 3.69108922e-04,\n",
            "       3.07332695e-04, 3.04680347e-04, 2.62384186e-04, 3.07634706e-04,\n",
            "       2.69717653e-04, 1.13851580e-04, 1.29177337e-04, 2.83211004e-04,\n",
            "       2.69290002e-04, 2.82048102e-04, 3.91980779e-04, 2.20276517e-04,\n",
            "       1.49045052e-04, 1.44317513e-04, 6.98241784e-05, 3.21952393e-04,\n",
            "       1.11415291e-04, 3.11038777e-04, 2.68674135e-04, 3.14658217e-04,\n",
            "       1.60407770e-04, 2.53251288e-04, 1.22947735e-04, 2.14427826e-04,\n",
            "       3.36500030e-04, 3.15297395e-04, 3.88473709e-04, 1.44106743e-04,\n",
            "       1.81243217e-04, 4.44054254e-04, 3.14518955e-04, 1.10910696e-04,\n",
            "       3.66028282e-04, 3.32472613e-04, 3.47832887e-04, 7.83622090e-05,\n",
            "       3.05220630e-04, 3.74552503e-04, 2.35674393e-04, 2.29603189e-04,\n",
            "       2.45619507e-04, 2.29817451e-04, 3.34183773e-04, 2.14326079e-04,\n",
            "       2.94606551e-04, 2.92945595e-04, 3.83676816e-04, 2.12365499e-04,\n",
            "       2.87952484e-04, 2.41814108e-04, 2.14899497e-04, 4.64667573e-05,\n",
            "       3.63129424e-04, 3.01712513e-04, 3.39208869e-04, 3.87650536e-04,\n",
            "       2.05511984e-04, 3.24804365e-04, 2.08510057e-04, 4.07680112e-04,\n",
            "       3.79808625e-04, 3.79397301e-04, 5.45053954e-05, 2.42220005e-04,\n",
            "       2.24100993e-04, 3.22854670e-04, 1.58523690e-04, 4.48156934e-04,\n",
            "       9.02197717e-05, 3.48735339e-04, 1.54698515e-04, 6.07335496e-05,\n",
            "       3.48672853e-04, 2.49821140e-04, 7.22798577e-05, 3.50448361e-04,\n",
            "       1.83867262e-04, 4.66001598e-04, 6.33635864e-05, 1.33408917e-04,\n",
            "       2.81256303e-04, 1.30923901e-04, 2.62611487e-04, 2.40641937e-04,\n",
            "       1.41699129e-04, 7.13372719e-05, 4.26469574e-04, 2.68425239e-04,\n",
            "       3.67662491e-04, 8.28040065e-05, 2.64947041e-04, 2.81500776e-04,\n",
            "       2.41738438e-04, 2.31549144e-04, 3.63346946e-04, 1.39584125e-04,\n",
            "       2.25669792e-04, 3.15155339e-04, 8.15026724e-05, 1.19720113e-04,\n",
            "       3.38056270e-04, 3.18554696e-04, 2.58177519e-04, 1.77267983e-04,\n",
            "       1.39242693e-04, 3.48152797e-04, 2.01477902e-04, 2.95096193e-04,\n",
            "       2.67175754e-04, 3.18885344e-04, 4.41729033e-04, 1.78395538e-04,\n",
            "       2.69112963e-04, 2.66059564e-04, 2.22080969e-04, 2.99025909e-04,\n",
            "       1.84149321e-04, 2.08673737e-04, 2.95406528e-04, 2.62982358e-04,\n",
            "       1.95645916e-04, 4.70281375e-04, 2.16016808e-04, 3.84514133e-04,\n",
            "       2.51183228e-04, 7.57972826e-04, 4.59172334e-05, 2.66868650e-04,\n",
            "       2.94294732e-04, 3.53713782e-04, 9.14830307e-05, 9.63939092e-05,\n",
            "       3.37968289e-04, 2.98790925e-04, 1.20669669e-04, 1.00090059e-04,\n",
            "       3.29395465e-04, 3.25703761e-04, 8.89225121e-05, 1.52020366e-04,\n",
            "       2.40475900e-04, 9.66983862e-05, 6.91101959e-05, 2.47240067e-04,\n",
            "       2.71100987e-04, 1.26548199e-04, 3.75568663e-04, 3.28608672e-04,\n",
            "       2.34570194e-04, 2.28791323e-04, 2.28831414e-04, 3.45081993e-04,\n",
            "       1.98084410e-04, 4.12561407e-04, 3.60792590e-04, 6.51169466e-05,\n",
            "       2.91044562e-04, 2.12245213e-04, 2.10489918e-04, 7.37000155e-05,\n",
            "       4.24266618e-04, 2.81332002e-04, 4.09699249e-04, 2.74218735e-04,\n",
            "       2.62859714e-04, 2.52674770e-04, 2.82755063e-04, 2.20056070e-04,\n",
            "       3.32636933e-04, 3.20068328e-04, 1.85039360e-04, 2.72490754e-04,\n",
            "       2.05122109e-04, 1.84949095e-04, 2.50250800e-04, 1.57267088e-04,\n",
            "       2.37347398e-04, 4.62938711e-04, 1.04090548e-04, 2.80414330e-04,\n",
            "       5.07405843e-04, 2.91333534e-04, 7.14121634e-05, 3.23617889e-04,\n",
            "       2.67859315e-04, 3.04207759e-04, 7.15058268e-05, 3.40166094e-04,\n",
            "       3.19496583e-04, 2.47966178e-04, 3.28688824e-04, 2.20898393e-04,\n",
            "       2.68028962e-04, 3.45102279e-04, 2.11439372e-04, 1.03557933e-04,\n",
            "       1.92955151e-04, 3.26558511e-04, 5.01194911e-04, 3.14252742e-04,\n",
            "       4.67659091e-04, 2.71230616e-04, 3.89273540e-04, 3.21297848e-04,\n",
            "       1.64382029e-04, 3.58935620e-04, 3.32463038e-04, 2.85474700e-04,\n",
            "       3.95595154e-04, 1.37529947e-04, 2.55971914e-04, 1.95258195e-04,\n",
            "       1.61738702e-04, 2.91667646e-04, 2.23055482e-04, 1.01499660e-04,\n",
            "       1.26657877e-04, 2.93515244e-04, 1.81946059e-04, 7.48056409e-05,\n",
            "       6.57170094e-05, 2.01851042e-04, 3.36654077e-04, 3.50309769e-04,\n",
            "       7.12967667e-05, 6.28894049e-05, 1.90862207e-04, 4.47314378e-04,\n",
            "       3.07584123e-04, 1.44354504e-04, 1.16285475e-04, 2.68011878e-04,\n",
            "       2.54263752e-04, 2.57375970e-04, 1.56930211e-04, 1.50517444e-04,\n",
            "       2.97251449e-04, 3.48157890e-04, 3.93833441e-04, 3.49091541e-04,\n",
            "       4.86585835e-04, 2.99325562e-04, 2.79024040e-04, 2.09472084e-04,\n",
            "       3.47306224e-04, 2.89315154e-04, 2.73622369e-04, 3.45999899e-04,\n",
            "       7.84557997e-05, 2.92178855e-04, 3.13913828e-04, 2.31946775e-04,\n",
            "       3.21118219e-04, 4.93519765e-05, 2.92883458e-04, 1.96139066e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/rezero/mul', 'index': 233, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0063879224471747875, -128), 'quantization_parameters': {'scales': array([0.00638792], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 234, 'shape': array([144], dtype=int32), 'shape_signature': array([144], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00019293, 0.00030075, 0.00051313, 0.00036835, 0.00025199,\n",
            "       0.0002026 , 0.00026398, 0.0001228 , 0.00057807, 0.00023195,\n",
            "       0.00032605, 0.00038679, 0.00017887, 0.0003737 , 0.00031612,\n",
            "       0.00018115, 0.00014313, 0.00024361, 0.00032455, 0.00021483,\n",
            "       0.00016102, 0.00018675, 0.00025017, 0.00016561, 0.00016849,\n",
            "       0.00039396, 0.00023566, 0.00018333, 0.00021136, 0.00029527,\n",
            "       0.00023173, 0.00018968, 0.00031399, 0.00020819, 0.00034828,\n",
            "       0.00017704, 0.00020089, 0.00016296, 0.00028942, 0.00027806,\n",
            "       0.00020473, 0.00037971, 0.00037035, 0.00014268, 0.0004112 ,\n",
            "       0.00024054, 0.00035781, 0.00022487, 0.00025079, 0.00024354,\n",
            "       0.00022199, 0.00016911, 0.0001342 , 0.00036295, 0.00020943,\n",
            "       0.00022466, 0.00027517, 0.00033624, 0.00031175, 0.00018777,\n",
            "       0.00029262, 0.00023158, 0.00016893, 0.00042799, 0.00034211,\n",
            "       0.00032842, 0.00017702, 0.0004113 , 0.00029168, 0.00043377,\n",
            "       0.00027145, 0.00022157, 0.00030698, 0.00022486, 0.00039889,\n",
            "       0.00025899, 0.00031986, 0.00026619, 0.00027869, 0.00030235,\n",
            "       0.00033045, 0.00029675, 0.00035014, 0.00025427, 0.00027168,\n",
            "       0.00021225, 0.00013984, 0.0001308 , 0.00015738, 0.00021955,\n",
            "       0.0003528 , 0.0001717 , 0.00032515, 0.00045181, 0.00029551,\n",
            "       0.00025024, 0.00018268, 0.000193  , 0.00046008, 0.00029965,\n",
            "       0.00018551, 0.00034598, 0.00034404, 0.00013847, 0.00035056,\n",
            "       0.0003442 , 0.00014638, 0.00034364, 0.00039251, 0.00016653,\n",
            "       0.00027769, 0.00027679, 0.00030363, 0.00061869, 0.00023478,\n",
            "       0.00039976, 0.0003064 , 0.00021402, 0.00040333, 0.00036925,\n",
            "       0.00030896, 0.00031078, 0.00017569, 0.00054861, 0.00015936,\n",
            "       0.00022292, 0.000176  , 0.00023503, 0.00040408, 0.00026922,\n",
            "       0.00030585, 0.00034784, 0.00017205, 0.00031571, 0.00023081,\n",
            "       0.00047525, 0.00036948, 0.00029715, 0.00024764, 0.00022961,\n",
            "       0.00029557, 0.0002516 , 0.00029414, 0.00041505], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 235, 'shape': array([144,   1,   1, 384], dtype=int32), 'shape_signature': array([144,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00710872, 0.01108113, 0.01890638, 0.01357194, 0.00928467,\n",
            "       0.00746481, 0.00972646, 0.00452467, 0.02129926, 0.0085462 ,\n",
            "       0.01201333, 0.0142515 , 0.00659056, 0.01376932, 0.01164747,\n",
            "       0.00667459, 0.00527356, 0.00897607, 0.01195828, 0.00791549,\n",
            "       0.00593288, 0.00688098, 0.00921769, 0.00610206, 0.00620798,\n",
            "       0.01451556, 0.00868315, 0.00675496, 0.00778752, 0.01087949,\n",
            "       0.00853826, 0.006989  , 0.01156906, 0.00767088, 0.0128325 ,\n",
            "       0.00652317, 0.00740172, 0.00600419, 0.01066387, 0.01024513,\n",
            "       0.0075434 , 0.01399046, 0.01364564, 0.00525699, 0.0151508 ,\n",
            "       0.00886295, 0.01318371, 0.0082854 , 0.00924049, 0.00897337,\n",
            "       0.00817928, 0.00623084, 0.00494452, 0.01337294, 0.00771649,\n",
            "       0.00827774, 0.01013863, 0.01238888, 0.01148642, 0.00691849,\n",
            "       0.0107817 , 0.00853271, 0.0062242 , 0.0157694 , 0.01260524,\n",
            "       0.01210088, 0.00652242, 0.01515465, 0.01074702, 0.0159824 ,\n",
            "       0.01000172, 0.00816393, 0.01131069, 0.00828522, 0.01469746,\n",
            "       0.0095425 , 0.01178537, 0.00980779, 0.01026842, 0.01114023,\n",
            "       0.01217552, 0.01093384, 0.01290112, 0.00936875, 0.01001018,\n",
            "       0.00782044, 0.00515246, 0.00481922, 0.00579867, 0.00808936,\n",
            "       0.01299891, 0.00632635, 0.01198046, 0.016647  , 0.01088806,\n",
            "       0.00922019, 0.006731  , 0.00711129, 0.0169519 , 0.01104064,\n",
            "       0.0068351 , 0.01274772, 0.01267628, 0.00510215, 0.01291639,\n",
            "       0.01268216, 0.00539335, 0.01266154, 0.01446229, 0.00613605,\n",
            "       0.01023145, 0.01019863, 0.01118726, 0.02279594, 0.00865043,\n",
            "       0.01472941, 0.01128954, 0.00788575, 0.01486074, 0.01360524,\n",
            "       0.01138386, 0.01145074, 0.00647338, 0.02021394, 0.00587185,\n",
            "       0.0082136 , 0.00648482, 0.00865986, 0.01488865, 0.00991937,\n",
            "       0.01126913, 0.01281617, 0.00633921, 0.01163259, 0.00850427,\n",
            "       0.0175108 , 0.01361367, 0.01094878, 0.00912453, 0.0084602 ,\n",
            "       0.01089058, 0.00927033, 0.01083783, 0.01529281], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 236, 'shape': array([384], dtype=int32), 'shape_signature': array([384], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.33070311e-05, 2.50830490e-05, 2.05053002e-05, 2.77426916e-05,\n",
            "       4.94687192e-05, 2.15956006e-05, 2.96001035e-05, 3.75521995e-05,\n",
            "       2.54124006e-05, 2.43032391e-05, 2.37200511e-05, 2.54043898e-05,\n",
            "       3.42558014e-05, 3.56397759e-05, 2.01541025e-05, 2.26376087e-05,\n",
            "       2.52046593e-05, 2.70088094e-05, 3.99043056e-05, 2.43216018e-05,\n",
            "       2.07419671e-05, 2.51086494e-05, 2.16979952e-05, 2.48366669e-05,\n",
            "       2.02257052e-05, 2.02190968e-05, 2.30097539e-05, 3.35553195e-05,\n",
            "       1.21775847e-05, 2.31465528e-05, 2.86505019e-05, 2.13818239e-05,\n",
            "       2.97596653e-05, 3.90284222e-05, 2.70835699e-05, 2.33147985e-05,\n",
            "       6.43616804e-05, 2.65792278e-05, 2.93244830e-05, 4.13693524e-05,\n",
            "       3.26903610e-05, 2.39740075e-05, 2.34119998e-05, 2.92674504e-05,\n",
            "       2.48558026e-05, 2.94465081e-05, 2.03978652e-05, 2.09933296e-05,\n",
            "       1.59495412e-05, 4.16331677e-05, 2.10681883e-05, 2.93502417e-05,\n",
            "       3.85248350e-05, 3.10742216e-05, 1.95547727e-05, 3.05954163e-05,\n",
            "       3.04443984e-05, 1.36439867e-05, 2.54259103e-05, 1.94390432e-05,\n",
            "       1.61337048e-05, 2.87784915e-05, 2.78029329e-05, 4.52777240e-05,\n",
            "       1.89018010e-05, 2.38544944e-05, 2.55509440e-05, 2.75378443e-05,\n",
            "       1.77487091e-05, 3.40461847e-05, 2.93350695e-05, 1.67515536e-05,\n",
            "       2.35890875e-05, 2.98105861e-05, 2.87930652e-05, 2.44122002e-05,\n",
            "       2.05931865e-05, 2.20846323e-05, 2.35020270e-05, 6.14281089e-05,\n",
            "       2.36955439e-05, 2.78213902e-05, 3.98716838e-05, 2.07155008e-05,\n",
            "       2.38925732e-05, 4.13977468e-05, 2.89168638e-05, 2.41225898e-05,\n",
            "       2.39411038e-05, 3.64986590e-05, 3.51677554e-05, 2.61132554e-05,\n",
            "       1.63601144e-05, 1.73439039e-05, 3.68170331e-05, 2.46891104e-05,\n",
            "       2.35370353e-05, 2.06352724e-05, 2.22841736e-05, 2.83916943e-05,\n",
            "       2.75457842e-05, 2.49811710e-05, 2.81852863e-05, 2.21669798e-05,\n",
            "       1.84648306e-05, 6.01242973e-05, 2.17409797e-05, 2.97251590e-05,\n",
            "       2.06039695e-05, 2.21776445e-05, 2.72150228e-05, 2.85121332e-05,\n",
            "       2.15035598e-05, 2.51830261e-05, 3.65470805e-05, 1.57906361e-05,\n",
            "       2.46419550e-05, 3.25762267e-05, 3.14979770e-05, 2.78761654e-05,\n",
            "       3.35309378e-05, 1.64845260e-05, 3.18843086e-05, 1.98008311e-05,\n",
            "       3.60536724e-05, 3.99239761e-05, 1.80716670e-05, 1.96315304e-05,\n",
            "       2.56093881e-05, 2.04306507e-05, 4.60495867e-05, 2.36683427e-05,\n",
            "       2.67137821e-05, 2.39606652e-05, 2.91567285e-05, 2.30439491e-05,\n",
            "       2.33327173e-05, 1.78304308e-05, 3.77627293e-05, 2.07985722e-05,\n",
            "       2.70028904e-05, 2.39457604e-05, 2.34752060e-05, 2.96911894e-05,\n",
            "       3.16890619e-05, 2.57088850e-05, 2.36624091e-05, 1.53923520e-05,\n",
            "       2.30010010e-05, 3.19869578e-05, 2.68698168e-05, 3.14451136e-05,\n",
            "       2.76738883e-05, 3.41388914e-05, 1.96250276e-05, 1.70970452e-05,\n",
            "       2.03762629e-05, 1.76059457e-05, 1.76377980e-05, 1.44782189e-05,\n",
            "       2.36274973e-05, 2.41046364e-05, 2.44020157e-05, 2.24946907e-05,\n",
            "       3.14974059e-05, 1.94816512e-05, 4.32084380e-05, 1.83997872e-05,\n",
            "       6.42760278e-05, 2.91803954e-05, 3.88753870e-05, 2.73619153e-05,\n",
            "       1.38780724e-05, 2.06376189e-05, 2.01545190e-05, 1.15344246e-05,\n",
            "       2.55749565e-05, 2.34594445e-05, 1.96516721e-05, 2.98345622e-05,\n",
            "       3.11008334e-05, 2.95487043e-05, 2.62430276e-05, 2.92464556e-05,\n",
            "       3.20396030e-05, 2.90129356e-05, 2.32407092e-05, 2.14554821e-05,\n",
            "       2.60874731e-05, 1.83906832e-05, 2.50679659e-05, 1.23995824e-05,\n",
            "       1.79535800e-05, 1.46222583e-05, 3.09515817e-05, 2.15928903e-05,\n",
            "       1.48063473e-05, 4.45037294e-05, 4.09361746e-05, 2.90124481e-05,\n",
            "       1.88025333e-05, 2.35043935e-05, 2.16996450e-05, 2.39262736e-05,\n",
            "       2.69084576e-05, 1.53518176e-05, 2.93715439e-05, 1.99269161e-05,\n",
            "       4.29956926e-05, 3.31455776e-05, 2.19036574e-05, 2.33485080e-05,\n",
            "       2.20604561e-05, 2.38787870e-05, 2.69372576e-05, 3.36917183e-05,\n",
            "       3.10237556e-05, 2.29270936e-05, 2.00464128e-05, 4.11739238e-05,\n",
            "       2.11798779e-05, 2.36646538e-05, 2.63681050e-05, 1.25665947e-05,\n",
            "       2.35580246e-05, 2.72705765e-05, 2.52376758e-05, 8.57296618e-06,\n",
            "       2.93127650e-05, 2.08115252e-05, 1.65488455e-05, 2.19104022e-05,\n",
            "       2.33420851e-05, 6.34822500e-05, 2.03411364e-05, 2.67516571e-05,\n",
            "       2.08127221e-05, 2.02762585e-05, 2.15158652e-05, 1.72407272e-05,\n",
            "       2.40989211e-05, 2.62544509e-05, 2.76141091e-05, 3.37819256e-05,\n",
            "       2.66135903e-05, 3.05844187e-05, 2.25636650e-05, 2.68272743e-05,\n",
            "       2.04823591e-05, 2.95435748e-05, 3.63585350e-05, 2.19772373e-05,\n",
            "       2.23429415e-05, 2.39017954e-05, 2.44475559e-05, 3.08925664e-05,\n",
            "       3.75157615e-05, 3.47385358e-05, 9.36856959e-05, 2.61598543e-05,\n",
            "       3.91799331e-05, 2.72663565e-05, 1.51138502e-05, 2.82290057e-05,\n",
            "       2.89389627e-05, 2.41479684e-05, 4.22216108e-05, 2.60691486e-05,\n",
            "       4.51208653e-05, 1.92787884e-05, 2.44060411e-05, 2.50329304e-05,\n",
            "       1.49123425e-05, 2.05602628e-05, 2.99207495e-05, 1.53732490e-05,\n",
            "       1.65075617e-05, 2.38042485e-05, 1.98620728e-05, 2.32795501e-05,\n",
            "       2.28163808e-05, 3.05495705e-05, 1.95801331e-05, 1.97826448e-05,\n",
            "       1.22873089e-05, 2.23892330e-05, 2.41420767e-05, 4.74393746e-05,\n",
            "       2.33232895e-05, 4.34208960e-05, 3.26842819e-05, 8.09069606e-05,\n",
            "       2.21693172e-05, 2.99396324e-05, 3.73037619e-05, 3.53770993e-05,\n",
            "       2.62108479e-05, 2.05401266e-05, 2.85222995e-05, 6.96925199e-05,\n",
            "       2.97908446e-05, 3.18444399e-05, 1.78240516e-05, 3.41487867e-05,\n",
            "       2.68127078e-05, 2.13739386e-05, 2.57520951e-05, 1.99222522e-05,\n",
            "       2.68999447e-05, 2.18558616e-05, 3.34371653e-05, 1.90594092e-05,\n",
            "       2.37471304e-05, 1.85613917e-05, 2.35798689e-05, 1.52950506e-05,\n",
            "       2.02800056e-05, 2.10879753e-05, 3.11059594e-05, 1.75605983e-05,\n",
            "       2.52593672e-05, 4.68245344e-05, 2.32621551e-05, 1.94115000e-05,\n",
            "       2.46539312e-05, 2.43760151e-05, 1.64996600e-05, 4.19325806e-05,\n",
            "       2.60751840e-05, 2.70026540e-05, 2.64830851e-05, 2.16528388e-05,\n",
            "       1.34994170e-05, 2.61292826e-05, 2.70944092e-05, 2.90644093e-05,\n",
            "       2.40452919e-05, 3.10290379e-05, 1.96778929e-05, 2.07484754e-05,\n",
            "       3.51240960e-05, 2.97784081e-05, 2.28484150e-05, 2.76899154e-05,\n",
            "       3.72163449e-05, 3.30415351e-05, 2.43018403e-05, 2.64384416e-05,\n",
            "       2.44861203e-05, 2.64960854e-05, 1.57193190e-05, 3.14208810e-05,\n",
            "       2.51306410e-05, 3.15595680e-05, 2.52625923e-05, 3.05365902e-05,\n",
            "       5.31170990e-05, 3.39269391e-05, 2.01015118e-05, 2.34468807e-05,\n",
            "       1.38712003e-05, 2.43070008e-05, 1.81932519e-05, 3.27252455e-05,\n",
            "       2.32070652e-05, 2.36431715e-05, 2.23997013e-05, 2.88091560e-05,\n",
            "       3.44703039e-05, 2.51408510e-05, 3.13467426e-05, 2.67579635e-05,\n",
            "       2.49930690e-05, 1.95377088e-05, 2.59650296e-05, 2.17486886e-05,\n",
            "       3.08082090e-05, 3.54747208e-05, 2.62865015e-05, 2.93783542e-05,\n",
            "       1.76346693e-05, 2.20449147e-05, 2.34982163e-05, 2.23709721e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 237, 'shape': array([384,   1,   1, 192], dtype=int32), 'shape_signature': array([384,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00168389, 0.00126811, 0.00103668, 0.00140257, 0.00250096,\n",
            "       0.0010918 , 0.00149648, 0.00189851, 0.00128476, 0.00122869,\n",
            "       0.0011992 , 0.00128436, 0.00173185, 0.00180182, 0.00101892,\n",
            "       0.00114448, 0.00127426, 0.00136547, 0.00201742, 0.00122961,\n",
            "       0.00104864, 0.0012694 , 0.00109697, 0.00125565, 0.00102254,\n",
            "       0.00102221, 0.00116329, 0.00169644, 0.00061566, 0.00117021,\n",
            "       0.00144847, 0.00108099, 0.00150454, 0.00197314, 0.00136925,\n",
            "       0.00117871, 0.0032539 , 0.00134375, 0.00148254, 0.00209149,\n",
            "       0.00165271, 0.00121204, 0.00118363, 0.00147966, 0.00125662,\n",
            "       0.00148871, 0.00103124, 0.00106135, 0.00080635, 0.00210483,\n",
            "       0.00106513, 0.00148384, 0.00194768, 0.001571  , 0.00098862,\n",
            "       0.0015468 , 0.00153916, 0.00068979, 0.00128544, 0.00098277,\n",
            "       0.00081566, 0.00145494, 0.00140562, 0.00228908, 0.00095561,\n",
            "       0.001206  , 0.00129177, 0.00139222, 0.00089731, 0.00172126,\n",
            "       0.00148308, 0.0008469 , 0.00119258, 0.00150712, 0.00145568,\n",
            "       0.00123419, 0.00104112, 0.00111652, 0.00118818, 0.00310559,\n",
            "       0.00119796, 0.00140655, 0.00201577, 0.0010473 , 0.00120792,\n",
            "       0.00209292, 0.00146193, 0.00121955, 0.00121038, 0.00184524,\n",
            "       0.00177796, 0.00132019, 0.00082711, 0.00087685, 0.00186134,\n",
            "       0.00124819, 0.00118995, 0.00104325, 0.00112661, 0.00143538,\n",
            "       0.00139262, 0.00126296, 0.00142495, 0.00112068, 0.00093352,\n",
            "       0.00303967, 0.00109915, 0.0015028 , 0.00104166, 0.00112122,\n",
            "       0.0013759 , 0.00144147, 0.00108714, 0.00127317, 0.00184769,\n",
            "       0.00079832, 0.00124581, 0.00164694, 0.00159243, 0.00140932,\n",
            "       0.00169521, 0.0008334 , 0.00161196, 0.00100106, 0.00182275,\n",
            "       0.00201842, 0.00091364, 0.0009925 , 0.00129472, 0.0010329 ,\n",
            "       0.0023281 , 0.00119659, 0.00135055, 0.00121137, 0.00147406,\n",
            "       0.00116502, 0.00117962, 0.00090144, 0.00190915, 0.0010515 ,\n",
            "       0.00136517, 0.00121061, 0.00118682, 0.00150108, 0.00160209,\n",
            "       0.00129975, 0.00119629, 0.00077818, 0.00116285, 0.00161715,\n",
            "       0.00135844, 0.00158975, 0.00139909, 0.00172594, 0.00099217,\n",
            "       0.00086437, 0.00103015, 0.00089009, 0.0008917 , 0.00073197,\n",
            "       0.00119452, 0.00121865, 0.00123368, 0.00113725, 0.0015924 ,\n",
            "       0.00098492, 0.00218447, 0.00093023, 0.00324957, 0.00147526,\n",
            "       0.0019654 , 0.00138332, 0.00070163, 0.00104337, 0.00101894,\n",
            "       0.00058314, 0.00129298, 0.00118603, 0.00099352, 0.00150833,\n",
            "       0.00157235, 0.00149388, 0.00132676, 0.0014786 , 0.00161981,\n",
            "       0.00146679, 0.00117497, 0.00108471, 0.00131889, 0.00092977,\n",
            "       0.00126735, 0.00062688, 0.00090767, 0.00073925, 0.0015648 ,\n",
            "       0.00109166, 0.00074856, 0.00224995, 0.00206959, 0.00146677,\n",
            "       0.00095059, 0.0011883 , 0.00109706, 0.00120963, 0.0013604 ,\n",
            "       0.00077613, 0.00148492, 0.00100743, 0.00217371, 0.00167572,\n",
            "       0.00110737, 0.00118042, 0.0011153 , 0.00120723, 0.00136185,\n",
            "       0.00170333, 0.00156845, 0.00115911, 0.00101348, 0.00208161,\n",
            "       0.00107078, 0.0011964 , 0.00133308, 0.00063532, 0.00119101,\n",
            "       0.0013787 , 0.00127593, 0.00043342, 0.00148195, 0.00105216,\n",
            "       0.00083665, 0.00110771, 0.00118009, 0.00320944, 0.00102838,\n",
            "       0.00135247, 0.00105222, 0.0010251 , 0.00108777, 0.00087163,\n",
            "       0.00121836, 0.00132733, 0.00139607, 0.0017079 , 0.00134549,\n",
            "       0.00154624, 0.00114074, 0.00135629, 0.00103552, 0.00149362,\n",
            "       0.00183816, 0.00111109, 0.00112958, 0.00120839, 0.00123598,\n",
            "       0.00156182, 0.00189666, 0.00175626, 0.00473642, 0.00132255,\n",
            "       0.0019808 , 0.00137849, 0.0007641 , 0.00142716, 0.00146305,\n",
            "       0.00122084, 0.00213458, 0.00131796, 0.00228115, 0.00097467,\n",
            "       0.00123388, 0.00126558, 0.00075392, 0.00103945, 0.00151269,\n",
            "       0.00077722, 0.00083456, 0.00120346, 0.00100416, 0.00117693,\n",
            "       0.00115352, 0.00154448, 0.0009899 , 0.00100014, 0.0006212 ,\n",
            "       0.00113192, 0.00122054, 0.00239837, 0.00117914, 0.00219521,\n",
            "       0.0016524 , 0.00409037, 0.0011208 , 0.00151364, 0.00188595,\n",
            "       0.00178854, 0.00132513, 0.00103844, 0.00144199, 0.00352341,\n",
            "       0.00150612, 0.00160994, 0.00090112, 0.00172644, 0.00135556,\n",
            "       0.00108059, 0.00130194, 0.0010072 , 0.00135997, 0.00110496,\n",
            "       0.00169047, 0.00096358, 0.00120057, 0.0009384 , 0.00119212,\n",
            "       0.00077326, 0.00102529, 0.00106613, 0.00157261, 0.0008878 ,\n",
            "       0.00127702, 0.00236728, 0.00117605, 0.00098138, 0.00124642,\n",
            "       0.00123237, 0.00083416, 0.00211996, 0.00131827, 0.00136516,\n",
            "       0.00133889, 0.00109469, 0.00068248, 0.001321  , 0.0013698 ,\n",
            "       0.00146939, 0.00121565, 0.00156872, 0.00099484, 0.00104897,\n",
            "       0.00177575, 0.00150549, 0.00115514, 0.0013999 , 0.00188153,\n",
            "       0.00167046, 0.00122862, 0.00133663, 0.00123793, 0.00133955,\n",
            "       0.00079471, 0.00158853, 0.00127052, 0.00159554, 0.00127719,\n",
            "       0.00154382, 0.00268541, 0.00171523, 0.00101626, 0.00118539,\n",
            "       0.00070128, 0.00122888, 0.00091979, 0.00165447, 0.00117327,\n",
            "       0.00119532, 0.00113245, 0.00145649, 0.0017427 , 0.00127103,\n",
            "       0.00158478, 0.00135279, 0.00126356, 0.00098776, 0.0013127 ,\n",
            "       0.00109954, 0.00155755, 0.00179348, 0.00132895, 0.00148527,\n",
            "       0.00089155, 0.00111451, 0.00118799, 0.001131  ], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 238, 'shape': array([192], dtype=int32), 'shape_signature': array([192], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([4.25407779e-05, 5.05224925e-05, 4.90028688e-05, 4.42587989e-05,\n",
            "       4.54347755e-05, 9.50266804e-06, 3.54243966e-05, 5.60879271e-05,\n",
            "       2.59915996e-05, 5.07108016e-05, 5.35072941e-05, 7.24463534e-05,\n",
            "       4.93217922e-05, 4.92820618e-05, 4.47026869e-05, 4.91895626e-05,\n",
            "       1.85927493e-05, 5.94781413e-05, 6.29135320e-05, 1.85740537e-05,\n",
            "       7.84023796e-05, 4.15394752e-05, 5.05227908e-05, 6.27620757e-05,\n",
            "       5.28986093e-05, 6.51331502e-05, 6.35067117e-05, 6.80929661e-05,\n",
            "       5.72790632e-05, 6.11241994e-05, 7.03378173e-05, 3.37168130e-05,\n",
            "       7.39561219e-05, 4.26894585e-05, 4.64077093e-05, 5.21903166e-05,\n",
            "       2.55780888e-05, 1.30212735e-04, 7.25337668e-05, 4.63261931e-05,\n",
            "       5.83816400e-05, 5.59873260e-05, 2.12925279e-05, 5.49306569e-05,\n",
            "       4.50044463e-05, 6.19421771e-05, 6.75123956e-05, 5.26118638e-05,\n",
            "       6.04296256e-05, 6.42898667e-05, 6.25525208e-05, 4.84330631e-05,\n",
            "       2.24276209e-05, 9.84335020e-06, 9.71524787e-05, 3.60108534e-05,\n",
            "       9.15218916e-05, 6.69347792e-05, 8.85921836e-05, 4.66659003e-05,\n",
            "       1.82257882e-05, 8.44484821e-05, 7.19943855e-05, 4.61894197e-05,\n",
            "       4.89808699e-05, 6.03273074e-05, 7.44352510e-05, 7.21159768e-06,\n",
            "       5.65888440e-05, 6.62266611e-05, 9.17996804e-05, 4.17907249e-05,\n",
            "       9.25881886e-06, 1.11461795e-05, 5.27307056e-05, 4.86039135e-05,\n",
            "       5.84430345e-05, 8.49503122e-05, 4.17234078e-05, 4.86950412e-05,\n",
            "       6.59532016e-05, 4.23306992e-05, 6.62076782e-05, 3.63220170e-05,\n",
            "       5.69899785e-05, 5.62541754e-05, 3.15475154e-05, 5.78242580e-05,\n",
            "       4.01120997e-05, 8.45277536e-05, 5.35854269e-05, 5.96445425e-05,\n",
            "       5.57735439e-05, 6.55629046e-05, 1.78020946e-05, 6.55965268e-05,\n",
            "       6.59996731e-05, 4.38816060e-05, 8.83669491e-05, 5.54971048e-05,\n",
            "       7.30756437e-05, 4.80798772e-05, 2.83454810e-05, 3.64603802e-05,\n",
            "       4.85771634e-05, 5.17895242e-05, 5.65173723e-05, 4.52966779e-05,\n",
            "       9.73843271e-05, 6.36097466e-05, 1.63120767e-05, 8.96731945e-05,\n",
            "       7.51716580e-05, 5.46242081e-05, 5.95866004e-05, 7.47429440e-05,\n",
            "       5.27704287e-05, 1.95626726e-05, 4.65444136e-05, 5.58714928e-05,\n",
            "       5.43085262e-05, 5.23686685e-05, 7.17020157e-05, 9.02297325e-05,\n",
            "       4.91693718e-05, 6.61720114e-05, 1.30621374e-05, 4.64557233e-05,\n",
            "       5.64941147e-05, 1.41947839e-05, 4.56803500e-05, 7.41564145e-05,\n",
            "       3.93007249e-05, 6.42827945e-05, 4.44354991e-05, 1.18604898e-04,\n",
            "       9.12298201e-05, 4.80571471e-05, 5.83612091e-05, 6.37958656e-05,\n",
            "       7.57541966e-06, 2.92837613e-05, 1.12748705e-04, 4.85056917e-05,\n",
            "       5.13042942e-05, 4.53318244e-05, 2.53605904e-05, 6.66735377e-06,\n",
            "       4.10972534e-05, 5.75437225e-05, 4.12516856e-05, 1.02996919e-05,\n",
            "       5.62786772e-05, 5.21267284e-05, 7.56964000e-05, 6.02521759e-05,\n",
            "       6.05077184e-05, 2.01865405e-05, 5.08604426e-05, 4.84989578e-05,\n",
            "       3.84549130e-05, 4.25533653e-05, 1.43257867e-05, 5.67575589e-05,\n",
            "       4.02939040e-05, 4.23017991e-05, 2.18647838e-05, 4.29882166e-05,\n",
            "       6.36783152e-05, 4.94574597e-05, 1.63553086e-05, 1.75102177e-05,\n",
            "       4.29899737e-05, 5.64679322e-05, 8.67428025e-05, 1.58390012e-05,\n",
            "       1.23072950e-05, 5.32729682e-05, 5.12494807e-05, 6.54217220e-05,\n",
            "       6.09117305e-05, 5.67404095e-05, 1.12335969e-04, 6.33900490e-05,\n",
            "       5.79247935e-05, 4.97584588e-05, 5.03201009e-05, 6.16601246e-05,\n",
            "       4.26514234e-05, 1.77602196e-04, 6.12251097e-05, 1.85664776e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 239, 'shape': array([192,   1,   1, 768], dtype=int32), 'shape_signature': array([192,   1,   1, 768], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00108109, 0.00128393, 0.00124531, 0.00112475, 0.00115463,\n",
            "       0.00024149, 0.00090024, 0.00142536, 0.00066052, 0.00128871,\n",
            "       0.00135978, 0.00184108, 0.00125341, 0.0012524 , 0.00113603,\n",
            "       0.00125005, 0.0004725 , 0.00151152, 0.00159882, 0.00047202,\n",
            "       0.00199244, 0.00105564, 0.00128394, 0.00159497, 0.00134431,\n",
            "       0.00165523, 0.0016139 , 0.00173045, 0.00145563, 0.00155335,\n",
            "       0.00178749, 0.00085684, 0.00187945, 0.00108487, 0.00117936,\n",
            "       0.00132631, 0.00065002, 0.00330909, 0.0018433 , 0.00117729,\n",
            "       0.00148365, 0.00142281, 0.00054111, 0.00139595, 0.0011437 ,\n",
            "       0.00157414, 0.00171569, 0.00133702, 0.0015357 , 0.0016338 ,\n",
            "       0.00158965, 0.00123083, 0.00056995, 0.00025015, 0.00246893,\n",
            "       0.00091514, 0.00232584, 0.00170101, 0.00225139, 0.00118592,\n",
            "       0.00046317, 0.00214609, 0.00182959, 0.00117381, 0.00124475,\n",
            "       0.0015331 , 0.00189162, 0.00018327, 0.00143809, 0.00168302,\n",
            "       0.0023329 , 0.00106203, 0.00023529, 0.00028326, 0.00134004,\n",
            "       0.00123517, 0.00148521, 0.00215884, 0.00106032, 0.00123749,\n",
            "       0.00167607, 0.00107575, 0.00168254, 0.00092305, 0.00144829,\n",
            "       0.00142959, 0.00080172, 0.00146949, 0.00101937, 0.0021481 ,\n",
            "       0.00136177, 0.00151575, 0.00141737, 0.00166615, 0.0004524 ,\n",
            "       0.001667  , 0.00167725, 0.00111516, 0.00224567, 0.00141035,\n",
            "       0.00185707, 0.00122185, 0.00072034, 0.00092657, 0.00123449,\n",
            "       0.00131613, 0.00143628, 0.00115112, 0.00247483, 0.00161651,\n",
            "       0.00041454, 0.00227886, 0.00191034, 0.00138816, 0.00151427,\n",
            "       0.00189944, 0.00134105, 0.00049715, 0.00118283, 0.00141986,\n",
            "       0.00138014, 0.00133084, 0.00182216, 0.00229301, 0.00124954,\n",
            "       0.00168163, 0.00033195, 0.00118058, 0.00143568, 0.00036073,\n",
            "       0.00116087, 0.00188454, 0.00099875, 0.00163362, 0.00112924,\n",
            "       0.00301411, 0.00231842, 0.00122128, 0.00148313, 0.00162124,\n",
            "       0.00019251, 0.00074419, 0.00286528, 0.00123267, 0.0013038 ,\n",
            "       0.00115202, 0.00064449, 0.00016944, 0.0010444 , 0.00146236,\n",
            "       0.00104833, 0.00026175, 0.00143021, 0.0013247 , 0.00192367,\n",
            "       0.00153119, 0.00153768, 0.000513  , 0.00129252, 0.0012325 ,\n",
            "       0.00097725, 0.00108141, 0.00036406, 0.00144238, 0.00102399,\n",
            "       0.00107502, 0.00055565, 0.00109246, 0.00161826, 0.00125686,\n",
            "       0.00041564, 0.00044499, 0.0010925 , 0.00143502, 0.00220439,\n",
            "       0.00040252, 0.00031277, 0.00135383, 0.0013024 , 0.00166256,\n",
            "       0.00154795, 0.00144194, 0.00285479, 0.00161093, 0.00147204,\n",
            "       0.00126451, 0.00127878, 0.00156697, 0.0010839 , 0.0045134 ,\n",
            "       0.00155591, 0.00047183], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 240, 'shape': array([384], dtype=int32), 'shape_signature': array([384], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([7.04387086e-04, 6.65137253e-04, 8.71301687e-04, 7.32189161e-04,\n",
            "       5.01856301e-03, 1.95934577e-03, 5.53576625e-04, 5.39926230e-04,\n",
            "       6.35323871e-04, 3.74484924e-04, 6.22244435e-04, 9.56336735e-04,\n",
            "       4.61237825e-04, 7.90132035e-04, 5.42861468e-04, 7.21628661e-04,\n",
            "       5.72181831e-04, 5.05081844e-04, 4.35734517e-04, 4.44727484e-04,\n",
            "       8.01724731e-04, 7.59139017e-04, 4.77273425e-04, 6.70334673e-04,\n",
            "       5.04984520e-04, 5.69856726e-04, 7.98789959e-04, 4.38504823e-04,\n",
            "       1.54301780e-03, 7.39695563e-04, 6.32967742e-04, 9.24332300e-04,\n",
            "       1.12093613e-03, 1.53325300e-03, 9.34764801e-04, 7.53184024e-04,\n",
            "       1.14171603e-03, 5.30345656e-04, 6.37548219e-04, 9.15758661e-04,\n",
            "       6.74148148e-04, 1.30909693e-03, 5.71516750e-04, 9.22062376e-04,\n",
            "       1.26666971e-03, 3.38742859e-03, 1.72725689e-04, 1.00984529e-03,\n",
            "       5.22247690e-04, 1.01090176e-03, 5.41560003e-04, 6.61368773e-04,\n",
            "       3.25092056e-04, 6.93072623e-04, 5.20900183e-04, 6.66693319e-04,\n",
            "       4.80737828e-04, 1.34697405e-03, 7.70002254e-04, 4.42961900e-04,\n",
            "       4.14471637e-04, 5.20696456e-04, 8.09334451e-04, 4.03364131e-04,\n",
            "       2.51072808e-04, 6.67365617e-04, 7.55213085e-04, 7.92124076e-04,\n",
            "       1.70658896e-04, 2.01401577e-04, 3.23099812e-04, 7.89586920e-04,\n",
            "       4.50867141e-04, 3.85058724e-04, 3.07648978e-03, 3.75809497e-04,\n",
            "       4.73534921e-04, 5.50388417e-04, 3.07442562e-04, 2.97816703e-04,\n",
            "       6.19335042e-04, 8.35218118e-04, 1.65516627e-04, 9.08276299e-04,\n",
            "       6.28079521e-04, 3.81439750e-04, 4.11534216e-04, 5.27625729e-04,\n",
            "       1.78959884e-03, 6.65856584e-04, 1.54897419e-03, 6.06395421e-04,\n",
            "       1.05809490e-03, 4.44235513e-04, 6.81120844e-04, 9.64046281e-04,\n",
            "       6.45699329e-04, 5.93122211e-04, 7.54926295e-04, 3.53815762e-04,\n",
            "       1.12310436e-03, 1.33381609e-03, 3.99255136e-04, 6.52617833e-04,\n",
            "       2.64476635e-03, 9.10196279e-04, 7.92758598e-04, 3.50716733e-03,\n",
            "       8.66502232e-04, 7.79676775e-04, 1.31055503e-03, 3.29513871e-03,\n",
            "       6.35255361e-04, 7.84093689e-04, 6.63969724e-04, 7.32795743e-04,\n",
            "       5.37205813e-03, 2.35174215e-04, 2.06031976e-03, 6.06273883e-04,\n",
            "       1.08255341e-03, 4.35094087e-04, 8.04389012e-04, 5.02174546e-04,\n",
            "       8.27383483e-04, 4.97453031e-04, 5.50911471e-04, 6.35382428e-04,\n",
            "       4.06950217e-04, 1.18827214e-03, 1.39877759e-03, 8.72076547e-04,\n",
            "       7.04629521e-04, 5.87907678e-04, 3.99307784e-04, 4.18877025e-04,\n",
            "       6.12405885e-04, 4.89681261e-04, 1.20280625e-03, 8.06274591e-04,\n",
            "       4.81487776e-04, 9.11782321e-04, 5.27470547e-04, 3.26388399e-04,\n",
            "       1.38928276e-03, 7.59411952e-04, 3.04081332e-04, 6.77532342e-04,\n",
            "       4.42563352e-04, 1.06378563e-03, 1.06952270e-03, 5.64347603e-04,\n",
            "       5.62505098e-04, 8.09417979e-04, 3.97527474e-04, 5.61631343e-04,\n",
            "       7.18352210e-04, 1.56773231e-03, 3.55910772e-04, 8.08826007e-04,\n",
            "       7.72964850e-04, 3.86796281e-04, 5.12850180e-04, 8.77713144e-04,\n",
            "       7.02426594e-04, 5.41775429e-04, 5.74618112e-04, 3.83163948e-04,\n",
            "       5.81183797e-03, 3.08638648e-03, 8.09810881e-04, 4.29315900e-04,\n",
            "       6.72986440e-04, 4.75820241e-04, 5.27090684e-04, 5.06627141e-04,\n",
            "       7.32088578e-04, 3.83577193e-04, 3.97948839e-04, 1.14176841e-03,\n",
            "       4.06347419e-04, 6.07862952e-04, 7.33846216e-04, 4.38698946e-04,\n",
            "       7.18735624e-04, 4.27328562e-03, 1.38978753e-03, 4.83543408e-04,\n",
            "       5.58450643e-04, 1.41706597e-03, 3.94323608e-04, 1.11022475e-03,\n",
            "       3.41813429e-04, 1.12549856e-03, 5.52322366e-04, 4.25497943e-04,\n",
            "       2.37256259e-04, 9.19099839e-04, 3.10786272e-04, 5.72700868e-04,\n",
            "       4.95279499e-04, 1.11548498e-03, 4.07132233e-04, 7.55185552e-04,\n",
            "       6.87733409e-04, 4.30563785e-04, 3.38341750e-04, 6.71970774e-04,\n",
            "       1.67354557e-03, 5.88272058e-04, 9.08269431e-04, 6.01214531e-04,\n",
            "       4.80816409e-04, 4.92934545e-04, 5.23400551e-04, 4.19311516e-04,\n",
            "       5.36480278e-04, 6.72373921e-04, 6.53401949e-04, 5.31009398e-04,\n",
            "       5.50153200e-04, 2.78980122e-04, 8.30201490e-04, 1.71764556e-03,\n",
            "       1.04426232e-03, 8.84971058e-04, 7.10398774e-04, 1.43085897e-04,\n",
            "       6.71371236e-04, 5.18619665e-04, 7.03279220e-04, 5.75162878e-04,\n",
            "       7.62808777e-04, 1.88422797e-04, 2.53236707e-04, 4.15167859e-04,\n",
            "       1.30267092e-03, 4.69519087e-04, 4.57509130e-04, 6.92180649e-04,\n",
            "       5.52569400e-04, 2.62845377e-03, 6.14128192e-04, 3.03824752e-04,\n",
            "       1.65155347e-04, 4.73410357e-04, 6.97179639e-04, 4.11902118e-04,\n",
            "       3.84299579e-04, 3.41149396e-04, 2.22301623e-03, 8.29628494e-04,\n",
            "       4.30798682e-04, 2.20685010e-03, 4.00526769e-04, 2.02879528e-04,\n",
            "       4.10524226e-04, 5.25113195e-04, 1.30948634e-03, 3.54214129e-03,\n",
            "       1.21460529e-03, 2.29796744e-03, 3.87605978e-04, 6.81633595e-04,\n",
            "       1.64089390e-04, 4.91599436e-04, 7.48732651e-04, 3.74928873e-04,\n",
            "       8.76304766e-05, 3.70614609e-04, 6.12688775e-04, 3.68974142e-04,\n",
            "       1.16051536e-03, 8.51310731e-04, 7.05511600e-04, 5.84443158e-04,\n",
            "       3.48112488e-04, 5.57996798e-04, 4.25705395e-04, 3.05640488e-03,\n",
            "       2.17813742e-03, 6.88783941e-04, 1.11882540e-03, 3.46720655e-04,\n",
            "       6.45150780e-04, 4.43945813e-04, 4.16619121e-04, 6.39317208e-04,\n",
            "       1.06016325e-03, 3.66063905e-04, 2.58089439e-03, 1.53734043e-04,\n",
            "       5.73735510e-04, 4.52604698e-04, 4.37273760e-04, 4.91674116e-04,\n",
            "       7.68710859e-04, 5.92153694e-04, 7.15208706e-04, 7.01181707e-04,\n",
            "       2.83991161e-04, 4.22439625e-04, 5.76239545e-04, 1.72804482e-03,\n",
            "       4.89431550e-04, 3.65634041e-04, 5.67612180e-04, 3.71443515e-04,\n",
            "       9.02157393e-04, 7.31887820e-04, 4.06967505e-04, 5.88871306e-04,\n",
            "       7.79059366e-04, 1.35466340e-03, 8.93057557e-04, 4.33500682e-04,\n",
            "       8.67038791e-04, 5.50990342e-04, 5.77286468e-04, 1.00549101e-03,\n",
            "       6.38540485e-04, 1.08327804e-04, 4.71392268e-04, 9.01649415e-04,\n",
            "       3.94399685e-04, 1.80205505e-04, 4.83836106e-04, 7.28530867e-04,\n",
            "       4.88353951e-04, 5.07611432e-04, 9.10734001e-04, 2.05993667e-04,\n",
            "       1.07740250e-03, 3.86543083e-03, 6.97124866e-04, 7.16137525e-04,\n",
            "       6.72745344e-04, 4.16038034e-04, 4.41820157e-04, 5.49803313e-04,\n",
            "       4.24858590e-04, 5.89943957e-04, 4.40567412e-04, 1.17833354e-03,\n",
            "       5.42953960e-04, 6.99017663e-04, 4.45035286e-04, 1.02425739e-03,\n",
            "       4.85264260e-04, 5.54338214e-04, 2.98814324e-04, 6.10947027e-04,\n",
            "       4.34870832e-04, 3.97175172e-04, 5.45288145e-04, 9.03815264e-04,\n",
            "       3.76000215e-04, 4.70060273e-04, 7.03128695e-04, 7.15741015e-04,\n",
            "       5.39915520e-04, 3.29022936e-04, 5.90465439e-04, 7.46703823e-04,\n",
            "       5.27296914e-04, 7.94867286e-04, 4.92002931e-04, 4.15980263e-04,\n",
            "       7.57020491e-04, 1.72351452e-03, 5.69454976e-04, 4.05060826e-04,\n",
            "       7.87468627e-04, 7.40803953e-04, 3.77928140e-04, 3.52580042e-04,\n",
            "       5.62565110e-04, 1.58910325e-03, 4.59464616e-04, 1.07182008e-04,\n",
            "       4.05773288e-04, 6.18213729e-04, 7.95897446e-04, 3.02096247e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block4_layer2/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer2/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 241, 'shape': array([  1,   5,   5, 384], dtype=int32), 'shape_signature': array([  1,   5,   5, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01652793, 0.01560696, 0.02044446, 0.01718029, 0.11775693,\n",
            "       0.04597462, 0.01298927, 0.01266898, 0.01490741, 0.00878702,\n",
            "       0.01460051, 0.02243975, 0.01082261, 0.01853987, 0.01273785,\n",
            "       0.01693249, 0.01342583, 0.01185138, 0.01022419, 0.01043521,\n",
            "       0.01881189, 0.01781265, 0.01119887, 0.01572892, 0.01184909,\n",
            "       0.01337127, 0.01874303, 0.0102892 , 0.03620579, 0.01735642,\n",
            "       0.01485213, 0.02168879, 0.02630195, 0.03597667, 0.02193358,\n",
            "       0.01767292, 0.02678953, 0.01244417, 0.01495961, 0.02148761,\n",
            "       0.0158184 , 0.03071701, 0.01341022, 0.02163552, 0.02972148,\n",
            "       0.07948355, 0.00405288, 0.02369529, 0.01225416, 0.02372007,\n",
            "       0.01270731, 0.01551854, 0.00762805, 0.01626245, 0.01222254,\n",
            "       0.01564347, 0.01128016, 0.03160577, 0.01806754, 0.01039378,\n",
            "       0.00972528, 0.01221776, 0.01899044, 0.00946465, 0.00589124,\n",
            "       0.01565925, 0.01772053, 0.01858662, 0.00400439, 0.00472574,\n",
            "       0.0075813 , 0.01852708, 0.01057927, 0.00903512, 0.0721876 ,\n",
            "       0.0088181 , 0.01111115, 0.01291446, 0.00721392, 0.00698805,\n",
            "       0.01453225, 0.01959779, 0.00388373, 0.02131204, 0.01473743,\n",
            "       0.00895021, 0.00965635, 0.01238035, 0.04199164, 0.01562384,\n",
            "       0.03634555, 0.01422863, 0.02482743, 0.01042366, 0.01598201,\n",
            "       0.02262064, 0.01515086, 0.01391718, 0.0177138 , 0.00830203,\n",
            "       0.02635283, 0.03129702, 0.00936823, 0.0153132 , 0.06205752,\n",
            "       0.02135709, 0.0186015 , 0.08229313, 0.02033184, 0.01829455,\n",
            "       0.03075122, 0.07731804, 0.0149058 , 0.01839819, 0.01557957,\n",
            "       0.01719452, 0.12605144, 0.00551819, 0.0483439 , 0.01422578,\n",
            "       0.02540133, 0.01020917, 0.0188744 , 0.01178316, 0.01941395,\n",
            "       0.01167237, 0.01292674, 0.01490879, 0.00954879, 0.02788194,\n",
            "       0.0328213 , 0.02046264, 0.01653362, 0.01379483, 0.00936947,\n",
            "       0.00982864, 0.01436966, 0.01149001, 0.02822297, 0.01891865,\n",
            "       0.01129776, 0.02139431, 0.01237671, 0.00765847, 0.03259851,\n",
            "       0.01781905, 0.00713505, 0.0158978 , 0.01038443, 0.02496096,\n",
            "       0.02509557, 0.01324201, 0.01319877, 0.0189924 , 0.00932769,\n",
            "       0.01317827, 0.01685561, 0.0367857 , 0.00835119, 0.01897851,\n",
            "       0.01813706, 0.00907589, 0.01203366, 0.0205949 , 0.01648193,\n",
            "       0.01271237, 0.013483  , 0.00899066, 0.13637055, 0.07241981,\n",
            "       0.01900162, 0.01007359, 0.01579114, 0.01116478, 0.0123678 ,\n",
            "       0.01188764, 0.01717793, 0.00900036, 0.00933758, 0.02679077,\n",
            "       0.00953465, 0.01426306, 0.01721917, 0.01029375, 0.01686461,\n",
            "       0.10026953, 0.03261035, 0.01134599, 0.01310364, 0.03325042,\n",
            "       0.00925252, 0.02605062, 0.0080204 , 0.026409  , 0.01295984,\n",
            "       0.009984  , 0.00556705, 0.02156601, 0.00729237, 0.01343801,\n",
            "       0.01162137, 0.02617404, 0.00955306, 0.01771988, 0.01613716,\n",
            "       0.01010287, 0.00793894, 0.01576731, 0.03926853, 0.01380338,\n",
            "       0.02131188, 0.01410706, 0.01128201, 0.01156635, 0.01228121,\n",
            "       0.00983884, 0.01258812, 0.01577676, 0.0153316 , 0.01245975,\n",
            "       0.01290894, 0.00654607, 0.01948007, 0.0403033 , 0.02450286,\n",
            "       0.0207652 , 0.01666899, 0.00335741, 0.01575324, 0.01216903,\n",
            "       0.01650194, 0.01349578, 0.01789875, 0.0044212 , 0.00594201,\n",
            "       0.00974161, 0.03056623, 0.01101692, 0.01073512, 0.01624152,\n",
            "       0.01296564, 0.06167476, 0.01441007, 0.00712903, 0.00387525,\n",
            "       0.01110823, 0.01635881, 0.00966498, 0.00901731, 0.00800482,\n",
            "       0.05216146, 0.01946663, 0.01010838, 0.05178213, 0.00939807,\n",
            "       0.00476042, 0.00963265, 0.0123214 , 0.03072614, 0.08311377,\n",
            "       0.02849983, 0.05392013, 0.00909489, 0.01599404, 0.00385024,\n",
            "       0.01153502, 0.01756847, 0.00879743, 0.00205619, 0.0086962 ,\n",
            "       0.0143763 , 0.00865771, 0.02723065, 0.01997539, 0.01655432,\n",
            "       0.01371353, 0.00816821, 0.01309299, 0.00998887, 0.07171632,\n",
            "       0.05110841, 0.01616181, 0.02625242, 0.00813555, 0.01513799,\n",
            "       0.01041687, 0.00977566, 0.01500111, 0.02487596, 0.00858942,\n",
            "       0.06055881, 0.00360726, 0.01346229, 0.01062004, 0.01026031,\n",
            "       0.01153678, 0.01803724, 0.01389446, 0.01678185, 0.01645272,\n",
            "       0.00666365, 0.00991224, 0.01352104, 0.04054732, 0.01148416,\n",
            "       0.00857934, 0.01331861, 0.00871565, 0.02116847, 0.01717322,\n",
            "       0.0095492 , 0.01381744, 0.01828006, 0.03178619, 0.02095495,\n",
            "       0.01017178, 0.02034443, 0.01292859, 0.01354561, 0.02359311,\n",
            "       0.01498289, 0.00254183, 0.01106088, 0.02115655, 0.0092543 ,\n",
            "       0.00422839, 0.01135286, 0.01709445, 0.01145887, 0.01191073,\n",
            "       0.02136971, 0.00483349, 0.02528047, 0.09069952, 0.01635753,\n",
            "       0.01680365, 0.01578548, 0.00976203, 0.01036699, 0.01290073,\n",
            "       0.009969  , 0.01384261, 0.01033759, 0.02764874, 0.01274002,\n",
            "       0.01640194, 0.01044243, 0.02403346, 0.01138637, 0.01300714,\n",
            "       0.00701146, 0.01433543, 0.01020393, 0.00931943, 0.01279479,\n",
            "       0.02120737, 0.00882257, 0.01102962, 0.0164984 , 0.01679434,\n",
            "       0.01266873, 0.00772028, 0.01385484, 0.01752086, 0.01237264,\n",
            "       0.01865098, 0.01154449, 0.00976067, 0.01776293, 0.04044101,\n",
            "       0.01336185, 0.00950446, 0.01847738, 0.01738243, 0.00886781,\n",
            "       0.00827303, 0.01320018, 0.03728715, 0.010781  , 0.00251495,\n",
            "       0.00952118, 0.01450594, 0.01867515, 0.00708847], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 242, 'shape': array([384], dtype=int32), 'shape_signature': array([384], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.48475214e-04, 1.33115376e-04, 5.56114319e-05, 1.19143231e-04,\n",
            "       1.97054142e-05, 2.66780571e-05, 1.99720656e-04, 1.19339442e-04,\n",
            "       1.13300594e-04, 1.56014081e-04, 1.18863340e-04, 8.29210767e-05,\n",
            "       1.42798672e-04, 1.42858393e-04, 1.18505865e-04, 1.86415607e-04,\n",
            "       6.27474001e-05, 1.18892705e-04, 1.21235571e-04, 8.33972954e-05,\n",
            "       1.49432759e-04, 1.05513733e-04, 6.35941906e-05, 8.29481214e-05,\n",
            "       1.22137542e-04, 8.51952573e-05, 8.62853558e-05, 1.37319745e-04,\n",
            "       5.97543622e-05, 1.13027883e-04, 1.37819865e-04, 1.11133144e-04,\n",
            "       5.45638468e-05, 4.92951585e-05, 1.48617459e-04, 1.15250004e-04,\n",
            "       6.41595834e-05, 1.35424314e-04, 9.24958149e-05, 1.19462558e-04,\n",
            "       7.06145875e-05, 1.41255034e-04, 1.13124028e-04, 1.01017933e-04,\n",
            "       5.04659802e-05, 2.45028259e-05, 1.51868138e-04, 3.76178359e-05,\n",
            "       6.67477143e-05, 1.19904144e-04, 4.38671232e-05, 9.31519826e-05,\n",
            "       1.58947660e-04, 8.38769629e-05, 1.43579833e-04, 1.03522951e-04,\n",
            "       1.13514252e-04, 4.63064425e-05, 9.57809316e-05, 5.79244261e-05,\n",
            "       1.53537592e-04, 1.31896493e-04, 1.22400132e-04, 1.37400697e-04,\n",
            "       1.12840033e-04, 1.75713198e-04, 1.20174576e-04, 7.11806424e-05,\n",
            "       9.30993920e-05, 3.91971334e-05, 1.58543276e-04, 2.13415871e-04,\n",
            "       1.43056372e-04, 1.07460182e-04, 2.00829563e-05, 1.65576188e-04,\n",
            "       1.10046778e-04, 8.71890661e-05, 8.22398943e-05, 4.21940604e-05,\n",
            "       1.15156319e-04, 1.16548632e-04, 1.33989597e-04, 4.00341305e-05,\n",
            "       1.09876171e-04, 1.33632624e-04, 1.15074115e-04, 1.30257729e-04,\n",
            "       2.06307977e-05, 1.07409389e-04, 4.26361512e-05, 1.07192333e-04,\n",
            "       3.48016729e-05, 1.44477701e-04, 1.37559648e-04, 6.33073068e-05,\n",
            "       1.23165795e-04, 1.23160891e-04, 9.18866572e-05, 1.19868389e-04,\n",
            "       5.58501488e-05, 8.29549172e-05, 1.29127482e-04, 7.54254943e-05,\n",
            "       5.09773963e-05, 1.62989556e-04, 1.23470789e-04, 3.41211417e-05,\n",
            "       1.19590804e-04, 7.25909122e-05, 7.70675251e-05, 4.02208352e-05,\n",
            "       1.23077727e-04, 2.31904647e-04, 4.24548161e-05, 4.18231211e-05,\n",
            "       4.95921850e-05, 1.22094163e-04, 5.74877267e-05, 1.17893236e-04,\n",
            "       3.64549269e-05, 8.20220594e-05, 1.52184250e-04, 1.07473505e-04,\n",
            "       1.18549375e-04, 1.28152809e-04, 9.79071265e-05, 7.43589044e-05,\n",
            "       1.50317559e-04, 1.50222346e-04, 5.18479101e-05, 1.15634160e-04,\n",
            "       1.36961418e-04, 1.50479536e-04, 9.54857169e-05, 1.11732006e-04,\n",
            "       1.68158600e-04, 1.15901676e-04, 3.55691882e-05, 1.17028416e-04,\n",
            "       1.44263598e-04, 8.80431180e-05, 1.76561240e-04, 1.93651664e-04,\n",
            "       8.17277614e-05, 1.15563940e-04, 1.30435903e-04, 5.49573451e-05,\n",
            "       7.71039340e-05, 5.11249709e-05, 9.40941609e-05, 1.92689593e-04,\n",
            "       1.18536074e-04, 7.86891542e-05, 1.15821516e-04, 9.24332417e-05,\n",
            "       1.65019868e-04, 2.37663498e-05, 6.43912645e-05, 5.34272476e-05,\n",
            "       1.36246381e-04, 1.14139453e-04, 1.13066810e-04, 5.14059393e-05,\n",
            "       1.11834102e-04, 1.01762213e-04, 1.00180623e-04, 9.99995827e-05,\n",
            "       1.86393845e-05, 3.06373950e-05, 1.22316604e-04, 1.58799725e-04,\n",
            "       5.11233302e-05, 7.80067203e-05, 8.80661901e-05, 4.64508157e-05,\n",
            "       1.03185055e-04, 7.05835992e-05, 2.09078702e-04, 1.08757507e-04,\n",
            "       1.28945932e-04, 2.31602753e-04, 1.01365076e-04, 1.21119039e-04,\n",
            "       1.00644502e-04, 1.76367448e-05, 2.81121083e-05, 1.22889076e-04,\n",
            "       8.99316001e-05, 2.84052912e-05, 1.12002082e-04, 4.07845837e-05,\n",
            "       1.01326041e-04, 4.14392853e-05, 7.61316551e-05, 8.27270123e-05,\n",
            "       1.67438469e-04, 3.62134997e-05, 7.03214755e-05, 1.36941890e-04,\n",
            "       1.23509599e-04, 8.12649814e-05, 2.06767247e-04, 9.98559481e-05,\n",
            "       1.15967152e-04, 1.15772193e-04, 1.34772868e-04, 1.33691472e-04,\n",
            "       3.17803679e-05, 1.21862096e-04, 4.13005801e-05, 1.76479371e-04,\n",
            "       1.41068536e-04, 1.41746088e-04, 8.53311431e-05, 1.21019890e-04,\n",
            "       1.22156955e-04, 1.05793188e-04, 9.40034806e-05, 1.29500870e-04,\n",
            "       1.07727545e-04, 1.71359934e-04, 1.24304919e-04, 2.14622978e-05,\n",
            "       8.14870436e-05, 7.73585125e-05, 1.02238795e-04, 8.85327318e-05,\n",
            "       9.39766032e-05, 9.58757737e-05, 1.90168153e-04, 9.13126350e-05,\n",
            "       1.27208783e-04, 3.84469313e-05, 1.44987091e-04, 1.81971191e-04,\n",
            "       3.21910593e-05, 1.12026748e-04, 1.48324631e-04, 4.55892950e-05,\n",
            "       1.85893485e-04, 3.43819775e-05, 9.15477285e-05, 1.05641993e-04,\n",
            "       1.50811829e-04, 1.50110354e-04, 1.08975204e-04, 1.51771193e-04,\n",
            "       1.55882270e-04, 1.56316004e-04, 2.39861438e-05, 1.00362493e-04,\n",
            "       1.51949993e-04, 5.40582951e-05, 1.49148385e-04, 1.46763472e-04,\n",
            "       1.54585301e-04, 1.40413438e-04, 4.10010944e-05, 2.84634025e-05,\n",
            "       6.21796207e-05, 6.30557406e-05, 9.44232816e-05, 7.55835936e-05,\n",
            "       1.58896684e-04, 1.07615415e-04, 8.00842899e-05, 1.37286013e-04,\n",
            "       2.21056500e-04, 6.93832189e-05, 1.07120330e-04, 1.67429112e-04,\n",
            "       3.24744688e-05, 7.71959822e-05, 1.01189296e-04, 9.78807147e-05,\n",
            "       9.56719814e-05, 1.43079014e-04, 7.96150998e-05, 5.43870046e-05,\n",
            "       3.51702292e-05, 8.69558717e-05, 2.91008655e-05, 1.01788522e-04,\n",
            "       5.41240734e-05, 1.56602982e-04, 1.16964540e-04, 1.34183734e-04,\n",
            "       1.14468465e-04, 1.35153139e-04, 3.18642306e-05, 1.12985683e-04,\n",
            "       1.01691629e-04, 9.30069000e-05, 3.74024239e-05, 8.19725901e-05,\n",
            "       6.38056372e-05, 7.94646330e-05, 1.42229081e-04, 9.53620620e-05,\n",
            "       1.04009414e-04, 9.02561733e-05, 9.31093819e-05, 3.52960124e-05,\n",
            "       1.31502922e-04, 1.41477358e-04, 1.16152485e-04, 1.13912611e-04,\n",
            "       1.69777544e-04, 1.03387771e-04, 9.51951879e-05, 1.26303043e-04,\n",
            "       9.57190714e-05, 3.27781636e-05, 3.55611228e-05, 9.02271422e-05,\n",
            "       3.76422868e-05, 1.05207611e-04, 1.04779421e-04, 2.67292580e-05,\n",
            "       1.32307425e-04, 2.12277504e-04, 1.48295818e-04, 1.17084237e-04,\n",
            "       9.76495867e-05, 1.53640460e-04, 1.41040204e-04, 5.91018907e-05,\n",
            "       1.26333543e-04, 1.70508254e-04, 1.02994331e-04, 1.65022677e-04,\n",
            "       3.73295697e-05, 2.58837772e-05, 7.98691690e-05, 6.19930724e-05,\n",
            "       1.50459658e-04, 1.26549596e-04, 1.49197818e-04, 1.55282702e-04,\n",
            "       5.91307435e-05, 8.00912676e-05, 1.31513851e-04, 1.28281958e-04,\n",
            "       1.10087181e-04, 1.58171606e-04, 1.27447434e-04, 7.15840652e-05,\n",
            "       1.45400612e-04, 1.41906916e-04, 1.36082395e-04, 9.29165908e-05,\n",
            "       9.62947233e-05, 1.39578202e-04, 1.17802003e-04, 6.59340149e-05,\n",
            "       7.34208224e-05, 2.12901999e-04, 6.78979995e-05, 1.23100297e-04,\n",
            "       7.25020291e-05, 1.24764294e-04, 1.25526713e-04, 7.97417015e-05,\n",
            "       1.19143944e-04, 9.33410047e-05, 1.15127994e-04, 7.29648091e-05,\n",
            "       6.71048474e-05, 2.61105342e-05, 8.79749132e-05, 1.41483310e-04,\n",
            "       1.33741283e-04, 1.44236779e-04, 8.43141170e-05, 6.71537637e-05,\n",
            "       1.23785008e-04, 3.30467119e-05, 1.56896727e-04, 1.61867341e-04,\n",
            "       1.08634020e-04, 2.01424307e-04, 5.60287517e-05, 1.58119772e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 243, 'shape': array([384,   1,   1, 144], dtype=int32), 'shape_signature': array([384,   1,   1, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([4.22591984e-04, 3.78874625e-04, 1.58281939e-04, 3.39106919e-04,\n",
            "       5.60857916e-05, 7.59314134e-05, 5.68447402e-04, 3.39665392e-04,\n",
            "       3.22477543e-04, 4.44049190e-04, 3.38310288e-04, 2.36010979e-04,\n",
            "       4.06435342e-04, 4.06605308e-04, 3.37292848e-04, 5.30578371e-04,\n",
            "       1.78592425e-04, 3.38393875e-04, 3.45062173e-04, 2.37366403e-04,\n",
            "       4.25317354e-04, 3.00314481e-04, 1.81002571e-04, 2.36087959e-04,\n",
            "       3.47629364e-04, 2.42483788e-04, 2.45586445e-04, 3.90841131e-04,\n",
            "       1.70073603e-04, 3.21701344e-04, 3.92264599e-04, 3.16308520e-04,\n",
            "       1.55300295e-04, 1.40304488e-04, 4.22996847e-04, 3.28025984e-04,\n",
            "       1.82611795e-04, 3.85446358e-04, 2.63262715e-04, 3.40015802e-04,\n",
            "       2.00984112e-04, 4.02041798e-04, 3.21975007e-04, 2.87518487e-04,\n",
            "       1.43636891e-04, 6.97402429e-05, 4.32248955e-04, 1.07068343e-04,\n",
            "       1.89978164e-04, 3.41272651e-04, 1.24855142e-04, 2.65130308e-04,\n",
            "       4.52398788e-04, 2.38731649e-04, 4.08658670e-04, 2.94648285e-04,\n",
            "       3.23085667e-04, 1.31797962e-04, 2.72612873e-04, 1.64865211e-04,\n",
            "       4.37000563e-04, 3.75405420e-04, 3.48376750e-04, 3.91071546e-04,\n",
            "       3.21166677e-04, 5.00117079e-04, 3.42042360e-04, 2.02595213e-04,\n",
            "       2.64980627e-04, 1.11563364e-04, 4.51247819e-04, 6.07426860e-04,\n",
            "       4.07168787e-04, 3.05854483e-04, 5.71603559e-05, 4.71264968e-04,\n",
            "       3.13216500e-04, 2.48158583e-04, 2.34072199e-04, 1.20093253e-04,\n",
            "       3.27759335e-04, 3.31722142e-04, 3.81362828e-04, 1.13945629e-04,\n",
            "       3.12730903e-04, 3.80346813e-04, 3.27525369e-04, 3.70741152e-04,\n",
            "       5.87196300e-05, 3.05709924e-04, 1.21351535e-04, 3.05092137e-04,\n",
            "       9.90529516e-05, 4.11214220e-04, 3.91523965e-04, 1.80186034e-04,\n",
            "       3.50555987e-04, 3.50542046e-04, 2.61528941e-04, 3.41170875e-04,\n",
            "       1.58961382e-04, 2.36107298e-04, 3.67524219e-04, 2.14676969e-04,\n",
            "       1.45092490e-04, 4.63902892e-04, 3.51424067e-04, 9.71160116e-05,\n",
            "       3.40380822e-04, 2.06609140e-04, 2.19350535e-04, 1.14477036e-04,\n",
            "       3.50305345e-04, 6.60049845e-04, 1.20835422e-04, 1.19037482e-04,\n",
            "       1.41149882e-04, 3.47505906e-04, 1.63622273e-04, 3.35549179e-04,\n",
            "       1.03758459e-04, 2.33452185e-04, 4.33148700e-04, 3.05892405e-04,\n",
            "       3.37416684e-04, 3.64750100e-04, 2.78664462e-04, 2.11641236e-04,\n",
            "       4.27835679e-04, 4.27564664e-04, 1.47570157e-04, 3.29119357e-04,\n",
            "       3.89821274e-04, 4.28296713e-04, 2.71772617e-04, 3.18013015e-04,\n",
            "       4.78615082e-04, 3.29880771e-04, 1.01237463e-04, 3.33087723e-04,\n",
            "       4.10604844e-04, 2.50589394e-04, 5.02530776e-04, 5.51173755e-04,\n",
            "       2.32614562e-04, 3.28919501e-04, 3.71248258e-04, 1.56420268e-04,\n",
            "       2.19454159e-04, 1.45512517e-04, 2.67811964e-04, 5.48435492e-04,\n",
            "       3.37378820e-04, 2.23966039e-04, 3.29652627e-04, 2.63084628e-04,\n",
            "       4.69681574e-04, 6.76440759e-05, 1.83271215e-04, 1.52065288e-04,\n",
            "       3.87786131e-04, 3.24865105e-04, 3.21812142e-04, 1.46312217e-04,\n",
            "       3.18303588e-04, 2.89636868e-04, 2.85135320e-04, 2.84620037e-04,\n",
            "       5.30516445e-05, 8.72005257e-05, 3.48139030e-04, 4.51977714e-04,\n",
            "       1.45507845e-04, 2.22023693e-04, 2.50655081e-04, 1.32208879e-04,\n",
            "       2.93686579e-04, 2.00895898e-04, 5.95082354e-04, 3.09546944e-04,\n",
            "       3.67007509e-04, 6.59190584e-04, 2.88506533e-04, 3.44730506e-04,\n",
            "       2.86455615e-04, 5.01979193e-05, 8.00130292e-05, 3.49768408e-04,\n",
            "       2.55964434e-04, 8.08474870e-05, 3.18781706e-04, 1.16081581e-04,\n",
            "       2.88395415e-04, 1.17944997e-04, 2.16686851e-04, 2.35458632e-04,\n",
            "       4.76565416e-04, 1.03071303e-04, 2.00149851e-04, 3.89765686e-04,\n",
            "       3.51534516e-04, 2.31297396e-04, 5.88503492e-04, 2.84211215e-04,\n",
            "       3.30067123e-04, 3.29512230e-04, 3.83592211e-04, 3.80514306e-04,\n",
            "       9.04536719e-05, 3.46845394e-04, 1.17550218e-04, 5.02297771e-04,\n",
            "       4.01511003e-04, 4.03439451e-04, 2.42870548e-04, 3.44448286e-04,\n",
            "       3.47684632e-04, 3.01109860e-04, 2.67553871e-04, 3.68586974e-04,\n",
            "       3.06615460e-04, 4.87726764e-04, 3.53798183e-04, 6.10862553e-05,\n",
            "       2.31929429e-04, 2.20178757e-04, 2.90993310e-04, 2.51982943e-04,\n",
            "       2.67477357e-04, 2.72882811e-04, 5.41258953e-04, 2.59895140e-04,\n",
            "       3.62063205e-04, 1.09428125e-04, 4.12664056e-04, 5.17928624e-04,\n",
            "       9.16225908e-05, 3.18851904e-04, 4.22163372e-04, 1.29756809e-04,\n",
            "       5.29092329e-04, 9.78584067e-05, 2.60564266e-04, 3.00679530e-04,\n",
            "       4.29242500e-04, 4.27245948e-04, 3.10166564e-04, 4.31973021e-04,\n",
            "       4.43674013e-04, 4.44908510e-04, 6.82696555e-05, 2.85652961e-04,\n",
            "       4.32481931e-04, 1.53861387e-04, 4.24507947e-04, 4.17720003e-04,\n",
            "       4.39982570e-04, 3.99646437e-04, 1.16697818e-04, 8.10128840e-05,\n",
            "       1.76976406e-04, 1.79470022e-04, 2.68748699e-04, 2.15126958e-04,\n",
            "       4.52253676e-04, 3.06296308e-04, 2.27936893e-04, 3.90745117e-04,\n",
            "       6.29173708e-04, 1.97479370e-04, 3.04887188e-04, 4.76538786e-04,\n",
            "       9.24292326e-05, 2.19716152e-04, 2.88006209e-04, 2.78589287e-04,\n",
            "       2.72302772e-04, 4.07233252e-04, 2.26601478e-04, 1.54796959e-04,\n",
            "       1.00101934e-04, 2.47494871e-04, 8.28272387e-05, 2.89711752e-04,\n",
            "       1.54048597e-04, 4.45725338e-04, 3.32905911e-04, 3.81915394e-04,\n",
            "       3.25801549e-04, 3.84674524e-04, 9.06923669e-05, 3.21581232e-04,\n",
            "       2.89435964e-04, 2.64717382e-04, 1.06455242e-04, 2.33311395e-04,\n",
            "       1.81604395e-04, 2.26173215e-04, 4.04814142e-04, 2.71420664e-04,\n",
            "       2.96032871e-04, 2.56888219e-04, 2.65009061e-04, 1.00459940e-04,\n",
            "       3.74285242e-04, 4.02674574e-04, 3.30594630e-04, 3.24219465e-04,\n",
            "       4.83222946e-04, 2.94263533e-04, 2.70945719e-04, 3.59485275e-04,\n",
            "       2.72436795e-04, 9.32936091e-05, 1.01214508e-04, 2.56805593e-04,\n",
            "       1.07137937e-04, 2.99443200e-04, 2.98224477e-04, 7.60771436e-05,\n",
            "       3.76575015e-04, 6.04186847e-04, 4.22081386e-04, 3.33246600e-04,\n",
            "       2.77931453e-04, 4.37293347e-04, 4.01430356e-04, 1.68216531e-04,\n",
            "       3.59572063e-04, 4.85302706e-04, 2.93143734e-04, 4.69689548e-04,\n",
            "       1.06247877e-04, 7.36707225e-05, 2.27324606e-04, 1.76445450e-04,\n",
            "       4.28240135e-04, 3.60187027e-04, 4.24648664e-04, 4.41967539e-04,\n",
            "       1.68298648e-04, 2.27956742e-04, 3.74316325e-04, 3.65117681e-04,\n",
            "       3.13331489e-04, 4.50189953e-04, 3.62742459e-04, 2.03743446e-04,\n",
            "       4.13841015e-04, 4.03897197e-04, 3.87319393e-04, 2.64460337e-04,\n",
            "       2.74075224e-04, 3.97269177e-04, 3.35289515e-04, 1.87662212e-04,\n",
            "       2.08971251e-04, 6.05964276e-04, 1.93252126e-04, 3.50369577e-04,\n",
            "       2.06356155e-04, 3.55105672e-04, 3.57275654e-04, 2.26961813e-04,\n",
            "       3.39108956e-04, 2.65668321e-04, 3.27678717e-04, 2.07673336e-04,\n",
            "       1.90994644e-04, 7.43161218e-05, 2.50395271e-04, 4.02691541e-04,\n",
            "       3.80656071e-04, 4.10528475e-04, 2.39975881e-04, 1.91133877e-04,\n",
            "       3.52318428e-04, 9.40579557e-05, 4.46561375e-04, 4.60708834e-04,\n",
            "       3.09195486e-04, 5.73296333e-04, 1.59469724e-04, 4.50042426e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/rezero/mul', 'index': 244, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.006016490049660206, -128), 'quantization_parameters': {'scales': array([0.00601649], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 245, 'shape': array([144], dtype=int32), 'shape_signature': array([144], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([9.79339820e-05, 1.98294161e-04, 3.64222913e-04, 2.96769314e-04,\n",
            "       1.91978761e-04, 1.18052769e-04, 1.43052981e-04, 9.77688760e-05,\n",
            "       2.61160108e-04, 1.26883635e-04, 1.64905679e-04, 1.54537556e-04,\n",
            "       9.83742138e-05, 1.78775619e-04, 1.87955549e-04, 8.62793095e-05,\n",
            "       1.01263075e-04, 2.21430077e-04, 1.71017440e-04, 1.16782699e-04,\n",
            "       1.17446776e-04, 1.03959457e-04, 1.26899889e-04, 7.83833239e-05,\n",
            "       1.08519656e-04, 1.55610658e-04, 1.54036723e-04, 1.28623331e-04,\n",
            "       1.29700682e-04, 1.89664381e-04, 1.34651913e-04, 9.84470680e-05,\n",
            "       1.81573618e-04, 1.08093693e-04, 2.61778769e-04, 1.33513560e-04,\n",
            "       1.29274544e-04, 1.11913898e-04, 1.94971726e-04, 1.99133909e-04,\n",
            "       1.25552382e-04, 1.79524184e-04, 2.04073935e-04, 9.47472290e-05,\n",
            "       1.91220344e-04, 1.46937076e-04, 2.36752690e-04, 1.37723036e-04,\n",
            "       1.21789235e-04, 1.26025756e-04, 1.50879045e-04, 1.15286035e-04,\n",
            "       8.51954610e-05, 2.08891564e-04, 1.45160258e-04, 1.03579529e-04,\n",
            "       1.56750859e-04, 2.21575305e-04, 2.15307955e-04, 1.39502372e-04,\n",
            "       2.12838189e-04, 1.38288713e-04, 1.37676208e-04, 1.87630649e-04,\n",
            "       2.14248139e-04, 2.50052137e-04, 9.74525756e-05, 3.42581101e-04,\n",
            "       2.19952562e-04, 1.89758706e-04, 1.28795422e-04, 1.39804484e-04,\n",
            "       1.85924640e-04, 1.35949405e-04, 1.75207344e-04, 1.64306824e-04,\n",
            "       2.67038326e-04, 1.55821414e-04, 1.57939765e-04, 2.04952463e-04,\n",
            "       1.71749169e-04, 1.81263385e-04, 1.87645841e-04, 1.36913543e-04,\n",
            "       1.41999073e-04, 1.16273906e-04, 1.14713097e-04, 8.31400321e-05,\n",
            "       1.12038244e-04, 1.30659275e-04, 2.22687973e-04, 6.96583957e-05,\n",
            "       1.96550114e-04, 1.98773589e-04, 1.40426448e-04, 1.88896694e-04,\n",
            "       1.37466035e-04, 1.08072301e-04, 2.21586859e-04, 2.08277605e-04,\n",
            "       1.22307014e-04, 1.64919315e-04, 1.80520714e-04, 1.13005997e-04,\n",
            "       1.87211670e-04, 1.32348010e-04, 9.50936883e-05, 2.30290898e-04,\n",
            "       1.74558547e-04, 7.80085538e-05, 1.41465513e-04, 1.93834683e-04,\n",
            "       2.21048889e-04, 2.25783660e-04, 1.19275268e-04, 1.98325361e-04,\n",
            "       1.54118112e-04, 1.26602987e-04, 1.82431919e-04, 2.00139897e-04,\n",
            "       1.69171210e-04, 1.62457392e-04, 1.38682051e-04, 1.79353636e-04,\n",
            "       1.04538667e-04, 1.85427445e-04, 9.68131353e-05, 1.46295642e-04,\n",
            "       1.56105569e-04, 1.48185893e-04, 2.12843297e-04, 2.13411709e-04,\n",
            "       1.08866021e-04, 1.75652865e-04, 1.46867736e-04, 2.63575232e-04,\n",
            "       1.76308808e-04, 1.90786173e-04, 1.54402107e-04, 1.16833049e-04,\n",
            "       1.94236040e-04, 1.71531734e-04, 1.91234940e-04, 1.89529761e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 246, 'shape': array([144,   1,   1, 384], dtype=int32), 'shape_signature': array([144,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00591167, 0.01196979, 0.02198589, 0.01791413, 0.01158857,\n",
            "       0.00712612, 0.00863522, 0.0059017 , 0.01576462, 0.00765918,\n",
            "       0.00995434, 0.00932848, 0.00593824, 0.01079158, 0.01134571,\n",
            "       0.00520815, 0.00611263, 0.01336636, 0.01032327, 0.00704945,\n",
            "       0.00708954, 0.00627539, 0.00766016, 0.00473152, 0.00655066,\n",
            "       0.00939325, 0.00929824, 0.0077642 , 0.00782923, 0.01144887,\n",
            "       0.0081281 , 0.00594264, 0.01096048, 0.00652495, 0.01580197,\n",
            "       0.00805939, 0.00780351, 0.00675555, 0.01176924, 0.01202048,\n",
            "       0.00757882, 0.01083677, 0.01231868, 0.0057193 , 0.01154279,\n",
            "       0.00886968, 0.0142913 , 0.00831349, 0.00735166, 0.0076074 ,\n",
            "       0.00910764, 0.00695911, 0.00514272, 0.01260949, 0.00876243,\n",
            "       0.00625246, 0.00946208, 0.01337513, 0.01299681, 0.0084209 ,\n",
            "       0.01284773, 0.00834764, 0.00831066, 0.0113261 , 0.01293284,\n",
            "       0.0150941 , 0.00588261, 0.0206795 , 0.01327718, 0.01145456,\n",
            "       0.00777458, 0.00843913, 0.01122312, 0.00820643, 0.01057618,\n",
            "       0.00991819, 0.01611945, 0.00940598, 0.00953385, 0.01237171,\n",
            "       0.01036744, 0.01094175, 0.01132702, 0.00826462, 0.00857161,\n",
            "       0.00701874, 0.00692452, 0.00501865, 0.00676306, 0.00788709,\n",
            "       0.0134423 , 0.00420485, 0.01186452, 0.01199873, 0.00847668,\n",
            "       0.01140253, 0.00829798, 0.00652366, 0.01337583, 0.01257243,\n",
            "       0.00738292, 0.00995516, 0.01089692, 0.00682147, 0.01130081,\n",
            "       0.00798903, 0.00574022, 0.01390124, 0.01053702, 0.00470889,\n",
            "       0.0085394 , 0.0117006 , 0.01334335, 0.01362916, 0.00719991,\n",
            "       0.01197168, 0.00930316, 0.00764224, 0.01101229, 0.01208121,\n",
            "       0.01021182, 0.00980655, 0.00837138, 0.01082647, 0.00631035,\n",
            "       0.01119311, 0.00584401, 0.00883096, 0.00942313, 0.00894507,\n",
            "       0.01284803, 0.01288235, 0.00657157, 0.01060308, 0.0088655 ,\n",
            "       0.01591041, 0.01064267, 0.01151658, 0.0093203 , 0.00705249,\n",
            "       0.01172483, 0.01035431, 0.01154367, 0.01144074], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 247, 'shape': array([384], dtype=int32), 'shape_signature': array([384], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([7.94731241e-05, 2.53622129e-05, 3.60660997e-05, 2.82628644e-05,\n",
            "       1.36052058e-05, 3.91940921e-05, 1.85461558e-05, 3.42629683e-05,\n",
            "       1.44926107e-05, 4.10505127e-05, 1.87944279e-05, 1.96172459e-05,\n",
            "       2.93181474e-05, 2.79345859e-05, 3.23151762e-05, 2.79005599e-05,\n",
            "       2.58928558e-05, 3.66993445e-05, 3.37279926e-05, 4.01359575e-05,\n",
            "       2.46141990e-05, 2.96175003e-05, 2.56659787e-05, 1.91221097e-05,\n",
            "       1.19875704e-05, 2.59284334e-05, 1.94060358e-05, 1.99352871e-05,\n",
            "       3.65773558e-05, 1.92393236e-05, 2.08043748e-05, 3.52089846e-05,\n",
            "       3.47704408e-05, 1.45550221e-05, 3.33845528e-05, 3.23871136e-05,\n",
            "       2.86358609e-05, 3.21471161e-05, 3.40293518e-05, 3.75978234e-05,\n",
            "       1.66258051e-05, 1.88039467e-05, 3.90567620e-05, 4.34747817e-05,\n",
            "       3.85550047e-05, 1.69796240e-05, 1.99669103e-05, 3.97951371e-05,\n",
            "       2.58623022e-05, 4.23089259e-05, 1.19169745e-05, 3.38849095e-05,\n",
            "       1.95708835e-05, 2.59079243e-05, 3.26179143e-05, 2.58557830e-05,\n",
            "       3.25698129e-05, 3.24546090e-05, 1.85960635e-05, 2.82608926e-05,\n",
            "       3.39064063e-05, 3.76102289e-05, 2.64735991e-05, 4.64585246e-05,\n",
            "       2.70221190e-05, 1.38315436e-05, 2.44049679e-05, 2.11059778e-05,\n",
            "       4.03908125e-05, 3.44462860e-05, 1.68818187e-05, 2.08640049e-05,\n",
            "       1.48760128e-05, 1.76357134e-05, 5.16128130e-05, 2.51858746e-05,\n",
            "       2.47652424e-05, 1.82786771e-05, 3.55249613e-05, 1.70324893e-05,\n",
            "       2.72543311e-05, 2.50881803e-05, 1.47709407e-05, 3.56051642e-05,\n",
            "       3.80195997e-05, 2.05621636e-05, 1.54772388e-05, 1.56057904e-05,\n",
            "       2.72462239e-05, 2.58240179e-05, 1.73099997e-05, 2.49515524e-05,\n",
            "       3.31518568e-05, 2.36422566e-05, 2.61359983e-05, 3.03711695e-05,\n",
            "       2.40687186e-05, 2.92256882e-05, 2.49883797e-05, 3.21497209e-05,\n",
            "       2.95496629e-05, 2.34359632e-05, 5.28163946e-05, 2.61007353e-05,\n",
            "       1.73546268e-05, 2.45771353e-05, 3.47019959e-05, 1.27915646e-05,\n",
            "       2.85504120e-05, 2.67588657e-05, 4.25014150e-05, 3.62853389e-05,\n",
            "       3.28988717e-05, 2.52387435e-05, 2.70373694e-05, 3.18444145e-05,\n",
            "       1.36229000e-05, 1.85020745e-05, 2.21392111e-05, 4.36901064e-05,\n",
            "       9.00806117e-06, 3.34483339e-05, 2.66831303e-05, 1.21409812e-05,\n",
            "       3.31336669e-05, 4.64189179e-05, 4.91788014e-05, 2.44559560e-05,\n",
            "       3.55573247e-05, 2.67458381e-05, 2.64338269e-05, 1.26091181e-05,\n",
            "       3.72804097e-05, 2.07227495e-05, 2.09976315e-05, 2.76733208e-05,\n",
            "       3.19055653e-05, 3.07400405e-05, 2.92416262e-05, 3.31126757e-05,\n",
            "       1.26168443e-05, 3.05103622e-05, 2.21521659e-05, 4.17345582e-05,\n",
            "       2.80441000e-05, 3.93417395e-05, 3.80261663e-05, 3.02441458e-05,\n",
            "       2.44790990e-05, 3.44373148e-05, 3.13969540e-05, 3.04031128e-05,\n",
            "       1.79464278e-05, 2.42685765e-05, 2.20232778e-05, 1.14717623e-05,\n",
            "       2.65893741e-05, 1.74101824e-05, 2.08397287e-05, 2.70213004e-05,\n",
            "       1.56444366e-05, 2.61129535e-05, 3.78388977e-05, 1.76810609e-05,\n",
            "       2.40440513e-05, 2.43324394e-05, 2.65215585e-05, 3.19107239e-05,\n",
            "       2.88772917e-05, 2.13338717e-05, 2.36239175e-05, 3.41214763e-05,\n",
            "       2.22071940e-05, 2.50476751e-05, 2.92857912e-05, 3.78561053e-05,\n",
            "       3.37301499e-05, 1.45285967e-05, 3.78553959e-05, 4.96861358e-05,\n",
            "       2.65454273e-05, 3.23845306e-05, 2.62587746e-05, 4.04223247e-05,\n",
            "       1.58997245e-05, 1.80421866e-05, 3.00716947e-05, 4.68724538e-05,\n",
            "       4.00339413e-05, 2.62833601e-05, 2.72181023e-05, 2.93499270e-05,\n",
            "       2.75634538e-05, 3.13576274e-05, 2.89531836e-05, 1.45503982e-05,\n",
            "       1.91407980e-05, 3.00291631e-05, 6.08601877e-05, 3.21558837e-05,\n",
            "       3.38889586e-05, 3.85721069e-05, 2.24258201e-05, 2.88697720e-05,\n",
            "       2.93109770e-05, 8.56518745e-05, 1.71930787e-05, 3.30611365e-05,\n",
            "       2.23493334e-05, 3.78919467e-05, 2.87833027e-05, 2.11319293e-05,\n",
            "       3.78199366e-05, 2.48915585e-05, 2.06835612e-05, 3.41811538e-05,\n",
            "       2.66334373e-05, 2.36818996e-05, 6.87588908e-05, 1.18081452e-05,\n",
            "       4.06146028e-05, 2.37884469e-05, 2.59268509e-05, 1.42930148e-05,\n",
            "       1.64898102e-05, 2.88083884e-05, 1.71042757e-05, 2.05796223e-05,\n",
            "       2.06974801e-05, 2.61993246e-05, 3.15173893e-05, 3.08657873e-05,\n",
            "       2.47402131e-05, 3.70302369e-05, 2.63652946e-05, 7.23438643e-05,\n",
            "       1.83298052e-05, 2.50429039e-05, 2.31013983e-05, 4.37240233e-05,\n",
            "       2.29235811e-05, 2.77573763e-05, 2.22948565e-05, 2.44536495e-05,\n",
            "       2.78569969e-05, 3.13888086e-05, 3.09115676e-05, 2.55843388e-05,\n",
            "       1.74310771e-05, 1.58818966e-05, 4.06533181e-05, 2.37291315e-05,\n",
            "       2.63770889e-05, 2.83275949e-05, 2.59935514e-05, 1.96690962e-05,\n",
            "       3.22588930e-05, 2.41702492e-05, 1.05621075e-05, 3.53642645e-05,\n",
            "       1.68659717e-05, 4.29147876e-05, 2.43869672e-05, 1.85165500e-05,\n",
            "       1.85496519e-05, 3.26380614e-05, 5.02025068e-05, 3.74441588e-05,\n",
            "       1.71593110e-05, 2.18171299e-05, 2.98678133e-05, 1.72130312e-05,\n",
            "       3.02254975e-05, 1.72071577e-05, 2.10908838e-05, 4.10126777e-05,\n",
            "       3.39587568e-05, 2.08640686e-05, 2.34796353e-05, 3.00843312e-05,\n",
            "       2.34912350e-05, 3.37106285e-05, 3.67745524e-05, 3.19784340e-05,\n",
            "       3.41877203e-05, 2.25461481e-05, 3.22066480e-05, 1.87567202e-05,\n",
            "       2.29915440e-05, 3.35698933e-05, 3.28839706e-05, 2.76892533e-05,\n",
            "       1.68746592e-05, 3.41862433e-05, 2.66255247e-05, 1.20103277e-05,\n",
            "       1.56526512e-05, 2.25787589e-05, 2.28875324e-05, 4.56446178e-05,\n",
            "       5.16711261e-05, 2.48119286e-05, 5.78897052e-05, 2.76148785e-05,\n",
            "       1.84777309e-05, 2.07206249e-05, 2.05887482e-05, 1.33304620e-05,\n",
            "       2.97670267e-05, 3.21928164e-05, 3.20688887e-05, 2.81195771e-05,\n",
            "       5.63423418e-05, 1.67150301e-05, 3.90674722e-05, 2.40653681e-05,\n",
            "       2.39182918e-05, 2.74325212e-05, 1.13095530e-05, 2.54678489e-05,\n",
            "       1.42506806e-05, 2.10297985e-05, 2.78479019e-05, 2.56107614e-05,\n",
            "       2.73485093e-05, 5.10556238e-05, 5.04990967e-05, 2.93072426e-05,\n",
            "       2.22977706e-05, 2.59270910e-05, 3.16550359e-05, 2.73868372e-05,\n",
            "       2.88741976e-05, 2.76575611e-05, 2.17055112e-05, 2.41553207e-05,\n",
            "       2.65014896e-05, 1.35211540e-05, 4.48437168e-05, 3.25570618e-05,\n",
            "       2.76066748e-05, 3.06073998e-05, 2.73981368e-05, 1.91195340e-05,\n",
            "       4.11602814e-05, 2.94376914e-05, 2.18834884e-05, 4.14732785e-05,\n",
            "       2.01642979e-05, 2.91477554e-05, 2.31906070e-05, 2.83460213e-05,\n",
            "       3.10018986e-05, 1.94292843e-05, 3.75974669e-05, 2.19391623e-05,\n",
            "       2.67618016e-05, 4.20574070e-05, 2.06354762e-05, 3.40191218e-05,\n",
            "       2.63934162e-05, 3.61654784e-05, 1.56697733e-05, 3.34866600e-05,\n",
            "       1.45199147e-05, 1.22917527e-05, 1.65978981e-05, 3.04007899e-05,\n",
            "       2.33093997e-05, 1.21203002e-05, 2.51022775e-05, 2.54365114e-05,\n",
            "       1.59841929e-05, 1.95625398e-05, 3.14131867e-05, 3.02031967e-05,\n",
            "       2.80104177e-05, 3.45953376e-05, 7.28477462e-05, 2.59833432e-05,\n",
            "       3.37054262e-05, 1.79195540e-05, 2.23785792e-05, 4.42051423e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 248, 'shape': array([384,   1,   1, 192], dtype=int32), 'shape_signature': array([384,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00354281, 0.00113062, 0.00160778, 0.00125992, 0.0006065 ,\n",
            "       0.00174722, 0.00082676, 0.0015274 , 0.00064606, 0.00182998,\n",
            "       0.00083783, 0.00087451, 0.00130697, 0.00124529, 0.00144057,\n",
            "       0.00124377, 0.00115427, 0.00163601, 0.00150355, 0.00178921,\n",
            "       0.00109727, 0.00132031, 0.00114416, 0.00085244, 0.00053439,\n",
            "       0.00115586, 0.0008651 , 0.00088869, 0.00163057, 0.00085767,\n",
            "       0.00092743, 0.00156957, 0.00155002, 0.00064884, 0.00148824,\n",
            "       0.00144378, 0.00127655, 0.00143308, 0.00151699, 0.00167606,\n",
            "       0.00074116, 0.00083826, 0.0017411 , 0.00193805, 0.00171873,\n",
            "       0.00075693, 0.0008901 , 0.00177402, 0.00115291, 0.00188608,\n",
            "       0.00053124, 0.00151055, 0.00087245, 0.00115494, 0.00145407,\n",
            "       0.00115262, 0.00145192, 0.00144679, 0.00082899, 0.00125984,\n",
            "       0.00151151, 0.00167662, 0.00118016, 0.00207106, 0.00120461,\n",
            "       0.00061659, 0.00108794, 0.00094088, 0.00180057, 0.00153557,\n",
            "       0.00075257, 0.00093009, 0.00066315, 0.00078618, 0.00230083,\n",
            "       0.00112275, 0.001104  , 0.00081484, 0.00158366, 0.00075929,\n",
            "       0.00121496, 0.0011184 , 0.00065847, 0.00158723, 0.00169487,\n",
            "       0.00091664, 0.00068996, 0.00069569, 0.0012146 , 0.0011512 ,\n",
            "       0.00077166, 0.00111231, 0.00147787, 0.00105394, 0.00116511,\n",
            "       0.00135391, 0.00107295, 0.00130284, 0.00111395, 0.00143319,\n",
            "       0.00131729, 0.00104475, 0.00235449, 0.00116354, 0.00077365,\n",
            "       0.00109562, 0.00154697, 0.00057023, 0.00127274, 0.00119288,\n",
            "       0.00189466, 0.00161756, 0.00146659, 0.00112511, 0.00120529,\n",
            "       0.00141958, 0.00060729, 0.0008248 , 0.00098694, 0.00194765,\n",
            "       0.00040157, 0.00149109, 0.0011895 , 0.00054123, 0.00147706,\n",
            "       0.0020693 , 0.00219233, 0.00109022, 0.0015851 , 0.0011923 ,\n",
            "       0.00117839, 0.0005621 , 0.00166191, 0.00092379, 0.00093605,\n",
            "       0.00123364, 0.00142231, 0.00137035, 0.00130356, 0.00147612,\n",
            "       0.00056244, 0.00136011, 0.00098752, 0.00186047, 0.00125017,\n",
            "       0.00175381, 0.00169516, 0.00134825, 0.00109125, 0.00153517,\n",
            "       0.00139964, 0.00135533, 0.00080003, 0.00108186, 0.00098177,\n",
            "       0.0005114 , 0.00118532, 0.00077612, 0.00092901, 0.00120458,\n",
            "       0.00069741, 0.00116408, 0.00168681, 0.0007882 , 0.00107185,\n",
            "       0.00108471, 0.0011823 , 0.00142254, 0.00128731, 0.00095104,\n",
            "       0.00105312, 0.00152109, 0.00098997, 0.00111659, 0.00130552,\n",
            "       0.00168758, 0.00150365, 0.00064767, 0.00168755, 0.00221495,\n",
            "       0.00118336, 0.00144366, 0.00117058, 0.00180198, 0.00070879,\n",
            "       0.0008043 , 0.00134056, 0.00208952, 0.00178466, 0.00117168,\n",
            "       0.00121335, 0.00130838, 0.00122874, 0.00139788, 0.0012907 ,\n",
            "       0.00064864, 0.00085327, 0.00133866, 0.00271307, 0.00143347,\n",
            "       0.00151073, 0.0017195 , 0.00099972, 0.00128698, 0.00130665,\n",
            "       0.00381825, 0.00076645, 0.00147382, 0.00099631, 0.00168918,\n",
            "       0.00128312, 0.00094203, 0.00168597, 0.00110963, 0.00092205,\n",
            "       0.00152375, 0.00118729, 0.00105571, 0.00306519, 0.00052639,\n",
            "       0.00181055, 0.00106046, 0.00115579, 0.00063716, 0.0007351 ,\n",
            "       0.00128424, 0.00076249, 0.00091741, 0.00092267, 0.00116793,\n",
            "       0.00140501, 0.00137596, 0.00110289, 0.00165076, 0.00117533,\n",
            "       0.003225  , 0.00081712, 0.00111638, 0.00102983, 0.00194916,\n",
            "       0.0010219 , 0.00123739, 0.00099388, 0.00109011, 0.00124183,\n",
            "       0.00139927, 0.001378  , 0.00114052, 0.00077706, 0.000708  ,\n",
            "       0.00181227, 0.00105782, 0.00117586, 0.00126281, 0.00115876,\n",
            "       0.00087682, 0.00143806, 0.00107748, 0.00047085, 0.00157649,\n",
            "       0.00075186, 0.00191309, 0.00108714, 0.00082544, 0.00082692,\n",
            "       0.00145496, 0.00223797, 0.00166921, 0.00076494, 0.00097258,\n",
            "       0.00133147, 0.00076734, 0.00134741, 0.00076707, 0.00094021,\n",
            "       0.00182829, 0.00151384, 0.00093009, 0.00104669, 0.00134112,\n",
            "       0.00104721, 0.00150278, 0.00163936, 0.00142556, 0.00152405,\n",
            "       0.00100508, 0.00143573, 0.00083615, 0.00102493, 0.0014965 ,\n",
            "       0.00146593, 0.00123435, 0.00075225, 0.00152398, 0.00118693,\n",
            "       0.00053541, 0.00069778, 0.00100653, 0.0010203 , 0.00203478,\n",
            "       0.00230343, 0.00110608, 0.00258065, 0.00123104, 0.00082371,\n",
            "       0.0009237 , 0.00091782, 0.00059426, 0.00132698, 0.00143512,\n",
            "       0.00142959, 0.00125354, 0.00251167, 0.00074514, 0.00174158,\n",
            "       0.0010728 , 0.00106625, 0.00122291, 0.00050417, 0.00113532,\n",
            "       0.00063528, 0.00093748, 0.00124142, 0.0011417 , 0.00121916,\n",
            "       0.002276  , 0.00225119, 0.00130648, 0.00099401, 0.0011558 ,\n",
            "       0.00141114, 0.00122087, 0.00128718, 0.00123294, 0.0009676 ,\n",
            "       0.00107681, 0.0011814 , 0.00060276, 0.00199908, 0.00145135,\n",
            "       0.00123067, 0.00136444, 0.00122137, 0.00085232, 0.00183487,\n",
            "       0.0013123 , 0.00097554, 0.00184883, 0.0008989 , 0.00129937,\n",
            "       0.00103381, 0.00126363, 0.00138203, 0.00086613, 0.00167605,\n",
            "       0.00097802, 0.00119301, 0.00187487, 0.0009199 , 0.00151653,\n",
            "       0.00117659, 0.00161221, 0.00069854, 0.00149279, 0.00064728,\n",
            "       0.00054795, 0.00073991, 0.00135523, 0.0010391 , 0.00054031,\n",
            "       0.00111903, 0.00113393, 0.00071256, 0.00087207, 0.00140036,\n",
            "       0.00134642, 0.00124867, 0.00154222, 0.00324746, 0.0011583 ,\n",
            "       0.00150255, 0.00079883, 0.00099761, 0.00197061], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 249, 'shape': array([192], dtype=int32), 'shape_signature': array([192], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.28349097e-06, 6.81793153e-06, 2.56997009e-06, 1.24300213e-05,\n",
            "       3.74880983e-06, 2.50850212e-06, 4.43776071e-06, 8.16913962e-05,\n",
            "       1.00000243e-05, 3.69830341e-05, 3.13772148e-06, 8.18858553e-06,\n",
            "       7.91312868e-06, 5.34809951e-05, 2.62973390e-06, 2.72080160e-06,\n",
            "       6.24936729e-05, 2.81470670e-06, 3.34780339e-06, 7.36499424e-05,\n",
            "       4.38785719e-05, 3.55891098e-06, 8.94561799e-06, 3.06276706e-06,\n",
            "       1.89898083e-06, 8.05816599e-05, 2.63952370e-05, 4.62261996e-05,\n",
            "       4.64467803e-06, 3.45030858e-05, 5.40348010e-05, 1.62403485e-05,\n",
            "       9.51639140e-06, 1.57611976e-05, 6.60821252e-06, 4.10331231e-05,\n",
            "       6.15157569e-06, 3.03173147e-06, 3.31417141e-06, 2.71204754e-05,\n",
            "       1.63505706e-06, 5.00657279e-06, 3.59551559e-05, 1.07429639e-06,\n",
            "       1.85782756e-05, 5.29982426e-05, 4.59620969e-05, 3.19387959e-06,\n",
            "       1.16689000e-06, 7.47791491e-05, 2.61943733e-05, 1.46652983e-05,\n",
            "       9.71751547e-07, 9.14941393e-06, 4.24017753e-06, 2.00375453e-05,\n",
            "       1.22340566e-06, 3.26520285e-06, 1.77263360e-06, 7.13514464e-06,\n",
            "       2.14270199e-06, 3.16077712e-05, 9.11709867e-05, 8.03330749e-06,\n",
            "       2.48495689e-06, 3.98135353e-06, 5.75539570e-06, 7.36606016e-05,\n",
            "       1.19796823e-05, 1.86726720e-06, 1.31231936e-05, 8.58548810e-05,\n",
            "       2.14696524e-06, 3.62202263e-06, 3.13518285e-06, 2.91630158e-06,\n",
            "       4.50655862e-05, 1.18667776e-05, 4.11669907e-06, 5.72099270e-05,\n",
            "       1.10620897e-06, 1.73971580e-06, 2.92322839e-05, 2.99614521e-06,\n",
            "       1.24158805e-05, 4.71808926e-06, 1.82273880e-06, 4.43332792e-05,\n",
            "       6.87960573e-06, 3.45445756e-06, 3.16124192e-06, 4.89025024e-06,\n",
            "       6.55432950e-06, 1.95445523e-06, 6.54539554e-06, 4.28117346e-06,\n",
            "       6.01820284e-05, 3.49802508e-06, 2.91561742e-06, 2.75082948e-06,\n",
            "       5.88564899e-06, 1.46197426e-05, 3.12274497e-05, 5.03784686e-05,\n",
            "       2.94580059e-06, 1.59822466e-05, 3.66924792e-06, 2.45612282e-05,\n",
            "       8.88554587e-06, 1.44737978e-05, 1.95513462e-06, 1.47885987e-06,\n",
            "       1.50821397e-05, 2.18034711e-06, 4.38985626e-06, 5.46989986e-06,\n",
            "       1.49093876e-06, 2.63629636e-06, 1.99080878e-05, 3.36602920e-06,\n",
            "       5.33812090e-05, 6.16668649e-06, 3.71898545e-06, 5.97715953e-05,\n",
            "       1.10694937e-05, 7.60490047e-06, 3.71956094e-06, 2.13267026e-06,\n",
            "       7.05946950e-05, 2.41473663e-06, 7.68756763e-06, 2.55319878e-06,\n",
            "       7.13965201e-05, 5.30088655e-05, 8.51609730e-06, 2.32917296e-06,\n",
            "       1.09717644e-06, 8.49690696e-06, 4.77351477e-06, 3.86417878e-06,\n",
            "       5.00667702e-05, 6.57722121e-05, 8.06905227e-05, 5.19353634e-05,\n",
            "       6.27604677e-05, 6.83566395e-06, 8.85431382e-06, 1.59140313e-06,\n",
            "       1.81492032e-05, 6.48577770e-05, 4.60039337e-05, 1.49497873e-05,\n",
            "       4.06382969e-06, 6.28897687e-05, 1.22567915e-04, 9.64133942e-05,\n",
            "       1.00632251e-05, 8.68257484e-05, 4.90924231e-06, 8.58815256e-05,\n",
            "       4.31723420e-05, 6.72237047e-06, 1.35385642e-06, 5.10025639e-05,\n",
            "       9.70722681e-07, 1.20901441e-05, 4.49330037e-05, 2.36692522e-05,\n",
            "       6.88905493e-05, 9.52132541e-06, 1.22913971e-05, 3.67958660e-06,\n",
            "       7.11090479e-06, 1.90343769e-06, 4.62273347e-05, 4.28081730e-05,\n",
            "       6.72916212e-05, 5.55441511e-06, 4.04648126e-05, 1.42147692e-05,\n",
            "       2.30422984e-06, 8.06007847e-06, 9.46085274e-05, 1.66953180e-06,\n",
            "       1.58678504e-05, 1.39513111e-04, 7.06492119e-06, 4.15631985e-06,\n",
            "       6.80388257e-06, 4.11312340e-06, 9.92224432e-06, 6.24127933e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 250, 'shape': array([192,   1,   1, 768], dtype=int32), 'shape_signature': array([192,   1,   1, 768], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([4.01702127e-05, 2.13385021e-04, 8.04339434e-05, 3.89030087e-04,\n",
            "       1.17328826e-04, 7.85101438e-05, 1.38891352e-04, 2.55674613e-03,\n",
            "       3.12976947e-04, 1.15748087e-03, 9.82032143e-05, 2.56283238e-04,\n",
            "       2.47662101e-04, 1.67382788e-03, 8.23044102e-05, 8.51546138e-05,\n",
            "       1.95590314e-03, 8.80936204e-05, 1.04778279e-04, 2.30506784e-03,\n",
            "       1.37329486e-03, 1.11385438e-04, 2.79976550e-04, 9.58573146e-05,\n",
            "       5.94335797e-05, 2.52201408e-03, 8.26108095e-04, 1.44677004e-03,\n",
            "       1.45367361e-04, 1.07986445e-03, 1.69116061e-03, 5.08284254e-04,\n",
            "       2.97840394e-04, 4.93287982e-04, 2.06821322e-04, 1.28423912e-03,\n",
            "       1.92529667e-04, 9.48859742e-05, 1.03725673e-04, 8.48806289e-04,\n",
            "       5.11733924e-05, 1.56693815e-04, 1.12531078e-03, 3.36229205e-05,\n",
            "       5.81455824e-04, 1.65871880e-03, 1.43850420e-03, 9.99608310e-05,\n",
            "       3.65208798e-05, 2.34040944e-03, 8.19821551e-04, 4.58988914e-04,\n",
            "       3.04135083e-05, 2.86354887e-04, 1.32707457e-04, 6.27127476e-04,\n",
            "       3.82896833e-05, 1.02193073e-04, 5.54792132e-05, 2.23313036e-04,\n",
            "       6.70614681e-05, 9.89248045e-04, 2.85343477e-03, 2.51423393e-04,\n",
            "       7.77732348e-05, 1.24606886e-04, 1.80130184e-04, 2.30540149e-03,\n",
            "       3.74935538e-04, 5.84410191e-05, 4.10724722e-04, 2.68705329e-03,\n",
            "       6.71949019e-05, 1.13360686e-04, 9.81237608e-05, 9.12732939e-05,\n",
            "       1.41044555e-03, 3.71401897e-04, 1.28842876e-04, 1.79053447e-03,\n",
            "       3.46217057e-05, 5.44489631e-05, 9.14900913e-04, 9.37722143e-05,\n",
            "       3.88587505e-04, 1.47664963e-04, 5.70473858e-05, 1.38752605e-03,\n",
            "       2.15315275e-04, 1.08116299e-04, 9.89393448e-05, 1.53053188e-04,\n",
            "       2.05134915e-04, 6.11697978e-05, 2.04855300e-04, 1.33990543e-04,\n",
            "       1.88355427e-03, 1.09479857e-04, 9.12518808e-05, 8.60944128e-05,\n",
            "       1.84206801e-04, 4.57563146e-04, 9.77344811e-04, 1.57672609e-03,\n",
            "       9.21965475e-05, 5.00206253e-04, 1.14838724e-04, 7.68707949e-04,\n",
            "       2.78096442e-04, 4.52995417e-04, 6.11910582e-05, 4.62847929e-05,\n",
            "       4.72035055e-04, 6.82396712e-05, 1.37392053e-04, 1.71194843e-04,\n",
            "       4.66628335e-05, 8.25098032e-05, 6.23075757e-04, 1.05348699e-04,\n",
            "       1.67070481e-03, 1.93002605e-04, 1.16395393e-04, 1.87070866e-03,\n",
            "       3.46448796e-04, 2.38015287e-04, 1.16413401e-04, 6.67475033e-05,\n",
            "       2.20944593e-03, 7.55755100e-05, 2.40602560e-04, 7.99090412e-05,\n",
            "       2.23454111e-03, 1.65905128e-03, 2.66533578e-04, 7.28975720e-05,\n",
            "       3.43390093e-05, 2.65932962e-04, 1.49399653e-04, 1.20939600e-04,\n",
            "       1.56697072e-03, 2.05851370e-03, 2.52542133e-03, 1.62545324e-03,\n",
            "       1.96425314e-03, 2.13940002e-04, 2.77118932e-04, 4.98071313e-05,\n",
            "       5.68026851e-04, 2.02989392e-03, 1.43981364e-03, 4.67892765e-04,\n",
            "       1.27188192e-04, 1.96829997e-03, 3.83608416e-03, 3.01750982e-03,\n",
            "       3.14954988e-04, 2.71743932e-03, 1.53647590e-04, 2.68788729e-03,\n",
            "       1.35119155e-03, 2.10394195e-04, 4.23724814e-05, 1.59625884e-03,\n",
            "       3.03813085e-05, 3.78392724e-04, 1.40629604e-03, 7.40791264e-04,\n",
            "       2.15611025e-03, 2.97994819e-04, 3.84691462e-04, 1.15162300e-04,\n",
            "       2.22554387e-04, 5.95730671e-05, 1.44680555e-03, 1.33979390e-03,\n",
            "       2.10606749e-03, 1.73839973e-04, 1.26645225e-03, 4.44888428e-04,\n",
            "       7.21169054e-05, 2.52261263e-04, 2.96102162e-03, 5.22523696e-05,\n",
            "       4.96625958e-04, 4.36642813e-03, 2.21115217e-04, 1.30082917e-04,\n",
            "       2.12945321e-04, 1.28730971e-04, 3.10542615e-04, 1.95337180e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 251, 'shape': array([384], dtype=int32), 'shape_signature': array([384], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.2444527e-03, 1.2787014e-03, 5.9404247e-04, 5.6993379e-04,\n",
            "       1.2790734e-03, 5.6178786e-04, 3.9378149e-04, 2.2323364e-03,\n",
            "       4.5029601e-04, 2.6917199e-03, 1.8298473e-04, 5.9218484e-04,\n",
            "       2.1410969e-04, 6.5605767e-05, 1.7446936e-04, 2.4834170e-03,\n",
            "       4.5189340e-04, 1.1673225e-03, 1.7639961e-03, 3.2218930e-04,\n",
            "       5.0138927e-04, 2.1928240e-04, 5.5267179e-04, 2.7231156e-04,\n",
            "       4.2093822e-04, 1.3095217e-03, 1.0855601e-03, 1.0928193e-03,\n",
            "       1.3536782e-03, 5.1618967e-04, 2.5332958e-04, 8.3730306e-04,\n",
            "       1.1178275e-03, 3.6496291e-04, 1.1029856e-03, 5.5575342e-04,\n",
            "       1.3185114e-03, 4.6195230e-04, 4.5771545e-04, 9.4654172e-04,\n",
            "       2.8775443e-04, 1.8075894e-03, 5.8699626e-04, 8.5268909e-04,\n",
            "       1.5836116e-03, 8.4467873e-04, 7.8947219e-04, 1.2409291e-03,\n",
            "       1.4795010e-03, 3.3867666e-03, 9.4891276e-04, 3.0210388e-03,\n",
            "       8.4889407e-04, 3.6724299e-04, 1.3553437e-03, 4.1233635e-04,\n",
            "       4.5362534e-04, 2.9711018e-04, 1.9751230e-04, 4.4892845e-04,\n",
            "       7.4580323e-04, 2.8339410e-03, 1.7401414e-03, 1.9267271e-03,\n",
            "       4.5516601e-04, 9.1126705e-05, 4.6047699e-04, 6.8303052e-04,\n",
            "       5.7489815e-04, 1.1559776e-03, 1.3715738e-03, 3.0457298e-04,\n",
            "       2.0639386e-03, 1.6563308e-03, 4.3430927e-04, 1.1218437e-03,\n",
            "       5.2763667e-04, 5.3410709e-04, 6.2873942e-04, 4.8257693e-04,\n",
            "       3.0146660e-03, 7.9628418e-04, 9.0134032e-05, 7.7253336e-04,\n",
            "       5.9246394e-04, 5.5913319e-04, 3.1705821e-04, 5.0367374e-04,\n",
            "       4.4035417e-04, 4.6747481e-04, 5.6886888e-04, 4.8521330e-04,\n",
            "       1.1325276e-03, 1.3257902e-03, 4.9538550e-04, 1.1410504e-03,\n",
            "       7.3956186e-04, 4.3591225e-04, 1.6529594e-03, 5.8213179e-04,\n",
            "       4.8248068e-04, 1.2095899e-03, 2.1918174e-03, 1.2411795e-03,\n",
            "       9.6059981e-04, 2.9043949e-04, 4.6315807e-04, 1.2465621e-03,\n",
            "       2.3314408e-03, 1.9754122e-03, 9.1051735e-04, 8.6178206e-04,\n",
            "       5.7870493e-04, 4.1459437e-04, 6.0232537e-04, 2.8120538e-03,\n",
            "       2.5838052e-04, 3.9865921e-04, 6.3992169e-04, 2.4975399e-03,\n",
            "       9.9118636e-04, 1.0369462e-03, 8.5675099e-04, 2.1391031e-03,\n",
            "       8.6573034e-04, 4.0945888e-04, 2.9354012e-03, 4.8003695e-04,\n",
            "       1.7304566e-04, 9.1951183e-04, 4.5228950e-04, 1.8817114e-04,\n",
            "       4.8271168e-04, 4.0604611e-04, 1.8896945e-03, 1.2139115e-03,\n",
            "       2.0044495e-03, 6.1430811e-04, 1.3660960e-03, 5.9286074e-04,\n",
            "       1.3520502e-03, 5.9325881e-03, 8.3914067e-04, 2.8982240e-04,\n",
            "       3.3277058e-04, 7.4710563e-04, 9.1086188e-04, 4.3500768e-04,\n",
            "       8.5609517e-04, 5.1584124e-04, 1.7184172e-03, 6.6952489e-04,\n",
            "       8.2874257e-04, 3.8848587e-04, 1.7843568e-03, 8.3640852e-04,\n",
            "       3.6928104e-04, 1.0004835e-03, 7.8242173e-04, 6.6378393e-04,\n",
            "       1.9033910e-03, 4.0074586e-04, 7.2951900e-04, 1.1433983e-03,\n",
            "       5.5404665e-04, 5.2450219e-04, 6.3322135e-04, 5.7622365e-04,\n",
            "       3.3759003e-04, 6.1689148e-04, 5.2884180e-04, 4.7838327e-04,\n",
            "       5.4501061e-04, 1.1675920e-03, 7.1447657e-04, 5.6065276e-04,\n",
            "       5.9479976e-04, 2.5723179e-04, 6.8585959e-04, 2.4824932e-03,\n",
            "       6.0595758e-03, 5.9130567e-04, 8.4409263e-04, 8.8826159e-04,\n",
            "       5.2900636e-04, 4.1894353e-04, 2.8656374e-04, 1.0299208e-03,\n",
            "       2.1753350e-04, 3.3350582e-03, 7.2480453e-04, 1.7109343e-04,\n",
            "       9.9367881e-04, 2.8183551e-03, 6.3960254e-04, 2.3782921e-03,\n",
            "       1.1790384e-03, 5.9288257e-04, 2.0554436e-04, 8.5773243e-04,\n",
            "       8.4592833e-04, 4.4185805e-04, 4.4469794e-04, 3.0437403e-04,\n",
            "       4.1538253e-04, 2.3469899e-03, 1.6885301e-03, 1.2115837e-03,\n",
            "       8.7159523e-04, 1.0800285e-03, 5.8504054e-04, 6.2815589e-04,\n",
            "       3.0134927e-04, 6.7408779e-04, 9.8939624e-04, 1.0686837e-03,\n",
            "       3.3873293e-04, 1.3218625e-03, 6.3218817e-04, 1.0880248e-03,\n",
            "       5.4823270e-04, 4.4526428e-04, 2.3951120e-04, 7.4957998e-04,\n",
            "       1.4070862e-03, 6.0413702e-04, 5.9168687e-04, 1.4430867e-03,\n",
            "       2.9677461e-04, 9.0931478e-04, 1.0830605e-03, 3.8450488e-04,\n",
            "       7.7215600e-04, 7.3072274e-04, 4.0038230e-04, 4.7571908e-04,\n",
            "       1.3321824e-03, 6.9187855e-04, 1.1405762e-03, 3.8242929e-03,\n",
            "       1.9671109e-03, 7.5076951e-04, 9.7495853e-04, 1.3926654e-04,\n",
            "       1.7364798e-03, 2.3115694e-03, 1.5988788e-03, 7.8520697e-04,\n",
            "       2.4977897e-04, 1.2577211e-03, 1.6178173e-03, 7.9327344e-04,\n",
            "       6.3004310e-04, 5.6531013e-04, 5.6027563e-04, 3.7164273e-04,\n",
            "       5.8314146e-04, 7.1573275e-04, 1.2121802e-03, 3.8880704e-03,\n",
            "       4.8737958e-04, 2.8106966e-04, 1.5154100e-03, 1.5631020e-03,\n",
            "       8.5308199e-04, 4.1590682e-03, 2.0989066e-04, 2.3754430e-03,\n",
            "       1.2877481e-03, 9.9412049e-04, 5.1090622e-04, 2.5676886e-04,\n",
            "       4.8871082e-04, 3.6845607e-04, 1.8969334e-03, 5.7229272e-04,\n",
            "       1.2328909e-03, 2.1796634e-03, 3.1268821e-04, 6.0151774e-04,\n",
            "       8.7844644e-04, 3.4043151e-03, 3.3790953e-03, 2.1180764e-03,\n",
            "       6.4485898e-04, 1.0652109e-03, 4.3653997e-04, 3.2191913e-04,\n",
            "       2.2906977e-04, 3.1542385e-04, 7.8736659e-04, 2.7316741e-03,\n",
            "       1.7048963e-03, 2.5429027e-03, 6.0139876e-04, 1.8074890e-04,\n",
            "       1.1238249e-03, 5.5531511e-04, 6.6393835e-04, 1.0747180e-03,\n",
            "       2.1921760e-04, 1.0655196e-03, 1.0733181e-03, 4.4872361e-04,\n",
            "       2.5694424e-03, 2.9115443e-04, 1.2057616e-03, 1.6456218e-04,\n",
            "       1.7499964e-03, 5.7635055e-04, 7.8708614e-04, 4.0840980e-04,\n",
            "       4.6686956e-04, 1.6289197e-03, 7.8006845e-04, 8.2833687e-04,\n",
            "       8.8829978e-04, 1.1764029e-03, 1.5174975e-03, 6.0114212e-04,\n",
            "       1.3732533e-03, 1.0001238e-03, 4.3697574e-04, 2.0313135e-03,\n",
            "       5.9416430e-04, 2.3574270e-03, 2.1709616e-03, 1.9027626e-03,\n",
            "       3.8624494e-04, 1.5775870e-03, 7.8794215e-04, 3.4576203e-03,\n",
            "       1.0421145e-03, 8.2865107e-04, 6.4020633e-04, 6.4397597e-04,\n",
            "       1.5252329e-04, 1.6463407e-04, 2.6158819e-03, 1.1667321e-03,\n",
            "       8.3380210e-04, 1.5261779e-04, 7.8375735e-05, 8.2462427e-04,\n",
            "       2.3296909e-04, 2.1800371e-04, 6.3299859e-04, 1.1098130e-03,\n",
            "       9.1923721e-04, 5.5379700e-04, 1.5279342e-03, 4.1809466e-04,\n",
            "       5.8582303e-04, 3.5726372e-04, 7.4438483e-04, 5.6917244e-04,\n",
            "       3.2807872e-04, 6.6137634e-04, 5.7939626e-04, 1.3678716e-03,\n",
            "       6.7690556e-04, 2.7457036e-03, 9.9185749e-04, 3.3419169e-03,\n",
            "       4.0901068e-04, 1.1709253e-04, 1.7169156e-03, 8.3192094e-04,\n",
            "       8.0245937e-04, 9.5937616e-04, 5.7687919e-04, 1.0375826e-03,\n",
            "       3.2946843e-04, 6.6094851e-04, 8.0281502e-04, 1.3464051e-03,\n",
            "       2.3780311e-03, 8.6457806e-04, 1.0993015e-03, 1.1557563e-03,\n",
            "       5.9656345e-04, 2.6658573e-03, 3.6724197e-04, 6.7220279e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block4_layer1/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer1/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 252, 'shape': array([  1,   5,   5, 384], dtype=int32), 'shape_signature': array([  1,   5,   5, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.02458999, 0.02526673, 0.01173809, 0.01126171, 0.02527408,\n",
            "       0.01110075, 0.007781  , 0.04411025, 0.00889771, 0.05318753,\n",
            "       0.00361572, 0.01170138, 0.00423074, 0.00129635, 0.00344746,\n",
            "       0.04907153, 0.00892927, 0.02306592, 0.034856  , 0.00636636,\n",
            "       0.00990729, 0.00433295, 0.01092062, 0.00538079, 0.0083176 ,\n",
            "       0.02587573, 0.02145032, 0.02159376, 0.02674825, 0.01019974,\n",
            "       0.00500571, 0.01654484, 0.02208791, 0.00721155, 0.02179464,\n",
            "       0.01098151, 0.02605337, 0.00912803, 0.00904431, 0.01870336,\n",
            "       0.00568594, 0.03571739, 0.01159886, 0.01684886, 0.03129166,\n",
            "       0.01669058, 0.01559972, 0.02452036, 0.02923447, 0.06692143,\n",
            "       0.01875021, 0.05969476, 0.01677388, 0.0072566 , 0.02678116,\n",
            "       0.00814763, 0.00896349, 0.0058708 , 0.00390278, 0.00887068,\n",
            "       0.01473683, 0.05599777, 0.03438464, 0.03807151, 0.00899393,\n",
            "       0.00180063, 0.00909888, 0.01349647, 0.0113598 , 0.02284175,\n",
            "       0.02710186, 0.00601826, 0.04078277, 0.03272857, 0.00858181,\n",
            "       0.02216727, 0.01042593, 0.01055379, 0.01242369, 0.00953557,\n",
            "       0.05956884, 0.01573432, 0.00178102, 0.01526501, 0.0117069 ,\n",
            "       0.01104829, 0.00626497, 0.00995243, 0.00870126, 0.00923715,\n",
            "       0.01124067, 0.00958766, 0.02237838, 0.02619719, 0.00978866,\n",
            "       0.02254679, 0.01461351, 0.00861349, 0.03266195, 0.01150274,\n",
            "       0.00953366, 0.02390111, 0.04330961, 0.02452531, 0.01898115,\n",
            "       0.00573899, 0.00915186, 0.02463167, 0.04606853, 0.03903351,\n",
            "       0.01799153, 0.01702854, 0.01143502, 0.00819225, 0.01190176,\n",
            "       0.05556528, 0.00510552, 0.00787738, 0.01264465, 0.04935059,\n",
            "       0.01958553, 0.02048973, 0.01692913, 0.04226799, 0.01710656,\n",
            "       0.00809078, 0.05800259, 0.00948538, 0.00341933, 0.01816926,\n",
            "       0.0089371 , 0.0037182 , 0.00953823, 0.00802334, 0.03733976,\n",
            "       0.0239865 , 0.03960728, 0.01213853, 0.02699362, 0.01171474,\n",
            "       0.02671608, 0.11722604, 0.01658115, 0.0057268 , 0.00657544,\n",
            "       0.01476257, 0.01799834, 0.00859561, 0.01691617, 0.01019286,\n",
            "       0.03395537, 0.0132296 , 0.01637569, 0.00767636, 0.03525832,\n",
            "       0.01652716, 0.00729688, 0.01976923, 0.0154604 , 0.01311616,\n",
            "       0.0376104 , 0.00791861, 0.01441506, 0.02259319, 0.01094778,\n",
            "       0.010364  , 0.01251225, 0.01138599, 0.00667067, 0.01218958,\n",
            "       0.01044974, 0.0094527 , 0.01076923, 0.02307124, 0.01411783,\n",
            "       0.01107832, 0.01175305, 0.00508282, 0.01355237, 0.04905327,\n",
            "       0.11973528, 0.01168401, 0.016679  , 0.01755176, 0.010453  ,\n",
            "       0.00827819, 0.00566241, 0.02035091, 0.00429839, 0.06589969,\n",
            "       0.01432191, 0.00338075, 0.01963478, 0.0556898 , 0.01263834,\n",
            "       0.04699429, 0.02329742, 0.01171517, 0.00406149, 0.01694852,\n",
            "       0.01671527, 0.00873097, 0.00878709, 0.00601433, 0.00820783,\n",
            "       0.04637577, 0.03336481, 0.02394051, 0.01722244, 0.02134102,\n",
            "       0.01156021, 0.01241216, 0.00595457, 0.01331976, 0.01955015,\n",
            "       0.02111685, 0.00669325, 0.02611958, 0.01249184, 0.02149902,\n",
            "       0.0108329 , 0.00879828, 0.00473266, 0.01481146, 0.02780357,\n",
            "       0.01193755, 0.01169154, 0.02851493, 0.00586417, 0.01796777,\n",
            "       0.02140093, 0.00759769, 0.01525756, 0.01443885, 0.00791143,\n",
            "       0.00940006, 0.0263235 , 0.0136713 , 0.02253742, 0.07556681,\n",
            "       0.03886948, 0.01483497, 0.01926487, 0.00275186, 0.03431229,\n",
            "       0.04567587, 0.03159333, 0.01551544, 0.00493555, 0.02485217,\n",
            "       0.03196755, 0.01567483, 0.01244945, 0.01117035, 0.01107087,\n",
            "       0.00734354, 0.01152269, 0.01414265, 0.02395229, 0.07682703,\n",
            "       0.00963046, 0.00555385, 0.02994402, 0.0308864 , 0.01685663,\n",
            "       0.08218186, 0.00414737, 0.04693799, 0.02544549, 0.0196435 ,\n",
            "       0.01009534, 0.00507367, 0.00965677, 0.00728057, 0.0374828 ,\n",
            "       0.01130832, 0.02436153, 0.04306945, 0.00617862, 0.0118858 ,\n",
            "       0.01735782, 0.06726818, 0.06676985, 0.04185252, 0.01274221,\n",
            "       0.02104823, 0.00862589, 0.00636102, 0.00452635, 0.00623267,\n",
            "       0.01555811, 0.05397701, 0.03368821, 0.05024694, 0.01188345,\n",
            "       0.00357154, 0.02220642, 0.01097285, 0.01311921, 0.02123608,\n",
            "       0.00433167, 0.02105433, 0.02120842, 0.00886664, 0.05077136,\n",
            "       0.00575312, 0.02382546, 0.0032517 , 0.03457937, 0.0113885 ,\n",
            "       0.01555257, 0.00807005, 0.00922519, 0.03218693, 0.0154139 ,\n",
            "       0.01636767, 0.01755252, 0.02324535, 0.02998526, 0.01187838,\n",
            "       0.02713505, 0.01976213, 0.0086345 , 0.04013811, 0.0117405 ,\n",
            "       0.04658201, 0.04289751, 0.03759798, 0.00763208, 0.03117261,\n",
            "       0.01556948, 0.06832147, 0.02059185, 0.01637388, 0.01265027,\n",
            "       0.01272476, 0.00301381, 0.00325312, 0.05168899, 0.02305425,\n",
            "       0.01647566, 0.00301568, 0.00154868, 0.01629431, 0.00460339,\n",
            "       0.00430768, 0.01250785, 0.02192955, 0.01816383, 0.01094285,\n",
            "       0.03019149, 0.00826142, 0.01157568, 0.00705942, 0.01470881,\n",
            "       0.01124667, 0.00648273, 0.01306859, 0.01144869, 0.02702871,\n",
            "       0.01337544, 0.05425422, 0.01959879, 0.06603521, 0.00808192,\n",
            "       0.00231371, 0.0339257 , 0.01643849, 0.01585634, 0.01895697,\n",
            "       0.01139895, 0.0205023 , 0.00651019, 0.01306013, 0.01586337,\n",
            "       0.02660454, 0.04698914, 0.01708379, 0.02172185, 0.02283738,\n",
            "       0.0117879 , 0.05267649, 0.00725658, 0.01328251], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 253, 'shape': array([384], dtype=int32), 'shape_signature': array([384], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([4.60571500e-05, 1.00670266e-04, 1.30144443e-04, 1.28677799e-04,\n",
            "       3.57316021e-05, 1.12948474e-04, 8.60424043e-05, 2.34409345e-05,\n",
            "       1.15148207e-04, 2.85171373e-05, 1.51175394e-04, 1.27673760e-04,\n",
            "       1.71185762e-04, 1.39385564e-04, 1.38478077e-04, 3.10592477e-05,\n",
            "       1.21558602e-04, 5.31918267e-05, 2.55147061e-05, 6.72112146e-05,\n",
            "       1.24147540e-04, 1.07740409e-04, 1.58324896e-04, 7.72110507e-05,\n",
            "       8.03036746e-05, 5.21744441e-05, 3.01433647e-05, 4.91062165e-05,\n",
            "       6.59192301e-05, 9.90332337e-05, 1.16619151e-04, 1.15346687e-04,\n",
            "       6.68897483e-05, 1.29897191e-04, 4.58879840e-05, 8.34571838e-05,\n",
            "       4.86490389e-05, 9.17075231e-05, 1.10861940e-04, 9.74451686e-05,\n",
            "       1.49370258e-04, 2.16415337e-05, 9.98595933e-05, 7.81474519e-05,\n",
            "       3.67867869e-05, 3.12392694e-05, 1.05649837e-04, 1.93476313e-04,\n",
            "       5.04944946e-05, 5.30605030e-05, 3.16596052e-05, 1.74096986e-05,\n",
            "       1.22222162e-04, 1.02966878e-04, 2.30349306e-05, 1.22243306e-04,\n",
            "       1.10359775e-04, 7.18068623e-05, 1.31819790e-04, 5.78459258e-05,\n",
            "       1.28605418e-04, 3.14228855e-05, 4.17740885e-05, 2.84740327e-05,\n",
            "       1.25625505e-04, 1.59210569e-04, 1.16182091e-04, 1.66731610e-04,\n",
            "       4.61582094e-05, 3.33024145e-05, 7.05011771e-05, 9.71632617e-05,\n",
            "       2.10626094e-05, 1.95074281e-05, 6.90012748e-05, 6.21606741e-05,\n",
            "       7.11503817e-05, 1.14832284e-04, 1.42368925e-04, 1.54121401e-04,\n",
            "       4.58433133e-05, 5.96834652e-05, 3.26579728e-04, 1.17423355e-04,\n",
            "       1.20669640e-04, 7.93372528e-05, 1.18676173e-04, 1.45019876e-04,\n",
            "       9.79980468e-05, 1.10168636e-04, 2.06271216e-05, 1.48632796e-04,\n",
            "       5.54212093e-05, 3.80402998e-05, 1.10280809e-04, 5.83640103e-05,\n",
            "       1.11755340e-04, 9.11363531e-05, 4.57592214e-05, 8.98970029e-05,\n",
            "       1.72276792e-04, 8.34573148e-05, 9.09174050e-05, 1.03313025e-04,\n",
            "       6.39572609e-05, 9.46324653e-05, 1.08502136e-04, 3.48778121e-05,\n",
            "       7.53134882e-05, 5.60020017e-05, 4.02462974e-05, 1.65514866e-04,\n",
            "       9.73305578e-05, 1.48865263e-04, 1.22555255e-04, 2.37259410e-05,\n",
            "       1.67957900e-04, 1.02567064e-04, 1.05459963e-04, 2.43288105e-05,\n",
            "       2.53954167e-05, 1.09906541e-04, 7.67528836e-05, 2.75421298e-05,\n",
            "       8.65819529e-05, 1.53741086e-04, 2.49706554e-05, 1.19696066e-04,\n",
            "       1.20369448e-04, 5.57846906e-05, 1.03315782e-04, 1.78413233e-04,\n",
            "       9.17820289e-05, 1.54199355e-04, 1.69110554e-05, 5.81719214e-05,\n",
            "       3.07305090e-05, 1.20788733e-04, 6.59998550e-05, 1.28764965e-04,\n",
            "       2.85242586e-05, 1.49054476e-05, 6.01048559e-05, 1.25767401e-04,\n",
            "       1.26206083e-04, 1.32355563e-04, 1.10820438e-04, 8.68738207e-05,\n",
            "       1.03660313e-04, 1.29697408e-04, 6.43112871e-05, 8.90753945e-05,\n",
            "       8.96696947e-05, 1.31550725e-04, 4.09949716e-05, 3.14548997e-05,\n",
            "       6.83833932e-05, 4.93415719e-05, 1.44158243e-04, 1.29773805e-04,\n",
            "       2.15896653e-05, 1.03271232e-04, 1.25702965e-04, 1.11886977e-04,\n",
            "       7.81002964e-05, 7.91179118e-05, 8.31740399e-05, 1.10041794e-04,\n",
            "       1.12840571e-04, 1.73772642e-04, 1.39932206e-04, 1.30762011e-04,\n",
            "       6.80443700e-05, 1.64081328e-04, 1.28339641e-04, 1.17017451e-04,\n",
            "       1.17714262e-04, 1.04783176e-04, 9.32617986e-05, 1.69732848e-05,\n",
            "       3.48481553e-05, 1.22769939e-04, 7.76209636e-05, 6.74963958e-05,\n",
            "       7.49293176e-05, 9.51052789e-05, 1.06713662e-04, 4.73512227e-05,\n",
            "       1.00399171e-04, 2.40564314e-05, 1.24645827e-04, 1.79537092e-04,\n",
            "       4.50197076e-05, 2.89645541e-05, 7.41391341e-05, 1.18360949e-05,\n",
            "       1.03158556e-04, 6.90446177e-05, 9.35964781e-05, 1.42220364e-04,\n",
            "       2.84796624e-05, 9.16041317e-05, 1.12825255e-04, 9.16232530e-05,\n",
            "       1.55790185e-04, 2.25587755e-05, 3.23679596e-05, 9.53834533e-05,\n",
            "       2.41165471e-05, 6.70467998e-05, 1.09650449e-04, 1.24238621e-04,\n",
            "       1.22447120e-04, 7.51959524e-05, 2.60572979e-05, 5.50873483e-05,\n",
            "       1.31713852e-04, 7.27911902e-05, 9.11597599e-05, 2.48665347e-05,\n",
            "       4.05678657e-05, 1.32155517e-04, 1.40664139e-04, 6.31449439e-05,\n",
            "       7.34940331e-05, 1.04836836e-04, 6.42865343e-05, 7.67183083e-05,\n",
            "       1.60042837e-04, 7.29237363e-05, 4.31817862e-05, 9.82323181e-05,\n",
            "       5.45313305e-05, 7.12163674e-05, 1.24177226e-04, 1.70404630e-04,\n",
            "       2.33429873e-05, 1.38951102e-04, 4.49119616e-05, 2.74259946e-05,\n",
            "       1.95985176e-05, 1.28569925e-04, 6.41528022e-05, 1.09609493e-04,\n",
            "       5.90099771e-05, 4.44193138e-05, 3.86130741e-05, 8.79776489e-05,\n",
            "       1.20430210e-04, 2.56111816e-05, 3.66648346e-05, 7.95657470e-05,\n",
            "       1.01992351e-04, 1.52910870e-04, 7.12633264e-05, 1.55092435e-04,\n",
            "       6.49079811e-05, 1.39578537e-04, 2.56935036e-05, 3.40919178e-05,\n",
            "       1.10550260e-04, 4.05880310e-05, 3.33273492e-05, 6.04764755e-05,\n",
            "       2.09963673e-05, 1.85316367e-05, 1.28700136e-04, 3.59170335e-05,\n",
            "       2.93749399e-05, 5.73893230e-05, 1.70239597e-04, 6.88919827e-05,\n",
            "       1.44705860e-04, 1.26579384e-04, 2.28316385e-05, 1.65520905e-04,\n",
            "       7.75842200e-05, 5.12636798e-05, 2.09581412e-04, 1.00287798e-04,\n",
            "       1.36086033e-04, 5.74778533e-05, 2.52894679e-05, 2.84280450e-05,\n",
            "       6.46893750e-05, 2.00903905e-05, 1.31673412e-04, 8.53262172e-05,\n",
            "       1.31422072e-04, 1.48907566e-04, 1.23222082e-04, 3.49527327e-05,\n",
            "       2.41857288e-05, 1.77970451e-05, 8.37517946e-05, 1.58232651e-04,\n",
            "       3.97372060e-05, 4.36342089e-05, 1.25505321e-04, 9.31177710e-05,\n",
            "       1.27093779e-04, 7.55076035e-05, 6.18657141e-05, 7.32087938e-05,\n",
            "       1.15027078e-05, 1.51240121e-04, 4.36515365e-05, 2.06474986e-04,\n",
            "       4.14781498e-05, 1.04630286e-04, 5.56895102e-05, 1.13714108e-04,\n",
            "       1.52966080e-04, 2.29172620e-05, 1.05839601e-04, 2.59410590e-05,\n",
            "       8.96274141e-05, 7.08076623e-05, 2.45100655e-05, 1.26262414e-04,\n",
            "       2.11876595e-05, 1.55040252e-04, 1.06640306e-04, 5.14105996e-05,\n",
            "       6.68326320e-05, 3.57224890e-05, 3.00081192e-05, 5.18747547e-05,\n",
            "       1.35310518e-04, 5.97205435e-05, 1.21929610e-04, 2.72344205e-05,\n",
            "       8.35562314e-05, 1.02680984e-04, 1.16961346e-04, 8.44319948e-05,\n",
            "       1.47188563e-04, 1.40374497e-04, 6.40370126e-05, 2.72307807e-05,\n",
            "       1.20590397e-04, 1.33920272e-04, 1.48760184e-04, 6.04675151e-05,\n",
            "       1.07170410e-04, 1.23552891e-04, 1.38088217e-04, 4.73207547e-05,\n",
            "       5.56558334e-05, 1.02117490e-04, 3.91475260e-05, 1.21988356e-04,\n",
            "       9.95096998e-05, 9.39371312e-05, 9.74642826e-05, 7.01735771e-05,\n",
            "       2.52737111e-04, 1.25219856e-04, 1.00944926e-04, 7.02205216e-05,\n",
            "       1.76783564e-04, 2.57499451e-05, 3.50820083e-05, 4.93854568e-05,\n",
            "       9.62723061e-05, 1.52815090e-04, 2.12755040e-05, 1.07903339e-04,\n",
            "       4.26424267e-05, 2.40543795e-05, 1.18453936e-04, 1.45560902e-04,\n",
            "       9.28956943e-05, 1.03020422e-04, 1.51768487e-04, 6.50142538e-05,\n",
            "       2.76724386e-05, 8.61161679e-05, 8.06371318e-05, 5.35696563e-05,\n",
            "       1.13997768e-04, 9.88379543e-06, 7.42390621e-05, 1.65970618e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 254, 'shape': array([384,   1,   1, 144], dtype=int32), 'shape_signature': array([384,   1,   1, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.32846733e-04, 2.90372205e-04, 3.75387201e-04, 3.71156842e-04,\n",
            "       1.03063838e-04, 3.25787347e-04, 2.48179771e-04, 6.76127747e-05,\n",
            "       3.32132215e-04, 8.22545189e-05, 4.36048635e-04, 3.68260778e-04,\n",
            "       4.93766333e-04, 4.02042177e-04, 3.99424636e-04, 8.95869525e-05,\n",
            "       3.50622286e-04, 1.53425921e-04, 7.35943395e-05, 1.93863292e-04,\n",
            "       3.58089805e-04, 3.10765259e-04, 4.56670590e-04, 2.22706702e-04,\n",
            "       2.31627040e-04, 1.50491396e-04, 8.69451906e-05, 1.41641431e-04,\n",
            "       1.90136707e-04, 2.85650371e-04, 3.36375000e-04, 3.32704716e-04,\n",
            "       1.92936059e-04, 3.74674040e-04, 1.32358793e-04, 2.40722991e-04,\n",
            "       1.40322751e-04, 2.64520175e-04, 3.19768966e-04, 2.81069777e-04,\n",
            "       4.30841930e-04, 6.24226013e-05, 2.88033916e-04, 2.25407653e-04,\n",
            "       1.06107400e-04, 9.01062012e-05, 3.04735237e-04, 5.58060943e-04,\n",
            "       1.45645768e-04, 1.53047135e-04, 9.13186159e-05, 5.02163421e-05,\n",
            "       3.52536241e-04, 2.96996528e-04, 6.64417021e-05, 3.52597242e-04,\n",
            "       3.18320526e-04, 2.07118923e-04, 3.80219572e-04, 1.66850150e-04,\n",
            "       3.70948052e-04, 9.06358255e-05, 1.20492718e-04, 8.21301874e-05,\n",
            "       3.62352846e-04, 4.59225208e-04, 3.35114339e-04, 4.80918825e-04,\n",
            "       1.33138237e-04, 9.60571197e-05, 2.03352814e-04, 2.80256645e-04,\n",
            "       6.07527581e-05, 5.62670102e-05, 1.99026515e-04, 1.79295559e-04,\n",
            "       2.05225384e-04, 3.31220974e-04, 4.10647364e-04, 4.44546080e-04,\n",
            "       1.32229950e-04, 1.72150336e-04, 9.41983017e-04, 3.38694634e-04,\n",
            "       3.48058180e-04, 2.28839504e-04, 3.42308253e-04, 4.18293756e-04,\n",
            "       2.82664492e-04, 3.17769212e-04, 5.94966405e-05, 4.28714789e-04,\n",
            "       1.59856325e-04, 1.09723020e-04, 3.18092760e-04, 1.68344515e-04,\n",
            "       3.22345877e-04, 2.62872694e-04, 1.31987399e-04, 2.59297929e-04,\n",
            "       4.96913271e-04, 2.40723355e-04, 2.62241170e-04, 2.97994964e-04,\n",
            "       1.84477612e-04, 2.72956851e-04, 3.12962366e-04, 1.00601173e-04,\n",
            "       2.17233406e-04, 1.61531556e-04, 1.16085983e-04, 4.77409252e-04,\n",
            "       2.80739187e-04, 4.29385342e-04, 3.53497046e-04, 6.84348415e-05,\n",
            "       4.84455901e-04, 2.95843318e-04, 3.04187561e-04, 7.01737517e-05,\n",
            "       7.32502594e-05, 3.17013211e-04, 2.21385184e-04, 7.94422158e-05,\n",
            "       2.49736040e-04, 4.43449098e-04, 7.20250828e-05, 3.45250010e-04,\n",
            "       3.47192312e-04, 1.60904747e-04, 2.98002909e-04, 5.14613173e-04,\n",
            "       2.64735078e-04, 4.44770907e-04, 4.87780635e-05, 1.67790451e-04,\n",
            "       8.86387425e-05, 3.48401692e-04, 1.90369246e-04, 3.71408270e-04,\n",
            "       8.22750590e-05, 4.29931097e-05, 1.73365785e-04, 3.62762104e-04,\n",
            "       3.64027423e-04, 3.81764927e-04, 3.19649262e-04, 2.50577898e-04,\n",
            "       2.98996660e-04, 3.74097785e-04, 1.85498764e-04, 2.56928091e-04,\n",
            "       2.58642278e-04, 3.79443460e-04, 1.18245443e-04, 9.07281647e-05,\n",
            "       1.97244299e-04, 1.42320292e-04, 4.15808434e-04, 3.74318159e-04,\n",
            "       6.22729931e-05, 2.97874416e-04, 3.62576247e-04, 3.22725566e-04,\n",
            "       2.25271637e-04, 2.28206845e-04, 2.39906280e-04, 3.17403348e-04,\n",
            "       3.25476110e-04, 5.01227914e-04, 4.03618906e-04, 3.77168501e-04,\n",
            "       1.96266439e-04, 4.73274384e-04, 3.70181457e-04, 3.37523845e-04,\n",
            "       3.39533726e-04, 3.02235450e-04, 2.69003300e-04, 4.89575577e-05,\n",
            "       1.00515637e-04, 3.54116259e-04, 2.23889045e-04, 1.94685868e-04,\n",
            "       2.16125292e-04, 2.74320628e-04, 3.07803712e-04, 1.36579343e-04,\n",
            "       2.89590273e-04, 6.93881084e-05, 3.59527068e-04, 5.17854816e-04,\n",
            "       1.29854350e-04, 8.35450410e-05, 2.13846113e-04, 3.41399027e-05,\n",
            "       2.97549414e-04, 1.99151531e-04, 2.69968645e-04, 4.10218840e-04,\n",
            "       8.21464273e-05, 2.64221948e-04, 3.25431931e-04, 2.64277100e-04,\n",
            "       4.49359504e-04, 6.50682850e-05, 9.33617848e-05, 2.75122991e-04,\n",
            "       6.95615017e-05, 1.93389045e-04, 3.16274556e-04, 3.58352496e-04,\n",
            "       3.53185111e-04, 2.16894376e-04, 7.51593834e-05, 1.58893337e-04,\n",
            "       3.79913981e-04, 2.09958103e-04, 2.62940215e-04, 7.17247603e-05,\n",
            "       1.17013507e-04, 3.81187914e-04, 4.05730098e-04, 1.82134580e-04,\n",
            "       2.11985374e-04, 3.02390225e-04, 1.85427372e-04, 2.21285445e-04,\n",
            "       4.61625808e-04, 2.10340426e-04, 1.24553073e-04, 2.83340225e-04,\n",
            "       1.57289571e-04, 2.05415708e-04, 3.58175428e-04, 4.91513230e-04,\n",
            "       6.73302566e-05, 4.00789024e-04, 1.29543565e-04, 7.91072380e-05,\n",
            "       5.65297487e-05, 3.70845664e-04, 1.85041630e-04, 3.16156424e-04,\n",
            "       1.70207728e-04, 1.28122585e-04, 1.11375128e-04, 2.53761769e-04,\n",
            "       3.47367575e-04, 7.38726085e-05, 1.05755651e-04, 2.29498575e-04,\n",
            "       2.94185622e-04, 4.41054435e-04, 2.05551158e-04, 4.47346916e-04,\n",
            "       1.87219877e-04, 4.02598787e-04, 7.41100594e-05, 9.83343489e-05,\n",
            "       3.18869948e-04, 1.17071671e-04, 9.61290425e-05, 1.74437679e-04,\n",
            "       6.05616915e-05, 5.34524515e-05, 3.71221278e-04, 1.03598701e-04,\n",
            "       8.47287520e-05, 1.65533129e-04, 4.91037208e-04, 1.98711277e-04,\n",
            "       4.17387986e-04, 3.65104177e-04, 6.58553254e-05, 4.77426685e-04,\n",
            "       2.23783078e-04, 1.47864397e-04, 6.04514324e-04, 2.89269025e-04,\n",
            "       3.92525078e-04, 1.65788486e-04, 7.29446620e-05, 8.19975394e-05,\n",
            "       1.86589328e-04, 5.79485022e-05, 3.79797362e-04, 2.46114010e-04,\n",
            "       3.79072386e-04, 4.29507345e-04, 3.55420430e-04, 1.00817277e-04,\n",
            "       6.97610521e-05, 5.13336017e-05, 2.41572765e-04, 4.56404523e-04,\n",
            "       1.14617556e-04, 1.25858031e-04, 3.62006191e-04, 2.68587872e-04,\n",
            "       3.66587919e-04, 2.17793306e-04, 1.78444781e-04, 2.11162638e-04,\n",
            "       3.31782830e-05, 4.36235365e-04, 1.25908016e-04, 5.95554186e-04,\n",
            "       1.19639124e-04, 3.01794440e-04, 1.60630210e-04, 3.27995716e-04,\n",
            "       4.41213662e-04, 6.61023005e-05, 3.05282592e-04, 7.48241073e-05,\n",
            "       2.58520333e-04, 2.04236843e-04, 7.06965657e-05, 3.64189938e-04,\n",
            "       6.11134528e-05, 4.47196420e-04, 3.07592127e-04, 1.48288163e-04,\n",
            "       1.92771302e-04, 1.03037557e-04, 8.65550901e-05, 1.49626969e-04,\n",
            "       3.90288158e-04, 1.72257278e-04, 3.51692433e-04, 7.85546654e-05,\n",
            "       2.41008674e-04, 2.96171900e-04, 3.37362027e-04, 2.43534727e-04,\n",
            "       4.24549071e-04, 4.04894672e-04, 1.84707649e-04, 7.85441662e-05,\n",
            "       3.47829628e-04, 3.86278174e-04, 4.29082225e-04, 1.74411834e-04,\n",
            "       3.09121155e-04, 3.56374600e-04, 3.98300122e-04, 1.36491464e-04,\n",
            "       1.60533076e-04, 2.94546568e-04, 1.12916692e-04, 3.51861876e-04,\n",
            "       2.87024683e-04, 2.70951219e-04, 2.81124900e-04, 2.02407900e-04,\n",
            "       7.28992105e-04, 3.61182785e-04, 2.91164441e-04, 2.02543291e-04,\n",
            "       5.09912556e-04, 7.42728589e-05, 1.01190155e-04, 1.42446865e-04,\n",
            "       2.77686777e-04, 4.40778153e-04, 6.13668308e-05, 3.11235199e-04,\n",
            "       1.22997342e-04, 6.93821858e-05, 3.41667241e-04, 4.19854274e-04,\n",
            "       2.67947325e-04, 2.97150982e-04, 4.37759358e-04, 1.87526399e-04,\n",
            "       7.98180772e-05, 2.48392520e-04, 2.32588864e-04, 1.54515728e-04,\n",
            "       3.28813912e-04, 2.85087117e-05, 2.14134328e-04, 4.78723843e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/rezero/mul', 'index': 255, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.007206270005553961, -128), 'quantization_parameters': {'scales': array([0.00720627], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 256, 'shape': array([144], dtype=int32), 'shape_signature': array([144], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00027623, 0.0003814 , 0.00047457, 0.00038345, 0.00025161,\n",
            "       0.00021868, 0.00027214, 0.0002631 , 0.00040268, 0.00026985,\n",
            "       0.000405  , 0.00044026, 0.00038447, 0.00041548, 0.000393  ,\n",
            "       0.00024177, 0.00029956, 0.00034592, 0.00038696, 0.00029397,\n",
            "       0.00029012, 0.00027205, 0.00039493, 0.00028123, 0.00028098,\n",
            "       0.00037849, 0.00031327, 0.00022929, 0.00038082, 0.00043188,\n",
            "       0.00032396, 0.0002886 , 0.00036695, 0.00032937, 0.00042345,\n",
            "       0.00026107, 0.00031417, 0.00023275, 0.00041829, 0.00035719,\n",
            "       0.00036685, 0.00040073, 0.00040758, 0.00025453, 0.00048166,\n",
            "       0.00027702, 0.00034793, 0.00033089, 0.00031972, 0.00033374,\n",
            "       0.00037211, 0.00026389, 0.00025545, 0.00053952, 0.00027905,\n",
            "       0.00020269, 0.00041472, 0.00050185, 0.00026748, 0.00040228,\n",
            "       0.0003381 , 0.00033949, 0.00033581, 0.00034841, 0.00037663,\n",
            "       0.00043717, 0.00020941, 0.0003658 , 0.00037288, 0.00036628,\n",
            "       0.00032739, 0.00034755, 0.00046888, 0.00029631, 0.00033303,\n",
            "       0.00055713, 0.00035908, 0.00047543, 0.00041258, 0.00049168,\n",
            "       0.00037962, 0.0004119 , 0.00035072, 0.00040536, 0.00033819,\n",
            "       0.00034259, 0.00022397, 0.00025375, 0.00024159, 0.00036816,\n",
            "       0.00043277, 0.00024727, 0.00035505, 0.00038953, 0.00032859,\n",
            "       0.0004777 , 0.00026357, 0.00026183, 0.00038305, 0.00034488,\n",
            "       0.00026908, 0.00041374, 0.00037072, 0.00022694, 0.00045394,\n",
            "       0.00036027, 0.00037291, 0.00033818, 0.00037569, 0.0002421 ,\n",
            "       0.00045911, 0.00047517, 0.00032409, 0.00038818, 0.00030095,\n",
            "       0.00036684, 0.00027911, 0.00026917, 0.00050101, 0.0003711 ,\n",
            "       0.00033188, 0.00036399, 0.00030347, 0.00035138, 0.00027711,\n",
            "       0.00034166, 0.00026125, 0.00037014, 0.00064876, 0.00036873,\n",
            "       0.00046464, 0.00030543, 0.00034431, 0.00043401, 0.0003013 ,\n",
            "       0.00052425, 0.00040813, 0.00039696, 0.00041206, 0.00033287,\n",
            "       0.00035084, 0.00039627, 0.00038124, 0.00050853], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 257, 'shape': array([144,   1,   1, 480], dtype=int32), 'shape_signature': array([144,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.0061382 , 0.00847496, 0.01054542, 0.00852053, 0.00559095,\n",
            "       0.00485933, 0.0060472 , 0.00584627, 0.00894799, 0.00599623,\n",
            "       0.00899939, 0.009783  , 0.00854321, 0.00923242, 0.00873284,\n",
            "       0.00537229, 0.00665654, 0.00768661, 0.00859869, 0.00653225,\n",
            "       0.00644675, 0.00604518, 0.00877566, 0.0062493 , 0.00624373,\n",
            "       0.00841045, 0.00696105, 0.00509506, 0.00846223, 0.00959671,\n",
            "       0.00719876, 0.0064129 , 0.00815388, 0.00731897, 0.00940941,\n",
            "       0.00580126, 0.00698125, 0.00517184, 0.00929474, 0.00793702,\n",
            "       0.00815174, 0.0089047 , 0.00905681, 0.00565589, 0.01070284,\n",
            "       0.0061557 , 0.00773129, 0.00735266, 0.00710455, 0.00741599,\n",
            "       0.00826867, 0.00586382, 0.00567626, 0.01198864, 0.00620084,\n",
            "       0.00450402, 0.00921536, 0.01115152, 0.00594362, 0.00893906,\n",
            "       0.0075129 , 0.00754388, 0.00746201, 0.00774196, 0.00836899,\n",
            "       0.00971439, 0.00465321, 0.00812833, 0.00828581, 0.00813915,\n",
            "       0.00727485, 0.00772287, 0.01041889, 0.00658418, 0.00740028,\n",
            "       0.01237993, 0.00797907, 0.01056445, 0.00916786, 0.01092561,\n",
            "       0.0084356 , 0.00915275, 0.00779335, 0.00900745, 0.0075149 ,\n",
            "       0.00761257, 0.00497684, 0.00563862, 0.00536835, 0.00818078,\n",
            "       0.00961663, 0.00549459, 0.00788951, 0.0086558 , 0.00730165,\n",
            "       0.01061496, 0.00585677, 0.00581813, 0.00851164, 0.00766365,\n",
            "       0.00597921, 0.00919371, 0.00823779, 0.00504285, 0.01008707,\n",
            "       0.00800549, 0.00828632, 0.00751467, 0.0083482 , 0.0053796 ,\n",
            "       0.01020194, 0.01055878, 0.00720151, 0.00862568, 0.0066873 ,\n",
            "       0.0081515 , 0.00620214, 0.00598118, 0.01113296, 0.00824612,\n",
            "       0.00737468, 0.00808823, 0.00674339, 0.0078079 , 0.00615759,\n",
            "       0.00759193, 0.00580531, 0.00822493, 0.01441613, 0.00819363,\n",
            "       0.01032471, 0.00678699, 0.00765093, 0.00964414, 0.00669509,\n",
            "       0.01164929, 0.00906897, 0.00882091, 0.00915628, 0.00739678,\n",
            "       0.00779603, 0.00880539, 0.00847159, 0.01130006], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 258, 'shape': array([480], dtype=int32), 'shape_signature': array([480], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.49637272e-05, 1.35952896e-05, 1.74868492e-05, 8.05842410e-06,\n",
            "       1.01545938e-05, 2.35001153e-05, 2.66361931e-05, 5.06718025e-05,\n",
            "       2.54975694e-05, 2.56192106e-05, 2.42731912e-05, 3.87258806e-05,\n",
            "       2.91074575e-05, 3.78740406e-05, 2.43946997e-05, 2.11373135e-05,\n",
            "       6.64104800e-06, 7.94584412e-06, 2.37397544e-05, 3.92269931e-06,\n",
            "       2.60190991e-05, 1.89228667e-05, 1.71842894e-05, 2.40145764e-05,\n",
            "       3.81159152e-05, 2.09740156e-05, 5.75148624e-06, 1.98019898e-05,\n",
            "       2.03294221e-05, 1.12728749e-05, 4.62723347e-06, 2.48021461e-05,\n",
            "       2.68808126e-05, 2.35088482e-05, 2.28794579e-05, 1.91886011e-05,\n",
            "       2.07310368e-05, 1.86817997e-05, 2.83924874e-05, 2.32927923e-05,\n",
            "       2.67151863e-05, 1.02814502e-05, 2.02258252e-05, 2.35510452e-05,\n",
            "       2.00240629e-05, 4.58300610e-06, 1.12545031e-05, 3.92125330e-05,\n",
            "       2.57627853e-05, 1.43688594e-05, 8.57171199e-06, 1.26263931e-05,\n",
            "       6.31917510e-06, 3.70766975e-05, 2.82888759e-05, 2.59504195e-05,\n",
            "       1.70516032e-05, 2.57534866e-05, 3.09284187e-05, 2.47150474e-05,\n",
            "       2.54025417e-05, 1.10283163e-05, 1.41718529e-05, 2.19570848e-05,\n",
            "       1.41991331e-05, 2.14399806e-05, 4.50102289e-06, 2.24266823e-05,\n",
            "       2.79289579e-05, 2.90358257e-05, 3.15295874e-05, 2.16634962e-05,\n",
            "       2.41076796e-05, 4.14670876e-06, 2.26285320e-05, 3.43215688e-05,\n",
            "       2.24121959e-05, 2.25198692e-05, 1.26324539e-05, 2.05929882e-05,\n",
            "       2.78962125e-05, 2.33020892e-05, 3.12094780e-05, 3.01925520e-05,\n",
            "       2.21093778e-05, 2.71594017e-05, 2.16739500e-05, 2.63288148e-05,\n",
            "       2.88284045e-05, 4.04055345e-06, 1.57178765e-05, 1.51794829e-05,\n",
            "       2.40914378e-05, 3.03022280e-05, 2.16526551e-05, 2.45984447e-05,\n",
            "       1.90827959e-05, 6.23862798e-06, 3.57775789e-05, 4.41397106e-06,\n",
            "       2.07353260e-05, 1.85082517e-05, 1.72797572e-05, 2.88971678e-05,\n",
            "       1.26186096e-05, 2.50927296e-05, 2.21415103e-05, 2.30992446e-05,\n",
            "       2.68212007e-05, 2.15737527e-05, 4.13337002e-05, 1.85253102e-05,\n",
            "       5.25350424e-06, 3.29205359e-05, 2.29637462e-05, 7.26105964e-06,\n",
            "       2.19427784e-05, 2.43308605e-05, 1.58373332e-05, 1.08288141e-05,\n",
            "       2.54240367e-05, 5.97886901e-06, 2.52270365e-05, 2.85442111e-05,\n",
            "       2.25541535e-05, 2.45820484e-05, 1.49578063e-05, 1.44916830e-05,\n",
            "       2.70441888e-05, 3.41219197e-06, 2.16837125e-05, 1.13783017e-05,\n",
            "       1.60293366e-05, 5.51228186e-06, 2.32224957e-05, 2.69754346e-05,\n",
            "       1.65532201e-05, 1.59782303e-05, 2.44911607e-05, 2.66441566e-05,\n",
            "       1.85415010e-05, 2.55902942e-05, 6.52744575e-06, 1.33363228e-05,\n",
            "       2.89593390e-05, 2.04272255e-05, 3.60385252e-06, 2.34385225e-05,\n",
            "       2.18562818e-05, 2.01385155e-05, 2.86825507e-05, 2.54697188e-05,\n",
            "       2.39371129e-05, 9.95069786e-06, 2.50969861e-05, 3.18108796e-05,\n",
            "       2.21885402e-05, 1.80020270e-05, 2.11462902e-05, 2.53713115e-05,\n",
            "       2.33573501e-05, 1.07357928e-05, 2.72273319e-05, 3.02441640e-05,\n",
            "       5.15935826e-05, 1.21619414e-05, 3.29266186e-05, 1.75207952e-05,\n",
            "       1.89616330e-05, 1.38147680e-05, 1.75682289e-05, 1.79790350e-05,\n",
            "       1.47248393e-05, 1.33577523e-05, 2.86293798e-05, 2.35294137e-05,\n",
            "       1.39826907e-05, 2.20833572e-05, 4.23537131e-05, 2.51004385e-05,\n",
            "       1.83280972e-05, 2.79039796e-05, 2.07869616e-05, 9.28208465e-06,\n",
            "       2.61162004e-05, 2.71893859e-05, 7.98403926e-06, 2.77363670e-05,\n",
            "       1.72088730e-05, 2.18547775e-05, 2.31456725e-05, 1.96299043e-05,\n",
            "       3.10112555e-05, 2.09275204e-05, 1.71682696e-05, 2.03580366e-05,\n",
            "       4.15782160e-05, 2.43574941e-05, 2.23423831e-05, 2.53848084e-05,\n",
            "       8.02127397e-06, 2.44144358e-05, 2.11379102e-05, 2.42064616e-05,\n",
            "       2.03784130e-05, 2.59755780e-05, 2.91327087e-05, 2.99061303e-05,\n",
            "       1.24952085e-05, 2.40456156e-05, 5.99943596e-05, 1.55082453e-05,\n",
            "       2.56582844e-05, 3.80608144e-05, 2.35109910e-05, 2.51838301e-05,\n",
            "       5.96455175e-06, 2.35905791e-05, 6.18395097e-06, 3.67901303e-05,\n",
            "       2.09006635e-06, 2.54258302e-05, 2.52839873e-05, 3.84732666e-05,\n",
            "       2.85378283e-05, 2.41101588e-05, 2.05559209e-05, 2.35686239e-05,\n",
            "       1.62246251e-05, 1.99706974e-05, 1.83444408e-05, 2.88339979e-05,\n",
            "       2.71321769e-05, 2.77655126e-05, 1.52268503e-05, 2.18171936e-05,\n",
            "       4.54055817e-06, 1.31860497e-05, 1.50824080e-05, 1.10614765e-05,\n",
            "       1.06908628e-05, 2.64404389e-05, 3.49764960e-05, 9.77541367e-06,\n",
            "       6.66528604e-06, 1.10968149e-05, 3.76904718e-05, 5.20812318e-06,\n",
            "       6.31031935e-06, 4.13649395e-05, 1.51897839e-05, 1.37370816e-05,\n",
            "       1.75187652e-05, 1.94044933e-05, 1.75386849e-05, 2.93663434e-05,\n",
            "       1.16517058e-05, 2.05879005e-05, 1.32510268e-05, 2.47144471e-05,\n",
            "       2.61180103e-05, 1.97608297e-05, 3.32755335e-05, 1.13217739e-05,\n",
            "       2.94275433e-05, 2.98508512e-05, 1.07777851e-05, 2.25433596e-05,\n",
            "       1.62353681e-05, 1.52008752e-05, 1.70918611e-05, 2.90075404e-05,\n",
            "       5.98654842e-05, 2.41073412e-05, 2.36117176e-05, 3.97709300e-05,\n",
            "       1.29668597e-05, 2.04482840e-05, 2.48731667e-05, 3.55749785e-06,\n",
            "       2.88350384e-05, 1.78499013e-05, 2.32821476e-05, 2.37431468e-05,\n",
            "       1.93141932e-05, 2.97201968e-05, 3.21274347e-05, 2.08421825e-05,\n",
            "       4.96197163e-06, 1.32455034e-05, 1.20583763e-05, 9.06272817e-06,\n",
            "       1.97274530e-05, 3.11034310e-05, 4.80815061e-06, 1.21244530e-05,\n",
            "       1.78318514e-05, 3.04124092e-06, 1.22677848e-05, 2.14420597e-05,\n",
            "       2.53203398e-05, 1.08140894e-05, 5.72136469e-06, 2.96143808e-05,\n",
            "       2.34539202e-05, 1.53889723e-05, 5.00627502e-05, 2.33720402e-05,\n",
            "       7.66303492e-06, 2.86440209e-05, 2.45561587e-05, 1.83798165e-05,\n",
            "       3.92579977e-06, 1.07074975e-05, 2.37875774e-05, 1.90177834e-05,\n",
            "       4.33354035e-05, 2.29809048e-05, 3.80845377e-05, 2.28484405e-05,\n",
            "       2.11080733e-05, 8.16647207e-06, 1.79687650e-05, 2.11462648e-05,\n",
            "       1.48461586e-05, 2.60759425e-05, 2.58132077e-05, 2.59258250e-05,\n",
            "       1.18850630e-05, 4.05944866e-06, 2.07968387e-05, 2.57186111e-05,\n",
            "       1.77104976e-05, 3.48583817e-05, 1.28150577e-05, 2.06721943e-05,\n",
            "       3.14587778e-05, 1.97363661e-05, 1.70318435e-05, 2.27114542e-05,\n",
            "       1.33918847e-05, 5.49234574e-06, 4.72480269e-06, 2.83874942e-05,\n",
            "       2.51785477e-05, 3.42146850e-05, 2.37159365e-05, 2.17875931e-05,\n",
            "       2.26848369e-05, 2.23553179e-05, 3.02707576e-05, 2.57046086e-05,\n",
            "       3.21005464e-05, 2.50601552e-05, 2.33757910e-05, 2.69711618e-05,\n",
            "       2.61059922e-05, 2.77894851e-05, 2.08290003e-05, 2.23040388e-05,\n",
            "       2.28025729e-05, 2.53477447e-05, 2.30233782e-05, 2.95131795e-05,\n",
            "       1.98182424e-05, 2.57149295e-05, 2.71182616e-05, 2.36088454e-05,\n",
            "       1.42060617e-05, 2.18357491e-05, 1.39953818e-05, 3.42204949e-05,\n",
            "       2.13171334e-05, 3.70748421e-05, 2.27629098e-05, 1.93586002e-05,\n",
            "       2.58043274e-05, 2.60540910e-05, 2.41428843e-05, 2.86455161e-05,\n",
            "       4.17641786e-05, 2.32950970e-05, 2.18475961e-05, 2.09886111e-05,\n",
            "       2.64249375e-05, 2.89975978e-05, 1.37129355e-05, 2.76900137e-05,\n",
            "       1.62103861e-05, 2.38841094e-05, 1.68412371e-05, 1.74777524e-05,\n",
            "       2.34486215e-05, 1.80261613e-05, 4.94362575e-05, 2.04624430e-05,\n",
            "       1.69298182e-05, 8.82539098e-06, 1.35872251e-05, 3.46693305e-05,\n",
            "       2.10178951e-05, 2.47150892e-05, 2.27569781e-05, 2.05308224e-05,\n",
            "       2.96621329e-05, 2.11158804e-05, 2.15670534e-05, 1.61907265e-05,\n",
            "       2.67824253e-05, 3.79429935e-06, 4.37922199e-06, 2.27328928e-05,\n",
            "       2.10506096e-06, 2.74890658e-06, 2.87996136e-05, 7.75328681e-06,\n",
            "       3.56145501e-05, 2.63690727e-05, 2.71868557e-05, 1.69076593e-05,\n",
            "       2.90975458e-05, 2.92778477e-05, 3.37007145e-06, 7.22024561e-06,\n",
            "       1.96108922e-05, 2.18022778e-05, 2.02128449e-05, 1.87286678e-05,\n",
            "       1.09086241e-05, 6.92020649e-06, 4.47419916e-05, 2.23507523e-05,\n",
            "       1.10622423e-05, 2.67309351e-05, 3.08773197e-05, 7.95733376e-06,\n",
            "       1.24235239e-05, 7.03919159e-06, 2.24278810e-05, 5.16381333e-05,\n",
            "       1.61572334e-05, 2.37946260e-05, 3.21804655e-05, 3.36831508e-05,\n",
            "       7.20671869e-06, 3.12240227e-05, 8.53768506e-06, 6.64566232e-06,\n",
            "       2.11770021e-05, 2.15987548e-05, 2.15506770e-05, 6.30485465e-06,\n",
            "       4.87658508e-05, 2.24261803e-05, 2.71451754e-05, 4.03069243e-05,\n",
            "       1.90965766e-05, 1.91266336e-05, 2.28824865e-05, 8.77298044e-06,\n",
            "       4.64250552e-05, 3.20512772e-05, 1.69025479e-05, 4.61056443e-05,\n",
            "       2.44436415e-05, 2.79935521e-05, 2.91172073e-05, 2.65108538e-05,\n",
            "       2.59443423e-05, 4.11604051e-05, 4.55988957e-05, 3.30003968e-05,\n",
            "       2.18699060e-05, 2.87437961e-05, 2.09607770e-05, 2.12910018e-05,\n",
            "       3.00292577e-05, 4.12883674e-06, 2.95415721e-05, 2.92512632e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 259, 'shape': array([480,   1,   1, 240], dtype=int32), 'shape_signature': array([480,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00078641, 0.00071449, 0.00091901, 0.0004235 , 0.00053367,\n",
            "       0.00123503, 0.00139984, 0.00266301, 0.00134   , 0.00134639,\n",
            "       0.00127566, 0.0020352 , 0.00152972, 0.00199044, 0.00128204,\n",
            "       0.00111085, 0.00034901, 0.00041759, 0.00124762, 0.00020615,\n",
            "       0.00136741, 0.00099447, 0.0009031 , 0.00126206, 0.00200315,\n",
            "       0.00110227, 0.00030226, 0.00104068, 0.00106839, 0.00059244,\n",
            "       0.00024318, 0.00130345, 0.0014127 , 0.00123549, 0.00120241,\n",
            "       0.00100844, 0.0010895 , 0.00098181, 0.00149214, 0.00122413,\n",
            "       0.00140399, 0.00054033, 0.00106295, 0.0012377 , 0.00105235,\n",
            "       0.00024086, 0.00059147, 0.00206078, 0.00135394, 0.00075514,\n",
            "       0.00045048, 0.00066357, 0.0003321 , 0.00194853, 0.0014867 ,\n",
            "       0.0013638 , 0.00089613, 0.00135345, 0.00162542, 0.00129888,\n",
            "       0.00133501, 0.00057958, 0.00074479, 0.00115393, 0.00074622,\n",
            "       0.00112676, 0.00023655, 0.00117861, 0.00146778, 0.00152595,\n",
            "       0.00165701, 0.00113851, 0.00126696, 0.00021793, 0.00118922,\n",
            "       0.00180374, 0.00117785, 0.00118351, 0.00066389, 0.00108225,\n",
            "       0.00146606, 0.00122462, 0.00164019, 0.00158674, 0.00116194,\n",
            "       0.00142734, 0.00113906, 0.00138369, 0.00151505, 0.00021235,\n",
            "       0.00082604, 0.00079774, 0.0012661 , 0.00159251, 0.00113794,\n",
            "       0.00129275, 0.00100288, 0.00032787, 0.00188026, 0.00023197,\n",
            "       0.00108973, 0.00097268, 0.00090812, 0.00151866, 0.00066316,\n",
            "       0.00131873, 0.00116363, 0.00121396, 0.00140956, 0.00113379,\n",
            "       0.00217226, 0.00097358, 0.00027609, 0.00173011, 0.00120684,\n",
            "       0.0003816 , 0.00115318, 0.00127869, 0.00083232, 0.0005691 ,\n",
            "       0.00133614, 0.00031421, 0.00132578, 0.00150012, 0.00118531,\n",
            "       0.00129189, 0.00078609, 0.0007616 , 0.00142128, 0.00017932,\n",
            "       0.00113957, 0.00059798, 0.00084241, 0.00028969, 0.00122044,\n",
            "       0.00141767, 0.00086994, 0.00083972, 0.00128711, 0.00140026,\n",
            "       0.00097443, 0.00134487, 0.00034304, 0.00070088, 0.00152193,\n",
            "       0.00107353, 0.0001894 , 0.00123179, 0.00114864, 0.00105836,\n",
            "       0.00150739, 0.00133854, 0.00125799, 0.00052295, 0.00131895,\n",
            "       0.00167179, 0.0011661 , 0.00094608, 0.00111132, 0.00133337,\n",
            "       0.00122752, 0.00056421, 0.00143091, 0.00158945, 0.00271145,\n",
            "       0.00063916, 0.00173043, 0.00092079, 0.00099651, 0.00072602,\n",
            "       0.00092328, 0.00094487, 0.00077385, 0.000702  , 0.00150459,\n",
            "       0.00123657, 0.00073485, 0.00116057, 0.00222586, 0.00131913,\n",
            "       0.00096322, 0.00146647, 0.00109244, 0.00048781, 0.00137251,\n",
            "       0.00142891, 0.00041959, 0.00145766, 0.0009044 , 0.00114856,\n",
            "       0.0012164 , 0.00103163, 0.00162977, 0.00109983, 0.00090226,\n",
            "       0.0010699 , 0.00218511, 0.00128009, 0.00117418, 0.00133408,\n",
            "       0.00042155, 0.00128308, 0.00111088, 0.00127215, 0.00107097,\n",
            "       0.00136512, 0.00153104, 0.00157169, 0.00065667, 0.0012637 ,\n",
            "       0.00315295, 0.00081502, 0.00134845, 0.00200025, 0.0012356 ,\n",
            "       0.00132351, 0.00031346, 0.00123978, 0.00032499, 0.00193347,\n",
            "       0.00010984, 0.00133623, 0.00132878, 0.00202193, 0.00149978,\n",
            "       0.00126709, 0.0010803 , 0.00123863, 0.00085267, 0.00104954,\n",
            "       0.00096408, 0.00151534, 0.00142591, 0.00145919, 0.00080023,\n",
            "       0.00114658, 0.00023862, 0.00069298, 0.00079264, 0.00058133,\n",
            "       0.00056185, 0.00138955, 0.00183816, 0.00051374, 0.00035029,\n",
            "       0.00058318, 0.00198079, 0.00027371, 0.00033163, 0.0021739 ,\n",
            "       0.00079829, 0.00072194, 0.00092068, 0.00101979, 0.00092173,\n",
            "       0.00154332, 0.00061234, 0.00108198, 0.0006964 , 0.00129885,\n",
            "       0.00137261, 0.00103851, 0.00174877, 0.00059501, 0.00154654,\n",
            "       0.00156878, 0.00056642, 0.00118475, 0.00085324, 0.00079887,\n",
            "       0.00089825, 0.00152447, 0.00314618, 0.00126694, 0.00124089,\n",
            "       0.00209013, 0.00068146, 0.00107464, 0.00130719, 0.00018696,\n",
            "       0.0015154 , 0.00093809, 0.00122357, 0.0012478 , 0.00101504,\n",
            "       0.00156192, 0.00168843, 0.00109534, 0.00026077, 0.00069611,\n",
            "       0.00063372, 0.00047628, 0.00103676, 0.00163461, 0.00025269,\n",
            "       0.00063719, 0.00093714, 0.00015983, 0.00064472, 0.00112687,\n",
            "       0.00133069, 0.00056832, 0.00030068, 0.00155636, 0.0012326 ,\n",
            "       0.00080875, 0.002631  , 0.0012283 , 0.00040272, 0.00150536,\n",
            "       0.00129053, 0.00096593, 0.00020632, 0.00056272, 0.00125013,\n",
            "       0.00099946, 0.00227745, 0.00120774, 0.0020015 , 0.00120078,\n",
            "       0.00110932, 0.00042918, 0.00094433, 0.00111132, 0.00078023,\n",
            "       0.0013704 , 0.00135659, 0.00136251, 0.00062461, 0.00021334,\n",
            "       0.00109296, 0.00135162, 0.00093076, 0.00183195, 0.00067348,\n",
            "       0.00108641, 0.00165329, 0.00103723, 0.00089509, 0.00119358,\n",
            "       0.0007038 , 0.00028865, 0.00024831, 0.00149188, 0.00132324,\n",
            "       0.00179812, 0.00124637, 0.00114503, 0.00119218, 0.00117486,\n",
            "       0.00159085, 0.00135088, 0.00168702, 0.00131701, 0.00122849,\n",
            "       0.00141745, 0.00137198, 0.00146045, 0.00109465, 0.00117217,\n",
            "       0.00119837, 0.00133213, 0.00120997, 0.00155104, 0.00104153,\n",
            "       0.00135143, 0.00142518, 0.00124074, 0.00074659, 0.00114756,\n",
            "       0.00073551, 0.00179843, 0.0011203 , 0.00194844, 0.00119628,\n",
            "       0.00101737, 0.00135612, 0.00136925, 0.00126881, 0.00150544,\n",
            "       0.00219488, 0.00122425, 0.00114818, 0.00110304, 0.00138874,\n",
            "       0.00152394, 0.00072067, 0.00145522, 0.00085192, 0.00125521,\n",
            "       0.00088508, 0.00091853, 0.00123232, 0.00094735, 0.00259808,\n",
            "       0.00107539, 0.00088973, 0.00046381, 0.00071406, 0.00182202,\n",
            "       0.00110458, 0.00129888, 0.00119597, 0.00107898, 0.00155887,\n",
            "       0.00110973, 0.00113344, 0.00085089, 0.00140753, 0.00019941,\n",
            "       0.00023015, 0.00119471, 0.00011063, 0.00014447, 0.00151354,\n",
            "       0.00040747, 0.00187169, 0.0013858 , 0.00142878, 0.00088857,\n",
            "       0.0015292 , 0.00153867, 0.00017711, 0.00037945, 0.00103063,\n",
            "       0.0011458 , 0.00106227, 0.00098427, 0.00057329, 0.00036369,\n",
            "       0.00235138, 0.00117462, 0.00058137, 0.00140482, 0.00162273,\n",
            "       0.00041819, 0.00065291, 0.00036994, 0.00117868, 0.0027138 ,\n",
            "       0.00084913, 0.00125051, 0.00169122, 0.00177019, 0.00037874,\n",
            "       0.00164095, 0.00044869, 0.00034926, 0.00111294, 0.0011351 ,\n",
            "       0.00113258, 0.00033135, 0.00256285, 0.00117859, 0.00142659,\n",
            "       0.00211829, 0.0010036 , 0.00100518, 0.00120257, 0.00046106,\n",
            "       0.00243983, 0.00168443, 0.0008883 , 0.00242304, 0.00128461,\n",
            "       0.00147118, 0.00153023, 0.00139325, 0.00136348, 0.00216315,\n",
            "       0.00239641, 0.00173431, 0.00114935, 0.0015106 , 0.00110157,\n",
            "       0.00111893, 0.00157816, 0.00021699, 0.00155253, 0.00153727],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 260, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([5.66549061e-05, 3.16879341e-05, 5.05793978e-05, 1.63812747e-05,\n",
            "       5.80284650e-05, 1.82871663e-05, 5.38065760e-05, 4.68086619e-05,\n",
            "       2.24405030e-05, 7.69960316e-05, 5.02837502e-05, 5.90020063e-05,\n",
            "       4.72307474e-05, 1.55764119e-05, 5.95176352e-05, 2.96628150e-05,\n",
            "       5.38863933e-05, 4.80731687e-05, 4.81492534e-05, 4.81205861e-05,\n",
            "       5.58672218e-05, 7.27538063e-05, 6.24345330e-06, 1.22300680e-05,\n",
            "       4.00191639e-05, 2.39310757e-05, 2.15003110e-05, 1.50666210e-05,\n",
            "       4.26393126e-05, 4.48858082e-05, 5.92808574e-05, 2.96976414e-05,\n",
            "       4.19862918e-05, 5.13564664e-05, 4.96380635e-05, 4.45701371e-05,\n",
            "       4.32504567e-05, 5.48306380e-05, 6.21182116e-05, 5.01948052e-05,\n",
            "       3.88783410e-05, 4.32969391e-05, 2.00240374e-05, 2.76495794e-05,\n",
            "       5.03801275e-05, 2.37731692e-05, 2.87987223e-05, 5.12640800e-05,\n",
            "       6.59706420e-05, 8.76109916e-05, 8.37025218e-05, 4.52549430e-05,\n",
            "       5.25063479e-05, 5.65139235e-05, 7.47808372e-05, 1.39129552e-05,\n",
            "       3.45646840e-05, 4.05593346e-05, 2.01025650e-05, 4.07339248e-05,\n",
            "       4.82288997e-05, 2.39260680e-05, 2.34606923e-05, 2.29050656e-05,\n",
            "       4.49676372e-05, 2.96851867e-05, 5.47584241e-05, 4.19454555e-05,\n",
            "       3.40000806e-05, 5.85860689e-05, 3.45457120e-05, 4.83243966e-05,\n",
            "       1.50489295e-05, 6.19939310e-05, 1.34701922e-05, 5.56124651e-05,\n",
            "       4.50603147e-05, 4.15654540e-05, 4.79122209e-05, 4.15731629e-05,\n",
            "       8.50986835e-05, 6.56242701e-05, 8.92102107e-05, 5.33807288e-05,\n",
            "       3.86454049e-05, 5.16619803e-05, 4.26531697e-05, 4.52138302e-05,\n",
            "       7.19712043e-05, 5.81522472e-05, 3.81089339e-05, 4.34764734e-05,\n",
            "       4.54534857e-05, 4.91833234e-05, 1.21913936e-05, 5.34541505e-05,\n",
            "       3.14599711e-05, 4.06282161e-05, 6.07850961e-05, 2.01076145e-05,\n",
            "       4.03215854e-05, 5.58814936e-05, 5.27947777e-05, 9.34356285e-05,\n",
            "       7.48353341e-05, 2.86426075e-05, 1.41256060e-05, 6.03157714e-05,\n",
            "       1.31316256e-05, 3.50137161e-05, 4.29037937e-05, 4.74130393e-05,\n",
            "       7.56864683e-05, 1.46502853e-05, 5.00893657e-05, 2.89945947e-05,\n",
            "       4.76768728e-05, 7.49630635e-05, 6.21335857e-05, 7.15841234e-05,\n",
            "       2.59927237e-05, 3.13426899e-05, 8.25891839e-05, 4.61161508e-05,\n",
            "       6.56338234e-05, 4.13847592e-05, 4.42695127e-05, 1.20365141e-04,\n",
            "       5.75737868e-05, 3.35948280e-05, 3.46513334e-05, 4.74341432e-05,\n",
            "       5.56903433e-05, 5.19691202e-05, 4.28218700e-05, 7.45586512e-05,\n",
            "       6.11479554e-05, 4.15250724e-05, 3.96885880e-05, 4.33094392e-05,\n",
            "       4.82015384e-05, 3.79882658e-05, 5.29658355e-05, 5.28514793e-05,\n",
            "       6.91383611e-05, 4.42160272e-05, 6.48679124e-05, 5.75211598e-05,\n",
            "       5.35761865e-05, 4.74903864e-05, 4.57742790e-05, 5.99559207e-05,\n",
            "       9.59677127e-05, 5.09162492e-05, 5.52622732e-05, 4.22080921e-05,\n",
            "       3.37152560e-05, 3.38711361e-05, 7.10921158e-05, 1.59057709e-05,\n",
            "       1.81717005e-05, 8.23789960e-05, 1.72439923e-05, 2.99075291e-05,\n",
            "       4.23058591e-05, 3.82335456e-05, 5.06668512e-05, 3.48055946e-05,\n",
            "       3.96326141e-05, 3.82417420e-05, 3.31727933e-05, 6.38065103e-05,\n",
            "       4.42160490e-05, 2.33382161e-05, 3.75326672e-05, 1.57298346e-05,\n",
            "       3.35531877e-05, 4.64130098e-05, 3.28204078e-05, 4.87198013e-05,\n",
            "       5.96698119e-05, 2.73678106e-05, 3.40618717e-05, 6.50727452e-05,\n",
            "       4.18708623e-05, 3.82702274e-05, 4.65687990e-05, 5.71007367e-05,\n",
            "       7.67327510e-05, 4.24270875e-05, 6.28531925e-05, 3.77728866e-05,\n",
            "       4.46073027e-05, 4.21485202e-05, 4.78671100e-05, 6.27468762e-05,\n",
            "       6.76524360e-05, 5.30633006e-05, 7.80350238e-05, 4.80897033e-05,\n",
            "       2.29302968e-05, 3.36742742e-05, 9.64600349e-06, 4.21218829e-05,\n",
            "       4.03140002e-05, 4.45411642e-05, 2.86350132e-05, 6.74940093e-05,\n",
            "       4.60265110e-05, 4.53058310e-05, 2.63558595e-05, 3.88313128e-05,\n",
            "       4.11212859e-05, 4.33288078e-05, 2.10202288e-05, 2.25030180e-05,\n",
            "       3.59188089e-05, 3.80455931e-05, 4.20246397e-05, 4.41263983e-05,\n",
            "       7.69752369e-05, 5.94495832e-05, 3.95937932e-05, 4.65609228e-05,\n",
            "       5.78639338e-05, 5.02754119e-05, 4.69445295e-05, 3.81715836e-05,\n",
            "       3.55868542e-05, 2.08781603e-05, 4.18013660e-05, 7.94750449e-05,\n",
            "       4.71276835e-05, 5.86985479e-05, 5.22151058e-05, 8.26824253e-05,\n",
            "       1.15524745e-05, 5.30643119e-05, 4.18696218e-05, 4.39202850e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 261, 'shape': array([240,   1,   1, 960], dtype=int32), 'shape_signature': array([240,   1,   1, 960], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00162273, 0.00090762, 0.00144872, 0.0004692 , 0.00166208,\n",
            "       0.00052379, 0.00154115, 0.00134071, 0.00064275, 0.00220535,\n",
            "       0.00144025, 0.00168996, 0.0013528 , 0.00044615, 0.00170473,\n",
            "       0.00084961, 0.00154344, 0.00137693, 0.00137911, 0.00137829,\n",
            "       0.00160017, 0.00208384, 0.00017883, 0.0003503 , 0.00114625,\n",
            "       0.00068544, 0.00061582, 0.00043154, 0.00122129, 0.00128564,\n",
            "       0.00169795, 0.00085061, 0.00120259, 0.00147097, 0.00142175,\n",
            "       0.0012766 , 0.0012388 , 0.00157048, 0.00177922, 0.0014377 ,\n",
            "       0.00111357, 0.00124013, 0.00057354, 0.00079195, 0.00144301,\n",
            "       0.00068092, 0.00082486, 0.00146833, 0.00188956, 0.00250939,\n",
            "       0.00239744, 0.00129621, 0.00150391, 0.0016187 , 0.0021419 ,\n",
            "       0.0003985 , 0.00099002, 0.00116172, 0.00057579, 0.00116672,\n",
            "       0.00138139, 0.0006853 , 0.00067197, 0.00065606, 0.00128798,\n",
            "       0.00085026, 0.00156841, 0.00120142, 0.00097384, 0.00167805,\n",
            "       0.00098947, 0.00138413, 0.00043104, 0.00177566, 0.00038582,\n",
            "       0.00159288, 0.00129064, 0.00119053, 0.00137232, 0.00119076,\n",
            "       0.00243743, 0.00187964, 0.0025552 , 0.00152895, 0.0011069 ,\n",
            "       0.00147972, 0.00122169, 0.00129503, 0.00206143, 0.00166562,\n",
            "       0.00109153, 0.00124527, 0.0013019 , 0.00140873, 0.00034919,\n",
            "       0.00153106, 0.00090109, 0.00116369, 0.00174103, 0.00057593,\n",
            "       0.00115491, 0.00160058, 0.00151217, 0.00267622, 0.00214346,\n",
            "       0.00082039, 0.00040459, 0.00172759, 0.00037612, 0.00100288,\n",
            "       0.00122887, 0.00135802, 0.00216784, 0.00041962, 0.00143468,\n",
            "       0.00083048, 0.00136558, 0.00214712, 0.00177966, 0.00205034,\n",
            "       0.00074449, 0.00089773, 0.00236555, 0.00132088, 0.00187991,\n",
            "       0.00118536, 0.00126799, 0.00344755, 0.00164905, 0.00096224,\n",
            "       0.0009925 , 0.00135863, 0.00159511, 0.00148852, 0.00122652,\n",
            "       0.00213554, 0.00175142, 0.00118938, 0.00113678, 0.00124049,\n",
            "       0.00138061, 0.00108808, 0.00151707, 0.00151379, 0.00198029,\n",
            "       0.00126645, 0.00185797, 0.00164754, 0.00153455, 0.00136024,\n",
            "       0.00131109, 0.00171728, 0.00274875, 0.00145836, 0.00158284,\n",
            "       0.00120894, 0.00096569, 0.00097015, 0.00203625, 0.00045558,\n",
            "       0.00052048, 0.00235953, 0.00049391, 0.00085662, 0.00121174,\n",
            "       0.0010951 , 0.00145122, 0.00099692, 0.00113517, 0.00109534,\n",
            "       0.00095015, 0.00182757, 0.00126645, 0.00066846, 0.00107503,\n",
            "       0.00045054, 0.00096104, 0.00132938, 0.00094006, 0.00139545,\n",
            "       0.00170909, 0.00078388, 0.00097561, 0.00186384, 0.00119928,\n",
            "       0.00109615, 0.00133384, 0.0016355 , 0.00219781, 0.00121521,\n",
            "       0.00180027, 0.00108191, 0.00127766, 0.00120724, 0.00137103,\n",
            "       0.00179722, 0.00193773, 0.00151986, 0.00223511, 0.00137741,\n",
            "       0.00065678, 0.00096451, 0.00027628, 0.00120647, 0.00115469,\n",
            "       0.00127577, 0.00082018, 0.00193319, 0.00131831, 0.00129767,\n",
            "       0.0007549 , 0.00111222, 0.00117781, 0.00124104, 0.00060207,\n",
            "       0.00064454, 0.0010288 , 0.00108972, 0.00120369, 0.00126389,\n",
            "       0.00220476, 0.00170278, 0.00113406, 0.00133362, 0.00165736,\n",
            "       0.00144001, 0.0013446 , 0.00109333, 0.00101929, 0.000598  ,\n",
            "       0.00119729, 0.00227636, 0.00134985, 0.00168127, 0.00149557,\n",
            "       0.00236822, 0.00033089, 0.00151989, 0.00119925, 0.00125798],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 262, 'shape': array([480], dtype=int32), 'shape_signature': array([480], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00761878, 0.02069892, 0.00138639, 0.0044846 , 0.00217963,\n",
            "       0.00098642, 0.00063439, 0.00105155, 0.00147275, 0.00112084,\n",
            "       0.00101424, 0.00089849, 0.00125995, 0.00061708, 0.01042305,\n",
            "       0.00110894, 0.0044322 , 0.00617683, 0.00071757, 0.00102718,\n",
            "       0.00092144, 0.00137511, 0.00275463, 0.00191378, 0.04221036,\n",
            "       0.00068324, 0.00292324, 0.00067295, 0.00074789, 0.0030578 ,\n",
            "       0.00386467, 0.00086994, 0.00068863, 0.00832871, 0.00460454,\n",
            "       0.00125181, 0.00406707, 0.00397058, 0.00070553, 0.00102041,\n",
            "       0.00079263, 0.00664216, 0.00266363, 0.00058913, 0.00748629,\n",
            "       0.00255481, 0.01025756, 0.00691273, 0.00087857, 0.01431576,\n",
            "       0.0075051 , 0.00374309, 0.00650067, 0.00274496, 0.00130821,\n",
            "       0.0071657 , 0.00338027, 0.00070814, 0.00087101, 0.00150504,\n",
            "       0.00078813, 0.01002801, 0.00546259, 0.00165772, 0.00099998,\n",
            "       0.00626582, 0.00763079, 0.00072235, 0.00492853, 0.01611412,\n",
            "       0.00065968, 0.00142181, 0.00151207, 0.00373867, 0.00098979,\n",
            "       0.00080858, 0.00658869, 0.00078745, 0.0039023 , 0.00067391,\n",
            "       0.00086429, 0.00082687, 0.00067121, 0.00506145, 0.00121023,\n",
            "       0.00108886, 0.00452597, 0.00064312, 0.00611759, 0.00240567,\n",
            "       0.01063286, 0.00691829, 0.00588636, 0.00247437, 0.00071755,\n",
            "       0.00065311, 0.00122364, 0.00940829, 0.00121209, 0.00531874,\n",
            "       0.00123533, 0.00120189, 0.00810314, 0.00086202, 0.00433089,\n",
            "       0.01082754, 0.00072784, 0.0009916 , 0.00170401, 0.01574118,\n",
            "       0.0029569 , 0.00609171, 0.00592469, 0.00076565, 0.00124721,\n",
            "       0.00926586, 0.00175323, 0.00120333, 0.01627071, 0.00511917,\n",
            "       0.0117251 , 0.0063059 , 0.00066555, 0.00128974, 0.00105295,\n",
            "       0.00090494, 0.00504811, 0.00179813, 0.00139381, 0.00240895,\n",
            "       0.00150325, 0.00996152, 0.00197171, 0.00409055, 0.00062859,\n",
            "       0.00461947, 0.00135721, 0.00381821, 0.0012092 , 0.00132636,\n",
            "       0.00070623, 0.00062846, 0.00510359, 0.00335048, 0.00844866,\n",
            "       0.00526372, 0.00514303, 0.00093241, 0.02167354, 0.00088139,\n",
            "       0.00054234, 0.00180283, 0.01318705, 0.00281025, 0.00048775,\n",
            "       0.00404997, 0.00123919, 0.00154609, 0.00067113, 0.00070788,\n",
            "       0.00112668, 0.00561973, 0.00416562, 0.00075876, 0.00759389,\n",
            "       0.00463887, 0.00101916, 0.00358753, 0.02433142, 0.00157226,\n",
            "       0.00278741, 0.00201197, 0.00440919, 0.00071033, 0.00066068,\n",
            "       0.00433212, 0.01487086, 0.01524759, 0.00327329, 0.00069193,\n",
            "       0.00783335, 0.00077171, 0.00149928, 0.0035767 , 0.00111985,\n",
            "       0.00097145, 0.00768011, 0.00095617, 0.00150261, 0.00084501,\n",
            "       0.00094187, 0.00072229, 0.00116353, 0.00166031, 0.0028251 ,\n",
            "       0.00201748, 0.00059372, 0.00384504, 0.00572634, 0.00059737,\n",
            "       0.00866582, 0.00062844, 0.00168493, 0.00054159, 0.00092322,\n",
            "       0.00685376, 0.00940312, 0.00323985, 0.00495224, 0.00130609,\n",
            "       0.00567769, 0.0031011 , 0.00187114, 0.00065165, 0.00096622,\n",
            "       0.00063263, 0.00849539, 0.00087148, 0.0046061 , 0.00171055,\n",
            "       0.00141112, 0.01676351, 0.00524357, 0.00602895, 0.00359838,\n",
            "       0.00100357, 0.00103859, 0.00119133, 0.00333873, 0.00164435,\n",
            "       0.00254504, 0.00051411, 0.00060926, 0.00425769, 0.00175468,\n",
            "       0.0009692 , 0.00827195, 0.00396263, 0.00570677, 0.01224813,\n",
            "       0.00730407, 0.01276796, 0.00082804, 0.00358226, 0.00209395,\n",
            "       0.0089624 , 0.01766116, 0.00779942, 0.00519698, 0.00608905,\n",
            "       0.00107945, 0.00104286, 0.00600152, 0.00990967, 0.01018867,\n",
            "       0.01319743, 0.00729871, 0.00563553, 0.0069734 , 0.00101158,\n",
            "       0.00053286, 0.00894461, 0.00100326, 0.00551684, 0.00158765,\n",
            "       0.00097558, 0.00720468, 0.000757  , 0.00552062, 0.0038881 ,\n",
            "       0.00292337, 0.0214964 , 0.00381855, 0.00103258, 0.00328273,\n",
            "       0.00604727, 0.00213154, 0.00492537, 0.00077889, 0.00204972,\n",
            "       0.00137178, 0.00206488, 0.00066513, 0.00116741, 0.00064751,\n",
            "       0.00097687, 0.00413473, 0.00953275, 0.00175939, 0.01754041,\n",
            "       0.01007521, 0.00727206, 0.01621216, 0.01398885, 0.0069106 ,\n",
            "       0.00417751, 0.00356918, 0.00189147, 0.00555849, 0.00193445,\n",
            "       0.00081483, 0.00484577, 0.00465679, 0.00056213, 0.00118747,\n",
            "       0.00237546, 0.00110309, 0.00173915, 0.00559655, 0.00078377,\n",
            "       0.00171407, 0.00194733, 0.00548134, 0.00539476, 0.02590991,\n",
            "       0.00297789, 0.00982413, 0.02840236, 0.00710884, 0.00206495,\n",
            "       0.00846213, 0.00728017, 0.00215377, 0.00151567, 0.01198323,\n",
            "       0.00465832, 0.01697104, 0.00110695, 0.0099918 , 0.00279826,\n",
            "       0.00199247, 0.00138777, 0.00505   , 0.0006423 , 0.00257535,\n",
            "       0.00130831, 0.00124219, 0.00845987, 0.01363262, 0.00088353,\n",
            "       0.00967912, 0.00445922, 0.00116625, 0.00084745, 0.00090194,\n",
            "       0.00078676, 0.00280116, 0.00093584, 0.01286463, 0.00131242,\n",
            "       0.00115324, 0.00207456, 0.00104975, 0.00060963, 0.0014412 ,\n",
            "       0.00399786, 0.00115193, 0.00053915, 0.00064912, 0.00239016,\n",
            "       0.00153352, 0.00082426, 0.00090933, 0.00680394, 0.00073722,\n",
            "       0.00129939, 0.00076539, 0.00153115, 0.00230513, 0.0012043 ,\n",
            "       0.00496489, 0.0010366 , 0.01584816, 0.00285097, 0.00155811,\n",
            "       0.00072949, 0.00084175, 0.00082787, 0.00247698, 0.00083153,\n",
            "       0.00083081, 0.00411319, 0.00122089, 0.01358375, 0.00068882,\n",
            "       0.00365727, 0.00344756, 0.01112623, 0.00145957, 0.02505648,\n",
            "       0.0094728 , 0.00463852, 0.00051807, 0.00466309, 0.00832299,\n",
            "       0.00076158, 0.00792304, 0.00368983, 0.00069611, 0.00093249,\n",
            "       0.00351867, 0.00074313, 0.01555403, 0.00905413, 0.00077789,\n",
            "       0.00107797, 0.00726475, 0.0031014 , 0.00555149, 0.00563919,\n",
            "       0.00448103, 0.00362648, 0.00173342, 0.00116202, 0.00074453,\n",
            "       0.00629962, 0.00476896, 0.0012977 , 0.00448744, 0.00255291,\n",
            "       0.00065493, 0.00114908, 0.0031579 , 0.00534862, 0.00102031,\n",
            "       0.00090819, 0.00217561, 0.00112407, 0.00276667, 0.00674265,\n",
            "       0.00129729, 0.01406102, 0.00339872, 0.00099717, 0.00078369,\n",
            "       0.00551555, 0.00478357, 0.00497425, 0.00121202, 0.00634868,\n",
            "       0.00276036, 0.00141842, 0.00262731, 0.00105834, 0.00143781,\n",
            "       0.00084161, 0.00182685, 0.00639466, 0.00487918, 0.00627976,\n",
            "       0.00636177, 0.00557918, 0.00739339, 0.00178899, 0.01369337,\n",
            "       0.00124708, 0.01036033, 0.00093915, 0.00085884, 0.00133502,\n",
            "       0.02927277, 0.00273713, 0.00277992, 0.00271995, 0.00067031,\n",
            "       0.00157699, 0.0007653 , 0.0073176 , 0.00081198, 0.01235459,\n",
            "       0.00925937, 0.00083303, 0.00360213, 0.00147674, 0.0011067 ,\n",
            "       0.01659665, 0.00252547, 0.00363999, 0.00095188, 0.00097135],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul', 'index': 263, 'shape': array([  1,   5,   1, 480], dtype=int32), 'shape_signature': array([  1,   5,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.05409572, 0.14696874, 0.00984382, 0.03184208, 0.01547603,\n",
            "       0.00700392, 0.00450437, 0.00746633, 0.01045701, 0.00795828,\n",
            "       0.00720141, 0.00637953, 0.00894604, 0.00438144, 0.07400692,\n",
            "       0.00787382, 0.03146996, 0.04385744, 0.005095  , 0.00729328,\n",
            "       0.0065425 , 0.00976373, 0.0195587 , 0.01358846, 0.2997067 ,\n",
            "       0.0048512 , 0.02075588, 0.00477817, 0.00531026, 0.02171132,\n",
            "       0.02744035, 0.00617686, 0.00488945, 0.05913641, 0.03269367,\n",
            "       0.00888822, 0.02887747, 0.02819236, 0.00500949, 0.00724524,\n",
            "       0.00562789, 0.04716137, 0.01891263, 0.004183  , 0.05315502,\n",
            "       0.01813997, 0.07283188, 0.04908253, 0.00623809, 0.10164631,\n",
            "       0.05328856, 0.02657713, 0.04615678, 0.01949005, 0.00928871,\n",
            "       0.05087868, 0.024001  , 0.00502798, 0.00618443, 0.01068625,\n",
            "       0.005596  , 0.07120197, 0.03878611, 0.01177031, 0.00710018,\n",
            "       0.04448926, 0.05418099, 0.00512892, 0.03499407, 0.11441524,\n",
            "       0.00468391, 0.01009528, 0.01073615, 0.02654569, 0.00702784,\n",
            "       0.00574117, 0.04678175, 0.00559111, 0.02770752, 0.00478494,\n",
            "       0.00613676, 0.00587102, 0.0047658 , 0.03593785, 0.00859302,\n",
            "       0.00773128, 0.03213576, 0.00456636, 0.04343675, 0.01708104,\n",
            "       0.07549663, 0.04912198, 0.04179501, 0.01756881, 0.00509484,\n",
            "       0.00463728, 0.00868822, 0.06680177, 0.00860619, 0.03776473,\n",
            "       0.0087712 , 0.0085338 , 0.05753479, 0.00612064, 0.03075065,\n",
            "       0.07687889, 0.00516792, 0.00704069, 0.01209897, 0.11176728,\n",
            "       0.02099492, 0.04325302, 0.04206715, 0.00543634, 0.00885561,\n",
            "       0.06579049, 0.01244846, 0.00854399, 0.11552707, 0.0363477 ,\n",
            "       0.08325186, 0.04477386, 0.00472562, 0.00915757, 0.00747627,\n",
            "       0.00642535, 0.03584317, 0.01276732, 0.00989647, 0.01710428,\n",
            "       0.01067356, 0.07072991, 0.01399978, 0.02904418, 0.00446316,\n",
            "       0.03279971, 0.00963663, 0.02711048, 0.00858568, 0.00941759,\n",
            "       0.00501442, 0.00446227, 0.03623708, 0.02378946, 0.05998814,\n",
            "       0.03737401, 0.03651708, 0.00662039, 0.15388884, 0.00625811,\n",
            "       0.00385076, 0.01280062, 0.09363217, 0.01995363, 0.00346318,\n",
            "       0.02875604, 0.00879864, 0.01097774, 0.00476522, 0.00502614,\n",
            "       0.00799981, 0.03990181, 0.0295772 , 0.0053874 , 0.05391897,\n",
            "       0.03293742, 0.00723634, 0.02547254, 0.17276068, 0.01116354,\n",
            "       0.01979147, 0.01428561, 0.03130665, 0.00504356, 0.00469101,\n",
            "       0.03075942, 0.10558769, 0.10826262, 0.0232414 , 0.00491294,\n",
            "       0.05561922, 0.00547941, 0.01064538, 0.02539565, 0.00795125,\n",
            "       0.00689763, 0.05453119, 0.00678907, 0.01066899, 0.00599984,\n",
            "       0.00668756, 0.00512849, 0.00826141, 0.01178872, 0.02005908,\n",
            "       0.01432477, 0.00421561, 0.027301  , 0.04065876, 0.00424149,\n",
            "       0.06153001, 0.00446212, 0.01196353, 0.00384544, 0.00655518,\n",
            "       0.04866379, 0.06676511, 0.02300391, 0.03516246, 0.00927361,\n",
            "       0.04031338, 0.02201874, 0.01328566, 0.0046269 , 0.00686048,\n",
            "       0.00449187, 0.06031994, 0.00618776, 0.03270476, 0.01214544,\n",
            "       0.01001939, 0.11902614, 0.03723099, 0.04280743, 0.02554963,\n",
            "       0.00712566, 0.00737431, 0.00845878, 0.02370599, 0.0116754 ,\n",
            "       0.01807058, 0.00365032, 0.0043259 , 0.03023092, 0.01245878,\n",
            "       0.00688165, 0.05873339, 0.02813594, 0.04051984, 0.08696553,\n",
            "       0.05186114, 0.0906565 , 0.00587936, 0.02543519, 0.01486768,\n",
            "       0.06363583, 0.1253997 , 0.05537828, 0.03690019, 0.04323415,\n",
            "       0.00766441, 0.00740462, 0.04261266, 0.07036171, 0.07234272,\n",
            "       0.09370586, 0.05182309, 0.040014  , 0.04951333, 0.00718254,\n",
            "       0.00378344, 0.06350954, 0.00712345, 0.0391713 , 0.01127278,\n",
            "       0.00692695, 0.05115547, 0.00537496, 0.03919813, 0.02760674,\n",
            "       0.02075683, 0.1526311 , 0.02711292, 0.00733166, 0.02330843,\n",
            "       0.04293753, 0.0151346 , 0.03497163, 0.00553039, 0.01455365,\n",
            "       0.00974005, 0.01466127, 0.00472266, 0.00828894, 0.00459754,\n",
            "       0.0069361 , 0.02935788, 0.06768548, 0.01249221, 0.12454233,\n",
            "       0.07153708, 0.05163391, 0.11511135, 0.09932515, 0.04906738,\n",
            "       0.02966161, 0.02534228, 0.01343006, 0.03946703, 0.0137352 ,\n",
            "       0.00578557, 0.03440648, 0.03306469, 0.00399126, 0.0084314 ,\n",
            "       0.01686648, 0.00783225, 0.01234852, 0.03973723, 0.00556503,\n",
            "       0.01217044, 0.01382667, 0.03891919, 0.03830446, 0.18396844,\n",
            "       0.02114398, 0.06975438, 0.20166555, 0.05047501, 0.01466177,\n",
            "       0.06008377, 0.05169147, 0.01529245, 0.0107617 , 0.08508462,\n",
            "       0.03307551, 0.12049969, 0.00785972, 0.07094488, 0.01986851,\n",
            "       0.01414712, 0.00985361, 0.03585658, 0.00456054, 0.01828581,\n",
            "       0.00928944, 0.00881991, 0.06006772, 0.09679583, 0.00627331,\n",
            "       0.06872479, 0.03166188, 0.00828073, 0.00601713, 0.00640405,\n",
            "       0.00558626, 0.01988911, 0.00664478, 0.09134286, 0.0093186 ,\n",
            "       0.00818833, 0.01473003, 0.00745358, 0.00432857, 0.01023294,\n",
            "       0.02838606, 0.00817908, 0.00382813, 0.00460896, 0.01697086,\n",
            "       0.01088845, 0.00585248, 0.0064565 , 0.04831006, 0.00523452,\n",
            "       0.00922605, 0.0054345 , 0.01087166, 0.01636712, 0.00855087,\n",
            "       0.03525226, 0.00736016, 0.11252686, 0.02024275, 0.01106307,\n",
            "       0.00517958, 0.00597671, 0.00587812, 0.01758733, 0.00590414,\n",
            "       0.00589899, 0.02920495, 0.00866867, 0.09644888, 0.00489087,\n",
            "       0.02596777, 0.02447874, 0.07899971, 0.0103634 , 0.17790882,\n",
            "       0.06725983, 0.03293494, 0.00367846, 0.03310936, 0.05909581,\n",
            "       0.00540746, 0.05625601, 0.02619892, 0.00494259, 0.00662095,\n",
            "       0.02498363, 0.00527646, 0.11043847, 0.06428715, 0.00552325,\n",
            "       0.0076539 , 0.051582  , 0.02202091, 0.03941733, 0.04003998,\n",
            "       0.03181668, 0.02574915, 0.01230784, 0.00825069, 0.0052864 ,\n",
            "       0.04472925, 0.03386112, 0.00921408, 0.03186223, 0.01812647,\n",
            "       0.00465024, 0.00815886, 0.02242204, 0.03797688, 0.00724449,\n",
            "       0.00644846, 0.01544751, 0.00798128, 0.01964419, 0.04787493,\n",
            "       0.00921116, 0.09983763, 0.02413194, 0.00708023, 0.00556445,\n",
            "       0.03916216, 0.03396485, 0.03531872, 0.00860569, 0.04507761,\n",
            "       0.01959944, 0.01007124, 0.01865469, 0.00751454, 0.01020887,\n",
            "       0.00597567, 0.01297123, 0.04540406, 0.03464372, 0.04458827,\n",
            "       0.04517052, 0.03961388, 0.05249535, 0.01270237, 0.09722719,\n",
            "       0.00885464, 0.07356159, 0.00666823, 0.006098  , 0.00947903,\n",
            "       0.20784576, 0.01943451, 0.01973827, 0.01931252, 0.00475938,\n",
            "       0.01119714, 0.0054339 , 0.05195725, 0.00576528, 0.08772141,\n",
            "       0.06574439, 0.00591477, 0.02557622, 0.01048533, 0.00785789,\n",
            "       0.11784135, 0.01793161, 0.02584504, 0.00675861, 0.00689689],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/skip/skip_project/conv2d/bn/FusedBatchNormV3', 'index': 264, 'shape': array([144], dtype=int32), 'shape_signature': array([144], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.7371776e-03, 3.3044556e-04, 4.7065929e-04, 4.7427148e-04,\n",
            "       1.1821437e-03, 2.1716370e-03, 1.6970421e-03, 1.3921197e-03,\n",
            "       6.6967087e-04, 1.5981077e-03, 5.1530777e-04, 9.7698357e-04,\n",
            "       1.8882606e-03, 3.5951310e-04, 4.0990952e-04, 2.3259784e-03,\n",
            "       1.6379632e-03, 5.2488403e-04, 1.2153457e-03, 1.6896517e-03,\n",
            "       2.3988418e-03, 1.6957984e-03, 9.3146018e-04, 1.7421093e-03,\n",
            "       1.6678091e-03, 6.3646701e-04, 1.0118429e-03, 1.4969166e-03,\n",
            "       2.1106675e-03, 5.5684661e-04, 2.0027135e-03, 2.2481605e-03,\n",
            "       4.3510512e-04, 1.8050256e-03, 2.8166178e-04, 1.4998208e-03,\n",
            "       1.4625157e-03, 1.4875584e-03, 4.6521859e-04, 5.7468354e-04,\n",
            "       1.1721257e-03, 1.0629564e-03, 2.8479003e-04, 2.0209332e-03,\n",
            "       6.3046551e-04, 1.2073014e-03, 1.0765331e-03, 1.5068795e-03,\n",
            "       1.1516681e-03, 1.3924040e-03, 1.0701601e-03, 1.4700299e-03,\n",
            "       1.9566712e-03, 6.1300595e-04, 1.4519545e-03, 2.6079584e-03,\n",
            "       1.4669721e-03, 4.4091971e-04, 6.5364258e-04, 1.3144424e-03,\n",
            "       6.5661466e-04, 1.1738308e-03, 2.0939510e-03, 3.6896814e-05,\n",
            "       5.7534833e-04, 3.4377445e-04, 1.5410370e-03, 4.7466109e-04,\n",
            "       9.3719852e-04, 6.2532950e-04, 1.1496665e-03, 1.2313311e-03,\n",
            "       6.4096221e-04, 2.4877854e-03, 4.5666241e-04, 7.5015414e-04,\n",
            "       4.3369576e-04, 6.1001058e-04, 7.9333875e-04, 4.2578983e-04,\n",
            "       5.0145778e-04, 3.0043055e-04, 8.7472243e-04, 1.1604626e-03,\n",
            "       1.0101940e-03, 2.1862024e-03, 1.6523158e-03, 1.8997882e-03,\n",
            "       1.8684975e-03, 1.2017989e-03, 4.7939696e-04, 2.0744456e-03,\n",
            "       6.0182315e-04, 6.7331514e-04, 1.1576620e-03, 4.8284695e-04,\n",
            "       1.5158254e-03, 2.5492338e-03, 1.0343574e-03, 7.3037477e-04,\n",
            "       1.5748339e-03, 7.4515480e-04, 2.3556396e-04, 2.1433560e-03,\n",
            "       4.1502577e-04, 1.4382399e-03, 1.4243489e-03, 6.2780973e-04,\n",
            "       8.0784503e-04, 3.1842529e-03, 7.3864998e-04, 3.7942725e-04,\n",
            "       7.3925644e-04, 7.9901383e-04, 1.5499069e-03, 1.2411093e-04,\n",
            "       8.6953363e-04, 2.3264713e-03, 6.1738299e-04, 4.6482048e-04,\n",
            "       7.0112321e-04, 1.1136527e-03, 1.4618308e-03, 2.3723043e-04,\n",
            "       2.3545867e-03, 1.2201617e-03, 1.9163889e-03, 1.0668382e-03,\n",
            "       7.0242689e-04, 7.0248637e-04, 3.0884714e-04, 1.3113240e-03,\n",
            "       2.4189693e-03, 7.6836557e-04, 1.8569521e-03, 9.0294931e-04,\n",
            "       6.6760735e-04, 6.7706488e-04, 8.9176034e-04, 1.4536605e-03,\n",
            "       8.0474123e-04, 8.7007135e-04, 8.6901389e-04, 3.9674123e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/skip/skip_project/conv2d/conv2d_4/Conv2D', 'index': 265, 'shape': array([144,   1,   1,  72], dtype=int32), 'shape_signature': array([144,   1,   1,  72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.6650395e-03, 3.1672345e-04, 4.5111467e-04, 4.5457686e-04,\n",
            "       1.1330539e-03, 2.0814575e-03, 1.6265707e-03, 1.3343104e-03,\n",
            "       6.4186211e-04, 1.5317446e-03, 4.9390906e-04, 9.3641330e-04,\n",
            "       1.8098486e-03, 3.4458394e-04, 3.9288760e-04, 2.2293897e-03,\n",
            "       1.5699450e-03, 5.0308765e-04, 1.1648772e-03, 1.6194872e-03,\n",
            "       2.2992273e-03, 1.6253785e-03, 8.9278031e-04, 1.6697664e-03,\n",
            "       1.5985515e-03, 6.1003707e-04, 9.6982502e-04, 1.4347556e-03,\n",
            "       2.0230198e-03, 5.3372298e-04, 1.9195486e-03, 2.1548034e-03,\n",
            "       4.1703691e-04, 1.7300700e-03, 2.6996547e-04, 1.4375392e-03,\n",
            "       1.4017832e-03, 1.4257859e-03, 4.4589990e-04, 5.5081921e-04,\n",
            "       1.1234520e-03, 1.0188160e-03, 2.7296384e-04, 1.9370117e-03,\n",
            "       6.0428475e-04, 1.1571669e-03, 1.0318289e-03, 1.4443047e-03,\n",
            "       1.1038439e-03, 1.3345829e-03, 1.0257205e-03, 1.4089854e-03,\n",
            "       1.8754184e-03, 5.8755022e-04, 1.3916605e-03, 2.4996602e-03,\n",
            "       1.4060545e-03, 4.2261006e-04, 6.2649936e-04, 1.2598587e-03,\n",
            "       6.2934804e-04, 1.1250862e-03, 2.0069974e-03, 3.5364636e-05,\n",
            "       5.5145635e-04, 3.2949884e-04, 1.4770438e-03, 4.5495029e-04,\n",
            "       8.9828036e-04, 5.9936201e-04, 1.1019254e-03, 1.1801989e-03,\n",
            "       6.1434560e-04, 2.3844775e-03, 4.3769903e-04, 7.1900320e-04,\n",
            "       4.1568608e-04, 5.8467925e-04, 7.6039450e-04, 4.0810846e-04,\n",
            "       4.8063419e-04, 2.8795484e-04, 8.3839864e-04, 1.1122732e-03,\n",
            "       9.6824463e-04, 2.0954181e-03, 1.5837017e-03, 1.8208975e-03,\n",
            "       1.7909061e-03, 1.1518929e-03, 4.5948950e-04, 1.9883020e-03,\n",
            "       5.7683181e-04, 6.4535503e-04, 1.1095889e-03, 4.6279622e-04,\n",
            "       1.4528792e-03, 2.4433741e-03, 9.9140452e-04, 7.0004520e-04,\n",
            "       1.5094372e-03, 7.1421143e-04, 2.2578191e-04, 2.0543509e-03,\n",
            "       3.9779139e-04, 1.3785155e-03, 1.3652013e-03, 6.0173927e-04,\n",
            "       7.7429839e-04, 3.0520235e-03, 7.0797675e-04, 3.6367113e-04,\n",
            "       7.0855801e-04, 7.6583395e-04, 1.4855454e-03, 1.1895708e-04,\n",
            "       8.3342532e-04, 2.2298621e-03, 5.9174548e-04, 4.4551832e-04,\n",
            "       6.7200832e-04, 1.0674071e-03, 1.4011267e-03, 2.2737919e-04,\n",
            "       2.2568100e-03, 1.1694932e-03, 1.8368087e-03, 1.0225365e-03,\n",
            "       6.7325786e-04, 6.7331491e-04, 2.9602193e-04, 1.2568699e-03,\n",
            "       2.3185189e-03, 7.3645840e-04, 1.7798402e-03, 8.6545339e-04,\n",
            "       6.3988427e-04, 6.4894906e-04, 8.5472903e-04, 1.3932957e-03,\n",
            "       7.7132351e-04, 8.3394069e-04, 8.3292718e-04, 3.8026614e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 266, 'shape': array([480], dtype=int32), 'shape_signature': array([480], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([7.09314074e-04, 2.40039208e-05, 6.88588596e-04, 8.54366881e-05,\n",
            "       1.72357846e-04, 5.27894124e-04, 6.40213955e-04, 5.58637956e-04,\n",
            "       4.07657324e-04, 5.53888618e-04, 2.71645520e-04, 1.76164322e-04,\n",
            "       3.05342954e-04, 6.33876363e-04, 5.05233220e-05, 7.30509928e-04,\n",
            "       2.06687968e-04, 9.34879572e-05, 7.71136605e-04, 1.57193397e-04,\n",
            "       6.25299464e-04, 5.47197938e-04, 8.86288821e-04, 2.88226962e-04,\n",
            "       1.76366430e-05, 5.95319783e-04, 1.70766492e-04, 9.13801487e-04,\n",
            "       6.89165841e-04, 1.77896896e-03, 8.65289112e-05, 6.39930659e-04,\n",
            "       1.18510250e-03, 7.30622851e-05, 3.28784459e-04, 8.57470324e-04,\n",
            "       2.27881115e-04, 3.34552577e-04, 5.58739586e-04, 6.57202967e-04,\n",
            "       8.01751215e-04, 1.88358827e-04, 1.28960324e-04, 8.40332068e-04,\n",
            "       1.48647378e-04, 2.11240680e-04, 7.07184023e-04, 4.25745879e-04,\n",
            "       5.58012980e-04, 1.87520025e-04, 2.89443706e-04, 2.06935641e-04,\n",
            "       1.96832581e-04, 4.02270322e-04, 5.19990514e-04, 4.06027626e-04,\n",
            "       6.98613469e-04, 7.11316534e-04, 7.85559649e-04, 7.66182668e-04,\n",
            "       7.96357344e-04, 3.31037387e-04, 1.69432734e-03, 6.23471220e-04,\n",
            "       4.55197296e-04, 6.16289792e-04, 2.24999400e-04, 6.50148490e-04,\n",
            "       2.51354184e-04, 4.61720774e-05, 6.09865005e-04, 7.86757562e-04,\n",
            "       8.31422745e-04, 1.83428565e-04, 7.02532590e-04, 6.04501634e-04,\n",
            "       7.54883979e-04, 5.68748161e-04, 1.48445601e-04, 6.81610894e-04,\n",
            "       6.66420266e-04, 5.26624382e-04, 6.86003594e-04, 5.34664956e-04,\n",
            "       3.90620407e-04, 5.64898364e-04, 6.66993801e-05, 7.28762825e-04,\n",
            "       1.86343605e-04, 2.27242359e-04, 4.31236520e-04, 1.70443644e-04,\n",
            "       1.00146499e-04, 5.03650226e-04, 7.54129898e-04, 4.92380990e-04,\n",
            "       8.77149927e-04, 2.21515627e-04, 5.82166656e-04, 9.24228734e-05,\n",
            "       8.55918974e-04, 6.22121268e-04, 2.13340405e-04, 8.01440852e-04,\n",
            "       1.27511972e-04, 6.08798291e-05, 5.17041481e-04, 5.31021564e-04,\n",
            "       4.80798801e-04, 3.84012616e-04, 4.79413429e-04, 1.87143800e-04,\n",
            "       1.23135280e-04, 6.93505048e-04, 7.16850744e-04, 2.25303607e-04,\n",
            "       6.86674379e-04, 6.27289584e-04, 1.55112415e-04, 9.31414615e-05,\n",
            "       2.57368549e-04, 1.57305141e-04, 7.09285494e-04, 7.01517158e-04,\n",
            "       7.30390952e-04, 6.87977416e-04, 1.63786719e-03, 2.59148190e-04,\n",
            "       4.58358438e-04, 2.23153416e-04, 4.48197970e-04, 1.14287157e-03,\n",
            "       1.11399789e-03, 1.32406902e-04, 7.34274916e-04, 7.15098344e-04,\n",
            "       5.08786528e-04, 1.49797983e-04, 5.89815143e-04, 6.38131634e-04,\n",
            "       6.73327420e-04, 6.45056658e-04, 1.10968991e-04, 1.75171881e-04,\n",
            "       1.02782942e-04, 4.74924804e-04, 6.93891561e-05, 9.15402954e-04,\n",
            "       4.08963315e-05, 7.89842627e-04, 7.84498581e-04, 4.12899099e-04,\n",
            "       2.87230476e-04, 1.34114164e-03, 8.88874463e-04, 2.35898333e-04,\n",
            "       7.43889599e-04, 7.46086531e-04, 7.40799238e-04, 6.37656194e-04,\n",
            "       5.61267545e-04, 6.64011866e-04, 7.15876406e-04, 7.45089259e-04,\n",
            "       9.53533890e-05, 2.02079117e-03, 4.50635125e-04, 2.71198247e-03,\n",
            "       6.89122826e-05, 1.54789793e-03, 4.03248414e-04, 1.02696111e-04,\n",
            "       1.21391895e-04, 3.67099565e-04, 1.03816052e-03, 5.82739667e-05,\n",
            "       9.59201017e-04, 3.81926620e-05, 7.53474233e-05, 7.38020695e-04,\n",
            "       2.36708380e-04, 5.23843511e-04, 3.86108499e-04, 1.21651996e-04,\n",
            "       8.95388075e-04, 8.55317805e-04, 7.87484532e-05, 7.46001315e-04,\n",
            "       7.26268336e-04, 7.46080303e-04, 9.16215475e-04, 6.44493208e-04,\n",
            "       7.73799140e-04, 6.15731231e-04, 3.52097279e-03, 5.70760109e-04,\n",
            "       6.17837475e-04, 1.73126435e-04, 1.64240517e-03, 6.91940426e-04,\n",
            "       6.81921883e-05, 7.27871084e-04, 1.08935009e-03, 8.76441482e-04,\n",
            "       7.91208528e-04, 1.88985679e-04, 2.53519160e-04, 5.18977351e-04,\n",
            "       6.97055875e-05, 5.53619815e-04, 7.10720051e-05, 1.93048618e-04,\n",
            "       4.70349973e-04, 2.64646165e-04, 6.49350986e-04, 6.59981219e-04,\n",
            "       2.84438895e-04, 9.18722653e-04, 1.25438964e-04, 1.34314905e-04,\n",
            "       1.94428634e-04, 2.89207004e-04, 1.55146699e-04, 4.45986108e-04,\n",
            "       2.77128100e-04, 7.73888896e-04, 8.62189103e-04, 5.80622000e-04,\n",
            "       1.72370987e-04, 2.47602467e-04, 4.27156425e-04, 1.23502547e-03,\n",
            "       5.94186014e-04, 1.41723722e-04, 5.66349656e-04, 9.18069913e-04,\n",
            "       1.16520314e-04, 9.19752711e-05, 1.51134981e-03, 1.17961354e-04,\n",
            "       1.56371412e-03, 8.80682273e-05, 8.06485186e-04, 6.98514850e-05,\n",
            "       5.67495772e-05, 8.38111373e-05, 2.93125107e-04, 1.87104408e-04,\n",
            "       1.98966794e-04, 4.92971267e-05, 6.34413795e-04, 1.56205567e-03,\n",
            "       5.27818687e-04, 8.18064902e-04, 1.14061404e-03, 8.56231927e-05,\n",
            "       8.26996344e-04, 1.34747097e-04, 6.33995864e-04, 4.41270560e-04,\n",
            "       5.85173024e-04, 2.69269192e-04, 7.30544620e-04, 9.15843339e-05,\n",
            "       6.21163985e-04, 8.00051668e-04, 9.68684762e-05, 5.27773751e-04,\n",
            "       8.14542727e-05, 1.89965504e-04, 1.27529795e-03, 6.29026617e-05,\n",
            "       1.38007657e-04, 4.34004876e-04, 7.92856517e-05, 3.87288630e-04,\n",
            "       2.03641411e-03, 4.19230200e-04, 6.00529253e-04, 1.45627244e-04,\n",
            "       5.64980262e-04, 8.90449272e-04, 8.73885059e-04, 6.26925670e-04,\n",
            "       7.24241603e-04, 7.63315649e-04, 6.42800238e-04, 1.09055988e-03,\n",
            "       2.10895058e-04, 2.38526220e-04, 5.05900767e-04, 1.13839254e-04,\n",
            "       5.77245701e-05, 5.61701832e-04, 2.12290601e-04, 1.23259349e-04,\n",
            "       4.30406100e-04, 3.58864869e-04, 8.93145771e-05, 5.77586703e-04,\n",
            "       7.68192229e-04, 1.11342968e-04, 2.77489482e-04, 7.54649402e-04,\n",
            "       9.82717844e-04, 7.26931961e-04, 9.95964510e-04, 4.41157783e-04,\n",
            "       8.45787217e-05, 6.04781962e-04, 3.16989637e-04, 6.24162029e-04,\n",
            "       1.29170628e-04, 3.04326502e-04, 4.87028155e-05, 2.50190124e-03,\n",
            "       3.91825510e-04, 6.48814093e-05, 1.89581653e-04, 5.15963591e-04,\n",
            "       7.56847265e-04, 1.46492181e-04, 2.20060712e-04, 5.52758866e-04,\n",
            "       4.78211470e-04, 3.53319396e-04, 4.19228250e-04, 5.43519331e-04,\n",
            "       1.96075038e-04, 1.52392924e-04, 7.02772930e-04, 2.13451730e-03,\n",
            "       1.56082897e-04, 5.85850910e-04, 1.78632909e-04, 8.81454675e-04,\n",
            "       1.70686923e-04, 7.61811563e-04, 7.93008003e-05, 6.02852204e-04,\n",
            "       7.78471003e-05, 2.41957358e-04, 2.23693743e-04, 4.80933115e-04,\n",
            "       7.57401460e-04, 5.21200127e-04, 5.06664568e-04, 4.83814889e-04,\n",
            "       2.37631888e-04, 1.56741322e-03, 7.02829158e-04, 5.32541366e-04,\n",
            "       5.67315437e-04, 6.06129644e-04, 6.00959873e-04, 1.84259552e-04,\n",
            "       4.41279175e-04, 7.18012161e-04, 6.68967783e-04, 5.29163575e-04,\n",
            "       7.65603676e-04, 6.95611234e-04, 5.62750385e-04, 8.52459852e-05,\n",
            "       6.65394473e-04, 6.50251983e-04, 8.03817762e-04, 2.51268793e-04,\n",
            "       1.33912149e-03, 5.65200520e-04, 1.09628018e-04, 9.90517554e-04,\n",
            "       7.95568121e-05, 1.03539649e-04, 4.16576804e-04, 4.93223139e-04,\n",
            "       6.37559395e-04, 7.34959554e-04, 4.49667190e-04, 5.41527406e-04,\n",
            "       5.94149518e-04, 1.41298879e-04, 4.74911736e-04, 1.19819415e-04,\n",
            "       5.83800138e-04, 2.97680468e-04, 8.85319081e-04, 7.66756129e-05,\n",
            "       6.50705246e-04, 5.63375579e-05, 1.06872385e-03, 9.93619979e-05,\n",
            "       7.25000806e-04, 7.21125456e-04, 3.77383782e-04, 7.94056919e-04,\n",
            "       3.86845022e-05, 1.19971759e-04, 6.93892071e-04, 1.22553459e-03,\n",
            "       8.44060851e-04, 7.90751947e-04, 9.63401908e-05, 5.67003081e-05,\n",
            "       8.37752130e-04, 6.35366829e-04, 8.16067914e-05, 2.04988034e-03,\n",
            "       1.50373948e-04, 1.78088885e-04, 1.37655530e-04, 1.16024504e-03,\n",
            "       2.39943620e-04, 2.52448663e-04, 6.83314516e-04, 2.60906178e-04,\n",
            "       3.06300906e-04, 7.00753648e-04, 1.60750467e-04, 5.95789636e-04,\n",
            "       5.09462785e-04, 8.75544036e-04, 2.54741259e-04, 1.77120557e-04,\n",
            "       1.28090708e-03, 8.08437646e-04, 4.08724649e-04, 5.10044687e-04,\n",
            "       2.44603085e-04, 2.06022392e-04, 1.08423911e-03, 3.52448493e-04,\n",
            "       6.99122844e-04, 4.76485962e-04, 6.48505811e-04, 1.34929345e-04,\n",
            "       2.00632654e-04, 7.18805604e-05, 5.45488263e-04, 4.86321049e-04,\n",
            "       1.15319403e-04, 3.26605717e-04, 4.17788659e-04, 5.99900435e-04,\n",
            "       1.32636551e-03, 4.47457976e-04, 1.44380110e-03, 7.89122860e-05,\n",
            "       5.70632692e-04, 1.99250440e-04, 7.71249397e-05, 1.05610794e-04,\n",
            "       5.56836567e-05, 3.98497068e-04, 2.16494795e-04, 6.80127006e-04,\n",
            "       8.03850242e-04, 8.96875688e-04, 7.51231972e-04, 6.91623834e-04,\n",
            "       5.79856423e-05, 5.91027958e-04, 4.86186618e-04, 6.09910057e-04,\n",
            "       4.82334464e-04, 3.59613012e-04, 1.00422313e-03, 1.26087602e-04,\n",
            "       6.22268242e-04, 5.02903968e-05, 2.83883768e-04, 8.28309567e-04,\n",
            "       5.74540114e-04, 5.68024872e-04, 7.95605825e-04, 3.28437200e-05,\n",
            "       3.37521866e-04, 4.07746236e-04, 6.42978819e-04, 7.67863996e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 267, 'shape': array([  1,   3,   3, 480], dtype=int32), 'shape_signature': array([  1,   3,   3, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01403411, 0.00047493, 0.01362405, 0.0016904 , 0.00341018,\n",
            "       0.01044463, 0.01266693, 0.01105291, 0.00806569, 0.01095894,\n",
            "       0.00537463, 0.00348549, 0.00604135, 0.01254154, 0.00099963,\n",
            "       0.01445348, 0.00408942, 0.0018497 , 0.0152573 , 0.00311014,\n",
            "       0.01237184, 0.01082657, 0.01753564, 0.00570271, 0.00034895,\n",
            "       0.01177868, 0.00337869, 0.01807999, 0.01363547, 0.03519773,\n",
            "       0.00171201, 0.01266133, 0.02344781, 0.00144557, 0.00650515,\n",
            "       0.01696545, 0.00450873, 0.00661928, 0.01105492, 0.01300307,\n",
            "       0.01586302, 0.00372677, 0.00255154, 0.01662636, 0.00294106,\n",
            "       0.0041795 , 0.01399197, 0.00842358, 0.01104055, 0.00371017,\n",
            "       0.00572678, 0.00409432, 0.00389442, 0.00795911, 0.01028825,\n",
            "       0.00803345, 0.01382239, 0.01407373, 0.01554266, 0.01515928,\n",
            "       0.0157563 , 0.00654973, 0.03352306, 0.01233567, 0.00900629,\n",
            "       0.01219358, 0.00445172, 0.01286349, 0.00497316, 0.00091354,\n",
            "       0.01206646, 0.01556637, 0.01645009, 0.00362922, 0.01389993,\n",
            "       0.01196035, 0.01493573, 0.01125295, 0.00293707, 0.01348599,\n",
            "       0.01318544, 0.01041951, 0.0135729 , 0.0105786 , 0.00772861,\n",
            "       0.01117678, 0.00131968, 0.01441891, 0.0036869 , 0.0044961 ,\n",
            "       0.00853222, 0.00337231, 0.00198145, 0.00996496, 0.01492081,\n",
            "       0.00974199, 0.01735482, 0.00438279, 0.01151844, 0.00182863,\n",
            "       0.01693476, 0.01230896, 0.00422104, 0.01585688, 0.00252288,\n",
            "       0.00120454, 0.01022991, 0.01050651, 0.00951283, 0.00759787,\n",
            "       0.00948542, 0.00370273, 0.00243629, 0.01372132, 0.01418323,\n",
            "       0.00445774, 0.01358617, 0.01241122, 0.00306897, 0.00184285,\n",
            "       0.00509216, 0.00311236, 0.01403354, 0.01387984, 0.01445113,\n",
            "       0.01361195, 0.03240597, 0.00512737, 0.00906884, 0.00441519,\n",
            "       0.00886781, 0.02261225, 0.02204097, 0.00261973, 0.01452797,\n",
            "       0.01414855, 0.01006658, 0.00296382, 0.01166977, 0.01262573,\n",
            "       0.0133221 , 0.01276275, 0.00219557, 0.00346586, 0.00203361,\n",
            "       0.00939661, 0.0013729 , 0.01811167, 0.00080915, 0.0156274 ,\n",
            "       0.01552167, 0.0081694 , 0.00568299, 0.02653511, 0.0175868 ,\n",
            "       0.00466736, 0.0147182 , 0.01476167, 0.01465706, 0.01261633,\n",
            "       0.01110494, 0.01313778, 0.01416395, 0.01474194, 0.00188661,\n",
            "       0.0399823 , 0.00891603, 0.05365784, 0.00136346, 0.03062588,\n",
            "       0.00797846, 0.00203189, 0.0024018 , 0.00726324, 0.02054049,\n",
            "       0.00115298, 0.01897824, 0.00075566, 0.00149078, 0.01460208,\n",
            "       0.00468339, 0.01036449, 0.00763934, 0.00240694, 0.01771567,\n",
            "       0.01692286, 0.00155807, 0.01475998, 0.01436956, 0.01476155,\n",
            "       0.01812775, 0.0127516 , 0.01530998, 0.01218253, 0.06966409,\n",
            "       0.01129275, 0.0122242 , 0.00342539, 0.03249575, 0.01369036,\n",
            "       0.00134921, 0.01440127, 0.0215533 , 0.0173408 , 0.01565443,\n",
            "       0.00373917, 0.00501599, 0.01026821, 0.00137916, 0.01095363,\n",
            "       0.00140619, 0.00381956, 0.00930609, 0.00523615, 0.01284771,\n",
            "       0.01305804, 0.00562776, 0.01817736, 0.00248187, 0.00265748,\n",
            "       0.00384686, 0.0057221 , 0.00306965, 0.00882404, 0.00548311,\n",
            "       0.01531175, 0.01705881, 0.01148788, 0.00341044, 0.00489893,\n",
            "       0.00845149, 0.02443556, 0.01175625, 0.00280407, 0.01120549,\n",
            "       0.01816444, 0.00230541, 0.00181977, 0.02990276, 0.00233392,\n",
            "       0.03093881, 0.00174247, 0.01595668, 0.00138204, 0.00112282,\n",
            "       0.00165824, 0.00579962, 0.00370195, 0.00393665, 0.00097537,\n",
            "       0.01255217, 0.030906  , 0.01044314, 0.0161858 , 0.02256758,\n",
            "       0.00169409, 0.01636251, 0.00266603, 0.0125439 , 0.00873074,\n",
            "       0.01157792, 0.00532762, 0.01445417, 0.00181204, 0.01229002,\n",
            "       0.0158294 , 0.00191659, 0.01044225, 0.00161161, 0.00375856,\n",
            "       0.02523237, 0.00124456, 0.00273055, 0.00858699, 0.0015687 ,\n",
            "       0.00766269, 0.0402914 , 0.00829467, 0.01188175, 0.0028813 ,\n",
            "       0.0111784 , 0.01761795, 0.01729022, 0.01240402, 0.01432946,\n",
            "       0.01510256, 0.0127181 , 0.02157724, 0.00417266, 0.00471935,\n",
            "       0.01000948, 0.00225236, 0.00114211, 0.01111353, 0.00420027,\n",
            "       0.00243874, 0.00851579, 0.00710031, 0.00176713, 0.01142782,\n",
            "       0.01519904, 0.00220297, 0.00549026, 0.01493109, 0.01944353,\n",
            "       0.01438269, 0.01970562, 0.00872851, 0.00167343, 0.01196589,\n",
            "       0.00627179, 0.01234934, 0.0025557 , 0.00602124, 0.00096361,\n",
            "       0.04950128, 0.00775245, 0.00128371, 0.00375096, 0.01020858,\n",
            "       0.01497458, 0.00289842, 0.004354  , 0.01093659, 0.00946164,\n",
            "       0.00699059, 0.00829463, 0.01075378, 0.00387944, 0.00301516,\n",
            "       0.01390469, 0.04223242, 0.00308817, 0.01159133, 0.00353434,\n",
            "       0.01743999, 0.00337712, 0.0150728 , 0.001569  , 0.01192771,\n",
            "       0.00154024, 0.00478724, 0.00442589, 0.00951549, 0.01498554,\n",
            "       0.01031219, 0.0100246 , 0.0095725 , 0.00470166, 0.031012  ,\n",
            "       0.0139058 , 0.01053658, 0.0112246 , 0.01199256, 0.01189027,\n",
            "       0.00364566, 0.00873091, 0.01420621, 0.01323584, 0.01046975,\n",
            "       0.01514783, 0.01376299, 0.01113428, 0.00168663, 0.01316514,\n",
            "       0.01286554, 0.01590391, 0.00497147, 0.02649514, 0.01118276,\n",
            "       0.00216904, 0.01959785, 0.00157407, 0.00204858, 0.00824217,\n",
            "       0.00975865, 0.01261441, 0.01454152, 0.00889688, 0.01071437,\n",
            "       0.01175553, 0.00279566, 0.00939635, 0.00237068, 0.01155076,\n",
            "       0.00588975, 0.01751645, 0.00151706, 0.01287451, 0.00111466,\n",
            "       0.0211452 , 0.00196592, 0.01434448, 0.0142678 , 0.00746671,\n",
            "       0.01571079, 0.00076539, 0.0023737 , 0.01372898, 0.02424777,\n",
            "       0.01670014, 0.0156454 , 0.00190614, 0.00112184, 0.01657532,\n",
            "       0.01257103, 0.00161463, 0.04055784, 0.00297522, 0.00352357,\n",
            "       0.00272358, 0.02295599, 0.0047474 , 0.00499481, 0.0135197 ,\n",
            "       0.00516215, 0.00606031, 0.01386474, 0.00318052, 0.01178798,\n",
            "       0.01007996, 0.01732305, 0.00504017, 0.00350441, 0.02534334,\n",
            "       0.01599532, 0.00808681, 0.01009147, 0.00483959, 0.00407625,\n",
            "       0.02145218, 0.00697336, 0.01383247, 0.0094275 , 0.01283099,\n",
            "       0.00266964, 0.00396961, 0.00142219, 0.01079274, 0.00962209,\n",
            "       0.00228165, 0.00646205, 0.00826614, 0.01186931, 0.02624276,\n",
            "       0.00885316, 0.02856628, 0.00156132, 0.01129023, 0.00394226,\n",
            "       0.00152595, 0.00208956, 0.00110173, 0.00788445, 0.00428345,\n",
            "       0.01345663, 0.01590455, 0.0177451 , 0.01486347, 0.0136841 ,\n",
            "       0.00114727, 0.01169376, 0.00961943, 0.01206736, 0.00954321,\n",
            "       0.00711511, 0.01986902, 0.0024947 , 0.01231187, 0.00099502,\n",
            "       0.00561677, 0.01638849, 0.01136754, 0.01123864, 0.01574143,\n",
            "       0.00064983, 0.00667803, 0.00806745, 0.01272164, 0.01519255],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 268, 'shape': array([480], dtype=int32), 'shape_signature': array([480], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.47046189e-05, 2.76284845e-04, 1.50276974e-04, 1.69334569e-04,\n",
            "       1.24701852e-04, 2.02247058e-04, 1.98648646e-04, 2.01685019e-04,\n",
            "       1.31666602e-04, 1.62469601e-04, 2.78846477e-04, 2.34535808e-04,\n",
            "       2.21807699e-04, 2.06321041e-04, 1.90949839e-04, 2.13783191e-04,\n",
            "       6.59763537e-05, 1.11276371e-04, 2.90497905e-04, 1.61654811e-04,\n",
            "       1.98325259e-04, 1.24628525e-04, 5.23442213e-05, 1.67100065e-04,\n",
            "       3.22750449e-04, 2.35734115e-04, 1.15181414e-04, 2.33551516e-04,\n",
            "       2.35095489e-04, 2.14258289e-05, 1.08069253e-04, 2.05596763e-04,\n",
            "       1.10391818e-04, 1.76995076e-04, 1.60645272e-04, 9.46392902e-05,\n",
            "       1.62447657e-04, 1.31985827e-04, 2.33840547e-04, 2.79348489e-04,\n",
            "       3.19505983e-04, 4.73247710e-05, 2.20362053e-04, 1.92240419e-04,\n",
            "       7.12535621e-05, 8.97646823e-05, 3.32324817e-05, 9.64207720e-05,\n",
            "       2.77532643e-04, 4.20345423e-05, 3.40859660e-05, 9.05814450e-05,\n",
            "       6.24881286e-05, 1.84799923e-04, 3.24981957e-04, 3.73665025e-05,\n",
            "       7.11209432e-05, 1.85721292e-04, 2.99751729e-04, 7.56530135e-05,\n",
            "       1.64667115e-04, 1.74118140e-05, 4.80999151e-05, 1.24990940e-04,\n",
            "       1.38246905e-04, 3.51154886e-05, 6.19147977e-05, 2.18862348e-04,\n",
            "       9.09061928e-05, 1.25765670e-04, 2.11640479e-04, 1.41582248e-04,\n",
            "       1.36823670e-04, 9.48475790e-05, 2.30420177e-04, 1.34255606e-04,\n",
            "       3.19003120e-05, 2.46081880e-04, 3.02444794e-04, 2.80589622e-04,\n",
            "       2.35926665e-04, 2.97635910e-04, 3.16281104e-04, 1.01416706e-04,\n",
            "       1.31079258e-04, 1.48097897e-04, 2.28870893e-04, 2.42380047e-04,\n",
            "       9.52568298e-05, 9.79565084e-05, 5.19499081e-05, 6.03517619e-05,\n",
            "       1.31029970e-04, 1.05875217e-04, 2.05394303e-04, 1.99569215e-04,\n",
            "       2.59968976e-04, 4.51936867e-05, 3.27284943e-04, 1.19387005e-04,\n",
            "       2.22666742e-04, 2.39259636e-04, 1.53325454e-04, 2.03081625e-04,\n",
            "       8.35083483e-05, 1.54382142e-04, 2.26761025e-04, 2.66151619e-04,\n",
            "       3.00383981e-04, 2.09823738e-05, 9.14097982e-05, 8.39929417e-05,\n",
            "       1.64245692e-04, 2.12070066e-04, 1.77810929e-04, 5.41425798e-05,\n",
            "       9.90083427e-05, 1.80967836e-04, 5.35176005e-05, 1.30835208e-04,\n",
            "       6.11045471e-05, 1.04545208e-04, 2.17707202e-04, 4.32860805e-04,\n",
            "       2.28142118e-04, 2.64011644e-04, 3.92146139e-05, 3.61649960e-04,\n",
            "       2.08099620e-04, 1.28570304e-04, 1.08401509e-04, 2.16731150e-05,\n",
            "       4.88703263e-05, 1.41252036e-04, 2.41287256e-04, 3.39264770e-05,\n",
            "       1.61278222e-04, 1.95640634e-04, 2.09775506e-04, 1.56576192e-04,\n",
            "       2.03187577e-04, 1.94313339e-04, 1.15512208e-04, 1.31329303e-04,\n",
            "       1.66569953e-04, 9.20861567e-05, 2.72740290e-04, 1.04242863e-04,\n",
            "       1.95677596e-04, 1.61570380e-04, 1.61052725e-04, 1.05306986e-04,\n",
            "       4.43330282e-05, 2.97907263e-05, 2.38072374e-04, 7.10599488e-05,\n",
            "       1.90434133e-04, 1.67057544e-04, 2.16516491e-04, 1.86632591e-04,\n",
            "       1.76223693e-04, 4.45908809e-05, 9.50653921e-05, 4.82845528e-04,\n",
            "       1.62233468e-04, 2.39513392e-05, 1.42070698e-04, 2.75833700e-05,\n",
            "       1.33879730e-04, 6.57381242e-05, 1.43808778e-04, 1.51276909e-04,\n",
            "       1.37946263e-04, 1.54546215e-04, 2.15034568e-04, 3.61182756e-04,\n",
            "       3.07689152e-05, 2.24815391e-04, 2.85810704e-04, 2.23538154e-04,\n",
            "       5.57391286e-05, 2.98842526e-04, 2.21579656e-04, 1.33480702e-04,\n",
            "       2.01714676e-04, 3.34639044e-04, 1.14253235e-04, 1.86801495e-04,\n",
            "       9.42924889e-05, 1.45168247e-04, 4.10536391e-04, 1.67810314e-04,\n",
            "       2.27021927e-04, 1.67971943e-04, 2.00065333e-05, 1.11488633e-04,\n",
            "       2.17626221e-04, 2.37541972e-04, 5.13660343e-05, 2.14118219e-04,\n",
            "       2.10141327e-04, 1.64723941e-04, 5.22424780e-05, 1.16016403e-04,\n",
            "       1.62745404e-04, 3.67889515e-05, 7.76875895e-05, 6.18488630e-05,\n",
            "       1.62646218e-04, 1.75853551e-04, 2.86724244e-04, 2.43896502e-04,\n",
            "       9.03584732e-05, 1.72328349e-04, 1.91049854e-04, 1.64585028e-04,\n",
            "       4.09063869e-05, 3.37396748e-04, 1.06582760e-04, 2.33564700e-04,\n",
            "       2.02156196e-04, 5.84439586e-05, 1.00866513e-04, 3.90551613e-05,\n",
            "       1.42561039e-04, 2.62988382e-04, 2.26540797e-04, 2.42176393e-04,\n",
            "       1.17858195e-04, 1.61479446e-04, 8.51537989e-05, 1.19289318e-04,\n",
            "       2.86924391e-04, 1.50721753e-04, 1.05848667e-04, 2.00902025e-04,\n",
            "       1.79460010e-04, 1.62687094e-04, 3.83474253e-05, 7.21123943e-05,\n",
            "       3.11752337e-05, 6.23016822e-05, 2.24283562e-04, 1.26292260e-04,\n",
            "       3.17782135e-04, 1.09124026e-04, 2.72588622e-05, 8.56980405e-05,\n",
            "       6.15309400e-05, 3.51905590e-04, 1.66675149e-04, 1.25440696e-04,\n",
            "       3.51168601e-05, 5.89947049e-05, 2.24867017e-05, 9.50593749e-05,\n",
            "       4.65283847e-05, 5.74737751e-05, 5.83209221e-05, 1.77239301e-04,\n",
            "       3.45399138e-04, 6.18474660e-05, 3.04498244e-04, 1.54718189e-04,\n",
            "       2.62641290e-04, 2.24374249e-04, 8.01596543e-05, 2.31689308e-04,\n",
            "       2.32140243e-04, 8.09395206e-05, 4.05264072e-05, 7.04273843e-05,\n",
            "       2.45623029e-04, 2.70582736e-04, 2.82310590e-04, 5.72850113e-05,\n",
            "       3.25042238e-05, 6.80358862e-05, 2.46873853e-04, 2.13474239e-04,\n",
            "       1.59017582e-04, 8.89216244e-05, 1.92545936e-04, 2.73446378e-04,\n",
            "       1.79196577e-04, 2.91712349e-04, 4.62991411e-05, 3.27454036e-05,\n",
            "       1.38812480e-04, 2.45055980e-05, 6.00120584e-05, 1.21700912e-04,\n",
            "       1.07053209e-04, 2.68627919e-05, 1.16664880e-04, 1.72223765e-04,\n",
            "       7.15648785e-05, 1.39266325e-04, 2.46790267e-04, 2.36905034e-04,\n",
            "       2.28075092e-04, 2.22265444e-04, 5.18051420e-05, 2.37893633e-04,\n",
            "       3.08875955e-04, 7.47884187e-05, 2.42102600e-04, 1.70088199e-04,\n",
            "       1.43230296e-04, 2.43687842e-04, 2.81756162e-04, 9.36990109e-05,\n",
            "       1.04243562e-04, 4.83090844e-05, 1.42641162e-04, 4.54408582e-05,\n",
            "       6.40100188e-05, 1.18974152e-04, 5.61913585e-05, 8.27933109e-05,\n",
            "       4.22874691e-05, 9.03127293e-05, 2.51606747e-04, 2.34616658e-04,\n",
            "       3.92120055e-05, 1.15540228e-04, 3.77494543e-05, 2.30899692e-04,\n",
            "       8.40135326e-05, 1.67510429e-04, 8.59589636e-05, 2.66654213e-04,\n",
            "       1.01182894e-04, 2.83979083e-04, 3.07667040e-04, 1.23414153e-04,\n",
            "       3.09603522e-04, 5.05023127e-05, 8.55828694e-05, 5.45864808e-04,\n",
            "       9.70355541e-05, 6.12308795e-05, 1.56757014e-04, 3.18398408e-04,\n",
            "       2.33436527e-04, 1.60428724e-04, 1.63869816e-04, 1.88264006e-04,\n",
            "       3.65586275e-05, 2.36948792e-04, 1.73726134e-04, 1.48258492e-04,\n",
            "       2.08487385e-04, 3.75293603e-04, 1.62303302e-04, 1.08479217e-04,\n",
            "       1.94127977e-04, 2.66409159e-04, 2.21682028e-04, 1.46176011e-04,\n",
            "       1.32820904e-04, 2.03094838e-04, 2.21562572e-04, 4.25778067e-04,\n",
            "       1.60393160e-04, 2.30877107e-04, 2.06483295e-04, 2.27420882e-04,\n",
            "       5.09865167e-05, 2.11430000e-04, 1.00283090e-04, 3.75693926e-04,\n",
            "       6.70829104e-05, 2.94764992e-04, 1.70732397e-04, 2.73366197e-04,\n",
            "       2.02795229e-04, 3.94551869e-04, 8.59014108e-05, 2.71096098e-04,\n",
            "       2.04466502e-04, 4.17670177e-04, 1.84191638e-04, 6.14033488e-05,\n",
            "       1.58058028e-04, 1.36515358e-04, 5.14266030e-05, 7.93126746e-05,\n",
            "       1.35419090e-04, 1.04779654e-04, 2.91660344e-05, 1.19919881e-04,\n",
            "       2.03781266e-04, 4.23589918e-05, 3.46270390e-05, 2.16243949e-04,\n",
            "       2.43949617e-04, 1.52556837e-04, 1.66809230e-04, 4.80599236e-04,\n",
            "       3.78511359e-05, 1.83020733e-04, 6.00605454e-05, 1.49524625e-04,\n",
            "       3.27310641e-04, 1.63831282e-04, 1.46053921e-04, 4.17774536e-05,\n",
            "       1.56782335e-04, 1.15452247e-04, 1.02515180e-04, 4.89312151e-05,\n",
            "       1.12136848e-04, 2.00579685e-04, 2.23476207e-04, 5.96685386e-05,\n",
            "       5.69738659e-05, 1.82606891e-04, 1.63233111e-04, 9.75580260e-05,\n",
            "       2.10283601e-04, 1.70272513e-04, 1.26715313e-04, 6.81010788e-05,\n",
            "       2.28974241e-04, 2.39631539e-04, 9.10325834e-05, 1.40199627e-04,\n",
            "       1.20493482e-04, 5.97668950e-05, 1.08668472e-04, 2.01860748e-05,\n",
            "       6.10317256e-05, 2.47714430e-04, 1.98518755e-04, 5.45088951e-05,\n",
            "       9.03301407e-05, 1.51799031e-04, 1.85401455e-04, 2.84715279e-05,\n",
            "       1.38508272e-04, 1.74382192e-04, 8.79978106e-05, 2.41042479e-04,\n",
            "       1.54481924e-04, 2.04628057e-04, 5.47323289e-05, 1.36954593e-04,\n",
            "       5.55227125e-05, 6.43819003e-05, 2.03368400e-04, 1.60639378e-04,\n",
            "       3.60255130e-04, 2.50420038e-04, 3.76574862e-05, 1.62732322e-04,\n",
            "       6.54688192e-05, 2.34061299e-04, 2.17638968e-04, 9.79610850e-05,\n",
            "       2.27958066e-04, 1.33570327e-04, 6.66849737e-05, 6.00733147e-05,\n",
            "       2.23993455e-04, 1.40563367e-04, 1.07859356e-04, 2.00372044e-04,\n",
            "       3.94766597e-04, 7.94744585e-04, 4.41310636e-04, 1.62686760e-04,\n",
            "       1.06841951e-04, 1.78894479e-04, 2.25359589e-04, 2.63571914e-04,\n",
            "       1.86097910e-04, 6.58115023e-05, 3.35872552e-04, 2.25903714e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 269, 'shape': array([480,   1,   1,  72], dtype=int32), 'shape_signature': array([480,   1,   1,  72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.32634736e-05, 2.64811824e-04, 1.44036560e-04, 1.62302778e-04,\n",
            "       1.19523480e-04, 1.93848537e-04, 1.90399543e-04, 1.93309839e-04,\n",
            "       1.26199011e-04, 1.55722882e-04, 2.67267082e-04, 2.24796458e-04,\n",
            "       2.12596904e-04, 1.97753339e-04, 1.83020442e-04, 2.04905620e-04,\n",
            "       6.32366136e-05, 1.06655505e-04, 2.78434658e-04, 1.54941925e-04,\n",
            "       1.90089588e-04, 1.19453194e-04, 5.01705726e-05, 1.60161057e-04,\n",
            "       3.09347903e-04, 2.25945012e-04, 1.10398381e-04, 2.23853043e-04,\n",
            "       2.25332900e-04, 2.05360993e-05, 1.03581566e-04, 1.97059140e-04,\n",
            "       1.05807681e-04, 1.69645165e-04, 1.53974310e-04, 9.07092908e-05,\n",
            "       1.55701840e-04, 1.26504980e-04, 2.24130068e-04, 2.67748255e-04,\n",
            "       3.06238158e-04, 4.53595603e-05, 2.11211285e-04, 1.84257427e-04,\n",
            "       6.82946848e-05, 8.60371074e-05, 3.18524690e-05, 9.24167980e-05,\n",
            "       2.66007817e-04, 4.02890146e-05, 3.26705085e-05, 8.68199568e-05,\n",
            "       5.98932420e-05, 1.77125912e-04, 3.11486743e-04, 3.58148172e-05,\n",
            "       6.81675738e-05, 1.78009024e-04, 2.87304225e-04, 7.25114442e-05,\n",
            "       1.57829141e-04, 1.66887694e-05, 4.61025156e-05, 1.19800563e-04,\n",
            "       1.32506058e-04, 3.36572812e-05, 5.93437180e-05, 2.09773862e-04,\n",
            "       8.71312150e-05, 1.20543118e-04, 2.02851879e-04, 1.35702896e-04,\n",
            "       1.31141918e-04, 9.09089358e-05, 2.20851740e-04, 1.28680505e-04,\n",
            "       3.05756184e-05, 2.35863074e-04, 2.89885444e-04, 2.68937845e-04,\n",
            "       2.26129559e-04, 2.85276270e-04, 3.03147186e-04, 9.72052731e-05,\n",
            "       1.25636056e-04, 1.41947981e-04, 2.19366790e-04, 2.32314953e-04,\n",
            "       9.13011900e-05, 9.38887606e-05, 4.97926339e-05, 5.78455911e-05,\n",
            "       1.25588806e-04, 1.01478639e-04, 1.96865090e-04, 1.91281884e-04,\n",
            "       2.49173492e-04, 4.33169698e-05, 3.13694094e-04, 1.14429335e-04,\n",
            "       2.13420266e-04, 2.29324127e-04, 1.46958453e-04, 1.94648441e-04,\n",
            "       8.00405760e-05, 1.47971266e-04, 2.17344539e-04, 2.55099381e-04,\n",
            "       2.87910225e-04, 2.01110579e-05, 8.76139093e-05, 8.05050440e-05,\n",
            "       1.57425209e-04, 2.03263626e-04, 1.70427142e-04, 5.18942506e-05,\n",
            "       9.48969173e-05, 1.73452951e-04, 5.12952247e-05, 1.25402134e-04,\n",
            "       5.85671187e-05, 1.00203855e-04, 2.08666679e-04, 4.14885813e-04,\n",
            "       2.18668269e-04, 2.53048289e-04, 3.75861855e-05, 3.46632063e-04,\n",
            "       1.99458067e-04, 1.23231279e-04, 1.03900020e-04, 2.07731155e-05,\n",
            "       4.68409344e-05, 1.35386392e-04, 2.31267550e-04, 3.25176443e-05,\n",
            "       1.54580979e-04, 1.87516445e-04, 2.01064351e-04, 1.50074193e-04,\n",
            "       1.94749999e-04, 1.86244273e-04, 1.10715438e-04, 1.25875711e-04,\n",
            "       1.59652962e-04, 8.82621825e-05, 2.61414447e-04, 9.99140684e-05,\n",
            "       1.87551879e-04, 1.54861002e-04, 1.54364840e-04, 1.00934005e-04,\n",
            "       4.24920509e-05, 2.85536353e-05, 2.28186167e-04, 6.81091115e-05,\n",
            "       1.82526157e-04, 1.60120297e-04, 2.07525416e-04, 1.78882474e-04,\n",
            "       1.68905812e-04, 4.27391969e-05, 9.11176976e-05, 4.62794851e-04,\n",
            "       1.55496557e-04, 2.29567340e-05, 1.36171060e-04, 2.64379414e-05,\n",
            "       1.28320229e-04, 6.30082795e-05, 1.37836963e-04, 1.44994978e-04,\n",
            "       1.32217901e-04, 1.48128514e-04, 2.06105033e-04, 3.46184272e-04,\n",
            "       2.94912043e-05, 2.15479697e-04, 2.73942103e-04, 2.14255502e-04,\n",
            "       5.34245009e-05, 2.86432769e-04, 2.12378320e-04, 1.27937776e-04,\n",
            "       1.93338259e-04, 3.20742809e-04, 1.09508750e-04, 1.79044364e-04,\n",
            "       9.03768960e-05, 1.39139986e-04, 3.93488444e-04, 1.60841810e-04,\n",
            "       2.17594599e-04, 1.60996729e-04, 1.91757408e-05, 1.06858948e-04,\n",
            "       2.08589059e-04, 2.27677796e-04, 4.92330037e-05, 2.05226737e-04,\n",
            "       2.01414980e-04, 1.57883609e-04, 5.00730530e-05, 1.11198700e-04,\n",
            "       1.55987233e-04, 3.52612515e-05, 7.44615318e-05, 5.92805227e-05,\n",
            "       1.55892165e-04, 1.68551051e-04, 2.74817721e-04, 2.33768442e-04,\n",
            "       8.66062401e-05, 1.65172227e-04, 1.83116310e-04, 1.57750459e-04,\n",
            "       3.92077054e-05, 3.23385990e-04, 1.02156795e-04, 2.23865674e-04,\n",
            "       1.93761443e-04, 5.60170120e-05, 9.66779262e-05, 3.74333540e-05,\n",
            "       1.36641043e-04, 2.52067519e-04, 2.17133449e-04, 2.32119768e-04,\n",
            "       1.12964008e-04, 1.54773836e-04, 8.16176980e-05, 1.14335700e-04,\n",
            "       2.75009545e-04, 1.44462872e-04, 1.01453188e-04, 1.92559353e-04,\n",
            "       1.72007742e-04, 1.55931339e-04, 3.67550092e-05, 6.91178502e-05,\n",
            "       2.98806481e-05, 5.97145408e-05, 2.14969943e-04, 1.21047844e-04,\n",
            "       3.04585905e-04, 1.04592538e-04, 2.61269088e-05, 8.21393405e-05,\n",
            "       5.89758056e-05, 3.37292324e-04, 1.59753792e-04, 1.20231642e-04,\n",
            "       3.36585945e-05, 5.65448863e-05, 2.15529180e-05, 9.11119350e-05,\n",
            "       4.45962432e-05, 5.50871155e-05, 5.58990832e-05, 1.69879248e-04,\n",
            "       3.31056071e-04, 5.92791876e-05, 2.91853619e-04, 1.48293359e-04,\n",
            "       2.51734833e-04, 2.15056876e-04, 7.68309401e-05, 2.22068164e-04,\n",
            "       2.22500370e-04, 7.75784210e-05, 3.88435037e-05, 6.75028132e-05,\n",
            "       2.35423271e-04, 2.59346503e-04, 2.70587334e-04, 5.49061915e-05,\n",
            "       3.11544500e-05, 6.52106246e-05, 2.36622145e-04, 2.04609489e-04,\n",
            "       1.52414214e-04, 8.52290614e-05, 1.84550256e-04, 2.62091227e-04,\n",
            "       1.71755251e-04, 2.79598695e-04, 4.43765202e-05, 3.13856144e-05,\n",
            "       1.33048146e-04, 2.34879772e-05, 5.75199956e-05, 1.16647156e-04,\n",
            "       1.02607708e-04, 2.57472857e-05, 1.11820249e-04, 1.65071993e-04,\n",
            "       6.85930718e-05, 1.33483147e-04, 2.36542051e-04, 2.27067299e-04,\n",
            "       2.18604036e-04, 2.13035630e-04, 4.96538778e-05, 2.28014847e-04,\n",
            "       2.96049548e-04, 7.16827490e-05, 2.32049031e-04, 1.63025106e-04,\n",
            "       1.37282506e-04, 2.33568440e-04, 2.70055927e-04, 8.98080616e-05,\n",
            "       9.99147378e-05, 4.63029974e-05, 1.36717834e-04, 4.35538786e-05,\n",
            "       6.13519369e-05, 1.14033624e-04, 5.38579516e-05, 7.93552317e-05,\n",
            "       4.05314386e-05, 8.65623952e-05, 2.41158516e-04, 2.24873947e-04,\n",
            "       3.75836862e-05, 1.10742294e-04, 3.61818675e-05, 2.21311333e-04,\n",
            "       8.05247837e-05, 1.60554380e-04, 8.23894297e-05, 2.55581108e-04,\n",
            "       9.69811663e-05, 2.72186560e-04, 2.94890837e-04, 1.18289252e-04,\n",
            "       2.96746904e-04, 4.84051488e-05, 8.20289497e-05, 5.23197174e-04,\n",
            "       9.30060487e-05, 5.86882015e-05, 1.50247506e-04, 3.05176567e-04,\n",
            "       2.23742827e-04, 1.53766756e-04, 1.57064947e-04, 1.80446150e-04,\n",
            "       3.50404916e-05, 2.27109238e-04, 1.66511978e-04, 1.42101897e-04,\n",
            "       1.99829723e-04, 3.59709142e-04, 1.55563481e-04, 1.03974504e-04,\n",
            "       1.86066609e-04, 2.55346240e-04, 2.12476443e-04, 1.40105898e-04,\n",
            "       1.27305379e-04, 1.94661116e-04, 2.12361949e-04, 4.08097170e-04,\n",
            "       1.53732661e-04, 2.21289694e-04, 1.97908856e-04, 2.17976994e-04,\n",
            "       4.88692458e-05, 2.02650146e-04, 9.61187252e-05, 3.60092847e-04,\n",
            "       6.42972227e-05, 2.82524561e-04, 1.63642559e-04, 2.62014364e-04,\n",
            "       1.94373948e-04, 3.78167693e-04, 8.23342634e-05, 2.59838533e-04,\n",
            "       1.95975808e-04, 4.00325982e-04, 1.76542890e-04, 5.88535077e-05,\n",
            "       1.51494503e-04, 1.30846413e-04, 4.92910585e-05, 7.60191324e-05,\n",
            "       1.29795662e-04, 1.00428566e-04, 2.79548840e-05, 1.14940078e-04,\n",
            "       1.95319037e-04, 4.05999890e-05, 3.31891133e-05, 2.07264195e-04,\n",
            "       2.33819344e-04, 1.46221748e-04, 1.59882300e-04, 4.60641837e-04,\n",
            "       3.62793289e-05, 1.75420602e-04, 5.75664671e-05, 1.43315454e-04,\n",
            "       3.13718716e-04, 1.57028015e-04, 1.39988872e-04, 4.00425997e-05,\n",
            "       1.50271779e-04, 1.10657973e-04, 9.82581259e-05, 4.68992948e-05,\n",
            "       1.07480249e-04, 1.92250402e-04, 2.14196116e-04, 5.71907403e-05,\n",
            "       5.46079646e-05, 1.75023946e-04, 1.56454684e-04, 9.35068238e-05,\n",
            "       2.01551346e-04, 1.63201767e-04, 1.21453319e-04, 6.52731105e-05,\n",
            "       2.19465845e-04, 2.29680591e-04, 8.72523597e-05, 1.34377682e-04,\n",
            "       1.15489864e-04, 5.72850113e-05, 1.04155901e-04, 1.93478263e-05,\n",
            "       5.84973168e-05, 2.37427827e-04, 1.90275052e-04, 5.22453556e-05,\n",
            "       8.65790862e-05, 1.45495418e-04, 1.77702459e-04, 2.72892175e-05,\n",
            "       1.32756570e-04, 1.67140781e-04, 8.43436064e-05, 2.31032929e-04,\n",
            "       1.48066902e-04, 1.96130655e-04, 5.24595125e-05, 1.31267414e-04,\n",
            "       5.32170743e-05, 6.17083715e-05, 1.94923312e-04, 1.53968664e-04,\n",
            "       3.45295150e-04, 2.40021080e-04, 3.60937192e-05, 1.55974689e-04,\n",
            "       6.27501577e-05, 2.24341653e-04, 2.08601283e-04, 9.38931480e-05,\n",
            "       2.18491870e-04, 1.28023676e-04, 6.39158097e-05, 5.75787053e-05,\n",
            "       2.14691885e-04, 1.34726317e-04, 1.03380378e-04, 1.92051375e-04,\n",
            "       3.78373486e-04, 7.61741947e-04, 4.22984740e-04, 1.55931019e-04,\n",
            "       1.02405225e-04, 1.71465697e-04, 2.16001295e-04, 2.52626807e-04,\n",
            "       1.78369999e-04, 6.30786089e-05, 3.21925094e-04, 2.16522822e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/rezero/mul', 'index': 270, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.008440016768872738, 127), 'quantization_parameters': {'scales': array([0.00844002], dtype=float32), 'zero_points': array([127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 271, 'shape': array([72], dtype=int32), 'shape_signature': array([72], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00061441, 0.0006025 , 0.00037597, 0.0005347 , 0.00078911,\n",
            "       0.00060956, 0.00082796, 0.00068021, 0.00077356, 0.00067725,\n",
            "       0.00075548, 0.00057321, 0.00050273, 0.00041447, 0.00043457,\n",
            "       0.00058839, 0.00049948, 0.00067126, 0.00071466, 0.00084289,\n",
            "       0.00034931, 0.00085486, 0.00079695, 0.00077723, 0.00074785,\n",
            "       0.00074795, 0.00049047, 0.00044452, 0.00056622, 0.00066808,\n",
            "       0.00070838, 0.00060429, 0.00064323, 0.00045982, 0.00072567,\n",
            "       0.00061317, 0.00053075, 0.00078114, 0.00060878, 0.00066164,\n",
            "       0.00048938, 0.00063367, 0.00183454, 0.00066216, 0.00077094,\n",
            "       0.00075381, 0.00080909, 0.0006486 , 0.00046346, 0.00054509,\n",
            "       0.00068084, 0.00058916, 0.00078039, 0.00054212, 0.00067644,\n",
            "       0.00073533, 0.00080632, 0.00062011, 0.00044989, 0.00051654,\n",
            "       0.00052036, 0.00077427, 0.00053623, 0.00060282, 0.00048306,\n",
            "       0.00066162, 0.00062913, 0.00064733, 0.00065543, 0.00060264,\n",
            "       0.00057723, 0.00064147], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 272, 'shape': array([ 72,   1,   1, 240], dtype=int32), 'shape_signature': array([ 72,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01244554, 0.01220431, 0.00761574, 0.01083103, 0.01598436,\n",
            "       0.01234735, 0.01677123, 0.01377848, 0.0156694 , 0.01371854,\n",
            "       0.01530311, 0.011611  , 0.01018335, 0.00839549, 0.00880263,\n",
            "       0.01191853, 0.01011746, 0.01359709, 0.01447618, 0.01707358,\n",
            "       0.00707566, 0.01731622, 0.01614318, 0.0157436 , 0.01514856,\n",
            "       0.01515062, 0.00993496, 0.0090043 , 0.01146949, 0.0135328 ,\n",
            "       0.01434895, 0.01224059, 0.01302943, 0.00931419, 0.01469923,\n",
            "       0.01242045, 0.01075089, 0.01582291, 0.01233151, 0.01340224,\n",
            "       0.00991299, 0.01283561, 0.03716074, 0.01341282, 0.01561628,\n",
            "       0.01526927, 0.01638895, 0.01313806, 0.00938789, 0.01104131,\n",
            "       0.01379117, 0.01193407, 0.01580757, 0.01098124, 0.01370197,\n",
            "       0.01489484, 0.01633295, 0.01256104, 0.00911301, 0.01046307,\n",
            "       0.01054043, 0.01568368, 0.01086185, 0.01221076, 0.00978489,\n",
            "       0.01340188, 0.01274367, 0.01311248, 0.01327638, 0.01220704,\n",
            "       0.01169233, 0.01299365], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 273, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.29460893e-05, 1.66718164e-05, 1.72290602e-05, 1.82581098e-05,\n",
            "       5.10007776e-05, 2.00959767e-05, 1.81643209e-05, 4.07915941e-05,\n",
            "       1.34656775e-05, 2.30312071e-05, 1.50956303e-05, 2.14870070e-05,\n",
            "       2.01179846e-05, 1.27351714e-05, 1.92979005e-05, 2.72500783e-05,\n",
            "       2.17591314e-05, 3.45462686e-05, 2.82656729e-05, 1.48737654e-05,\n",
            "       1.76230333e-05, 5.72629961e-06, 4.49407125e-05, 7.46046135e-06,\n",
            "       1.69253890e-05, 2.18041441e-05, 2.00895938e-05, 2.12953601e-05,\n",
            "       2.84600046e-05, 1.52547800e-05, 1.27419116e-05, 1.92414591e-05,\n",
            "       2.97328679e-05, 2.40578975e-05, 2.97483057e-05, 1.60583077e-05,\n",
            "       2.30200440e-05, 2.24269261e-05, 2.36181113e-05, 1.76678113e-05,\n",
            "       4.70998093e-05, 3.10119322e-05, 3.24700886e-05, 5.27146331e-05,\n",
            "       1.72634318e-05, 1.96830479e-05, 1.50745063e-05, 2.13062885e-05,\n",
            "       1.16327255e-05, 2.11907318e-05, 1.36978260e-05, 1.64646535e-05,\n",
            "       2.01691564e-05, 9.03928685e-06, 1.91767431e-05, 1.12347998e-05,\n",
            "       2.27720375e-05, 2.62235426e-05, 1.82768999e-05, 1.83777029e-05,\n",
            "       2.44956336e-05, 1.96345391e-05, 8.67770941e-05, 1.33047852e-05,\n",
            "       3.26985974e-05, 1.18228281e-05, 2.28097088e-05, 1.85504196e-05,\n",
            "       2.27632827e-05, 3.92425063e-05, 2.37941040e-05, 1.31507541e-05,\n",
            "       2.37019158e-05, 1.23314703e-05, 2.18116584e-05, 4.83878903e-05,\n",
            "       1.44836795e-05, 1.58704097e-05, 4.17816846e-05, 8.14439863e-06,\n",
            "       1.55243815e-05, 1.25906854e-05, 4.28929452e-05, 5.12654287e-06,\n",
            "       3.60058766e-05, 1.06790203e-05, 2.81014218e-05, 2.04911103e-05,\n",
            "       1.61715943e-05, 2.16467051e-05, 1.93307787e-05, 1.41965093e-05,\n",
            "       4.63096985e-05, 1.54592817e-05, 1.58180155e-05, 1.02472377e-05,\n",
            "       2.16696262e-05, 3.80206511e-05, 3.50485097e-05, 2.39127785e-05,\n",
            "       2.84418438e-05, 4.52778186e-05, 2.55776267e-05, 2.06041150e-05,\n",
            "       1.88438007e-05, 1.38251662e-05, 2.00094692e-05, 3.69557747e-05,\n",
            "       1.85909375e-05, 2.61456080e-05, 3.03190682e-05, 5.56159721e-05,\n",
            "       1.41999026e-05, 5.07317782e-05, 1.37115767e-05, 1.71809334e-05,\n",
            "       3.58662692e-05, 1.52268103e-05, 2.24359355e-05, 1.42205163e-05,\n",
            "       2.28737190e-05, 1.80375300e-05, 2.25339336e-05, 2.35197094e-05,\n",
            "       2.83247882e-05, 1.35343289e-05, 3.04676869e-05, 2.10005419e-05,\n",
            "       2.24207070e-05, 1.58754938e-05, 2.49335844e-05, 1.74291727e-05,\n",
            "       2.03635918e-05, 9.52993923e-06, 2.18286823e-05, 1.88530157e-05,\n",
            "       2.59981171e-05, 4.04724378e-05, 1.35797281e-05, 2.54783731e-06,\n",
            "       2.04540793e-05, 2.77332492e-05, 3.37780912e-05, 1.93619308e-05,\n",
            "       8.00617181e-06, 1.77423299e-05, 2.72675588e-05, 2.67436244e-05,\n",
            "       6.91813966e-06, 1.49155712e-05, 2.16652970e-05, 1.82019776e-05,\n",
            "       1.59558476e-05, 7.63823846e-06, 1.70745225e-05, 3.20744875e-05,\n",
            "       1.62884462e-05, 7.43586088e-06, 1.49462894e-05, 2.44845905e-05,\n",
            "       1.23017226e-05, 2.77499348e-05, 1.33440863e-05, 1.69371233e-05,\n",
            "       7.86042528e-06, 1.68649331e-05, 1.51709564e-05, 1.18608941e-05,\n",
            "       1.99227252e-05, 2.46618310e-05, 3.12055236e-05, 2.30130227e-05,\n",
            "       9.68589757e-06, 4.74786975e-05, 1.72445125e-05, 3.55504708e-05,\n",
            "       1.83010434e-05, 1.70118328e-05, 4.52738896e-05, 1.65825149e-05,\n",
            "       1.68874776e-05, 2.11876322e-05, 1.96057463e-05, 1.71822267e-05,\n",
            "       2.34981289e-05, 1.19734204e-05, 2.46724576e-05, 2.74552422e-05,\n",
            "       1.98594989e-05, 5.66761992e-06, 2.50298290e-05, 7.96448603e-06,\n",
            "       2.93321227e-05, 1.74803481e-05, 1.37961952e-05, 6.78131892e-06,\n",
            "       1.92449825e-05, 1.52178300e-05, 1.54482041e-05, 1.35824448e-05,\n",
            "       1.23608825e-05, 2.04621847e-05, 2.78604693e-05, 1.63609602e-05,\n",
            "       4.70122322e-05, 1.22152460e-05, 3.78337318e-05, 1.71967349e-05,\n",
            "       2.91684410e-05, 7.26775943e-06, 2.55602554e-05, 3.56626661e-05,\n",
            "       9.12640189e-06, 1.39081585e-05, 2.49665991e-05, 5.08386438e-06,\n",
            "       1.99306342e-05, 1.20909108e-05, 2.68395452e-05, 2.20229540e-05,\n",
            "       1.05747995e-05, 3.77944198e-05, 3.48281246e-05, 2.25258409e-05,\n",
            "       1.48290883e-05, 3.44245673e-05, 1.45240056e-05, 3.62992068e-05,\n",
            "       1.97605932e-05, 2.07609119e-05, 2.34441268e-05, 6.61503191e-06,\n",
            "       1.89477851e-05, 7.53185714e-06, 1.98907965e-05, 1.46352604e-05,\n",
            "       2.62384874e-05, 1.54143800e-05, 1.30124608e-05, 2.12798222e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 274, 'shape': array([240,   1,   1, 120], dtype=int32), 'shape_signature': array([240,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00122386, 0.00088921, 0.00091893, 0.00097382, 0.00272019,\n",
            "       0.00107184, 0.00096882, 0.00217567, 0.00071821, 0.0012284 ,\n",
            "       0.00080514, 0.00114604, 0.00107302, 0.00067925, 0.00102928,\n",
            "       0.00145342, 0.00116055, 0.00184257, 0.00150758, 0.00079331,\n",
            "       0.00093995, 0.00030542, 0.00239697, 0.00039791, 0.00090274,\n",
            "       0.00116295, 0.0010715 , 0.00113581, 0.00151795, 0.00081363,\n",
            "       0.00067961, 0.00102627, 0.00158584, 0.00128316, 0.00158666,\n",
            "       0.00085649, 0.0012278 , 0.00119617, 0.0012597 , 0.00094233,\n",
            "       0.00251213, 0.00165406, 0.00173183, 0.0028116 , 0.00092077,\n",
            "       0.00104982, 0.00080402, 0.0011364 , 0.00062045, 0.00113023,\n",
            "       0.00073059, 0.00087816, 0.00107575, 0.00048212, 0.00102281,\n",
            "       0.00059922, 0.00121457, 0.00139866, 0.00097482, 0.0009802 ,\n",
            "       0.0013065 , 0.00104723, 0.00462836, 0.00070963, 0.00174402,\n",
            "       0.00063058, 0.00121658, 0.00098941, 0.00121411, 0.00209305,\n",
            "       0.00126909, 0.00070141, 0.00126417, 0.00065771, 0.00116335,\n",
            "       0.00258083, 0.0007725 , 0.00084647, 0.00222848, 0.00043439,\n",
            "       0.00082801, 0.00067154, 0.00228775, 0.00027343, 0.00192042,\n",
            "       0.00056958, 0.00149882, 0.00109292, 0.00086253, 0.00115455,\n",
            "       0.00103103, 0.00075719, 0.00246998, 0.00082454, 0.00084367,\n",
            "       0.00054655, 0.00115578, 0.00202788, 0.00186935, 0.00127542,\n",
            "       0.00151698, 0.00241495, 0.00136421, 0.00109895, 0.00100506,\n",
            "       0.00073738, 0.00106723, 0.00197108, 0.00099157, 0.00139451,\n",
            "       0.0016171 , 0.00296634, 0.00075737, 0.00270584, 0.00073132,\n",
            "       0.00091637, 0.00191297, 0.00081214, 0.00119665, 0.00075847,\n",
            "       0.00122   , 0.00096205, 0.00120187, 0.00125445, 0.00151074,\n",
            "       0.00072187, 0.00162503, 0.00112009, 0.00119584, 0.00084674,\n",
            "       0.00132986, 0.00092961, 0.00108612, 0.00050829, 0.00116426,\n",
            "       0.00100555, 0.00138664, 0.00215865, 0.00072429, 0.00013589,\n",
            "       0.00109094, 0.00147919, 0.0018016 , 0.00103269, 0.00042702,\n",
            "       0.00094631, 0.00145435, 0.0014264 , 0.00036899, 0.00079554,\n",
            "       0.00115554, 0.00097082, 0.00085102, 0.00040739, 0.00091069,\n",
            "       0.00171073, 0.00086876, 0.0003966 , 0.00079718, 0.00130592,\n",
            "       0.00065613, 0.00148008, 0.00071172, 0.00090336, 0.00041925,\n",
            "       0.00089951, 0.00080916, 0.00063262, 0.0010626 , 0.00131537,\n",
            "       0.00166438, 0.00122743, 0.00051661, 0.00253233, 0.00091976,\n",
            "       0.00189613, 0.00097611, 0.00090735, 0.00241474, 0.00088445,\n",
            "       0.00090071, 0.00113007, 0.0010457 , 0.00091643, 0.0012533 ,\n",
            "       0.00063862, 0.00131594, 0.00146436, 0.00105923, 0.00030229,\n",
            "       0.001335  , 0.0004248 , 0.00156446, 0.00093234, 0.00073584,\n",
            "       0.00036169, 0.00102645, 0.00081166, 0.00082395, 0.00072444,\n",
            "       0.00065928, 0.00109138, 0.00148597, 0.00087263, 0.00250745,\n",
            "       0.00065151, 0.00201791, 0.00091721, 0.00155573, 0.00038763,\n",
            "       0.00136329, 0.00190211, 0.00048677, 0.00074181, 0.00133162,\n",
            "       0.00027115, 0.00106302, 0.00064488, 0.00143152, 0.00117462,\n",
            "       0.00056402, 0.00201581, 0.0018576 , 0.00120144, 0.00079093,\n",
            "       0.00183608, 0.00077466, 0.00193606, 0.00105396, 0.00110731,\n",
            "       0.00125042, 0.00035282, 0.0010106 , 0.00040172, 0.0010609 ,\n",
            "       0.00078059, 0.00139946, 0.00082214, 0.00069404, 0.00113498],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 275, 'shape': array([120], dtype=int32), 'shape_signature': array([120], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([4.39292198e-05, 3.17741651e-05, 3.64743173e-05, 1.54967202e-05,\n",
            "       2.39171186e-05, 2.40395693e-05, 4.85343517e-05, 4.86243007e-05,\n",
            "       3.91243957e-05, 2.45710580e-05, 5.59689070e-05, 2.32257607e-05,\n",
            "       3.79649391e-05, 1.77065740e-05, 1.44477535e-05, 2.87547264e-05,\n",
            "       2.57465108e-05, 8.63950754e-06, 3.13815835e-05, 3.10288706e-05,\n",
            "       3.81947320e-05, 5.65710034e-05, 1.38259529e-05, 4.64188633e-06,\n",
            "       3.79668418e-05, 2.81216508e-05, 3.49724032e-05, 2.95762729e-05,\n",
            "       3.62942592e-05, 2.11936931e-05, 4.47003222e-05, 1.70166695e-05,\n",
            "       5.37832202e-05, 4.17421688e-06, 8.09511221e-06, 1.71738338e-05,\n",
            "       3.24303765e-05, 3.26128757e-05, 2.79944434e-05, 4.83268996e-05,\n",
            "       1.38702298e-05, 7.83128598e-06, 1.14230330e-04, 3.34691613e-05,\n",
            "       3.92492220e-05, 3.14049939e-05, 1.75221139e-05, 3.56717755e-05,\n",
            "       3.17945851e-05, 3.59603000e-05, 1.51685263e-05, 2.66869338e-05,\n",
            "       3.61358216e-05, 4.55257068e-05, 2.66169554e-05, 1.30166982e-05,\n",
            "       3.35351106e-05, 4.90335115e-05, 1.87653677e-05, 3.38858117e-05,\n",
            "       4.12784284e-05, 4.51630622e-05, 3.15133148e-05, 1.56846800e-05,\n",
            "       5.41110567e-05, 3.20035761e-05, 4.95660715e-05, 6.67303466e-05,\n",
            "       1.75817277e-05, 5.59384971e-05, 1.68993247e-05, 1.01831698e-04,\n",
            "       4.14799360e-05, 1.30854551e-05, 4.56688249e-05, 2.12795730e-05,\n",
            "       1.95211742e-05, 1.55924336e-05, 1.34431075e-05, 2.49075802e-05,\n",
            "       4.68575672e-05, 4.47688180e-05, 7.67978490e-05, 2.81086486e-05,\n",
            "       3.08052258e-05, 4.13081143e-05, 4.11592482e-05, 1.23371592e-05,\n",
            "       2.92082441e-05, 3.29095565e-05, 3.27709095e-05, 2.33069168e-05,\n",
            "       1.82657914e-05, 3.12601587e-05, 3.88663175e-05, 4.31799235e-05,\n",
            "       6.05171226e-05, 4.52694258e-05, 3.36043449e-05, 5.50585210e-05,\n",
            "       1.89743168e-05, 7.30818647e-05, 1.17399486e-05, 6.30076647e-06,\n",
            "       3.44947402e-05, 4.56285015e-05, 3.16183432e-05, 1.96395085e-05,\n",
            "       2.08356651e-05, 1.72890777e-05, 3.92589536e-05, 5.95974634e-05,\n",
            "       2.58174678e-05, 4.26711049e-05, 2.32711027e-05, 1.83032862e-05,\n",
            "       3.74826705e-05, 3.93162445e-05, 2.69249795e-05, 1.27925941e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 276, 'shape': array([120,   1,   1, 480], dtype=int32), 'shape_signature': array([120,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00173851, 0.00125747, 0.00144348, 0.00061328, 0.00094652,\n",
            "       0.00095137, 0.00192075, 0.00192431, 0.00154835, 0.0009724 ,\n",
            "       0.00221498, 0.00091916, 0.00150247, 0.00070074, 0.00057177,\n",
            "       0.00113797, 0.00101892, 0.00034191, 0.00124193, 0.00122797,\n",
            "       0.00151156, 0.00223881, 0.00054716, 0.0001837 , 0.00150254,\n",
            "       0.00111292, 0.00138404, 0.00117049, 0.00143635, 0.00083874,\n",
            "       0.00176902, 0.00067344, 0.00212848, 0.0001652 , 0.00032037,\n",
            "       0.00067966, 0.00128344, 0.00129066, 0.00110788, 0.00191254,\n",
            "       0.00054892, 0.00030992, 0.00452068, 0.00132455, 0.00155329,\n",
            "       0.00124286, 0.00069344, 0.00141172, 0.00125828, 0.00142313,\n",
            "       0.0006003 , 0.00105614, 0.00143008, 0.00180169, 0.00105337,\n",
            "       0.00051514, 0.00132716, 0.00194051, 0.00074264, 0.00134104,\n",
            "       0.0016336 , 0.00178733, 0.00124714, 0.00062072, 0.00214145,\n",
            "       0.00126655, 0.00196158, 0.00264086, 0.0006958 , 0.00221377,\n",
            "       0.00066879, 0.00403   , 0.00164157, 0.00051786, 0.00180735,\n",
            "       0.00084214, 0.00077255, 0.00061707, 0.00053201, 0.00098572,\n",
            "       0.0018544 , 0.00177173, 0.00303929, 0.0011124 , 0.00121912,\n",
            "       0.00163477, 0.00162888, 0.00048824, 0.00115592, 0.0013024 ,\n",
            "       0.00129691, 0.00092237, 0.00072287, 0.00123713, 0.00153814,\n",
            "       0.00170885, 0.00239497, 0.00179154, 0.0013299 , 0.00217895,\n",
            "       0.00075091, 0.00289223, 0.00046461, 0.00024935, 0.00136513,\n",
            "       0.00180575, 0.0012513 , 0.00077724, 0.00082457, 0.00068422,\n",
            "       0.00155368, 0.00235858, 0.00102173, 0.00168872, 0.00092096,\n",
            "       0.00072436, 0.00148338, 0.00155595, 0.00106556, 0.00050627],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 277, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00153391, 0.00391167, 0.01241056, 0.00098625, 0.00114879,\n",
            "       0.00546231, 0.01322304, 0.0011354 , 0.00248262, 0.00133992,\n",
            "       0.00297932, 0.00359208, 0.00960635, 0.0033748 , 0.002904  ,\n",
            "       0.00602787, 0.01438309, 0.00161655, 0.00657457, 0.00623865,\n",
            "       0.00290401, 0.00382857, 0.00312092, 0.00687677, 0.01358963,\n",
            "       0.00663072, 0.00189078, 0.00348689, 0.00351127, 0.00218956,\n",
            "       0.01546621, 0.00098124, 0.00213101, 0.0136283 , 0.00502242,\n",
            "       0.00303281, 0.00172703, 0.00498263, 0.00508591, 0.00221989,\n",
            "       0.00930039, 0.00987816, 0.00149773, 0.01720731, 0.00415201,\n",
            "       0.00397542, 0.00310089, 0.00580993, 0.00518678, 0.01342372,\n",
            "       0.00705638, 0.0033553 , 0.0017128 , 0.00546308, 0.00178529,\n",
            "       0.00277032, 0.00289655, 0.00516689, 0.00692864, 0.00323207,\n",
            "       0.00153568, 0.00968986, 0.00188672, 0.01418995, 0.00295247,\n",
            "       0.00868028, 0.00293382, 0.00179735, 0.00727152, 0.00663739,\n",
            "       0.00097214, 0.00990048, 0.00375602, 0.00313392, 0.00386057,\n",
            "       0.0013826 , 0.00154479, 0.01060551, 0.01181827, 0.00658981,\n",
            "       0.00929896, 0.00570547, 0.0019432 , 0.00173836, 0.00165973,\n",
            "       0.00220988, 0.0028063 , 0.00138275, 0.010892  , 0.01622108,\n",
            "       0.00253067, 0.009669  , 0.01747957, 0.00703141, 0.01241324,\n",
            "       0.00774773, 0.00327843, 0.00193286, 0.00602926, 0.00403777,\n",
            "       0.00311465, 0.03739392, 0.00196067, 0.00377662, 0.00127255,\n",
            "       0.0126796 , 0.00532412, 0.00833404, 0.00135307, 0.00893882,\n",
            "       0.00140144, 0.01212309, 0.00523999, 0.01482311, 0.00994745,\n",
            "       0.00283692, 0.01390343, 0.01022641, 0.00278369, 0.00612829,\n",
            "       0.00159291, 0.01838098, 0.00140388, 0.00128809, 0.00183734,\n",
            "       0.01195025, 0.00267594, 0.01123272, 0.00192201, 0.00334782,\n",
            "       0.00429703, 0.00436228, 0.00135249, 0.00172781, 0.00235558,\n",
            "       0.00194561, 0.01673175, 0.00271791, 0.00993698, 0.00119581,\n",
            "       0.00174825, 0.00159753, 0.01521487, 0.01102992, 0.00095639,\n",
            "       0.00376017, 0.00338442, 0.01360737, 0.00652938, 0.00597398,\n",
            "       0.00649312, 0.00426464, 0.00275856, 0.00620186, 0.00178223,\n",
            "       0.01663903, 0.00134229, 0.00184199, 0.01463173, 0.00728755,\n",
            "       0.00308143, 0.0014528 , 0.00617376, 0.00174073, 0.00168131,\n",
            "       0.0051566 , 0.00235973, 0.00718616, 0.00138996, 0.00312715,\n",
            "       0.01181144, 0.01248507, 0.00628389, 0.01849992, 0.00655767,\n",
            "       0.00350989, 0.00322502, 0.00612744, 0.0046785 , 0.00509377,\n",
            "       0.00853815, 0.00180826, 0.01125362, 0.00339772, 0.00592336,\n",
            "       0.00372654, 0.00585483, 0.00141859, 0.00176212, 0.0024617 ,\n",
            "       0.0055277 , 0.00524249, 0.00676249, 0.00496203, 0.0045517 ,\n",
            "       0.00189368, 0.00541171, 0.01124324, 0.00374174, 0.00759312,\n",
            "       0.00674682, 0.00659593, 0.00385216, 0.00191097, 0.00285731,\n",
            "       0.00325775, 0.02054646, 0.0113678 , 0.00186516, 0.00481371,\n",
            "       0.0027899 , 0.00721427, 0.00949506, 0.00688347, 0.01027046,\n",
            "       0.0025305 , 0.00524427, 0.00313162, 0.00386649, 0.01172753,\n",
            "       0.01408272, 0.00121086, 0.02042174, 0.00352412, 0.00796985,\n",
            "       0.0018517 , 0.00223857, 0.0016131 , 0.0015193 , 0.00264365,\n",
            "       0.01821777, 0.00535094, 0.00713196, 0.00922449, 0.00110121,\n",
            "       0.0072994 , 0.00199211, 0.00360303, 0.00209823, 0.00236049],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul', 'index': 278, 'shape': array([  1,   3,   1, 240], dtype=int32), 'shape_signature': array([  1,   3,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00997237, 0.02543092, 0.0806846 , 0.00641193, 0.00746862,\n",
            "       0.03551204, 0.08596681, 0.00738153, 0.01614025, 0.00871123,\n",
            "       0.01936939, 0.02335315, 0.06245362, 0.02194053, 0.01887975,\n",
            "       0.03918889, 0.0935086 , 0.01050965, 0.0427432 , 0.04055927,\n",
            "       0.01887979, 0.02489063, 0.02029001, 0.04470787, 0.0883501 ,\n",
            "       0.04310821, 0.01229249, 0.02266927, 0.0228278 , 0.01423493,\n",
            "       0.10055029, 0.00637933, 0.01385429, 0.08860151, 0.03265219,\n",
            "       0.01971718, 0.01122792, 0.03239354, 0.03306497, 0.01443212,\n",
            "       0.0604645 , 0.06422076, 0.00973718, 0.1118697 , 0.02699342,\n",
            "       0.02584535, 0.02015975, 0.03777205, 0.03372072, 0.08727147,\n",
            "       0.04587555, 0.0218138 , 0.0111354 , 0.03551705, 0.0116067 ,\n",
            "       0.01801066, 0.01883129, 0.03359146, 0.04504507, 0.02101265,\n",
            "       0.00998392, 0.06299654, 0.01226608, 0.09225295, 0.01919483,\n",
            "       0.05643302, 0.01907359, 0.01168511, 0.04727424, 0.04315161,\n",
            "       0.00632019, 0.06436589, 0.02441899, 0.02037449, 0.02509866,\n",
            "       0.00898868, 0.0100431 , 0.06894946, 0.07683398, 0.04284222,\n",
            "       0.06045524, 0.03709291, 0.01263328, 0.01130156, 0.01079037,\n",
            "       0.01436709, 0.01824458, 0.00898969, 0.070812  , 0.10545794,\n",
            "       0.01645262, 0.06286097, 0.11363974, 0.04571325, 0.08070207,\n",
            "       0.05037023, 0.02131403, 0.01256607, 0.03919794, 0.02625071,\n",
            "       0.02024925, 0.24310867, 0.01274691, 0.02455289, 0.00827323,\n",
            "       0.08243371, 0.03461363, 0.05418199, 0.00879671, 0.05811385,\n",
            "       0.00911118, 0.07881569, 0.0340667 , 0.09636934, 0.06467123,\n",
            "       0.01844362, 0.09039018, 0.06648487, 0.0180976 , 0.03984176,\n",
            "       0.01035595, 0.11950008, 0.00912703, 0.00837422, 0.01194509,\n",
            "       0.07769199, 0.01739705, 0.07302718, 0.01249554, 0.02176516,\n",
            "       0.02793623, 0.02836045, 0.00879292, 0.011233  , 0.01531432,\n",
            "       0.012649  , 0.10877791, 0.01766991, 0.06460315, 0.00777428,\n",
            "       0.01136587, 0.01038603, 0.09891628, 0.07170866, 0.00621779,\n",
            "       0.02444593, 0.02200312, 0.0884654 , 0.04244938, 0.03883858,\n",
            "       0.04221363, 0.02772567, 0.01793421, 0.04032007, 0.01158682,\n",
            "       0.10817512, 0.00872663, 0.01197532, 0.09512509, 0.04737845,\n",
            "       0.02003325, 0.00944509, 0.04013742, 0.01131698, 0.01093066,\n",
            "       0.03352456, 0.01534127, 0.04671928, 0.00903653, 0.02033052,\n",
            "       0.07678954, 0.08116901, 0.0408534 , 0.12027331, 0.04263329,\n",
            "       0.02281879, 0.0209668 , 0.03983625, 0.03041628, 0.03311609,\n",
            "       0.05550897, 0.01175604, 0.07316301, 0.02208959, 0.03850945,\n",
            "       0.02422732, 0.03806393, 0.00922269, 0.01145604, 0.01600423,\n",
            "       0.03593716, 0.03408295, 0.04396486, 0.03225959, 0.0295919 ,\n",
            "       0.01231134, 0.03518309, 0.07309557, 0.02432611, 0.04936505,\n",
            "       0.04386304, 0.04288204, 0.02504402, 0.01242376, 0.01857618,\n",
            "       0.02117957, 0.13357845, 0.07390533, 0.01212597, 0.03129531,\n",
            "       0.01813792, 0.04690204, 0.06173012, 0.04475141, 0.06677119,\n",
            "       0.01645149, 0.03409448, 0.02035958, 0.02513719, 0.07624407,\n",
            "       0.09155584, 0.00787213, 0.13276759, 0.02291135, 0.05181431,\n",
            "       0.01203844, 0.01455361, 0.01048721, 0.00987743, 0.01718716,\n",
            "       0.11843895, 0.034788  , 0.04636695, 0.05997108, 0.0071593 ,\n",
            "       0.04745548, 0.01295127, 0.02342431, 0.01364117, 0.0153462 ],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 279, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([7.78678455e-04, 2.64512654e-03, 1.62396859e-03, 8.58035288e-04,\n",
            "       7.26858620e-04, 1.22705789e-03, 9.41731094e-04, 5.73383237e-04,\n",
            "       1.82440854e-03, 8.20864574e-04, 8.74393008e-05, 5.04158961e-04,\n",
            "       1.08163431e-03, 2.86336057e-04, 7.09576649e-04, 1.64970267e-03,\n",
            "       1.10636960e-04, 1.11467973e-03, 3.27981106e-04, 2.02014882e-04,\n",
            "       5.84503810e-04, 1.84826538e-04, 3.67828063e-04, 2.19969559e-04,\n",
            "       6.03658671e-04, 1.28544139e-04, 9.68150038e-04, 1.14234281e-03,\n",
            "       3.04288813e-04, 1.14184630e-03, 7.05843267e-04, 6.56492077e-04,\n",
            "       7.80484173e-04, 1.04015293e-04, 3.76776501e-04, 3.42992891e-04,\n",
            "       4.61279211e-04, 7.47756974e-04, 1.28653555e-04, 6.69346889e-04,\n",
            "       3.14686447e-04, 3.18029226e-04, 7.06411665e-04, 8.39953194e-04,\n",
            "       7.20629061e-04, 1.07434660e-03, 1.47552369e-03, 2.19415757e-04,\n",
            "       6.84746265e-05, 3.90577421e-04, 9.58174991e-04, 1.95384002e-03,\n",
            "       2.37404820e-04, 3.19146289e-04, 5.82849316e-04, 5.01002767e-04,\n",
            "       6.06626854e-04, 9.78868804e-04, 2.97895866e-03, 1.00956869e-03,\n",
            "       3.29545699e-04, 7.04961771e-04, 2.74780090e-04, 7.63595570e-04,\n",
            "       1.07111433e-03, 1.08645600e-03, 4.10835055e-04, 7.08550448e-04,\n",
            "       1.11336238e-03, 8.65084803e-05, 8.27817596e-04, 1.26324303e-04,\n",
            "       4.93312429e-04, 3.20825668e-04, 3.48948321e-04, 9.39519552e-04,\n",
            "       6.17349462e-04, 1.49913563e-03, 4.53324057e-04, 1.73263528e-04,\n",
            "       1.57780154e-03, 1.11148914e-03, 7.46512960e-04, 2.98661063e-04,\n",
            "       3.48105445e-04, 1.75769499e-04, 6.11400523e-04, 8.54474551e-04,\n",
            "       2.13903957e-03, 2.75183847e-04, 4.54356341e-04, 3.38782149e-04,\n",
            "       5.98082610e-04, 1.21527631e-03, 3.30909126e-04, 4.36739792e-04,\n",
            "       1.05062791e-04, 8.55205057e-04, 1.16999639e-04, 6.45574939e-04,\n",
            "       2.61624285e-04, 1.32559246e-04, 4.82478819e-04, 2.03373580e-04,\n",
            "       5.98857005e-04, 9.12396281e-05, 7.77489040e-04, 7.62031850e-05,\n",
            "       1.01942394e-03, 4.53914487e-04, 1.29080424e-03, 4.83496959e-04,\n",
            "       1.08858268e-03, 1.53024320e-03, 1.97906676e-03, 8.28261254e-04,\n",
            "       8.78953433e-05, 3.79014964e-04, 1.52444502e-03, 1.16692204e-03,\n",
            "       6.05205540e-04, 1.39364376e-04, 6.45796128e-04, 7.59184477e-04,\n",
            "       5.48262440e-04, 4.36525064e-04, 7.35589128e-04, 3.34953947e-04,\n",
            "       7.09157146e-04, 5.18261513e-04, 1.28462052e-04, 7.32669025e-04,\n",
            "       8.10852449e-04, 5.10868034e-04, 5.99769759e-04, 8.21634836e-04,\n",
            "       2.45920324e-04, 2.13224426e-04, 1.26011891e-03, 2.21399052e-04,\n",
            "       1.77850437e-04, 2.51308433e-04, 1.49348183e-04, 8.57981970e-04,\n",
            "       1.51891727e-04, 6.94425136e-04, 5.51391684e-04, 1.04215113e-04,\n",
            "       6.32541545e-04, 2.73495622e-04, 1.68756128e-03, 4.45030979e-04,\n",
            "       8.44668888e-04, 1.15569936e-04, 9.23711283e-04, 4.31623077e-04,\n",
            "       9.79243545e-04, 1.09732046e-03, 4.21415549e-04, 1.64897356e-04,\n",
            "       1.93048254e-04, 8.50797049e-04, 1.19908724e-03, 4.09504661e-04,\n",
            "       9.49958849e-05, 1.58714526e-03, 5.18450281e-04, 1.26372193e-04,\n",
            "       5.28934936e-04, 1.19226996e-03, 3.92030604e-04, 1.18849834e-03,\n",
            "       5.74700971e-05, 7.00145552e-04, 2.19246303e-03, 1.20407887e-04,\n",
            "       1.81591429e-04, 1.50287384e-03, 1.48871797e-04, 7.08495034e-04,\n",
            "       1.44207233e-03, 8.89540417e-04, 4.84567645e-05, 2.48148019e-04,\n",
            "       2.14133266e-04, 1.17167314e-04, 4.09582601e-04, 1.06808124e-03,\n",
            "       2.50568759e-04, 5.77061495e-04, 6.61231403e-04, 4.19868811e-05,\n",
            "       5.85723959e-04, 6.20419567e-04, 1.39099866e-04, 2.39512476e-04,\n",
            "       1.03895622e-03, 7.87108496e-04, 1.95506960e-03, 5.90053736e-04,\n",
            "       8.21513357e-04, 5.98552986e-04, 9.21169762e-04, 5.12942206e-04,\n",
            "       3.47540510e-04, 1.37120101e-03, 2.31305457e-04, 1.31475925e-03,\n",
            "       4.64412966e-04, 1.00769539e-04, 3.96307179e-04, 7.13988324e-04,\n",
            "       1.27349095e-03, 1.44753500e-03, 5.85819143e-05, 3.01189546e-04,\n",
            "       7.83838914e-05, 2.72884528e-04, 5.40807669e-04, 1.42026797e-03,\n",
            "       5.48702315e-04, 4.89646627e-04, 6.85248000e-04, 4.34777961e-04,\n",
            "       3.12373741e-04, 9.33877076e-04, 9.58193385e-04, 6.86940446e-04,\n",
            "       7.43843499e-04, 8.32175720e-04, 5.32769132e-04, 1.06354761e-04,\n",
            "       1.45593207e-04, 1.69498834e-03, 8.51172488e-04, 2.50829570e-03,\n",
            "       4.83565207e-04, 2.26213888e-04, 1.59357360e-03, 2.21065944e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 280, 'shape': array([  1,   3,   3, 240], dtype=int32), 'shape_signature': array([  1,   3,   3, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01567595, 0.05325032, 0.0326929 , 0.01727352, 0.01463274,\n",
            "       0.02470249, 0.01895844, 0.01154306, 0.03672805, 0.01652522,\n",
            "       0.00176028, 0.01014947, 0.0217749 , 0.00576437, 0.01428483,\n",
            "       0.03321096, 0.00222729, 0.02244016, 0.00660275, 0.00406686,\n",
            "       0.01176693, 0.00372083, 0.00740492, 0.00442831, 0.01215254,\n",
            "       0.00258778, 0.0194903 , 0.02299706, 0.00612578, 0.02298706,\n",
            "       0.01420967, 0.01321616, 0.0157123 , 0.00209398, 0.00758507,\n",
            "       0.00690496, 0.00928624, 0.01505346, 0.00258999, 0.01347495,\n",
            "       0.0063351 , 0.0064024 , 0.01422112, 0.0169095 , 0.01450733,\n",
            "       0.02162819, 0.02970448, 0.00441716, 0.0013785 , 0.0078629 ,\n",
            "       0.01928948, 0.0393337 , 0.00477931, 0.00642489, 0.01173362,\n",
            "       0.01008593, 0.0122123 , 0.01970608, 0.05997086, 0.02032412,\n",
            "       0.00663424, 0.01419193, 0.00553173, 0.01537231, 0.02156312,\n",
            "       0.02187197, 0.00827072, 0.01426417, 0.02241364, 0.00174154,\n",
            "       0.0166652 , 0.0025431 , 0.00993111, 0.0064587 , 0.00702485,\n",
            "       0.01891392, 0.01242816, 0.03017982, 0.00912609, 0.00348805,\n",
            "       0.03176349, 0.02237593, 0.01502841, 0.00601249, 0.00700788,\n",
            "       0.0035385 , 0.0123084 , 0.01720184, 0.04306204, 0.00553986,\n",
            "       0.00914687, 0.00682019, 0.01204029, 0.02446532, 0.00666169,\n",
            "       0.00879222, 0.00211507, 0.01721655, 0.00235538, 0.01299638,\n",
            "       0.00526689, 0.00266861, 0.00971301, 0.00409421, 0.01205588,\n",
            "       0.00183679, 0.01565201, 0.00153408, 0.02052252, 0.00913797,\n",
            "       0.02598581, 0.00973351, 0.02191478, 0.03080607, 0.03984155,\n",
            "       0.01667413, 0.00176946, 0.00763013, 0.03068934, 0.02349187,\n",
            "       0.01218369, 0.00280561, 0.01300083, 0.01528351, 0.01103734,\n",
            "       0.0087879 , 0.0148085 , 0.00674312, 0.01427639, 0.01043337,\n",
            "       0.00258613, 0.01474971, 0.01632366, 0.01028453, 0.01207426,\n",
            "       0.01654073, 0.00495074, 0.00429252, 0.02536806, 0.00445709,\n",
            "       0.00358039, 0.00505921, 0.0030066 , 0.01727245, 0.00305781,\n",
            "       0.01397981, 0.01110033, 0.002098  , 0.012734  , 0.00550587,\n",
            "       0.03397311, 0.00895913, 0.01700444, 0.00232659, 0.01859568,\n",
            "       0.00868921, 0.01971363, 0.02209069, 0.00848372, 0.00331963,\n",
            "       0.00388635, 0.01712781, 0.02413941, 0.00824394, 0.00191241,\n",
            "       0.03195159, 0.01043717, 0.00254406, 0.01064824, 0.02400216,\n",
            "       0.00789216, 0.02392623, 0.00115696, 0.01409497, 0.04413753,\n",
            "       0.00242399, 0.0036557 , 0.03025508, 0.00299701, 0.01426306,\n",
            "       0.02903106, 0.01790777, 0.00097551, 0.00499559, 0.00431082,\n",
            "       0.00235875, 0.00824551, 0.02150206, 0.00504432, 0.0116171 ,\n",
            "       0.01331157, 0.00084526, 0.01179149, 0.01248997, 0.00280029,\n",
            "       0.00482174, 0.02091573, 0.01584566, 0.03935845, 0.01187866,\n",
            "       0.01653828, 0.01204976, 0.01854451, 0.01032629, 0.00699651,\n",
            "       0.02760431, 0.00465652, 0.02646805, 0.00934932, 0.00202864,\n",
            "       0.00797825, 0.01437364, 0.02563726, 0.02914103, 0.00117934,\n",
            "       0.00606339, 0.00157798, 0.00549357, 0.01088726, 0.0285921 ,\n",
            "       0.01104619, 0.00985731, 0.01379506, 0.00875273, 0.00628855,\n",
            "       0.01880033, 0.01928985, 0.01382913, 0.01497467, 0.01675293,\n",
            "       0.01072543, 0.00214108, 0.00293101, 0.03412263, 0.01713536,\n",
            "       0.05049571, 0.00973488, 0.00455402, 0.032081  , 0.00445039],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 281, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.32887804e-04, 4.35567017e-05, 2.11118677e-05, 1.65366611e-04,\n",
            "       2.11987208e-04, 6.72691895e-05, 7.27494116e-05, 1.90145380e-04,\n",
            "       6.00735220e-05, 1.61835735e-04, 1.77276437e-04, 9.81155754e-05,\n",
            "       4.96016546e-05, 1.24382161e-04, 8.13068109e-05, 7.91429266e-05,\n",
            "       4.89331105e-05, 1.63211080e-04, 1.03286264e-04, 1.40126605e-04,\n",
            "       1.82701580e-04, 6.40106664e-05, 1.74010464e-04, 1.61464355e-04,\n",
            "       3.28423739e-05, 1.57550661e-04, 1.39601922e-04, 1.56595750e-04,\n",
            "       2.03864736e-04, 1.98786613e-04, 2.10557682e-05, 1.35605995e-04,\n",
            "       3.00379994e-04, 1.61690434e-04, 9.57611192e-05, 1.36561808e-04,\n",
            "       1.97019923e-04, 9.97296447e-05, 1.70361222e-04, 1.64621481e-04,\n",
            "       4.46449485e-05, 4.77583053e-05, 2.08736266e-04, 1.40216134e-05,\n",
            "       1.80876857e-04, 1.60666532e-04, 7.92759747e-05, 1.51898450e-04,\n",
            "       1.40004588e-04, 1.88289909e-04, 9.87662934e-05, 4.25491235e-05,\n",
            "       2.12652260e-04, 5.37639316e-05, 2.36011649e-04, 1.35812952e-04,\n",
            "       9.66489897e-05, 8.97131540e-05, 2.76458541e-05, 1.41727680e-04,\n",
            "       1.78258342e-04, 8.84742185e-05, 2.44285882e-04, 2.51155288e-05,\n",
            "       1.29610009e-04, 3.39761064e-05, 1.81744617e-04, 1.63500707e-04,\n",
            "       3.39161452e-05, 2.02169918e-04, 1.84607663e-04, 1.00382837e-04,\n",
            "       1.42468649e-04, 2.37183980e-04, 1.54023946e-04, 1.10914072e-04,\n",
            "       2.52808270e-04, 3.54997355e-05, 3.23247295e-05, 7.60302428e-05,\n",
            "       2.19313315e-05, 4.51410451e-05, 1.74083980e-04, 1.80256291e-04,\n",
            "       3.01979948e-04, 1.60258249e-04, 1.82133474e-04, 2.28133140e-04,\n",
            "       4.04935963e-05, 2.00172108e-05, 1.64714744e-04, 5.06216602e-05,\n",
            "       1.60814870e-05, 2.96177168e-05, 5.44303839e-05, 5.78495601e-05,\n",
            "       3.22727195e-04, 2.47370685e-04, 2.68878648e-04, 1.52984750e-04,\n",
            "       1.45864789e-04, 1.34946880e-04, 1.59802410e-04, 3.46730638e-04,\n",
            "       2.33116793e-04, 1.01082420e-04, 7.89984697e-05, 1.97578949e-04,\n",
            "       1.88292106e-04, 3.13572345e-05, 2.03364412e-04, 3.10250034e-05,\n",
            "       5.85355447e-05, 1.27147614e-05, 2.50111134e-05, 1.32875357e-04,\n",
            "       1.04078754e-04, 9.79139440e-05, 1.06189713e-04, 3.44246073e-05,\n",
            "       2.10881713e-04, 3.69188274e-05, 1.56369511e-04, 1.70224594e-04,\n",
            "       2.49842880e-04, 2.07022895e-05, 2.05735429e-04, 1.19008386e-04,\n",
            "       2.03937831e-04, 1.27603271e-04, 3.76253796e-04, 1.07844171e-04,\n",
            "       1.39826894e-04, 1.45414844e-04, 2.05992590e-04, 1.57914634e-04,\n",
            "       4.44163088e-05, 2.24328774e-04, 3.57815043e-05, 1.53463814e-04,\n",
            "       1.68519065e-04, 2.09369391e-04, 7.30350002e-05, 6.06456924e-05,\n",
            "       2.22280432e-04, 9.37334262e-05, 1.43915531e-04, 7.25771970e-05,\n",
            "       5.17109620e-05, 2.52234284e-04, 3.93745613e-05, 1.84074277e-04,\n",
            "       1.80370000e-04, 1.16070296e-04, 1.83011653e-04, 3.81470491e-05,\n",
            "       1.18824006e-04, 1.18818483e-04, 2.45900319e-05, 1.67186037e-04,\n",
            "       2.26187345e-04, 1.99157395e-04, 4.20289289e-05, 1.63023200e-04,\n",
            "       1.93202737e-04, 4.10553803e-05, 1.45156198e-04, 1.27138250e-04,\n",
            "       2.90395750e-04, 1.59504794e-04, 8.65910188e-05, 3.66897366e-05,\n",
            "       2.61692650e-04, 2.81596549e-05, 4.09650092e-05, 1.13262824e-04,\n",
            "       3.63381638e-04, 2.41339312e-05, 2.84161710e-04, 4.84313714e-05,\n",
            "       4.64803852e-05, 2.23848343e-04, 2.07032033e-04, 1.79907089e-04,\n",
            "       2.24776551e-04, 1.55687376e-04, 4.30539003e-05, 1.85326033e-04,\n",
            "       1.60267475e-04, 6.89938970e-05, 1.50506472e-04, 1.89411745e-04,\n",
            "       7.58565584e-05, 8.02687791e-05, 1.76987989e-04, 2.85926595e-04,\n",
            "       7.31660766e-05, 8.60649088e-05, 4.90091770e-05, 5.18080633e-05,\n",
            "       1.08120817e-04, 6.83898179e-05, 2.04705182e-04, 2.49581935e-04,\n",
            "       1.75110574e-04, 3.16255755e-05, 7.29435778e-05, 2.46588879e-05,\n",
            "       5.67298666e-05, 1.94561682e-04, 2.21776383e-04, 5.20903050e-05,\n",
            "       3.59922524e-05, 4.19568314e-05, 2.72986712e-04, 1.14191833e-04,\n",
            "       3.59588623e-04, 1.12966263e-04, 2.52345082e-04, 6.50311631e-05,\n",
            "       3.41810592e-05, 1.92267922e-04, 3.08242597e-05, 1.12155816e-04,\n",
            "       3.57803838e-05, 1.64710029e-04, 1.37241950e-04, 3.47020978e-04,\n",
            "       1.77046357e-04, 2.97570426e-04, 2.32883958e-05, 1.41272700e-04,\n",
            "       1.02494159e-04, 2.97065562e-05, 1.67941238e-04, 3.15031757e-05,\n",
            "       1.90808496e-04, 1.08890206e-04, 5.82710672e-05, 2.48509401e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 282, 'shape': array([240,   1,   1,  72], dtype=int32), 'shape_signature': array([240,   1,   1,  72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.41631962e-04, 4.51921114e-05, 2.19045487e-05, 1.71575579e-04,\n",
            "       2.19946625e-04, 6.97949217e-05, 7.54809080e-05, 1.97284709e-04,\n",
            "       6.23290834e-05, 1.67912134e-04, 1.83932585e-04, 1.01799487e-04,\n",
            "       5.14640305e-05, 1.29052292e-04, 8.43596135e-05, 8.21144786e-05,\n",
            "       5.07703880e-05, 1.69339110e-04, 1.07164320e-04, 1.45387894e-04,\n",
            "       1.89561426e-04, 6.64140534e-05, 1.80543982e-04, 1.67526799e-04,\n",
            "       3.40754959e-05, 1.63466160e-04, 1.44843507e-04, 1.62475408e-04,\n",
            "       2.11519175e-04, 2.06250392e-04, 2.18463429e-05, 1.40697550e-04,\n",
            "       3.11658281e-04, 1.67761376e-04, 9.93566282e-05, 1.41689248e-04,\n",
            "       2.04417374e-04, 1.03474165e-04, 1.76757720e-04, 1.70802465e-04,\n",
            "       4.63212200e-05, 4.95514723e-05, 2.16573622e-04, 1.45480790e-05,\n",
            "       1.87668178e-04, 1.66699028e-04, 8.22525253e-05, 1.57601738e-04,\n",
            "       1.45261292e-04, 1.95359564e-04, 1.02474638e-04, 4.41467018e-05,\n",
            "       2.20636648e-04, 5.57825879e-05, 2.44873110e-04, 1.40912278e-04,\n",
            "       1.00277837e-04, 9.30815877e-05, 2.86838640e-05, 1.47049082e-04,\n",
            "       1.84951350e-04, 9.17961297e-05, 2.53458013e-04, 2.60585330e-05,\n",
            "       1.34476431e-04, 3.52517964e-05, 1.88568520e-04, 1.69639621e-04,\n",
            "       3.51895833e-05, 2.09760721e-04, 1.91539075e-04, 1.04151877e-04,\n",
            "       1.47817875e-04, 2.46089447e-04, 1.59807038e-04, 1.15078525e-04,\n",
            "       2.62300397e-04, 3.68326328e-05, 3.35384175e-05, 7.88849284e-05,\n",
            "       2.27547807e-05, 4.68359431e-05, 1.80620264e-04, 1.87024314e-04,\n",
            "       3.13318305e-04, 1.66275408e-04, 1.88971986e-04, 2.36698790e-04,\n",
            "       4.20139950e-05, 2.07687899e-05, 1.70899235e-04, 5.25223368e-05,\n",
            "       1.66852933e-05, 3.07297632e-05, 5.64740658e-05, 6.00216190e-05,\n",
            "       3.34844546e-04, 2.56658619e-04, 2.78974156e-04, 1.58728828e-04,\n",
            "       1.51341534e-04, 1.40013683e-04, 1.65802456e-04, 3.59749218e-04,\n",
            "       2.41869551e-04, 1.04877727e-04, 8.19646011e-05, 2.04997385e-04,\n",
            "       1.95361848e-04, 3.25345936e-05, 2.11000079e-04, 3.21898879e-05,\n",
            "       6.07333604e-05, 1.31921588e-05, 2.59501976e-05, 1.37864379e-04,\n",
            "       1.07986569e-04, 1.01590289e-04, 1.10176785e-04, 3.57171375e-05,\n",
            "       2.18799629e-04, 3.83050065e-05, 1.62240671e-04, 1.76615969e-04,\n",
            "       2.59223656e-04, 2.14795909e-05, 2.13460109e-04, 1.23476755e-04,\n",
            "       2.11595019e-04, 1.32394358e-04, 3.90380883e-04, 1.11893365e-04,\n",
            "       1.45076934e-04, 1.50874694e-04, 2.13726933e-04, 1.63843812e-04,\n",
            "       4.60839947e-05, 2.32751583e-04, 3.71249807e-05, 1.59225878e-04,\n",
            "       1.74846398e-04, 2.17230525e-04, 7.57772214e-05, 6.29227361e-05,\n",
            "       2.30626320e-04, 9.72528069e-05, 1.49319079e-04, 7.53022323e-05,\n",
            "       5.36525367e-05, 2.61704845e-04, 4.08529449e-05, 1.90985651e-04,\n",
            "       1.87142301e-04, 1.20428347e-04, 1.89883140e-04, 3.95793431e-05,\n",
            "       1.23285456e-04, 1.23279722e-04, 2.55133054e-05, 1.73463312e-04,\n",
            "       2.34679930e-04, 2.06635101e-04, 4.36069749e-05, 1.69144187e-04,\n",
            "       2.00456852e-04, 4.25968719e-05, 1.50606327e-04, 1.31911875e-04,\n",
            "       3.01299151e-04, 1.65493664e-04, 8.98422222e-05, 3.80673155e-05,\n",
            "       2.71518336e-04, 2.92169570e-05, 4.25031103e-05, 1.17515468e-04,\n",
            "       3.77025426e-04, 2.50400808e-05, 2.94831028e-04, 5.02498078e-05,\n",
            "       4.82255709e-05, 2.32253107e-04, 2.14805405e-04, 1.86662000e-04,\n",
            "       2.33216168e-04, 1.61532924e-04, 4.46704325e-05, 1.92284409e-04,\n",
            "       1.66284983e-04, 7.15843926e-05, 1.56157490e-04, 1.96523528e-04,\n",
            "       7.87047175e-05, 8.32826045e-05, 1.83633296e-04, 2.96662183e-04,\n",
            "       7.59132236e-05, 8.92963581e-05, 5.08493104e-05, 5.37532833e-05,\n",
            "       1.12180394e-04, 7.09576270e-05, 2.12391184e-04, 2.58952903e-04,\n",
            "       1.81685391e-04, 3.28130118e-05, 7.56823647e-05, 2.55847481e-05,\n",
            "       5.88598850e-05, 2.01866831e-04, 2.30103353e-04, 5.40461224e-05,\n",
            "       3.73436415e-05, 4.35321708e-05, 2.83236470e-04, 1.18479358e-04,\n",
            "       3.73089977e-04, 1.17207768e-04, 2.61819805e-04, 6.74728653e-05,\n",
            "       3.54644435e-05, 1.99486938e-04, 3.19816099e-05, 1.16366893e-04,\n",
            "       3.71238202e-05, 1.70894346e-04, 1.42394929e-04, 3.60050471e-04,\n",
            "       1.83693861e-04, 3.08743212e-04, 2.41627986e-05, 1.46577018e-04,\n",
            "       1.06342472e-04, 3.08219387e-05, 1.74246874e-04, 3.26860172e-05,\n",
            "       1.97972724e-04, 1.12978669e-04, 6.04589513e-05, 2.57840118e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/rezero/mul', 'index': 283, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.008170079439878464, 127), 'quantization_parameters': {'scales': array([0.00817008], dtype=float32), 'zero_points': array([127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 284, 'shape': array([72], dtype=int32), 'shape_signature': array([72], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.0004022 , 0.00036068, 0.00031613, 0.00031108, 0.00041413,\n",
            "       0.00036867, 0.00042632, 0.00040914, 0.00049868, 0.00051441,\n",
            "       0.00039659, 0.00032672, 0.00033367, 0.00025971, 0.00043697,\n",
            "       0.00043113, 0.000316  , 0.00038432, 0.00039121, 0.00054441,\n",
            "       0.00023712, 0.00037537, 0.00036687, 0.00055376, 0.00042141,\n",
            "       0.0004107 , 0.00042105, 0.00026224, 0.00037459, 0.00036858,\n",
            "       0.00058963, 0.00038424, 0.00053232, 0.00044337, 0.00050902,\n",
            "       0.00041548, 0.00044627, 0.00042662, 0.00038537, 0.00038295,\n",
            "       0.00040148, 0.00056491, 0.00119381, 0.00042952, 0.00054995,\n",
            "       0.00036541, 0.00040361, 0.0003889 , 0.00031091, 0.00041606,\n",
            "       0.00038407, 0.0003206 , 0.00054146, 0.00037377, 0.00048074,\n",
            "       0.00066312, 0.00052437, 0.00028331, 0.0005671 , 0.00027828,\n",
            "       0.00030062, 0.00041818, 0.00043203, 0.00046208, 0.00028116,\n",
            "       0.00046716, 0.00046066, 0.00035623, 0.00041643, 0.00041101,\n",
            "       0.0004254 , 0.0004012 ], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 285, 'shape': array([ 72,   1,   1, 144], dtype=int32), 'shape_signature': array([ 72,   1,   1, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.0279134 , 0.02503186, 0.02194018, 0.02158969, 0.02874157,\n",
            "       0.02558656, 0.0295876 , 0.02839537, 0.03460947, 0.03570111,\n",
            "       0.02752401, 0.02267547, 0.02315734, 0.01802431, 0.03032692,\n",
            "       0.02992142, 0.02193126, 0.0266727 , 0.02715122, 0.03778309,\n",
            "       0.01645659, 0.02605161, 0.02546172, 0.0384325 , 0.02924696,\n",
            "       0.02850377, 0.02922198, 0.01820025, 0.02599742, 0.02558025,\n",
            "       0.04092153, 0.02666723, 0.03694435, 0.03077061, 0.03532723,\n",
            "       0.02883519, 0.03097215, 0.0296085 , 0.02674591, 0.02657761,\n",
            "       0.02786383, 0.03920639, 0.08285324, 0.02980994, 0.03816809,\n",
            "       0.02536009, 0.02801136, 0.02699086, 0.02157801, 0.02887534,\n",
            "       0.02665502, 0.02225026, 0.0375789 , 0.02594041, 0.03336467,\n",
            "       0.04602183, 0.03639242, 0.01966208, 0.03935817, 0.0193136 ,\n",
            "       0.02086339, 0.02902234, 0.02998368, 0.03206967, 0.01951311,\n",
            "       0.03242195, 0.03197075, 0.02472303, 0.02890124, 0.02852529,\n",
            "       0.0295239 , 0.02784388], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer6/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 286, 'shape': array([144], dtype=int32), 'shape_signature': array([144], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([7.3442386e-08, 2.9847314e-08, 3.2066836e-08, 8.4880206e-08,\n",
            "       8.4291374e-09, 1.3422485e-08, 8.0741171e-07, 5.7450837e-08,\n",
            "       2.6117545e-08, 3.8593488e-08, 9.5258734e-08, 3.7131191e-08,\n",
            "       5.2269129e-08, 6.0620771e-08, 9.1881747e-09, 6.0925331e-08,\n",
            "       3.4824865e-08, 3.7200820e-08, 1.5018972e-07, 2.7099517e-08,\n",
            "       4.2695766e-07, 1.9696586e-08, 1.7485778e-08, 5.1668266e-08,\n",
            "       7.6957384e-08, 4.0848548e-08, 1.2818394e-07, 6.5136533e-08,\n",
            "       1.3822813e-08, 3.1154094e-08, 1.3596885e-07, 1.8110994e-07,\n",
            "       5.8904149e-08, 1.6547450e-08, 3.8958291e-08, 9.2119796e-09,\n",
            "       2.3011298e-08, 3.4341861e-07, 3.5956617e-08, 1.1176889e-08,\n",
            "       2.1938940e-08, 2.4809195e-08, 1.1568375e-08, 3.5445532e-07,\n",
            "       3.1072645e-08, 5.2520960e-08, 2.2480101e-07, 9.8129092e-08,\n",
            "       1.4700303e-08, 5.0638981e-08, 2.8402272e-07, 2.3366818e-08,\n",
            "       1.5315855e-08, 1.4653386e-07, 3.0545085e-08, 1.5604034e-08,\n",
            "       6.3844050e-09, 1.3251825e-08, 6.5453506e-08, 4.6444878e-08,\n",
            "       1.6673887e-08, 9.0660697e-09, 1.4183524e-07, 7.5308639e-09,\n",
            "       9.5380528e-08, 3.2835445e-08, 1.1524194e-08, 2.3323350e-08,\n",
            "       3.3143301e-08, 3.2362756e-08, 1.7115191e-08, 2.5848539e-07,\n",
            "       4.1854868e-08, 1.6506441e-07, 6.7989414e-09, 5.1059285e-08,\n",
            "       1.9873641e-08, 3.3668786e-09, 2.4431804e-08, 9.6443173e-08,\n",
            "       4.6099398e-08, 3.2385415e-08, 9.8582005e-09, 1.7184346e-08,\n",
            "       7.6373183e-09, 3.4027174e-08, 2.1512335e-08, 2.0860506e-08,\n",
            "       3.3160241e-08, 4.8088640e-09, 3.3492277e-08, 1.5322072e-08,\n",
            "       1.3960358e-08, 1.2943679e-08, 5.2824407e-09, 6.0518275e-08,\n",
            "       3.9827587e-08, 4.1269221e-08, 8.4535998e-08, 2.5983425e-08,\n",
            "       9.8521627e-07, 1.5443783e-08, 9.0824393e-08, 5.8429592e-08,\n",
            "       2.6303866e-08, 2.2507835e-07, 1.6558181e-08, 1.2242599e-07,\n",
            "       5.0829410e-08, 4.7501224e-08, 1.4082982e-08, 6.6066019e-09,\n",
            "       1.2623646e-08, 1.8675898e-08, 4.0198458e-08, 9.7571778e-08,\n",
            "       2.9454441e-08, 5.2984184e-08, 3.0894864e-08, 7.4189927e-08,\n",
            "       4.6007710e-08, 2.4133032e-08, 3.2723381e-08, 4.4897977e-08,\n",
            "       2.2237103e-08, 1.1651744e-08, 8.5474035e-08, 1.0117815e-07,\n",
            "       2.4049637e-08, 4.0423109e-07, 3.6533199e-09, 1.1458980e-08,\n",
            "       5.0742539e-08, 8.3834273e-09, 1.3217252e-07, 4.6946894e-08,\n",
            "       3.3543511e-08, 6.1390897e-09, 6.0553248e-08, 1.7981105e-07,\n",
            "       1.4970725e-08, 4.2592503e-09, 2.4143199e-08, 4.2801297e-08],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 287, 'shape': array([144,   1,   1,  72], dtype=int32), 'shape_signature': array([144,   1,   1,  72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([6.05958594e-05, 2.46264262e-05, 2.64577102e-05, 7.00329765e-05,\n",
            "       6.95471408e-06, 1.10746269e-05, 6.66179403e-04, 4.74015469e-05,\n",
            "       2.15490691e-05, 3.18427228e-05, 7.85960947e-05, 3.06362090e-05,\n",
            "       4.31262233e-05, 5.00169954e-05, 7.58098076e-06, 5.02682851e-05,\n",
            "       2.87333060e-05, 3.06936599e-05, 1.23918566e-04, 2.23592742e-05,\n",
            "       3.52274306e-04, 1.62512624e-05, 1.44271689e-05, 4.26304614e-05,\n",
            "       6.34960161e-05, 3.37033271e-05, 1.05762032e-04, 5.37428605e-05,\n",
            "       1.14049290e-05, 2.57046249e-05, 1.12185204e-04, 1.49430227e-04,\n",
            "       4.86006466e-05, 1.36529725e-05, 3.21437146e-05, 7.60062221e-06,\n",
            "       1.89861657e-05, 2.83347879e-04, 2.96670933e-05, 9.22182971e-06,\n",
            "       1.81013838e-05, 2.04695752e-05, 9.54483676e-06, 2.92454060e-04,\n",
            "       2.56374242e-05, 4.33340028e-05, 1.85478857e-04, 8.09643680e-05,\n",
            "       1.21289286e-05, 4.17812189e-05, 2.34341511e-04, 1.92794978e-05,\n",
            "       1.26368086e-05, 1.20902194e-04, 2.52021455e-05, 1.28745796e-05,\n",
            "       5.26764597e-06, 1.09338189e-05, 5.40043911e-05, 3.83207480e-05,\n",
            "       1.37572933e-05, 7.48023422e-06, 1.17025447e-04, 6.21356685e-06,\n",
            "       7.86965829e-05, 2.70918736e-05, 9.50838421e-06, 1.92436346e-05,\n",
            "       2.73458809e-05, 2.67018695e-05, 1.41214050e-05, 2.13271167e-04,\n",
            "       3.45336230e-05, 1.36191375e-04, 5.60967192e-06, 4.21280056e-05,\n",
            "       1.63973473e-05, 2.77794470e-06, 2.01581970e-05, 7.95733504e-05,\n",
            "       3.80357014e-05, 2.67205651e-05, 8.13380575e-06, 1.41784640e-05,\n",
            "       6.30139994e-06, 2.80751465e-05, 1.77494021e-05, 1.72115906e-05,\n",
            "       2.73598580e-05, 3.96769838e-06, 2.76338142e-05, 1.26419391e-05,\n",
            "       1.15184148e-05, 1.06795733e-05, 4.35843731e-06, 4.99324269e-05,\n",
            "       3.28609531e-05, 3.40504157e-05, 6.97489741e-05, 2.14384090e-05,\n",
            "       8.12882383e-04, 1.27423600e-05, 7.49374085e-05, 4.82090982e-05,\n",
            "       2.17027991e-05, 1.85707686e-04, 1.36618273e-05, 1.01011254e-04,\n",
            "       4.19383396e-05, 3.91923204e-05, 1.16195897e-05, 5.45097646e-06,\n",
            "       1.04155206e-05, 1.54091140e-05, 3.31669507e-05, 8.05045420e-05,\n",
            "       2.43022751e-05, 4.37162016e-05, 2.54907391e-05, 6.12126387e-05,\n",
            "       3.79600497e-05, 1.99116857e-05, 2.69994125e-05, 3.70444322e-05,\n",
            "       1.83473931e-05, 9.61362275e-06, 7.05229322e-05, 8.34800885e-05,\n",
            "       1.98428788e-05, 3.33523058e-04, 3.01428190e-06, 9.45457759e-06,\n",
            "       4.18666641e-05, 6.91700006e-06, 1.09052926e-04, 3.87349537e-05,\n",
            "       2.76760857e-05, 5.06524111e-06, 4.99612870e-05, 1.48358537e-04,\n",
            "       1.23520485e-05, 3.51422318e-06, 1.99200749e-05, 3.53145006e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 288, 'shape': array([72], dtype=int32), 'shape_signature': array([72], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.2502674e-06, 2.1415567e-06, 1.1884226e-06, 7.2754702e-08,\n",
            "       2.5605922e-07, 1.5206983e-06, 1.3768608e-06, 8.1533904e-07,\n",
            "       3.0591600e-08, 1.1012181e-06, 1.0100472e-08, 2.4075470e-07,\n",
            "       4.9292436e-07, 8.6834524e-07, 7.6464642e-07, 2.6292224e-07,\n",
            "       6.8702752e-07, 9.5382700e-07, 7.8968833e-07, 1.6306679e-07,\n",
            "       6.8913232e-07, 3.4877198e-07, 1.8276691e-07, 5.0742592e-06,\n",
            "       7.5555661e-08, 1.1900075e-06, 3.7549515e-07, 4.5664677e-07,\n",
            "       1.4730741e-06, 9.3830010e-07, 1.9714682e-06, 2.4261118e-07,\n",
            "       2.0805321e-07, 3.5446197e-07, 4.3604109e-07, 1.5488941e-06,\n",
            "       2.1321031e-07, 9.5010606e-08, 1.0852859e-06, 1.2828330e-06,\n",
            "       1.9083491e-06, 8.2041981e-07, 1.6171367e-06, 1.0301825e-06,\n",
            "       1.9887136e-06, 1.8125928e-06, 1.7659838e-06, 8.4577397e-07,\n",
            "       6.2145392e-07, 9.2447311e-07, 2.8821123e-08, 1.4569373e-06,\n",
            "       1.3151642e-06, 1.2005839e-07, 1.4665113e-06, 6.6050404e-07,\n",
            "       2.9471158e-07, 2.0113544e-06, 5.8286992e-07, 9.1657972e-07,\n",
            "       3.6631863e-07, 4.8542375e-07, 2.2417375e-06, 6.7801011e-07,\n",
            "       7.4273891e-07, 6.4141278e-07, 4.9971891e-07, 2.6434654e-07,\n",
            "       1.0680170e-06, 8.6482189e-08, 7.7551590e-07, 2.3814798e-07],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 289, 'shape': array([ 72,   1,   1, 288], dtype=int32), 'shape_signature': array([ 72,   1,   1, 288], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.0735375e-04, 1.8388398e-04, 1.0204348e-04, 6.2470558e-06,\n",
            "       2.1986432e-05, 1.3057420e-04, 1.1822365e-04, 7.0008791e-05,\n",
            "       2.6267367e-06, 9.4555689e-05, 8.6727329e-07, 2.0672314e-05,\n",
            "       4.2324769e-05, 7.4560150e-05, 6.5656088e-05, 2.2575723e-05,\n",
            "       5.8991369e-05, 8.1900012e-05, 6.7806301e-05, 1.4001670e-05,\n",
            "       5.9172096e-05, 2.9947179e-05, 1.5693215e-05, 4.3569942e-04,\n",
            "       6.4875594e-06, 1.0217957e-04, 3.2241755e-05, 3.9209808e-05,\n",
            "       1.2648497e-04, 8.0566795e-05, 1.6927940e-04, 2.0831720e-05,\n",
            "       1.7864413e-05, 3.0435747e-05, 3.7440510e-05, 1.3299524e-04,\n",
            "       1.8307226e-05, 8.1580511e-06, 9.3187678e-05, 1.1014999e-04,\n",
            "       1.6385970e-04, 7.0445050e-05, 1.3885486e-04, 8.8456247e-05,\n",
            "       1.7076018e-04, 1.5563762e-04, 1.5163556e-04, 7.2622075e-05,\n",
            "       5.3360913e-05, 7.9379548e-05, 2.4747153e-06, 1.2509940e-04,\n",
            "       1.1292610e-04, 1.0308770e-05, 1.2592146e-04, 5.6713940e-05,\n",
            "       2.5305304e-05, 1.7270421e-04, 5.0047911e-05, 7.8701785e-05,\n",
            "       3.1453816e-05, 4.1680734e-05, 1.9248598e-04, 5.8217091e-05,\n",
            "       6.3775005e-05, 5.5074674e-05, 4.2908181e-05, 2.2698019e-05,\n",
            "       9.1704896e-05, 7.4257619e-06, 6.6589389e-05, 2.0448490e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 290, 'shape': array([144], dtype=int32), 'shape_signature': array([144], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.5399975e-03, 4.0201610e-04, 2.0940026e-04, 2.3152161e-04,\n",
            "       5.1623007e-04, 1.3272524e-03, 2.1010518e-04, 3.9557926e-04,\n",
            "       3.6439771e-04, 2.6935519e-04, 4.6187692e-04, 1.1260105e-04,\n",
            "       1.9792552e-04, 2.4786932e-04, 2.1791649e-03, 1.2873838e-03,\n",
            "       3.1673047e-04, 2.1329245e-03, 1.3737779e-04, 8.0385909e-04,\n",
            "       1.3480699e-04, 1.2806831e-04, 1.2234169e-03, 1.5421128e-03,\n",
            "       9.5806614e-04, 2.9129689e-03, 1.0716392e-03, 7.7129039e-04,\n",
            "       7.6175283e-04, 3.9267025e-04, 1.8871049e-04, 1.5313644e-04,\n",
            "       1.2905258e-03, 1.3507738e-03, 2.4017775e-04, 7.0179056e-04,\n",
            "       3.1691947e-04, 2.4068081e-04, 1.1785247e-03, 6.6342996e-04,\n",
            "       1.9660464e-03, 8.8412419e-04, 2.4481248e-03, 2.2310442e-04,\n",
            "       7.0566550e-04, 6.8510335e-04, 1.9151680e-04, 1.3430789e-04,\n",
            "       2.2222432e-04, 5.5391720e-04, 2.5554630e-04, 1.9223776e-03,\n",
            "       1.9289082e-04, 1.3098012e-04, 3.1918476e-04, 1.0059525e-03,\n",
            "       3.0363520e-04, 5.0584547e-04, 2.2317474e-03, 2.3467030e-04,\n",
            "       4.3245644e-04, 1.3043113e-04, 8.2791486e-04, 6.2622817e-04,\n",
            "       3.5412158e-04, 7.5809547e-04, 1.7712392e-03, 6.9724722e-04,\n",
            "       2.0254219e-04, 2.8283545e-03, 1.3293045e-03, 5.4817036e-04,\n",
            "       2.0794782e-03, 2.1582606e-04, 8.6713431e-04, 5.8414174e-05,\n",
            "       3.4668483e-04, 1.0677241e-03, 7.0184976e-04, 7.6237688e-04,\n",
            "       6.0863327e-04, 3.1950709e-04, 9.4049529e-04, 9.3550136e-04,\n",
            "       8.6397468e-04, 1.5164051e-03, 3.7608884e-04, 6.3722237e-04,\n",
            "       1.4351888e-03, 3.2684440e-04, 1.5189550e-03, 1.8234219e-03,\n",
            "       3.7527911e-04, 3.6119493e-03, 7.7204010e-04, 5.5800047e-04,\n",
            "       1.3855733e-03, 2.2197694e-03, 1.0862909e-03, 3.4928558e-04,\n",
            "       1.4942382e-04, 1.5035676e-03, 6.5061898e-04, 8.7009754e-04,\n",
            "       5.2026199e-04, 1.8127283e-04, 1.5234317e-04, 9.8084907e-05,\n",
            "       1.2185873e-03, 1.8327465e-04, 1.1400252e-04, 7.9505239e-04,\n",
            "       2.5576551e-04, 4.2470399e-04, 3.4350011e-04, 4.2006961e-04,\n",
            "       1.8466439e-04, 2.5722098e-03, 1.0068867e-03, 2.5365394e-04,\n",
            "       1.0274135e-03, 1.1479226e-03, 1.4404448e-03, 1.0354600e-03,\n",
            "       1.5878648e-04, 9.5058687e-04, 6.2456419e-04, 6.3990400e-04,\n",
            "       1.4068199e-03, 9.5054813e-05, 1.5402667e-04, 8.3744182e-04,\n",
            "       8.4972620e-04, 7.3247065e-04, 4.0342443e-04, 1.7423381e-04,\n",
            "       1.3229423e-04, 1.8822521e-04, 4.6795476e-04, 2.2625556e-04,\n",
            "       4.7490461e-04, 2.3163350e-03, 3.4433190e-04, 1.4386084e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block3_layer4/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer6/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block3_layer4/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 291, 'shape': array([  1,   5,   5, 144], dtype=int32), 'shape_signature': array([  1,   5,   5, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.03000218, 0.00783206, 0.00407953, 0.0045105 , 0.01005718,\n",
            "       0.02585748, 0.00409326, 0.00770666, 0.00709918, 0.00524757,\n",
            "       0.00899827, 0.00219369, 0.00385598, 0.00482898, 0.04245441,\n",
            "       0.02508076, 0.00617053, 0.04155356, 0.00267639, 0.01566075,\n",
            "       0.0026263 , 0.00249502, 0.02383456, 0.03004339, 0.01866501,\n",
            "       0.05675035, 0.02087764, 0.01502625, 0.01484044, 0.00764999,\n",
            "       0.00367645, 0.0029834 , 0.02514198, 0.02631573, 0.00467913,\n",
            "       0.01367226, 0.00617421, 0.00468893, 0.02295998, 0.01292492,\n",
            "       0.03830244, 0.01722448, 0.04769428, 0.00434651, 0.01374775,\n",
            "       0.01334716, 0.00373112, 0.00261658, 0.00432937, 0.01079139,\n",
            "       0.00497854, 0.03745169, 0.00375789, 0.00255175, 0.00621835,\n",
            "       0.01959793, 0.00591541, 0.00985486, 0.04347882, 0.00457184,\n",
            "       0.0084251 , 0.00254105, 0.01612941, 0.01220015, 0.00689898,\n",
            "       0.01476919, 0.03450722, 0.01358374, 0.00394592, 0.0551019 ,\n",
            "       0.02589746, 0.01067943, 0.04051232, 0.00420472, 0.01689348,\n",
            "       0.00113802, 0.0067541 , 0.02080136, 0.01367341, 0.0148526 ,\n",
            "       0.01185737, 0.00622463, 0.0183227 , 0.0182254 , 0.01683192,\n",
            "       0.02954255, 0.00732695, 0.01241434, 0.0279603 , 0.00636757,\n",
            "       0.02959223, 0.03552384, 0.00731117, 0.07036787, 0.01504086,\n",
            "       0.01087094, 0.02699369, 0.04324547, 0.02116308, 0.00680477,\n",
            "       0.00291107, 0.02929245, 0.01267534, 0.01695121, 0.01013573,\n",
            "       0.00353155, 0.00296794, 0.00191089, 0.02374047, 0.00357055,\n",
            "       0.00222099, 0.01548918, 0.00498281, 0.00827407, 0.00669206,\n",
            "       0.00818378, 0.00359763, 0.0501117 , 0.01961613, 0.00494168,\n",
            "       0.02001603, 0.02236379, 0.0280627 , 0.0201728 , 0.00309347,\n",
            "       0.0185193 , 0.01216774, 0.01246659, 0.02740761, 0.00185185,\n",
            "       0.00300074, 0.01631501, 0.01655434, 0.01426997, 0.0078595 ,\n",
            "       0.00339442, 0.00257735, 0.003667  , 0.00911668, 0.0044079 ,\n",
            "       0.00925207, 0.04512675, 0.00670826, 0.02802692], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 292, 'shape': array([144], dtype=int32), 'shape_signature': array([144], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.08044509e-05, 5.30364377e-05, 1.83510827e-04, 1.26370040e-04,\n",
            "       9.84006838e-05, 3.88669396e-05, 3.40464961e-04, 9.41910039e-05,\n",
            "       5.99832383e-05, 1.82149030e-04, 1.66039346e-04, 1.35529466e-04,\n",
            "       1.47048762e-04, 1.60644253e-04, 3.05829417e-05, 2.81321245e-05,\n",
            "       1.18923475e-04, 4.52368331e-05, 1.70403975e-04, 2.66224906e-05,\n",
            "       2.26998469e-04, 2.22321381e-04, 2.56774947e-05, 3.11480944e-05,\n",
            "       4.99699272e-05, 1.88935628e-05, 3.06514230e-05, 3.04784153e-05,\n",
            "       7.09184387e-05, 2.57524749e-04, 1.34501897e-04, 1.80880830e-04,\n",
            "       2.68051153e-05, 4.51831183e-05, 4.43697558e-04, 3.83441366e-05,\n",
            "       1.87356200e-04, 1.57437549e-04, 4.64676341e-05, 6.83886537e-05,\n",
            "       2.30799978e-05, 5.54189755e-05, 4.79111659e-05, 1.82925971e-04,\n",
            "       4.57623064e-05, 2.03256262e-04, 1.95870351e-04, 1.50256557e-04,\n",
            "       1.70930143e-04, 4.17903138e-05, 2.16992179e-04, 3.18143793e-05,\n",
            "       1.74813467e-04, 9.41271937e-05, 1.53994042e-04, 2.20794427e-05,\n",
            "       1.35267357e-04, 1.39405762e-04, 2.79897540e-05, 1.74222776e-04,\n",
            "       2.26840100e-04, 1.49127620e-04, 3.56819219e-05, 9.36443830e-05,\n",
            "       6.60484802e-05, 3.92531656e-05, 2.77397703e-05, 6.25675530e-05,\n",
            "       2.04340831e-04, 1.30024695e-04, 3.77830547e-05, 1.59840885e-04,\n",
            "       2.30387996e-05, 2.14114931e-04, 5.40386245e-05, 2.02008130e-04,\n",
            "       1.55609756e-04, 4.05585342e-05, 4.67809696e-05, 8.68522402e-05,\n",
            "       9.10733943e-05, 2.32134378e-04, 7.65013683e-05, 3.11760596e-05,\n",
            "       3.86924294e-05, 4.22874436e-05, 1.10311033e-04, 3.72261638e-05,\n",
            "       4.90966850e-05, 2.24121468e-04, 1.99372716e-05, 2.06723307e-05,\n",
            "       1.46358754e-04, 2.17665020e-05, 6.02439541e-05, 1.96388777e-04,\n",
            "       2.97486040e-05, 5.85195558e-05, 4.36840965e-05, 1.94948341e-04,\n",
            "       2.48305267e-04, 6.06570757e-05, 1.84020580e-04, 4.07912376e-05,\n",
            "       5.53245445e-05, 1.76602145e-04, 1.69139792e-04, 2.78830237e-04,\n",
            "       6.36574987e-05, 1.40196236e-04, 1.85924931e-04, 7.55302972e-05,\n",
            "       1.34334434e-04, 1.30454573e-04, 1.41177108e-04, 1.70469211e-04,\n",
            "       1.69146675e-04, 2.65880481e-05, 2.52193477e-05, 1.82208372e-04,\n",
            "       2.58256841e-05, 2.69532902e-05, 2.34615654e-05, 3.69545269e-05,\n",
            "       1.59971576e-04, 2.73215719e-05, 7.66542144e-05, 4.23815909e-05,\n",
            "       3.64395128e-05, 2.45341915e-04, 2.70081568e-04, 3.73987750e-05,\n",
            "       2.98100676e-05, 7.33201814e-05, 2.46431591e-04, 1.66965110e-04,\n",
            "       1.99286209e-04, 1.68264174e-04, 1.64710014e-04, 1.15987146e-04,\n",
            "       1.54009307e-04, 3.95737334e-05, 1.78605420e-04, 2.36322012e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 293, 'shape': array([144,   1,   1,  72], dtype=int32), 'shape_signature': array([144,   1,   1,  72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.55451339e-05, 6.11985379e-05, 2.11752413e-04, 1.45817889e-04,\n",
            "       1.13544163e-04, 4.48484097e-05, 3.92861170e-04, 1.08686625e-04,\n",
            "       6.92144240e-05, 2.10181053e-04, 1.91592146e-04, 1.56386915e-04,\n",
            "       1.69678984e-04, 1.85366764e-04, 3.52895368e-05, 3.24615467e-05,\n",
            "       1.37225332e-04, 5.21986040e-05, 1.96628476e-04, 3.07195878e-05,\n",
            "       2.61932641e-04, 2.56535772e-04, 2.96291601e-05, 3.59416626e-05,\n",
            "       5.76601014e-05, 2.18012083e-05, 3.53685573e-05, 3.51689232e-05,\n",
            "       8.18325061e-05, 2.97156803e-04, 1.55201211e-04, 2.08717669e-04,\n",
            "       3.09303177e-05, 5.21366237e-05, 5.11980848e-04, 4.42451492e-05,\n",
            "       2.16189583e-04, 1.81666561e-04, 5.36188199e-05, 7.89133992e-05,\n",
            "       2.66319184e-05, 6.39477366e-05, 5.52845049e-05, 2.11077553e-04,\n",
            "       5.28049459e-05, 2.34536608e-04, 2.26014032e-04, 1.73380453e-04,\n",
            "       1.97235611e-04, 4.82216783e-05, 2.50386423e-04, 3.67104876e-05,\n",
            "       2.01716568e-04, 1.08613000e-04, 1.77693117e-04, 2.54773822e-05,\n",
            "       1.56084468e-04, 1.60859752e-04, 3.22972664e-05, 2.01034971e-04,\n",
            "       2.61749898e-04, 1.72077765e-04, 4.11732290e-05, 1.08055887e-04,\n",
            "       7.62130803e-05, 4.52940731e-05, 3.20088111e-05, 7.21964534e-05,\n",
            "       2.35788073e-04, 1.50034990e-04, 4.35977163e-05, 1.84439763e-04,\n",
            "       2.65843810e-05, 2.47066375e-04, 6.23549568e-05, 2.33096391e-04,\n",
            "       1.79557479e-04, 4.68003345e-05, 5.39803768e-05, 1.00218458e-04,\n",
            "       1.05089232e-04, 2.67858937e-04, 8.82746244e-05, 3.59739315e-05,\n",
            "       4.46470403e-05, 4.87953148e-05, 1.27287465e-04, 4.29551219e-05,\n",
            "       5.66524723e-05, 2.58612883e-04, 2.30055393e-05, 2.38537214e-05,\n",
            "       1.68882791e-04, 2.51162801e-05, 6.95152630e-05, 2.26612232e-04,\n",
            "       3.43267966e-05, 6.75254851e-05, 5.04069067e-05, 2.24950127e-04,\n",
            "       2.86518480e-04, 6.99919619e-05, 2.12340630e-04, 4.70688501e-05,\n",
            "       6.38387719e-05, 2.03780524e-04, 1.95169734e-04, 3.21741129e-04,\n",
            "       7.34541391e-05, 1.61771881e-04, 2.14538042e-04, 8.71541124e-05,\n",
            "       1.55007976e-04, 1.50531021e-04, 1.62903714e-04, 1.96703753e-04,\n",
            "       1.95177679e-04, 3.06798429e-05, 2.91005053e-05, 2.10249520e-04,\n",
            "       2.98001560e-05, 3.11012955e-05, 2.70722085e-05, 4.26416809e-05,\n",
            "       1.84590579e-04, 3.15262550e-05, 8.84509936e-05, 4.89039521e-05,\n",
            "       4.20474098e-05, 2.83099071e-04, 3.11646058e-04, 4.31542976e-05,\n",
            "       3.43977190e-05, 8.46038674e-05, 2.84356443e-04, 1.92660387e-04,\n",
            "       2.29955564e-04, 1.94159365e-04, 1.90058228e-04, 1.33837108e-04,\n",
            "       1.77710725e-04, 4.56639755e-05, 2.06092096e-04, 2.72691032e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/rezero/mul', 'index': 294, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.008651794865727425, -128), 'quantization_parameters': {'scales': array([0.00865179], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 295, 'shape': array([72], dtype=int32), 'shape_signature': array([72], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.0007442 , 0.0015252 , 0.00061617, 0.00063999, 0.00079462,\n",
            "       0.00085496, 0.00068747, 0.00073295, 0.00107581, 0.00074538,\n",
            "       0.00085046, 0.0006998 , 0.00064804, 0.00043335, 0.00037282,\n",
            "       0.00082324, 0.00069848, 0.00075258, 0.00103343, 0.00085136,\n",
            "       0.00045853, 0.00070316, 0.00081155, 0.00108938, 0.00108617,\n",
            "       0.00097548, 0.00057221, 0.00039626, 0.00081969, 0.000887  ,\n",
            "       0.00103779, 0.00095177, 0.00080135, 0.00067004, 0.00112563,\n",
            "       0.00069453, 0.00070518, 0.00076704, 0.00062233, 0.00077475,\n",
            "       0.001035  , 0.00086572, 0.00201319, 0.00122554, 0.00084495,\n",
            "       0.00060251, 0.00071566, 0.00097853, 0.00052748, 0.00060306,\n",
            "       0.00048199, 0.00098112, 0.00101465, 0.0004517 , 0.0006877 ,\n",
            "       0.0006493 , 0.00117349, 0.00052743, 0.00076078, 0.00072298,\n",
            "       0.0005156 , 0.00111439, 0.00096809, 0.00064021, 0.00075401,\n",
            "       0.00072558, 0.00071824, 0.00052418, 0.00075375, 0.00086722,\n",
            "       0.00059541, 0.00091723], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 296, 'shape': array([ 72,   1,   1, 240], dtype=int32), 'shape_signature': array([ 72,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01782664, 0.03653463, 0.01475974, 0.01533026, 0.01903435,\n",
            "       0.02047959, 0.01646771, 0.01755701, 0.0257699 , 0.01785483,\n",
            "       0.02037199, 0.01676308, 0.01552311, 0.01038034, 0.00893048,\n",
            "       0.0197198 , 0.01673129, 0.01802732, 0.02475487, 0.0203935 ,\n",
            "       0.0109835 , 0.01684349, 0.01943978, 0.02609505, 0.02601802,\n",
            "       0.02336668, 0.01370666, 0.0094921 , 0.0196349 , 0.02124713,\n",
            "       0.02485911, 0.02279877, 0.0191956 , 0.0160501 , 0.02696338,\n",
            "       0.01663684, 0.01689186, 0.01837354, 0.01490727, 0.0185584 ,\n",
            "       0.02479232, 0.02073751, 0.04822391, 0.02935653, 0.02023984,\n",
            "       0.01443255, 0.01714279, 0.02343961, 0.01263516, 0.01444569,\n",
            "       0.01154568, 0.0235016 , 0.02430485, 0.01081991, 0.0164731 ,\n",
            "       0.0155534 , 0.02810984, 0.01263406, 0.0182236 , 0.01731818,\n",
            "       0.01235066, 0.02669401, 0.02318966, 0.01533547, 0.01806163,\n",
            "       0.01738053, 0.01720461, 0.0125561 , 0.01805522, 0.02077325,\n",
            "       0.01426232, 0.02197124], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block3_layer3/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block3_layer3/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block3_layer3/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer3/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 297, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.90049141e-05, 3.25650617e-05, 2.47155294e-05, 3.49814181e-05,\n",
            "       4.05875471e-05, 1.64646372e-05, 2.05083743e-05, 1.86669640e-05,\n",
            "       2.60026791e-05, 3.94232920e-05, 2.99467210e-05, 2.77578220e-05,\n",
            "       1.86653306e-05, 1.14986033e-05, 2.99070889e-05, 1.93856231e-05,\n",
            "       4.16575385e-05, 3.50441478e-05, 7.23356789e-05, 1.87488604e-05,\n",
            "       4.18444761e-05, 3.20191430e-05, 8.47397405e-06, 1.27217554e-05,\n",
            "       2.44420753e-05, 1.97170521e-05, 2.31650156e-05, 2.19994145e-05,\n",
            "       2.69035136e-05, 4.21328841e-05, 2.02327101e-05, 2.50282501e-05,\n",
            "       1.41618184e-05, 2.14557203e-05, 2.40011741e-05, 3.28696915e-05,\n",
            "       6.92170433e-05, 1.88825124e-05, 1.94222157e-05, 1.15864195e-05,\n",
            "       2.12216255e-05, 3.63947620e-05, 1.37129100e-05, 2.29878933e-05,\n",
            "       3.66074237e-05, 2.49058685e-05, 1.90591418e-05, 4.18025302e-05,\n",
            "       1.86781162e-05, 1.31255574e-05, 1.96146320e-05, 8.33239756e-06,\n",
            "       3.00481752e-05, 2.20751317e-05, 2.56279454e-05, 2.87861676e-05,\n",
            "       2.16387762e-05, 4.48429018e-05, 3.64175248e-05, 4.57601600e-05,\n",
            "       3.05066060e-05, 3.67418688e-05, 2.11108090e-05, 3.47339410e-05,\n",
            "       1.66956252e-05, 2.19093617e-05, 2.48858105e-05, 1.96147794e-05,\n",
            "       1.88695485e-05, 2.25618878e-05, 2.12776613e-05, 6.53252437e-06,\n",
            "       9.52557002e-06, 6.87212887e-05, 2.80742370e-05, 2.47271382e-05,\n",
            "       2.30730020e-05, 4.28594030e-05, 1.71190586e-05, 2.43901850e-05,\n",
            "       2.47477674e-05, 2.07817375e-05, 1.73178905e-05, 3.14225217e-05,\n",
            "       1.71509819e-05, 2.23741099e-05, 3.92660768e-05, 1.66778373e-05,\n",
            "       1.91615600e-05, 2.84415255e-05, 2.50640933e-05, 2.43703798e-05,\n",
            "       1.56836559e-05, 1.03721877e-05, 1.56132937e-05, 1.98826692e-05,\n",
            "       3.50602859e-05, 2.30705682e-05, 2.62456379e-05, 1.94410313e-05,\n",
            "       1.91805993e-05, 1.80074276e-05, 1.94143431e-05, 2.26989378e-05,\n",
            "       2.54181996e-05, 1.67768030e-05, 4.76191381e-05, 2.05215802e-05,\n",
            "       3.61288512e-05, 1.56979168e-05, 3.75036871e-05, 1.45465838e-05,\n",
            "       3.30688308e-05, 2.74126760e-05, 2.30387705e-05, 1.44075957e-05,\n",
            "       2.47935113e-05, 4.87696161e-05, 2.03330128e-05, 4.16380135e-05,\n",
            "       1.82171079e-05, 2.53995422e-05, 2.33862938e-05, 2.05306133e-05,\n",
            "       2.01926723e-05, 2.10727503e-05, 1.53592409e-05, 5.83565597e-05,\n",
            "       1.05096333e-05, 3.43334177e-05, 3.05718131e-05, 2.65724084e-05,\n",
            "       1.61516109e-05, 1.97616446e-05, 1.35635582e-05, 2.12197701e-05,\n",
            "       4.52312997e-05, 1.94617933e-05, 2.02178908e-05, 1.98267062e-05,\n",
            "       2.13005933e-05, 2.48589695e-05, 2.96856688e-05, 1.95228695e-05,\n",
            "       2.11669721e-05, 3.67904395e-05, 2.20301590e-05, 3.35165278e-05,\n",
            "       4.36957671e-05, 1.36155995e-05, 2.39670226e-05, 2.48362103e-05,\n",
            "       1.41230748e-05, 3.50817791e-05, 1.81796040e-05, 2.70794935e-05,\n",
            "       2.59790668e-05, 1.84890996e-05, 2.32218790e-05, 1.34979637e-05,\n",
            "       2.49034165e-05, 3.54288823e-05, 1.70465719e-05, 1.97684949e-05,\n",
            "       2.49479417e-05, 3.09971110e-05, 1.78041391e-05, 2.12126797e-05,\n",
            "       1.65474885e-05, 2.25538406e-05, 2.57710362e-05, 2.88593928e-05,\n",
            "       1.61544176e-05, 1.20373252e-05, 3.42565545e-05, 1.98722282e-05,\n",
            "       1.96706969e-05, 2.94759411e-05, 2.64449682e-05, 3.05925932e-05,\n",
            "       2.00400500e-05, 1.79825656e-05, 3.30473595e-05, 4.59838229e-05,\n",
            "       2.27379915e-05, 1.33072617e-05, 9.75506009e-06, 2.74846952e-05,\n",
            "       1.63163804e-05, 1.91886047e-05, 4.11089713e-05, 1.98672424e-05,\n",
            "       2.21523060e-05, 5.05518256e-05, 1.94815511e-05, 2.76389455e-05,\n",
            "       1.83823340e-05, 3.18140155e-05, 1.07428550e-05, 1.24185572e-05,\n",
            "       1.75162295e-05, 2.33986721e-05, 2.11097413e-05, 1.69327377e-05,\n",
            "       1.33149224e-05, 3.73880794e-05, 4.62187054e-05, 2.44722141e-05,\n",
            "       2.01473140e-05, 2.47735315e-05, 1.01645528e-05, 3.38738246e-05,\n",
            "       2.05248689e-05, 1.78413011e-05, 2.12734558e-05, 3.66366439e-05,\n",
            "       2.51682650e-05, 1.54110930e-05, 3.23373570e-05, 2.95078098e-05,\n",
            "       1.74199413e-05, 1.73114950e-05, 8.49459411e-06, 2.02134615e-05,\n",
            "       1.43950301e-05, 2.24117757e-05, 6.24179665e-06, 2.88803512e-05,\n",
            "       2.10384460e-05, 4.87369653e-05, 1.94980821e-05, 2.91026572e-05,\n",
            "       2.48086562e-05, 2.89694417e-05, 3.15762663e-05, 1.54510890e-05,\n",
            "       4.12167246e-05, 3.15116522e-05, 3.42363419e-05, 2.54810166e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 298, 'shape': array([240,   1,   1, 120], dtype=int32), 'shape_signature': array([240,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00083903, 0.00143768, 0.00109114, 0.00154436, 0.00179186,\n",
            "       0.00072688, 0.0009054 , 0.00082411, 0.00114797, 0.00174046,\n",
            "       0.00132209, 0.00122545, 0.00082404, 0.00050764, 0.00132034,\n",
            "       0.00085584, 0.0018391 , 0.00154713, 0.00319347, 0.00082772,\n",
            "       0.00184735, 0.00141358, 0.00037411, 0.00056164, 0.00107907,\n",
            "       0.00087047, 0.00102269, 0.00097123, 0.00118774, 0.00186008,\n",
            "       0.00089323, 0.00110495, 0.00062522, 0.00094723, 0.0010596 ,\n",
            "       0.00145113, 0.00305579, 0.00083362, 0.00085745, 0.00051152,\n",
            "       0.00093689, 0.00160676, 0.0006054 , 0.00101487, 0.00161614,\n",
            "       0.00109954, 0.00084142, 0.0018455 , 0.0008246 , 0.00057947,\n",
            "       0.00086595, 0.00036786, 0.00132657, 0.00097457, 0.00113142,\n",
            "       0.00127085, 0.00095531, 0.00197972, 0.00160776, 0.00202022,\n",
            "       0.00134681, 0.00162208, 0.000932  , 0.00153343, 0.00073708,\n",
            "       0.00096725, 0.00109866, 0.00086595, 0.00083305, 0.00099606,\n",
            "       0.00093937, 0.0002884 , 0.00042053, 0.00303391, 0.00123942,\n",
            "       0.00109165, 0.00101863, 0.00189216, 0.00075577, 0.00107678,\n",
            "       0.00109256, 0.00091747, 0.00076455, 0.00138724, 0.00075718,\n",
            "       0.00098777, 0.00173352, 0.00073629, 0.00084594, 0.00125564,\n",
            "       0.00110653, 0.0010759 , 0.0006924 , 0.00045791, 0.0006893 ,\n",
            "       0.00087778, 0.00154784, 0.00101852, 0.00115869, 0.00085828,\n",
            "       0.00084678, 0.00079499, 0.0008571 , 0.00100211, 0.00112216,\n",
            "       0.00074066, 0.00210229, 0.00090599, 0.00159502, 0.00069303,\n",
            "       0.00165571, 0.0006422 , 0.00145992, 0.00121021, 0.00101712,\n",
            "       0.00063607, 0.00109458, 0.00215308, 0.00089766, 0.00183823,\n",
            "       0.00080425, 0.00112134, 0.00103246, 0.00090639, 0.00089147,\n",
            "       0.00093032, 0.00067808, 0.00257632, 0.00046398, 0.00151575,\n",
            "       0.00134968, 0.00117312, 0.00071306, 0.00087244, 0.0005988 ,\n",
            "       0.00093681, 0.00199687, 0.0008592 , 0.00089258, 0.00087531,\n",
            "       0.00094038, 0.00109747, 0.00131056, 0.0008619 , 0.00093448,\n",
            "       0.00162422, 0.00097259, 0.00147969, 0.00192908, 0.0006011 ,\n",
            "       0.0010581 , 0.00109647, 0.00062351, 0.00154879, 0.00080259,\n",
            "       0.00119551, 0.00114692, 0.00081626, 0.0010252 , 0.00059591,\n",
            "       0.00109944, 0.00156411, 0.00075257, 0.00087274, 0.0011014 ,\n",
            "       0.00136846, 0.00078602, 0.0009365 , 0.00073054, 0.00099571,\n",
            "       0.00113774, 0.00127408, 0.00071318, 0.00053142, 0.00151236,\n",
            "       0.00087732, 0.00086842, 0.0013013 , 0.00116749, 0.0013506 ,\n",
            "       0.00088473, 0.00079389, 0.00145897, 0.00203009, 0.00100384,\n",
            "       0.00058749, 0.00043067, 0.00121339, 0.00072034, 0.00084714,\n",
            "       0.00181488, 0.0008771 , 0.00097798, 0.00223176, 0.00086007,\n",
            "       0.0012202 , 0.00081154, 0.00140452, 0.00047428, 0.00054825,\n",
            "       0.00077331, 0.001033  , 0.00093195, 0.00074755, 0.00058783,\n",
            "       0.00165061, 0.00204046, 0.0010804 , 0.00088946, 0.0010937 ,\n",
            "       0.00044874, 0.00149546, 0.00090613, 0.00078766, 0.00093918,\n",
            "       0.00161743, 0.00111113, 0.00068037, 0.00142763, 0.00130271,\n",
            "       0.00076906, 0.00076427, 0.00037502, 0.00089238, 0.00063551,\n",
            "       0.00098943, 0.00027556, 0.00127501, 0.00092881, 0.00215164,\n",
            "       0.0008608 , 0.00128482, 0.00109525, 0.00127894, 0.00139403,\n",
            "       0.00068213, 0.00181964, 0.00139118, 0.00151147, 0.00112494],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 299, 'shape': array([120], dtype=int32), 'shape_signature': array([120], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([7.8364646e-05, 7.1352530e-05, 3.9535957e-05, 3.1855143e-05,\n",
            "       5.4637672e-05, 5.6511471e-05, 6.2293526e-05, 8.7303699e-05,\n",
            "       1.2573777e-05, 8.2594655e-05, 7.9933816e-05, 9.6940748e-05,\n",
            "       2.6863041e-05, 3.4149998e-05, 5.6077562e-05, 6.2837855e-05,\n",
            "       6.2401115e-05, 5.3594467e-05, 7.1148628e-05, 3.1790885e-05,\n",
            "       3.0466601e-05, 7.1272652e-06, 4.1591986e-05, 6.1005572e-05,\n",
            "       5.2065167e-05, 6.2467465e-05, 5.2033982e-05, 9.1003487e-05,\n",
            "       7.4844807e-05, 2.8981582e-05, 8.0902391e-05, 2.6841213e-05,\n",
            "       3.9697275e-05, 5.7391026e-05, 6.2148189e-05, 6.5999928e-05,\n",
            "       2.1653828e-05, 3.0075538e-05, 8.9166700e-05, 6.9554982e-05,\n",
            "       4.6914029e-05, 4.3467124e-05, 3.0706764e-05, 6.2941501e-05,\n",
            "       1.0914535e-04, 5.3710577e-05, 2.6923824e-05, 5.8835889e-05,\n",
            "       9.5022137e-05, 4.5665434e-05, 5.6693480e-05, 2.6951711e-05,\n",
            "       1.7108039e-05, 7.3853604e-05, 6.1202460e-05, 2.9925715e-05,\n",
            "       5.9438218e-05, 3.5195575e-05, 6.6565037e-05, 3.8761325e-05,\n",
            "       4.5489032e-05, 4.8048529e-05, 8.5672233e-05, 1.4297334e-05,\n",
            "       4.4729582e-05, 7.4155076e-05, 4.8702230e-05, 6.1450766e-05,\n",
            "       6.8765417e-05, 1.0306003e-04, 5.8019450e-05, 3.1876458e-05,\n",
            "       4.9353082e-05, 5.8921021e-05, 8.2563900e-05, 4.2091429e-05,\n",
            "       4.0784951e-05, 7.3355623e-05, 5.7705431e-05, 4.4997585e-05,\n",
            "       7.0794624e-05, 3.2792603e-05, 7.1238195e-05, 1.9703879e-05,\n",
            "       6.6597262e-05, 2.6158441e-05, 2.9013077e-05, 3.9425373e-05,\n",
            "       2.5631150e-05, 5.6895013e-05, 5.1417017e-05, 6.3956802e-05,\n",
            "       4.3759013e-05, 9.4039919e-05, 1.1831249e-05, 4.4614033e-05,\n",
            "       4.5142551e-05, 9.5215015e-05, 4.9584323e-05, 5.0295566e-05,\n",
            "       3.3983160e-05, 5.6150850e-05, 4.8357426e-05, 4.6264206e-05,\n",
            "       5.2990028e-05, 4.5971541e-05, 4.1326250e-05, 4.6239180e-05,\n",
            "       6.1555977e-05, 5.3495769e-05, 2.6771380e-05, 3.5011257e-05,\n",
            "       2.5413330e-05, 4.8663638e-05, 6.6011984e-05, 5.2909763e-05,\n",
            "       4.5781529e-05, 6.9907466e-05, 6.7140885e-05, 2.3363174e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 300, 'shape': array([120,   1,   1, 480], dtype=int32), 'shape_signature': array([120,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00239651, 0.00218206, 0.00120907, 0.00097418, 0.0016709 ,\n",
            "       0.0017282 , 0.00190503, 0.00266987, 0.00038452, 0.00252587,\n",
            "       0.00244449, 0.00296459, 0.00082151, 0.00104436, 0.00171493,\n",
            "       0.00192167, 0.00190832, 0.001639  , 0.00217583, 0.00097221,\n",
            "       0.00093171, 0.00021796, 0.00127194, 0.00186564, 0.00159223,\n",
            "       0.00191035, 0.00159128, 0.00278302, 0.00228886, 0.0008863 ,\n",
            "       0.00247411, 0.00082084, 0.001214  , 0.0017551 , 0.00190058,\n",
            "       0.00201837, 0.00066221, 0.00091975, 0.00272685, 0.00212709,\n",
            "       0.0014347 , 0.00132929, 0.00093906, 0.00192484, 0.00333782,\n",
            "       0.00164255, 0.00082337, 0.00179929, 0.00290592, 0.00139652,\n",
            "       0.00173377, 0.00082422, 0.00052319, 0.00225855, 0.00187166,\n",
            "       0.00091517, 0.00181771, 0.00107633, 0.00203566, 0.00118538,\n",
            "       0.00139112, 0.00146939, 0.00261998, 0.00043723, 0.0013679 ,\n",
            "       0.00226777, 0.00148939, 0.00187925, 0.00210295, 0.00315173,\n",
            "       0.00177432, 0.00097483, 0.00150929, 0.00180189, 0.00252492,\n",
            "       0.00128722, 0.00124726, 0.00224332, 0.00176472, 0.00137609,\n",
            "       0.002165  , 0.00100285, 0.00217857, 0.00060257, 0.00203664,\n",
            "       0.00079996, 0.00088726, 0.00120569, 0.00078384, 0.00173993,\n",
            "       0.00157241, 0.00195589, 0.00133821, 0.00287588, 0.00036182,\n",
            "       0.00136436, 0.00138053, 0.00291181, 0.00151636, 0.00153811,\n",
            "       0.00103925, 0.00171718, 0.00147884, 0.00141483, 0.00162051,\n",
            "       0.00140588, 0.00126382, 0.00141406, 0.00188247, 0.00163598,\n",
            "       0.00081871, 0.0010707 , 0.00077718, 0.00148821, 0.00201874,\n",
            "       0.00161806, 0.00140007, 0.00213787, 0.00205327, 0.00071448],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 301, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00115055, 0.00787577, 0.00514741, 0.00470378, 0.00632224,\n",
            "       0.00531182, 0.00157041, 0.00483874, 0.0074495 , 0.00091282,\n",
            "       0.00553334, 0.00088166, 0.00141917, 0.00090912, 0.00979192,\n",
            "       0.00072028, 0.00214075, 0.00068062, 0.00757685, 0.00196695,\n",
            "       0.00105639, 0.00126208, 0.00167131, 0.00636971, 0.00581521,\n",
            "       0.00229025, 0.02237157, 0.00695989, 0.00157179, 0.00329243,\n",
            "       0.00055563, 0.01212552, 0.00778892, 0.00947107, 0.0098481 ,\n",
            "       0.00228195, 0.00113371, 0.00086039, 0.00049003, 0.00404126,\n",
            "       0.00096375, 0.01099226, 0.00346897, 0.0046366 , 0.00370509,\n",
            "       0.00323834, 0.00091132, 0.00063548, 0.00169422, 0.00262699,\n",
            "       0.00631818, 0.00168484, 0.01445339, 0.01225626, 0.0057366 ,\n",
            "       0.00178085, 0.01073628, 0.00148005, 0.00749329, 0.00868737,\n",
            "       0.00194493, 0.00274054, 0.00888218, 0.01801228, 0.01041452,\n",
            "       0.00742758, 0.00068732, 0.00510452, 0.00428695, 0.0051871 ,\n",
            "       0.00947038, 0.00431484, 0.0042432 , 0.00200867, 0.0012007 ,\n",
            "       0.00131458, 0.00558803, 0.00372215, 0.004899  , 0.00097845,\n",
            "       0.00127765, 0.00060893, 0.00039895, 0.00450135, 0.0017362 ,\n",
            "       0.00163068, 0.00131521, 0.00218747, 0.00518245, 0.0062776 ,\n",
            "       0.00405535, 0.00204357, 0.00996799, 0.00309452, 0.00796253,\n",
            "       0.00275693, 0.00326436, 0.01390007, 0.00311238, 0.00302421,\n",
            "       0.0008737 , 0.00624221, 0.00074394, 0.00263309, 0.00074721,\n",
            "       0.00082016, 0.00115688, 0.00063622, 0.00093208, 0.00227417,\n",
            "       0.00079894, 0.00956369, 0.00121105, 0.00577425, 0.00854882,\n",
            "       0.0018998 , 0.00312549, 0.00024724, 0.00330515, 0.0009819 ,\n",
            "       0.00308552, 0.00224551, 0.0017154 , 0.00438704, 0.01000792,\n",
            "       0.00359074, 0.00596928, 0.00906416, 0.00108634, 0.00096562,\n",
            "       0.00857694, 0.00083075, 0.00184127, 0.00453675, 0.00245973,\n",
            "       0.00104156, 0.00457877, 0.0142988 , 0.00306833, 0.00736438,\n",
            "       0.00608756, 0.00052715, 0.00431631, 0.00788401, 0.00025035,\n",
            "       0.00166164, 0.01182027, 0.00364048, 0.00124594, 0.00337252,\n",
            "       0.00064337, 0.00977103, 0.00079993, 0.00186496, 0.00085392,\n",
            "       0.00889253, 0.00065964, 0.00265696, 0.00559642, 0.00574971,\n",
            "       0.00195556, 0.0072267 , 0.00183646, 0.00467644, 0.00549353,\n",
            "       0.00785741, 0.00484645, 0.00329698, 0.00280655, 0.00580797,\n",
            "       0.00108551, 0.00211181, 0.00039623, 0.0017901 , 0.00189858,\n",
            "       0.01064886, 0.00082971, 0.00124153, 0.00158624, 0.00132893,\n",
            "       0.00361261, 0.0051595 , 0.00094852, 0.00169899, 0.00311468,\n",
            "       0.00406352, 0.00093992, 0.00121507, 0.00978071, 0.00091494,\n",
            "       0.01009586, 0.00708382, 0.00773545, 0.00404407, 0.00095234,\n",
            "       0.00166419, 0.00207242, 0.00284617, 0.00253027, 0.00869414,\n",
            "       0.00176285, 0.00453648, 0.00160008, 0.0012912 , 0.00214168,\n",
            "       0.0023098 , 0.01042615, 0.00335298, 0.0063407 , 0.00366316,\n",
            "       0.00367318, 0.00571988, 0.00328953, 0.00070236, 0.00129794,\n",
            "       0.00145178, 0.00170704, 0.00741777, 0.01001547, 0.00087538,\n",
            "       0.00120573, 0.000651  , 0.004521  , 0.01274715, 0.00238697,\n",
            "       0.00457237, 0.00174075, 0.01415045, 0.00111842, 0.00106293,\n",
            "       0.00751762, 0.00786148, 0.0032669 , 0.00504151, 0.0027627 ,\n",
            "       0.0089868 , 0.00741171, 0.00143843, 0.01049531, 0.00237782],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul', 'index': 302, 'shape': array([  1,   3,   1, 240], dtype=int32), 'shape_signature': array([  1,   3,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01163873, 0.07966957, 0.05207001, 0.04758243, 0.06395439,\n",
            "       0.0537332 , 0.01588592, 0.04894763, 0.0753575 , 0.00923393,\n",
            "       0.05597403, 0.00891872, 0.014356  , 0.00919645, 0.09905285,\n",
            "       0.00728621, 0.02165538, 0.006885  , 0.07664569, 0.01989726,\n",
            "       0.01068621, 0.01276694, 0.01690658, 0.06443457, 0.05882539,\n",
            "       0.02316769, 0.22630578, 0.0704047 , 0.01589984, 0.03330545,\n",
            "       0.00562059, 0.1226591 , 0.07879099, 0.09580725, 0.09962121,\n",
            "       0.02308374, 0.01146839, 0.00870352, 0.00495708, 0.04088046,\n",
            "       0.00974909, 0.11119528, 0.03509137, 0.04690281, 0.03747982,\n",
            "       0.0327583 , 0.00921874, 0.00642837, 0.01713839, 0.02657409,\n",
            "       0.06391332, 0.01704345, 0.14620727, 0.12398165, 0.05803022,\n",
            "       0.01801469, 0.10860583, 0.01497184, 0.07580043, 0.08787946,\n",
            "       0.01967445, 0.02772272, 0.08985015, 0.18220818, 0.10535098,\n",
            "       0.07513576, 0.00695277, 0.05163623, 0.04336581, 0.05247159,\n",
            "       0.09580024, 0.04364792, 0.04292328, 0.02031931, 0.01214597,\n",
            "       0.013298  , 0.05652724, 0.0376524 , 0.04955719, 0.00989783,\n",
            "       0.01292438, 0.00615982, 0.00403573, 0.04553464, 0.01756302,\n",
            "       0.01649559, 0.01330439, 0.02212797, 0.05242456, 0.06350277,\n",
            "       0.04102299, 0.0206723 , 0.10083393, 0.03130345, 0.08054723,\n",
            "       0.02788847, 0.03302154, 0.14061002, 0.03148412, 0.03059222,\n",
            "       0.00883812, 0.06314483, 0.00752552, 0.02663574, 0.00755861,\n",
            "       0.00829656, 0.0117027 , 0.00643588, 0.00942873, 0.02300496,\n",
            "       0.00808187, 0.09674417, 0.01225071, 0.05841107, 0.08647799,\n",
            "       0.01921795, 0.03161678, 0.00250101, 0.03343413, 0.00993268,\n",
            "       0.03121242, 0.02271505, 0.01735262, 0.04437829, 0.10123787,\n",
            "       0.03632308, 0.06038389, 0.09169098, 0.01098922, 0.00976803,\n",
            "       0.08676247, 0.00840371, 0.01862589, 0.04589275, 0.02488204,\n",
            "       0.01053618, 0.0463178 , 0.14464352, 0.03103857, 0.07449641,\n",
            "       0.06158041, 0.00533254, 0.04366284, 0.07975284, 0.00253244,\n",
            "       0.01680873, 0.11957123, 0.03682631, 0.01260368, 0.03411569,\n",
            "       0.00650823, 0.09884153, 0.00809196, 0.01886557, 0.00863811,\n",
            "       0.08995487, 0.00667279, 0.02687719, 0.05661219, 0.05816275,\n",
            "       0.01978197, 0.07310365, 0.01857721, 0.04730581, 0.0555713 ,\n",
            "       0.07948378, 0.04902562, 0.03335153, 0.02839047, 0.05875211,\n",
            "       0.01098073, 0.02136255, 0.00400817, 0.01810821, 0.01920557,\n",
            "       0.10772149, 0.00839319, 0.01255909, 0.01604609, 0.01344313,\n",
            "       0.03654433, 0.05219233, 0.00959499, 0.01718657, 0.03150745,\n",
            "       0.04110569, 0.00950806, 0.01229135, 0.09893945, 0.00925535,\n",
            "       0.10212745, 0.0716583 , 0.07825011, 0.04090895, 0.00963371,\n",
            "       0.01683458, 0.0209641 , 0.02879122, 0.0255956 , 0.08794801,\n",
            "       0.01783255, 0.04589007, 0.01618606, 0.01306147, 0.02166473,\n",
            "       0.02336538, 0.10546859, 0.03391796, 0.06414113, 0.03705573,\n",
            "       0.03715711, 0.05786105, 0.03327617, 0.0071049 , 0.01312969,\n",
            "       0.0146859 , 0.017268  , 0.07503656, 0.10131428, 0.00885518,\n",
            "       0.01219689, 0.0065854 , 0.04573346, 0.12894733, 0.02414611,\n",
            "       0.04625309, 0.01760909, 0.14314285, 0.01131373, 0.01075238,\n",
            "       0.07604661, 0.07952502, 0.03304725, 0.05099878, 0.02794681,\n",
            "       0.09090848, 0.07497517, 0.01455087, 0.10616821, 0.02405348],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 303, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([8.8874908e-04, 9.4703173e-05, 5.2860480e-05, 1.0576422e-04,\n",
            "       5.8639928e-04, 1.7004274e-03, 3.6134801e-04, 5.6928804e-04,\n",
            "       1.6882038e-04, 8.7170780e-04, 1.6783028e-04, 7.9112151e-04,\n",
            "       1.6977870e-03, 1.1857116e-03, 1.5475949e-03, 7.0619158e-04,\n",
            "       6.9388526e-04, 5.1415770e-04, 8.2058294e-05, 4.0596232e-04,\n",
            "       6.0890825e-04, 6.0431845e-04, 7.8724435e-05, 1.5739808e-04,\n",
            "       1.8169604e-04, 2.9696015e-04, 1.6532899e-04, 3.6018807e-04,\n",
            "       2.4280215e-03, 2.9952973e-04, 7.7598449e-04, 1.3823953e-03,\n",
            "       5.8462180e-04, 1.8628357e-03, 1.3633432e-03, 4.8678834e-04,\n",
            "       2.6624193e-03, 1.0398877e-03, 5.8232900e-04, 1.5948636e-04,\n",
            "       3.3612439e-04, 6.3611416e-04, 1.0103137e-03, 1.2712618e-03,\n",
            "       4.3205442e-04, 6.7490881e-04, 7.0213672e-04, 4.9500959e-04,\n",
            "       5.2136072e-04, 2.6252508e-04, 2.0960108e-03, 2.4490760e-04,\n",
            "       6.4348243e-04, 7.2748626e-05, 4.6936551e-05, 2.5065539e-03,\n",
            "       4.0852241e-04, 3.0341826e-03, 1.1418990e-04, 8.0329010e-05,\n",
            "       7.4590283e-04, 2.2147482e-03, 1.0180737e-04, 1.0136049e-04,\n",
            "       7.8959047e-04, 1.2918758e-04, 1.1815664e-03, 2.0110386e-03,\n",
            "       1.1217967e-03, 2.9919820e-04, 7.3452928e-04, 2.8052786e-05,\n",
            "       2.1361621e-04, 7.9026242e-04, 1.5144500e-04, 5.5769866e-04,\n",
            "       3.3832941e-04, 8.8282197e-04, 3.3410720e-03, 1.0306636e-03,\n",
            "       7.4311130e-04, 4.4725084e-04, 3.4537379e-04, 5.6463236e-04,\n",
            "       1.4158111e-04, 4.1638405e-04, 8.5641845e-04, 3.9256644e-04,\n",
            "       4.2109037e-04, 2.4473757e-04, 3.8193865e-04, 3.7295328e-04,\n",
            "       1.2614982e-03, 1.0675425e-04, 5.3041795e-04, 3.4828470e-04,\n",
            "       1.0465591e-04, 2.6694749e-04, 1.6828071e-03, 7.9629378e-04,\n",
            "       7.3927455e-04, 1.9315245e-03, 3.1461928e-03, 4.9755973e-04,\n",
            "       1.0973723e-03, 9.7775797e-04, 1.8362424e-04, 1.0412972e-03,\n",
            "       5.8710546e-04, 1.3507614e-04, 1.1691216e-03, 5.7493628e-04,\n",
            "       6.0011644e-04, 1.3779069e-03, 1.2935339e-03, 3.6560002e-04,\n",
            "       6.4313295e-04, 7.4353436e-04, 6.7878776e-04, 8.2122919e-04,\n",
            "       1.5355152e-04, 5.1172113e-04, 5.4540293e-04, 9.5328921e-04,\n",
            "       1.7754156e-03, 2.3054401e-04, 2.1026514e-03, 1.7487057e-04,\n",
            "       4.8061844e-04, 6.8935606e-04, 7.1882107e-04, 6.3391787e-04,\n",
            "       1.6011436e-04, 8.4370746e-05, 6.3376740e-04, 7.6155749e-04,\n",
            "       6.6505896e-04, 6.2637898e-04, 1.9586070e-04, 1.8089555e-03,\n",
            "       1.5562611e-03, 1.4438832e-03, 5.3601099e-05, 1.0333462e-04,\n",
            "       7.8968611e-04, 6.9757248e-04, 4.7233552e-04, 2.4020504e-04,\n",
            "       1.2364719e-04, 1.2665475e-04, 1.0149810e-03, 2.8737175e-04,\n",
            "       1.2359695e-03, 6.5246201e-04, 9.7703969e-04, 1.1366807e-03,\n",
            "       9.9461037e-04, 1.1553662e-03, 9.2678651e-04, 1.5229728e-03,\n",
            "       1.1069564e-03, 3.4146081e-04, 6.6303951e-04, 3.2532841e-04,\n",
            "       6.2031846e-04, 2.9728469e-04, 2.9391309e-03, 1.1220722e-03,\n",
            "       3.6487641e-04, 1.1433769e-03, 3.7616305e-04, 1.7468522e-04,\n",
            "       9.0923032e-04, 5.5323449e-05, 1.1534427e-04, 3.4942813e-04,\n",
            "       9.4271312e-04, 3.3753744e-04, 7.3110324e-04, 1.0178341e-03,\n",
            "       5.6511577e-04, 6.3375730e-05, 1.8906108e-03, 2.6840373e-04,\n",
            "       2.7431449e-04, 2.7456016e-03, 3.3638789e-04, 3.0255571e-04,\n",
            "       7.7876053e-04, 8.1600499e-04, 5.3409953e-04, 1.8664369e-03,\n",
            "       3.7071126e-04, 8.7240427e-05, 9.5620903e-04, 2.7523545e-04,\n",
            "       8.3065039e-04, 3.2637327e-04, 9.4471918e-04, 1.7581861e-04,\n",
            "       6.1805546e-04, 7.5792754e-04, 4.7040987e-04, 6.5728911e-04,\n",
            "       2.8510898e-04, 5.4193044e-04, 7.5818726e-04, 2.6523613e-04,\n",
            "       1.0478931e-03, 2.0249536e-04, 4.1475618e-05, 4.2677497e-05,\n",
            "       3.8488547e-04, 9.4379828e-04, 8.2011143e-04, 1.1582098e-03,\n",
            "       3.5191365e-04, 2.7266843e-04, 1.2743606e-03, 2.0555883e-04,\n",
            "       4.3256121e-04, 9.9346240e-04, 1.1824119e-03, 7.5020635e-04,\n",
            "       1.3203238e-03, 5.1008095e-04, 4.7785716e-04, 6.0419441e-04,\n",
            "       1.9811005e-04, 2.0189793e-04, 5.8572780e-04, 3.6920389e-04,\n",
            "       6.2650663e-04, 2.1179860e-04, 4.6392740e-03, 1.2672556e-04,\n",
            "       1.1664511e-04, 3.0767056e-04, 1.1882614e-04, 7.0307276e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 304, 'shape': array([  1,   3,   3, 240], dtype=int32), 'shape_signature': array([  1,   3,   3, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01777796, 0.00189438, 0.00105739, 0.00211564, 0.01172995,\n",
            "       0.03401425, 0.00722817, 0.01138767, 0.00337697, 0.01743708,\n",
            "       0.00335717, 0.01582508, 0.03396143, 0.02371821, 0.03095708,\n",
            "       0.0141262 , 0.01388003, 0.01028488, 0.00164144, 0.00812061,\n",
            "       0.01218021, 0.01208839, 0.00157475, 0.00314849, 0.00363453,\n",
            "       0.0059402 , 0.00330713, 0.00720497, 0.04856857, 0.0059916 ,\n",
            "       0.01552229, 0.02765254, 0.01169439, 0.03726296, 0.02727143,\n",
            "       0.0097374 , 0.05325731, 0.02080124, 0.01164853, 0.00319026,\n",
            "       0.00672361, 0.01272442, 0.02020966, 0.0254295 , 0.00864254,\n",
            "       0.01350044, 0.01404509, 0.00990185, 0.01042896, 0.00525138,\n",
            "       0.04192724, 0.00489897, 0.01287181, 0.00145522, 0.00093889,\n",
            "       0.05013948, 0.00817182, 0.06069382, 0.00228418, 0.00160685,\n",
            "       0.01492056, 0.04430239, 0.00203649, 0.00202755, 0.01579446,\n",
            "       0.00258418, 0.02363529, 0.04022751, 0.02243969, 0.00598497,\n",
            "       0.01469305, 0.00056115, 0.00427304, 0.0158079 , 0.00302941,\n",
            "       0.01115584, 0.00676772, 0.0176594 , 0.06683264, 0.02061673,\n",
            "       0.01486472, 0.00894652, 0.00690863, 0.01129454, 0.0028321 ,\n",
            "       0.00832908, 0.01713124, 0.00785264, 0.00842322, 0.00489557,\n",
            "       0.00764005, 0.00746032, 0.02523419, 0.00213544, 0.01061014,\n",
            "       0.00696686, 0.00209347, 0.00533984, 0.03366178, 0.01592854,\n",
            "       0.01478797, 0.03863696, 0.0629344 , 0.00995286, 0.02195112,\n",
            "       0.01955844, 0.0036731 , 0.02082943, 0.01174408, 0.00270198,\n",
            "       0.02338635, 0.01150065, 0.01200434, 0.02756276, 0.02587502,\n",
            "       0.00731323, 0.01286481, 0.01487318, 0.01357803, 0.01642734,\n",
            "       0.00307154, 0.01023614, 0.01090989, 0.01906898, 0.03551426,\n",
            "       0.00461165, 0.04206008, 0.003498  , 0.00961398, 0.01378943,\n",
            "       0.01437883, 0.01268048, 0.00320282, 0.0016877 , 0.01267747,\n",
            "       0.0152337 , 0.01330341, 0.01252968, 0.00391787, 0.03618517,\n",
            "       0.03113044, 0.0288825 , 0.0010722 , 0.00206704, 0.01579637,\n",
            "       0.01395379, 0.00944829, 0.00480491, 0.00247336, 0.00253352,\n",
            "       0.02030302, 0.0057484 , 0.02472353, 0.01305143, 0.01954407,\n",
            "       0.02273742, 0.01989554, 0.0231112 , 0.01853884, 0.03046456,\n",
            "       0.02214284, 0.00683036, 0.01326301, 0.00650766, 0.01240845,\n",
            "       0.00594669, 0.05879247, 0.02244521, 0.00729875, 0.02287137,\n",
            "       0.00752452, 0.00349429, 0.01818765, 0.00110665, 0.00230727,\n",
            "       0.00698973, 0.01885742, 0.00675188, 0.01462451, 0.02036009,\n",
            "       0.01130421, 0.00126773, 0.03781855, 0.00536897, 0.00548721,\n",
            "       0.05492123, 0.00672889, 0.00605213, 0.01557782, 0.01632283,\n",
            "       0.01068378, 0.03733499, 0.00741547, 0.0017451 , 0.01912739,\n",
            "       0.00550563, 0.01661579, 0.00652856, 0.01889755, 0.00351696,\n",
            "       0.01236318, 0.01516109, 0.00940977, 0.01314799, 0.00570314,\n",
            "       0.01084043, 0.01516629, 0.00530561, 0.02096137, 0.00405059,\n",
            "       0.00082965, 0.00085369, 0.007699  , 0.01887913, 0.01640498,\n",
            "       0.02316808, 0.00703945, 0.00545428, 0.02549148, 0.00411187,\n",
            "       0.00865267, 0.01987258, 0.0236522 , 0.01500664, 0.0264109 ,\n",
            "       0.01020333, 0.00955874, 0.01208591, 0.00396287, 0.00403864,\n",
            "       0.01171652, 0.00738532, 0.01253223, 0.00423668, 0.09280103,\n",
            "       0.00253494, 0.00233329, 0.00615444, 0.00237692, 0.01406381],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 305, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.25247330e-04, 2.73038138e-04, 1.69425737e-04, 1.94896973e-04,\n",
            "       5.71788769e-05, 1.98656835e-05, 3.10624455e-04, 2.53348353e-05,\n",
            "       1.01477868e-04, 2.87220813e-04, 1.28577405e-04, 1.13916729e-04,\n",
            "       1.04918865e-04, 1.61802949e-04, 2.86530503e-05, 1.45728249e-04,\n",
            "       1.50831751e-04, 1.91418614e-04, 2.08873389e-04, 3.35628371e-04,\n",
            "       1.27445805e-04, 2.12361672e-04, 2.19775116e-04, 6.61911909e-05,\n",
            "       1.17205345e-04, 3.70343041e-04, 1.50467662e-04, 1.20868011e-04,\n",
            "       8.48919517e-05, 1.41103301e-04, 1.82831151e-04, 2.50825124e-05,\n",
            "       2.89044765e-05, 2.83097124e-05, 2.34268628e-05, 1.01883874e-04,\n",
            "       6.22989392e-05, 1.74465720e-04, 3.17175523e-04, 1.57245289e-04,\n",
            "       1.54357171e-04, 5.63036665e-05, 7.69143298e-05, 3.71349815e-05,\n",
            "       4.60030205e-05, 7.89484475e-05, 9.91453999e-05, 2.60586123e-04,\n",
            "       1.67194012e-04, 1.31917433e-04, 3.45863118e-05, 2.13542851e-04,\n",
            "       2.63071252e-05, 6.59448779e-05, 3.09710420e-04, 5.93812802e-05,\n",
            "       5.66761846e-05, 1.61453409e-05, 8.94104669e-05, 2.65424285e-04,\n",
            "       9.79590550e-05, 9.37150253e-05, 7.10688109e-05, 9.97132447e-05,\n",
            "       3.62498104e-05, 5.64901165e-05, 9.74494251e-05, 2.03078180e-05,\n",
            "       5.94586163e-05, 2.97510051e-05, 3.40520055e-05, 2.30698235e-04,\n",
            "       1.97322093e-04, 3.54220319e-05, 3.91179521e-04, 1.99186499e-04,\n",
            "       7.35405265e-05, 7.03629703e-05, 2.73296046e-05, 1.01714308e-04,\n",
            "       1.59724121e-04, 2.39382163e-04, 3.18757608e-04, 1.20694385e-04,\n",
            "       1.95698580e-04, 1.80619769e-04, 1.79747149e-04, 1.99479153e-04,\n",
            "       1.27450417e-04, 8.90115916e-05, 7.57087546e-05, 8.43019297e-05,\n",
            "       2.15132568e-05, 2.30892532e-04, 4.22479352e-05, 1.88957521e-04,\n",
            "       9.76384545e-05, 2.53894123e-05, 4.56021044e-05, 3.20946740e-04,\n",
            "       2.01789589e-04, 2.69301363e-05, 6.49438589e-05, 2.68652249e-04,\n",
            "       1.07660722e-04, 1.55189948e-04, 2.14712069e-04, 2.09121747e-04,\n",
            "       1.42580786e-04, 1.93397282e-04, 1.08077678e-04, 2.07468602e-05,\n",
            "       2.24131087e-04, 4.46189079e-05, 3.50003320e-05, 1.39235170e-04,\n",
            "       5.94923695e-05, 1.83260287e-04, 8.41370274e-05, 1.40313656e-04,\n",
            "       1.85419762e-04, 9.90045519e-05, 1.36631264e-04, 5.09292586e-05,\n",
            "       1.65699767e-05, 1.27070991e-04, 1.69728391e-05, 1.30785134e-04,\n",
            "       1.45298953e-04, 1.89253318e-04, 4.66590609e-05, 1.94579334e-04,\n",
            "       1.59192539e-04, 2.23774347e-04, 4.27170198e-05, 3.76130774e-05,\n",
            "       2.40814879e-05, 3.48442700e-05, 1.34272384e-04, 3.40164806e-05,\n",
            "       2.67199939e-05, 1.08565182e-04, 2.64093251e-04, 8.80197113e-05,\n",
            "       1.20127806e-04, 1.65779697e-04, 2.87167350e-05, 2.10313126e-04,\n",
            "       2.26396995e-04, 1.54232985e-04, 1.49967935e-04, 2.40233458e-05,\n",
            "       8.96539932e-05, 8.25036332e-05, 1.24772254e-04, 3.22888773e-05,\n",
            "       3.18905833e-04, 3.38620739e-05, 1.23713049e-04, 2.34485942e-05,\n",
            "       5.02166586e-05, 6.23498563e-05, 2.48908182e-04, 9.89599866e-05,\n",
            "       7.01933750e-05, 1.39095369e-04, 2.68035383e-05, 4.40408949e-05,\n",
            "       1.54119989e-04, 3.89338129e-05, 1.31212932e-04, 1.70262691e-04,\n",
            "       1.61982913e-04, 2.07960649e-04, 2.86983821e-04, 7.77521491e-05,\n",
            "       1.38072006e-04, 1.75402136e-04, 2.25886615e-04, 1.46822000e-04,\n",
            "       5.15255379e-05, 1.13557719e-04, 1.12375346e-04, 6.19873463e-05,\n",
            "       4.28424282e-05, 2.88306510e-05, 2.20507005e-04, 1.63053512e-04,\n",
            "       4.67827776e-05, 1.89066850e-04, 2.02829560e-05, 3.10126707e-05,\n",
            "       2.32146049e-05, 1.59876232e-04, 2.00479277e-04, 1.65293270e-04,\n",
            "       1.22102181e-04, 1.41253913e-04, 4.62044336e-05, 8.18189656e-05,\n",
            "       1.06324442e-04, 3.66411659e-05, 1.58073599e-04, 1.65906342e-04,\n",
            "       2.10456099e-04, 1.61215576e-04, 1.56422138e-05, 7.50205072e-05,\n",
            "       4.20018987e-05, 2.83392728e-04, 2.73583602e-04, 2.44241324e-04,\n",
            "       3.32829622e-05, 3.02448985e-04, 8.44493334e-05, 7.22088589e-05,\n",
            "       1.88296282e-04, 5.61855595e-05, 2.41862945e-05, 2.33339830e-04,\n",
            "       2.64482631e-04, 2.69891723e-04, 4.33636669e-05, 4.86161007e-05,\n",
            "       6.59840953e-05, 2.34219860e-05, 8.98837825e-05, 9.64274732e-05,\n",
            "       1.82084594e-04, 2.41672300e-04, 1.06512416e-04, 3.86113570e-05,\n",
            "       4.36209084e-05, 6.71961170e-05, 1.52606644e-05, 8.89384537e-05,\n",
            "       8.54613900e-05, 3.61097947e-04, 8.78008868e-05, 1.17618438e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 306, 'shape': array([240,   1,   1,  72], dtype=int32), 'shape_signature': array([240,   1,   1,  72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.50142034e-04, 3.27308400e-04, 2.03101547e-04, 2.33635554e-04,\n",
            "       6.85440027e-05, 2.38142748e-05, 3.72365554e-04, 3.03704983e-05,\n",
            "       1.21648060e-04, 3.44310072e-04, 1.54134017e-04, 1.36559320e-04,\n",
            "       1.25773004e-04, 1.93963613e-04, 3.43482570e-05, 1.74693836e-04,\n",
            "       1.80811738e-04, 2.29465819e-04, 2.50389974e-04, 4.02339327e-04,\n",
            "       1.52777488e-04, 2.54571612e-04, 2.63458584e-04, 7.93476429e-05,\n",
            "       1.40501594e-04, 4.43954050e-04, 1.80375268e-04, 1.44892270e-04,\n",
            "       1.01765450e-04, 1.69149615e-04, 2.19171474e-04, 3.00680222e-05,\n",
            "       3.46496563e-05, 3.39366743e-05, 2.80832883e-05, 1.22134763e-04,\n",
            "       7.46817532e-05, 2.09143298e-04, 3.80218728e-04, 1.88500053e-04,\n",
            "       1.85037876e-04, 6.74948315e-05, 9.22021645e-05, 4.45160949e-05,\n",
            "       5.51467820e-05, 9.46405853e-05, 1.18851975e-04, 3.12381366e-04,\n",
            "       2.00426235e-04, 1.58137918e-04, 4.14608403e-05, 2.55987572e-04,\n",
            "       3.15360448e-05, 7.90523700e-05, 3.71269824e-04, 7.11841640e-05,\n",
            "       6.79413934e-05, 1.93544602e-05, 1.07182081e-04, 3.18181177e-04,\n",
            "       1.17429823e-04, 1.12342233e-04, 8.51947625e-05, 1.19532684e-04,\n",
            "       4.34549838e-05, 6.77183416e-05, 1.16818897e-04, 2.43442901e-05,\n",
            "       7.12768742e-05, 3.56644450e-05, 4.08203305e-05, 2.76552833e-04,\n",
            "       2.36542706e-04, 4.24626705e-05, 4.68932092e-04, 2.38777677e-04,\n",
            "       8.81577653e-05, 8.43486196e-05, 3.27617563e-05, 1.21931487e-04,\n",
            "       1.91471583e-04, 2.86962808e-04, 3.82115279e-04, 1.44684134e-04,\n",
            "       2.34596489e-04, 2.16520551e-04, 2.15474487e-04, 2.39128509e-04,\n",
            "       1.52783017e-04, 1.06703927e-04, 9.07569556e-05, 1.01058155e-04,\n",
            "       2.57893262e-05, 2.76785751e-04, 5.06453216e-05, 2.26515549e-04,\n",
            "       1.17045507e-04, 3.04359237e-05, 5.46661795e-05, 3.84739513e-04,\n",
            "       2.41898175e-04, 3.22828892e-05, 7.78523827e-05, 3.22050764e-04,\n",
            "       1.29059845e-04, 1.86036181e-04, 2.57389183e-04, 2.50687706e-04,\n",
            "       1.70920772e-04, 2.31837781e-04, 1.29559674e-04, 2.48705983e-05,\n",
            "       2.68680364e-04, 5.34875580e-05, 4.19571516e-05, 1.66910162e-04,\n",
            "       7.13173358e-05, 2.19685913e-04, 1.00860474e-04, 1.68203012e-04,\n",
            "       2.22274612e-04, 1.18683129e-04, 1.63788689e-04, 6.10521820e-05,\n",
            "       1.98634989e-05, 1.52328183e-04, 2.03464351e-05, 1.56780559e-04,\n",
            "       1.74179208e-04, 2.26870136e-04, 5.59332220e-05, 2.33254774e-04,\n",
            "       1.90834340e-04, 2.68252712e-04, 5.12076404e-05, 4.50892185e-05,\n",
            "       2.88680312e-05, 4.17700685e-05, 1.60960961e-04, 4.07777479e-05,\n",
            "       3.20309773e-05, 1.30144079e-04, 3.16585589e-04, 1.05514897e-04,\n",
            "       1.44004938e-04, 1.98730791e-04, 3.44246000e-05, 2.52115889e-04,\n",
            "       2.71396653e-04, 1.84889010e-04, 1.79776223e-04, 2.87983312e-05,\n",
            "       1.07474014e-04, 9.89024193e-05, 1.49572530e-04, 3.87067557e-05,\n",
            "       3.82292958e-04, 4.05926476e-05, 1.48302803e-04, 2.81093398e-05,\n",
            "       6.01979409e-05, 7.47427839e-05, 2.98382249e-04, 1.18629709e-04,\n",
            "       8.41453148e-05, 1.66742582e-04, 3.21311272e-05, 5.27946577e-05,\n",
            "       1.84753560e-04, 4.66724705e-05, 1.57293383e-04, 2.04104857e-04,\n",
            "       1.94179345e-04, 2.49295816e-04, 3.44025990e-04, 9.32065086e-05,\n",
            "       1.65515812e-04, 2.10265833e-04, 2.70784833e-04, 1.76004978e-04,\n",
            "       6.17669793e-05, 1.36128947e-04, 1.34711561e-04, 7.43082201e-05,\n",
            "       5.13579762e-05, 3.45611588e-05, 2.64335948e-04, 1.95462751e-04,\n",
            "       5.60815279e-05, 2.26646604e-04, 2.43144859e-05, 3.71768874e-05,\n",
            "       2.78288426e-05, 1.91653933e-04, 2.40327412e-04, 1.98147682e-04,\n",
            "       1.46371749e-04, 1.69330160e-04, 5.53882310e-05, 9.80816621e-05,\n",
            "       1.27457955e-04, 4.39241267e-05, 1.89493003e-04, 1.98882612e-04,\n",
            "       2.52287282e-04, 1.93259490e-04, 1.87513288e-05, 8.99319130e-05,\n",
            "       5.03503798e-05, 3.39721126e-04, 3.27962276e-04, 2.92787794e-04,\n",
            "       3.98984303e-05, 3.62565072e-04, 1.01234851e-04, 8.65614129e-05,\n",
            "       2.25722877e-04, 6.73532486e-05, 2.89936688e-05, 2.79719476e-04,\n",
            "       3.17052356e-04, 3.23536602e-04, 5.19828209e-05, 5.82792491e-05,\n",
            "       7.90993872e-05, 2.80774439e-05, 1.07749482e-04, 1.15593823e-04,\n",
            "       2.18276531e-04, 2.89708143e-04, 1.27683292e-04, 4.62859207e-05,\n",
            "       5.22911905e-05, 8.05523086e-05, 1.82939420e-05, 1.06616251e-04,\n",
            "       1.02448073e-04, 4.32871369e-04, 1.05252577e-04, 1.40996795e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/rezero/mul', 'index': 307, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.008683810941874981, -128), 'quantization_parameters': {'scales': array([0.00868381], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 308, 'shape': array([72], dtype=int32), 'shape_signature': array([72], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00050409, 0.00059317, 0.00039751, 0.00050568, 0.00056458,\n",
            "       0.00057787, 0.00060169, 0.00056699, 0.00083965, 0.00064907,\n",
            "       0.00054685, 0.000612  , 0.00043826, 0.00044635, 0.00057606,\n",
            "       0.00047501, 0.00040347, 0.0004533 , 0.00057854, 0.00060701,\n",
            "       0.00052506, 0.00037948, 0.00059175, 0.00072977, 0.00081106,\n",
            "       0.00082495, 0.00040709, 0.00036572, 0.00057321, 0.00073193,\n",
            "       0.00087388, 0.00069799, 0.00047196, 0.00039964, 0.0007702 ,\n",
            "       0.00056289, 0.00059795, 0.00068177, 0.00056076, 0.00051974,\n",
            "       0.00062285, 0.00053998, 0.001605  , 0.00061644, 0.00063434,\n",
            "       0.00045266, 0.00070078, 0.00060518, 0.00049235, 0.00055439,\n",
            "       0.00044775, 0.00058161, 0.00066495, 0.00041309, 0.00064168,\n",
            "       0.00072873, 0.00080446, 0.00040147, 0.00022045, 0.00041226,\n",
            "       0.00055671, 0.0006425 , 0.00060512, 0.00053028, 0.00051513,\n",
            "       0.0005334 , 0.00050585, 0.00056225, 0.00053175, 0.00042961,\n",
            "       0.00059843, 0.0006328 ], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 309, 'shape': array([ 72,   1,   1, 240], dtype=int32), 'shape_signature': array([ 72,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01092342, 0.01285379, 0.00861396, 0.01095793, 0.0122342 ,\n",
            "       0.01252222, 0.01303833, 0.01228641, 0.01819491, 0.01406513,\n",
            "       0.01184996, 0.01326178, 0.00949692, 0.00967218, 0.01248294,\n",
            "       0.01029335, 0.00874304, 0.00982295, 0.0125368 , 0.01315376,\n",
            "       0.01137778, 0.00822319, 0.01282308, 0.01581378, 0.01757527,\n",
            "       0.01787636, 0.00882156, 0.0079251 , 0.01242129, 0.01586069,\n",
            "       0.01893662, 0.01512528, 0.01022726, 0.00865997, 0.01668997,\n",
            "       0.01219769, 0.01295744, 0.01477369, 0.01215156, 0.01126266,\n",
            "       0.013497  , 0.01170118, 0.03477975, 0.01335798, 0.0137459 ,\n",
            "       0.00980905, 0.0151857 , 0.01311409, 0.01066904, 0.01201348,\n",
            "       0.00970263, 0.01260334, 0.0144092 , 0.00895142, 0.01390489,\n",
            "       0.0157914 , 0.01743231, 0.00869973, 0.00477712, 0.00893359,\n",
            "       0.01206364, 0.01392276, 0.01311266, 0.01149093, 0.01116257,\n",
            "       0.01155863, 0.01096155, 0.01218371, 0.01152288, 0.00930954,\n",
            "       0.01296771, 0.01371262], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block3_layer2/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block3_layer2/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block3_layer2/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer2/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 310, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.57561551e-05, 1.45247941e-05, 1.47353558e-05, 1.13183205e-05,\n",
            "       1.42970957e-05, 1.12733233e-05, 6.26920882e-06, 1.57607046e-05,\n",
            "       1.56730111e-05, 1.24938751e-05, 1.10621886e-05, 7.31635009e-06,\n",
            "       8.78193896e-06, 1.91671788e-05, 3.35162463e-06, 8.17450564e-06,\n",
            "       1.12042117e-05, 2.12559462e-05, 4.25877397e-06, 8.71533484e-06,\n",
            "       5.63294134e-06, 2.04535281e-05, 1.02135054e-05, 1.37627922e-05,\n",
            "       1.32810001e-05, 2.40432582e-05, 1.97900572e-05, 8.00338967e-06,\n",
            "       1.27213025e-05, 9.92670994e-06, 1.16098136e-05, 1.27185558e-05,\n",
            "       9.80954337e-06, 1.99171245e-05, 1.18126191e-05, 2.08480924e-05,\n",
            "       1.70053354e-05, 1.08024469e-05, 1.03116181e-05, 1.33645244e-05,\n",
            "       8.29687451e-06, 1.01038186e-05, 2.11751012e-05, 2.15569635e-05,\n",
            "       2.12226587e-05, 8.00329053e-06, 1.14911727e-05, 8.70898475e-06,\n",
            "       3.89035231e-05, 1.56827846e-05, 2.96154813e-05, 1.24686239e-05,\n",
            "       1.12142943e-05, 3.31523261e-05, 2.21102855e-05, 9.81755147e-06,\n",
            "       1.99261722e-05, 1.31217321e-05, 7.50101162e-06, 1.51161648e-05,\n",
            "       1.34744714e-05, 1.46023267e-05, 1.62838060e-05, 2.33823794e-05,\n",
            "       1.37376555e-05, 2.52662994e-05, 5.50398772e-06, 1.69813266e-05,\n",
            "       4.75669840e-05, 1.45575941e-05, 1.83574812e-05, 1.31735860e-05,\n",
            "       1.03080756e-05, 1.72619748e-05, 1.59459069e-05, 1.97731060e-05,\n",
            "       7.40049427e-06, 8.29800774e-06, 7.14866337e-06, 1.37232446e-05,\n",
            "       6.95750941e-06, 1.27248932e-05, 1.37978495e-05, 1.16808105e-05,\n",
            "       2.88619467e-05, 1.03674411e-05, 8.58852309e-06, 1.32186651e-05,\n",
            "       3.17308804e-05, 2.77966210e-05, 1.18460930e-05, 2.90420485e-06,\n",
            "       1.01995292e-05, 3.08385825e-05, 6.73296108e-06, 1.37527750e-05,\n",
            "       2.82575893e-05, 8.17637101e-06, 2.04124590e-05, 1.19957967e-05,\n",
            "       3.24085740e-05, 7.04685044e-06, 1.53725723e-05, 2.30749411e-05,\n",
            "       4.45718069e-05, 3.32905838e-05, 2.43019695e-05, 2.06355198e-05,\n",
            "       1.49108764e-05, 9.38287849e-06, 8.96909205e-06, 1.49099160e-05,\n",
            "       2.04692678e-05, 1.66852678e-05, 1.14095401e-05, 7.49697256e-06,\n",
            "       3.72425457e-05, 1.71977899e-05, 1.17806139e-05, 3.01222062e-05,\n",
            "       1.57004615e-05, 1.43916277e-05, 1.30408744e-05, 1.34529055e-05,\n",
            "       5.33921411e-06, 1.77843776e-05, 2.14030770e-05, 2.89677719e-05,\n",
            "       8.72007604e-06, 3.19744140e-05, 1.21807088e-05, 1.05913168e-05,\n",
            "       1.42187318e-05, 2.75526636e-05, 1.30168519e-05, 1.41779574e-05,\n",
            "       1.98608177e-05, 2.49528803e-05, 1.31293436e-05, 3.98256225e-06,\n",
            "       1.38103787e-05, 1.10458423e-05, 1.02090853e-05, 5.06418746e-06,\n",
            "       1.24536846e-05, 1.83048305e-05, 1.39680269e-05, 1.62063916e-05,\n",
            "       1.11653208e-05, 9.74593786e-06, 5.28735109e-06, 9.28281770e-06,\n",
            "       1.11071231e-05, 1.28675811e-05, 9.91148136e-06, 1.56444185e-05,\n",
            "       1.79985709e-05, 1.27635358e-05, 1.81839732e-05, 2.31833637e-05,\n",
            "       1.44085570e-05, 1.29172358e-05, 9.92685000e-06, 3.31112169e-05,\n",
            "       1.50641836e-05, 1.68275637e-05, 8.67842027e-06, 2.25117146e-05,\n",
            "       1.32902860e-05, 9.29648104e-06, 1.43042989e-05, 1.27188769e-05,\n",
            "       1.14565246e-05, 1.01396190e-05, 1.11421523e-05, 8.40507346e-06,\n",
            "       7.21698279e-06, 2.18913228e-05, 9.97973530e-06, 1.36018807e-05,\n",
            "       1.86126945e-05, 1.31686866e-05, 8.68654934e-06, 9.03141336e-06,\n",
            "       1.03534767e-05, 1.08863642e-05, 9.15556666e-06, 1.52157236e-05,\n",
            "       1.85119898e-05, 7.45923808e-06, 1.81201103e-05, 1.16130159e-05,\n",
            "       3.01761174e-05, 8.50268225e-06, 8.66217670e-06, 1.59538613e-05,\n",
            "       8.96166966e-06, 5.27778730e-06, 8.81962933e-06, 9.93763206e-06,\n",
            "       6.65091693e-06, 1.87796068e-05, 2.23519837e-05, 2.15525197e-05,\n",
            "       7.88057878e-06, 2.43438535e-05, 3.67554057e-05, 1.68204479e-05,\n",
            "       1.00131483e-05, 2.18726855e-05, 1.00355028e-05, 1.62408160e-05,\n",
            "       1.05991548e-05, 2.18297228e-05, 1.64725370e-05, 1.09880530e-05,\n",
            "       2.70581841e-05, 1.16572783e-05, 9.02677766e-06, 1.47507189e-05,\n",
            "       1.49310090e-05, 1.01178121e-05, 6.78932383e-06, 1.96814253e-05,\n",
            "       1.86738271e-05, 1.28824176e-05, 5.17327408e-06, 1.60225190e-05,\n",
            "       1.61523894e-05, 1.53169112e-05, 9.60814123e-06, 2.16012904e-05,\n",
            "       1.68335373e-05, 1.00770203e-05, 3.72059403e-05, 1.94478962e-05,\n",
            "       9.60216130e-06, 2.81965731e-05, 2.42228962e-05, 1.09096663e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 311, 'shape': array([240,   1,   1, 120], dtype=int32), 'shape_signature': array([240,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00188481, 0.00106291, 0.00107832, 0.00082826, 0.00104625,\n",
            "       0.00082497, 0.00045878, 0.00115335, 0.00114694, 0.00091429,\n",
            "       0.00080952, 0.0005354 , 0.00064265, 0.00140264, 0.00024527,\n",
            "       0.0005982 , 0.00081991, 0.00155549, 0.00031165, 0.00063778,\n",
            "       0.00041221, 0.00149677, 0.00074742, 0.00100715, 0.00097189,\n",
            "       0.00175946, 0.00144822, 0.00058568, 0.00093093, 0.00072643,\n",
            "       0.0008496 , 0.00093073, 0.00071785, 0.00145752, 0.00086444,\n",
            "       0.00152564, 0.00124444, 0.00079051, 0.00075459, 0.000978  ,\n",
            "       0.00060716, 0.00073939, 0.00154958, 0.00157752, 0.00155306,\n",
            "       0.00058567, 0.00084091, 0.00063732, 0.00284693, 0.00114765,\n",
            "       0.00216723, 0.00091244, 0.00082065, 0.00242606, 0.00161801,\n",
            "       0.00071844, 0.00145818, 0.00096024, 0.00054892, 0.00110619,\n",
            "       0.00098605, 0.00106859, 0.00119163, 0.0017111 , 0.00100531,\n",
            "       0.00184897, 0.00040278, 0.00124268, 0.00348091, 0.00106531,\n",
            "       0.00134338, 0.00096403, 0.00075434, 0.00126322, 0.00116691,\n",
            "       0.00144698, 0.00054156, 0.00060724, 0.00052313, 0.00100425,\n",
            "       0.00050914, 0.0009312 , 0.00100971, 0.00085479, 0.00211209,\n",
            "       0.00075868, 0.0006285 , 0.00096733, 0.00232204, 0.00203413,\n",
            "       0.00086689, 0.00021253, 0.00074639, 0.00225674, 0.00049271,\n",
            "       0.00100642, 0.00206787, 0.00059834, 0.00149377, 0.00087784,\n",
            "       0.00237163, 0.00051568, 0.00112495, 0.0016886 , 0.00326172,\n",
            "       0.00243618, 0.0017784 , 0.00151009, 0.00109116, 0.00068663,\n",
            "       0.00065635, 0.00109109, 0.00149792, 0.00122101, 0.00083494,\n",
            "       0.00054862, 0.00272538, 0.00125852, 0.00086209, 0.00220432,\n",
            "       0.00114895, 0.00105317, 0.00095432, 0.00098447, 0.00039072,\n",
            "       0.00130144, 0.00156626, 0.00211984, 0.00063813, 0.00233986,\n",
            "       0.00089137, 0.00077506, 0.00104051, 0.00201628, 0.00095256,\n",
            "       0.00103753, 0.0014534 , 0.00182603, 0.00096079, 0.00029144,\n",
            "       0.00101063, 0.00080832, 0.00074709, 0.00037059, 0.00091135,\n",
            "       0.00133953, 0.00102217, 0.00118597, 0.00081707, 0.0007132 ,\n",
            "       0.00038692, 0.00067931, 0.00081281, 0.00094164, 0.00072531,\n",
            "       0.00114484, 0.00131712, 0.00093402, 0.00133069, 0.00169654,\n",
            "       0.00105441, 0.00094527, 0.00072644, 0.00242305, 0.00110238,\n",
            "       0.00123143, 0.00063508, 0.00164739, 0.00097257, 0.00068031,\n",
            "       0.00104678, 0.00093076, 0.00083838, 0.00074201, 0.00081537,\n",
            "       0.00061508, 0.00052813, 0.00160199, 0.00073031, 0.00099537,\n",
            "       0.00136206, 0.00096367, 0.00063567, 0.00066091, 0.00075766,\n",
            "       0.00079665, 0.00067   , 0.00111347, 0.00135469, 0.00054586,\n",
            "       0.00132601, 0.00084983, 0.00220826, 0.00062222, 0.00063389,\n",
            "       0.00116749, 0.00065581, 0.00038622, 0.00064541, 0.00072723,\n",
            "       0.00048671, 0.00137427, 0.0016357 , 0.00157719, 0.00057669,\n",
            "       0.00178146, 0.00268973, 0.00123091, 0.00073275, 0.00160062,\n",
            "       0.00073439, 0.00118849, 0.00077564, 0.00159748, 0.00120545,\n",
            "       0.0008041 , 0.00198009, 0.00085307, 0.00066057, 0.00107944,\n",
            "       0.00109264, 0.00074041, 0.00049684, 0.00144027, 0.00136653,\n",
            "       0.00094272, 0.00037858, 0.00117251, 0.00118202, 0.00112088,\n",
            "       0.00070312, 0.00158076, 0.00123186, 0.00073743, 0.0027227 ,\n",
            "       0.00142318, 0.00070268, 0.0020634 , 0.00177261, 0.00079836],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 312, 'shape': array([120], dtype=int32), 'shape_signature': array([120], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([7.63250428e-05, 4.86117024e-05, 3.32446871e-05, 3.41256236e-05,\n",
            "       7.98014080e-05, 1.77532675e-05, 1.47974215e-05, 5.38440836e-05,\n",
            "       6.13970769e-06, 4.79662122e-05, 3.87375658e-05, 2.45136252e-05,\n",
            "       3.46753768e-05, 1.88746835e-05, 2.76338396e-05, 3.04092464e-05,\n",
            "       7.30147303e-06, 4.05579631e-05, 3.07327318e-05, 1.45341974e-05,\n",
            "       5.09093079e-05, 1.52904431e-05, 5.55860315e-05, 1.71145584e-05,\n",
            "       4.20541801e-05, 2.53654089e-05, 1.01601154e-05, 3.75612071e-05,\n",
            "       3.08469098e-05, 1.04406272e-05, 3.18837192e-05, 2.87093808e-05,\n",
            "       6.32695355e-06, 9.91343950e-06, 3.92825314e-05, 7.48106831e-05,\n",
            "       4.08028354e-05, 1.17493310e-05, 2.86451286e-05, 5.33539678e-05,\n",
            "       5.52356460e-06, 2.35481984e-05, 7.67135934e-05, 3.27464768e-05,\n",
            "       2.53932576e-05, 1.59410429e-05, 4.18191630e-05, 5.68116520e-05,\n",
            "       4.86749123e-05, 1.26205787e-05, 2.37232962e-05, 2.67617470e-05,\n",
            "       5.19737259e-05, 1.30179760e-05, 1.25085407e-05, 3.48331560e-05,\n",
            "       4.69712795e-05, 4.43228782e-05, 4.85461751e-05, 3.97222211e-05,\n",
            "       2.16994686e-05, 5.42872913e-05, 3.04149344e-05, 8.88971772e-06,\n",
            "       1.23913378e-05, 3.59211190e-05, 1.13472497e-05, 4.72176689e-05,\n",
            "       1.18571270e-05, 1.26967579e-05, 4.47035163e-05, 2.26307002e-05,\n",
            "       5.73876241e-05, 3.33548269e-05, 1.14572222e-05, 5.85383023e-05,\n",
            "       1.18345179e-05, 1.57022732e-05, 4.83662989e-05, 2.52222871e-05,\n",
            "       1.77298189e-05, 2.52255613e-05, 1.38590076e-05, 5.04704076e-05,\n",
            "       4.29587853e-05, 4.39406394e-05, 6.67462009e-05, 1.30477947e-05,\n",
            "       3.64939115e-05, 3.36681442e-05, 3.96993746e-05, 5.26300119e-06,\n",
            "       7.31823093e-05, 8.86036942e-05, 1.51945351e-05, 2.01992698e-05,\n",
            "       1.11818343e-04, 5.00758943e-05, 3.99157070e-05, 4.46938720e-05,\n",
            "       4.84546399e-05, 2.94454421e-05, 4.22588528e-05, 6.14502933e-05,\n",
            "       4.86346762e-05, 4.38820571e-05, 4.24190403e-05, 5.86077440e-05,\n",
            "       4.17876508e-05, 4.50533407e-05, 4.21447294e-05, 4.65626144e-05,\n",
            "       2.30661954e-05, 3.18610728e-05, 3.31207011e-05, 3.55934135e-05,\n",
            "       1.99886072e-05, 1.12783146e-05, 1.93007854e-05, 3.94810340e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 313, 'shape': array([120,   1,   1, 480], dtype=int32), 'shape_signature': array([120,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00301792, 0.00192213, 0.00131451, 0.00134934, 0.00315538,\n",
            "       0.00070197, 0.0005851 , 0.00212902, 0.00024277, 0.0018966 ,\n",
            "       0.0015317 , 0.00096928, 0.00137108, 0.00074631, 0.00109265,\n",
            "       0.00120239, 0.0002887 , 0.00160368, 0.00121519, 0.00057469,\n",
            "       0.00201298, 0.00060459, 0.0021979 , 0.00067672, 0.00166284,\n",
            "       0.00100296, 0.00040174, 0.00148519, 0.0012197 , 0.00041283,\n",
            "       0.0012607 , 0.00113518, 0.00025017, 0.00039198, 0.00155325,\n",
            "       0.00295805, 0.00161336, 0.00046457, 0.00113264, 0.00210964,\n",
            "       0.0002184 , 0.00093111, 0.00303329, 0.00129481, 0.00100406,\n",
            "       0.00063032, 0.00165355, 0.00224636, 0.00192463, 0.00049902,\n",
            "       0.00093803, 0.00105817, 0.00205506, 0.00051474, 0.00049459,\n",
            "       0.00137732, 0.00185726, 0.00175255, 0.00191954, 0.00157063,\n",
            "       0.00085801, 0.00214654, 0.00120262, 0.0003515 , 0.00048996,\n",
            "       0.00142034, 0.00044868, 0.00186701, 0.00046884, 0.00050204,\n",
            "       0.0017676 , 0.00089483, 0.00226913, 0.00131886, 0.00045302,\n",
            "       0.00231463, 0.00046794, 0.00062087, 0.00191242, 0.0009973 ,\n",
            "       0.00070104, 0.00099743, 0.00054799, 0.00199562, 0.00169861,\n",
            "       0.00173743, 0.00263917, 0.00051592, 0.00144298, 0.00133125,\n",
            "       0.00156973, 0.0002081 , 0.00289366, 0.00350343, 0.0006008 ,\n",
            "       0.00079869, 0.00442134, 0.00198002, 0.00157828, 0.00176721,\n",
            "       0.00191592, 0.00116429, 0.00167093, 0.00242977, 0.00192304,\n",
            "       0.00173512, 0.00167727, 0.00231738, 0.0016523 , 0.00178143,\n",
            "       0.00166642, 0.00184111, 0.00091205, 0.0012598 , 0.00130961,\n",
            "       0.00140738, 0.00079036, 0.00044595, 0.00076316, 0.0015611 ],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 314, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00162022, 0.00143922, 0.00540842, 0.00138288, 0.00297384,\n",
            "       0.00090007, 0.00287892, 0.00333625, 0.00189651, 0.00126677,\n",
            "       0.00244401, 0.00672367, 0.00087147, 0.0138103 , 0.00108271,\n",
            "       0.00111069, 0.00125964, 0.00270406, 0.00175866, 0.0055955 ,\n",
            "       0.00113112, 0.00210268, 0.00500044, 0.00118186, 0.00048407,\n",
            "       0.00402522, 0.00161477, 0.00814943, 0.00565428, 0.00029521,\n",
            "       0.00160864, 0.00081483, 0.00232527, 0.00072816, 0.0022739 ,\n",
            "       0.00368996, 0.00191024, 0.00232809, 0.00635351, 0.01570253,\n",
            "       0.00070465, 0.0017576 , 0.00059092, 0.00205661, 0.00604443,\n",
            "       0.0017588 , 0.00637597, 0.00085473, 0.01327383, 0.00311717,\n",
            "       0.00190404, 0.00303213, 0.00489963, 0.00818226, 0.00095116,\n",
            "       0.00097598, 0.00696843, 0.00253643, 0.00775516, 0.00848257,\n",
            "       0.00050185, 0.00915337, 0.00052013, 0.00317088, 0.00664281,\n",
            "       0.00355358, 0.00120259, 0.00164021, 0.00852383, 0.00170283,\n",
            "       0.00659836, 0.00605943, 0.00343276, 0.01071845, 0.00081947,\n",
            "       0.00430304, 0.00153283, 0.00313982, 0.0035536 , 0.00163802,\n",
            "       0.00285469, 0.00098361, 0.00250981, 0.00097532, 0.00575204,\n",
            "       0.00535328, 0.00422311, 0.00151434, 0.0030074 , 0.00637387,\n",
            "       0.00054501, 0.00198873, 0.00080533, 0.00288804, 0.00183141,\n",
            "       0.00113957, 0.00201614, 0.00751298, 0.00631202, 0.00367123,\n",
            "       0.00389944, 0.00301963, 0.00423254, 0.00097036, 0.00122893,\n",
            "       0.00147752, 0.00116143, 0.0007193 , 0.00201471, 0.00792813,\n",
            "       0.00554332, 0.00153395, 0.00114868, 0.00179996, 0.00491163,\n",
            "       0.00243572, 0.00505766, 0.00243426, 0.00251606, 0.00086484,\n",
            "       0.00522238, 0.00828836, 0.00057068, 0.00481901, 0.00132435,\n",
            "       0.00174143, 0.00089346, 0.00316661, 0.0060032 , 0.00156017,\n",
            "       0.00314399, 0.00256094, 0.00110006, 0.00122625, 0.00170932,\n",
            "       0.0065351 , 0.0081984 , 0.0010911 , 0.00791051, 0.00468998,\n",
            "       0.00286873, 0.00248725, 0.00168452, 0.00216734, 0.00608976,\n",
            "       0.00120927, 0.00242568, 0.0031055 , 0.00092666, 0.00058983,\n",
            "       0.00098867, 0.00065988, 0.00522127, 0.00071376, 0.00659978,\n",
            "       0.00505637, 0.00069116, 0.00125417, 0.00238813, 0.00759781,\n",
            "       0.00162357, 0.00432416, 0.00210299, 0.00956347, 0.00461716,\n",
            "       0.00979213, 0.00553935, 0.00119625, 0.00092582, 0.00481935,\n",
            "       0.0042529 , 0.00121449, 0.00978046, 0.00323464, 0.00102387,\n",
            "       0.00344398, 0.00226279, 0.00859067, 0.00736015, 0.00065201,\n",
            "       0.00316258, 0.00411627, 0.0032557 , 0.00156195, 0.00052331,\n",
            "       0.00807368, 0.0006498 , 0.0039886 , 0.00280058, 0.00347197,\n",
            "       0.0021267 , 0.00518496, 0.00074692, 0.00483754, 0.00125596,\n",
            "       0.00357511, 0.0045024 , 0.00771964, 0.00534959, 0.00136069,\n",
            "       0.00410327, 0.00672525, 0.00085674, 0.01012984, 0.00152845,\n",
            "       0.0008253 , 0.00992221, 0.00810248, 0.00427283, 0.00086624,\n",
            "       0.0034063 , 0.00871934, 0.00052929, 0.001037  , 0.00835923,\n",
            "       0.00074177, 0.00083555, 0.00059111, 0.00767843, 0.00727983,\n",
            "       0.0006446 , 0.00055078, 0.00515047, 0.00397489, 0.00226687,\n",
            "       0.00110296, 0.00082844, 0.00617693, 0.0020714 , 0.00177633,\n",
            "       0.00167679, 0.00819279, 0.00235933, 0.00069433, 0.00342083,\n",
            "       0.00081066, 0.00093998, 0.00106601, 0.00448083, 0.00232159],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul', 'index': 315, 'shape': array([  1,   3,   1, 240], dtype=int32), 'shape_signature': array([  1,   3,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01914149, 0.01700314, 0.06389581, 0.01633751, 0.03513332,\n",
            "       0.01063354, 0.03401192, 0.03941492, 0.02240559, 0.01496581,\n",
            "       0.02887389, 0.07943435, 0.01029567, 0.1631566 , 0.01279125,\n",
            "       0.01312179, 0.01488156, 0.03194616, 0.02077704, 0.06610593,\n",
            "       0.0133632 , 0.02484129, 0.0590758 , 0.0139626 , 0.00571882,\n",
            "       0.04755448, 0.01907714, 0.09627837, 0.06680039, 0.00348759,\n",
            "       0.01900465, 0.00962654, 0.02747107, 0.00860253, 0.02686419,\n",
            "       0.04359367, 0.02256786, 0.02750429, 0.07506116, 0.18551168,\n",
            "       0.00832477, 0.02076449, 0.00698118, 0.024297  , 0.07140968,\n",
            "       0.0207787 , 0.07532652, 0.01009788, 0.15681873, 0.03682661,\n",
            "       0.02249452, 0.03582197, 0.05788484, 0.09666631, 0.01123712,\n",
            "       0.0115304 , 0.08232587, 0.02996569, 0.09162045, 0.10021421,\n",
            "       0.00592893, 0.10813907, 0.00614492, 0.03746113, 0.07847906,\n",
            "       0.0419825 , 0.01420754, 0.01937763, 0.10070163, 0.02011744,\n",
            "       0.07795382, 0.07158684, 0.04055502, 0.12662919, 0.00968136,\n",
            "       0.05083665, 0.01810901, 0.03709428, 0.04198271, 0.01935182,\n",
            "       0.0337257 , 0.0116205 , 0.02965121, 0.01152256, 0.06795535,\n",
            "       0.06324429, 0.0498924 , 0.01789066, 0.03552987, 0.07530166,\n",
            "       0.00643877, 0.0234951 , 0.0095143 , 0.03411964, 0.02163652,\n",
            "       0.01346305, 0.02381894, 0.08875934, 0.07457103, 0.04337243,\n",
            "       0.04606843, 0.03567434, 0.05000379, 0.01146399, 0.01451876,\n",
            "       0.01745563, 0.01372133, 0.00849794, 0.023802  , 0.09366397,\n",
            "       0.06548952, 0.01812232, 0.01357066, 0.0212649 , 0.05802664,\n",
            "       0.02877591, 0.05975187, 0.02875862, 0.02972508, 0.01021735,\n",
            "       0.06169781, 0.09791974, 0.00674209, 0.05693245, 0.01564604,\n",
            "       0.02057349, 0.01055546, 0.0374107 , 0.07092261, 0.018432  ,\n",
            "       0.03714355, 0.03025528, 0.01299622, 0.01448708, 0.0201941 ,\n",
            "       0.07720651, 0.096857  , 0.01289036, 0.09345577, 0.05540805,\n",
            "       0.03389149, 0.02938469, 0.01990118, 0.02560518, 0.07194523,\n",
            "       0.01428643, 0.0286573 , 0.0366888 , 0.01094771, 0.00696827,\n",
            "       0.01168024, 0.00779591, 0.06168476, 0.00843241, 0.07797069,\n",
            "       0.05973661, 0.00816545, 0.01481697, 0.02821366, 0.08976146,\n",
            "       0.01918112, 0.05108622, 0.02484495, 0.1129841 , 0.05454766,\n",
            "       0.11568549, 0.06544254, 0.0141326 , 0.01093781, 0.05693642,\n",
            "       0.05024426, 0.0143481 , 0.11554759, 0.03821447, 0.01209613,\n",
            "       0.04068756, 0.02673285, 0.10149126, 0.08695376, 0.00770287,\n",
            "       0.03736316, 0.04863009, 0.03846329, 0.01845313, 0.00618242,\n",
            "       0.09538353, 0.00767685, 0.04712186, 0.03308645, 0.04101824,\n",
            "       0.02512509, 0.06125583, 0.00882417, 0.05715136, 0.01483806,\n",
            "       0.04223686, 0.05319191, 0.09120087, 0.0632007 , 0.01607538,\n",
            "       0.04847657, 0.07945296, 0.01012159, 0.1196752 , 0.01805732,\n",
            "       0.00975025, 0.1172222 , 0.09572379, 0.05047973, 0.0102339 ,\n",
            "       0.04024248, 0.10301137, 0.00625314, 0.01225122, 0.09875698,\n",
            "       0.00876333, 0.00987133, 0.00698347, 0.09071391, 0.08600486,\n",
            "       0.00761533, 0.00650699, 0.06084837, 0.04695987, 0.02678111,\n",
            "       0.01303049, 0.00978733, 0.07297505, 0.02447178, 0.02098579,\n",
            "       0.01980986, 0.09679072, 0.0278734 , 0.00820287, 0.04041413,\n",
            "       0.00957719, 0.01110503, 0.01259402, 0.05293711, 0.02742762],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 316, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.0268533e-04, 1.0177665e-03, 1.8349303e-03, 6.3382823e-04,\n",
            "       7.3008705e-04, 4.7612598e-04, 2.5805028e-04, 1.3705237e-03,\n",
            "       6.5978669e-04, 1.0688704e-03, 6.1396870e-04, 6.3071685e-04,\n",
            "       6.1985198e-04, 1.4383938e-03, 3.5928260e-04, 9.6911803e-04,\n",
            "       1.9142940e-03, 4.7280145e-04, 3.0685676e-04, 1.7833852e-03,\n",
            "       9.1826316e-04, 5.8352167e-04, 7.0249703e-04, 9.6108136e-04,\n",
            "       6.5845362e-04, 7.1757933e-04, 4.6032004e-04, 1.2331766e-03,\n",
            "       1.2904562e-03, 3.1395824e-04, 2.4317999e-03, 6.2636787e-04,\n",
            "       1.0536234e-03, 6.6239329e-04, 1.2707662e-04, 7.1470560e-05,\n",
            "       1.8663785e-03, 7.3210400e-04, 1.5230289e-04, 1.3023068e-03,\n",
            "       7.6721539e-04, 7.3573727e-04, 6.6962885e-04, 2.2786627e-04,\n",
            "       4.1305957e-05, 2.8604879e-03, 8.4087478e-05, 9.5209113e-04,\n",
            "       3.4574903e-05, 6.5909798e-04, 2.4486269e-04, 2.5571955e-04,\n",
            "       2.4813677e-03, 3.6863118e-04, 1.6978864e-03, 1.2101899e-03,\n",
            "       1.3607560e-03, 1.3986018e-03, 1.4438421e-03, 1.0955130e-03,\n",
            "       7.3060440e-04, 1.5949548e-03, 1.0091920e-03, 1.8697225e-04,\n",
            "       1.3849697e-03, 1.5181393e-04, 2.9426659e-04, 1.9411310e-04,\n",
            "       2.7880684e-04, 7.7882071e-04, 7.3086201e-05, 2.1564828e-03,\n",
            "       2.6075724e-03, 3.4150624e-04, 1.4300781e-03, 4.7450673e-04,\n",
            "       1.7735784e-04, 1.0097265e-03, 8.9379522e-04, 1.3552577e-03,\n",
            "       2.2100037e-04, 8.1210257e-04, 8.6551643e-04, 1.5605239e-03,\n",
            "       2.5771785e-04, 5.5806024e-04, 1.9380607e-04, 2.7070384e-04,\n",
            "       5.5863394e-04, 8.6513697e-05, 9.7983889e-04, 3.6014229e-04,\n",
            "       4.7179189e-04, 7.3828484e-04, 4.2882169e-04, 5.8732467e-04,\n",
            "       1.5417674e-03, 1.3660497e-03, 5.7569414e-04, 2.7647874e-04,\n",
            "       1.3290443e-04, 9.5786969e-04, 4.9503788e-04, 6.8499998e-04,\n",
            "       1.2853215e-03, 3.2133024e-04, 1.6192526e-04, 7.3807657e-04,\n",
            "       9.0057345e-04, 1.0513136e-03, 2.7226370e-03, 8.0510945e-04,\n",
            "       9.7733783e-04, 4.0219733e-04, 3.0294841e-04, 9.3812821e-05,\n",
            "       3.7511560e-04, 4.9212010e-04, 6.9680536e-05, 1.1211443e-03,\n",
            "       9.2378823e-04, 1.4559512e-03, 7.9985074e-04, 1.7500942e-03,\n",
            "       2.7235076e-04, 2.6433372e-03, 2.6921617e-04, 2.1190198e-04,\n",
            "       2.6430123e-04, 4.7449651e-04, 2.5445330e-03, 8.5275335e-04,\n",
            "       1.0108090e-03, 3.6931154e-04, 5.6871324e-04, 1.8505366e-04,\n",
            "       3.9589024e-04, 9.8482717e-04, 1.5946002e-04, 8.2053425e-04,\n",
            "       1.0256459e-03, 1.7266953e-04, 1.0257058e-03, 2.4904576e-04,\n",
            "       2.3617721e-03, 2.0888673e-04, 2.7722440e-04, 1.7107198e-04,\n",
            "       7.7821122e-04, 9.7686099e-04, 5.5602094e-04, 9.7869697e-04,\n",
            "       9.7469689e-05, 1.5587554e-03, 2.3342662e-03, 3.7936232e-04,\n",
            "       1.3921898e-03, 9.2296483e-04, 1.4663734e-03, 1.9299732e-04,\n",
            "       3.6399110e-04, 3.7332566e-04, 5.9365609e-04, 1.0035944e-03,\n",
            "       7.1719216e-05, 1.1174649e-04, 6.0623046e-04, 1.5756786e-03,\n",
            "       6.6303904e-04, 1.4354014e-03, 3.7973718e-04, 5.9875532e-04,\n",
            "       1.5334282e-03, 2.4492861e-04, 4.7354650e-04, 2.7495588e-03,\n",
            "       2.1635000e-04, 4.2566196e-05, 2.7336684e-04, 6.8842858e-04,\n",
            "       2.9684883e-04, 5.0574959e-05, 1.5907862e-03, 1.1763143e-04,\n",
            "       1.1269810e-03, 1.8861899e-03, 6.9648196e-04, 1.6750646e-04,\n",
            "       2.4221999e-04, 1.2051397e-03, 4.7074552e-04, 7.7221968e-04,\n",
            "       5.3831760e-04, 1.9101999e-03, 4.3860736e-04, 1.1662019e-03,\n",
            "       1.6600295e-03, 1.2232395e-03, 1.3239442e-03, 4.2880516e-04,\n",
            "       2.0676181e-03, 9.0700123e-05, 5.7450618e-04, 1.6866077e-04,\n",
            "       8.6905388e-04, 1.3527141e-03, 1.7120338e-04, 1.5969016e-03,\n",
            "       1.7549124e-03, 4.2617781e-04, 1.7798415e-03, 4.1974479e-04,\n",
            "       9.9231035e-04, 1.3746611e-03, 1.3570776e-04, 4.9634109e-04,\n",
            "       8.1752351e-04, 1.8707563e-03, 1.2276069e-03, 5.2229367e-04,\n",
            "       7.5669063e-04, 1.0618493e-03, 6.6422409e-04, 1.1539267e-04,\n",
            "       2.1050172e-03, 9.5085060e-04, 3.5893728e-04, 1.9248282e-04,\n",
            "       2.3857180e-04, 5.4376334e-04, 4.2301125e-04, 3.0679835e-04,\n",
            "       3.6667756e-04, 7.8049581e-04, 7.1132736e-04, 7.5172877e-04,\n",
            "       5.2750052e-04, 5.0774164e-04, 7.3333265e-04, 2.6113036e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 317, 'shape': array([  1,   3,   3, 240], dtype=int32), 'shape_signature': array([  1,   3,   3, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00432588, 0.02172201, 0.03916259, 0.01352768, 0.01558212,\n",
            "       0.01016187, 0.00550752, 0.02925084, 0.01408171, 0.02281271,\n",
            "       0.01310382, 0.01346128, 0.01322939, 0.03069938, 0.0076681 ,\n",
            "       0.02068371, 0.04085643, 0.01009092, 0.00654919, 0.03806247,\n",
            "       0.01959833, 0.012454  , 0.01499327, 0.02051219, 0.01405326,\n",
            "       0.01531517, 0.00982453, 0.02631946, 0.02754197, 0.00670075,\n",
            "       0.05190147, 0.01336846, 0.02248729, 0.01413734, 0.00271217,\n",
            "       0.00152538, 0.03983378, 0.01562516, 0.00325057, 0.0277949 ,\n",
            "       0.01637454, 0.01570271, 0.01429177, 0.00486331, 0.00088159,\n",
            "       0.06105088, 0.00179466, 0.02032031, 0.00073793, 0.01406701,\n",
            "       0.00522606, 0.00545778, 0.05295938, 0.00786763, 0.03623768,\n",
            "       0.02582886, 0.02904237, 0.02985011, 0.03081566, 0.02338134,\n",
            "       0.01559316, 0.03404083, 0.021539  , 0.00399052, 0.02955916,\n",
            "       0.00324014, 0.00628048, 0.00414292, 0.00595052, 0.01662223,\n",
            "       0.00155987, 0.04602542, 0.05565295, 0.00728871, 0.0305219 ,\n",
            "       0.01012731, 0.00378532, 0.02155041, 0.01907611, 0.02892502,\n",
            "       0.00471677, 0.01733256, 0.01847256, 0.03330598, 0.00550043,\n",
            "       0.01191058, 0.00413637, 0.00577758, 0.01192282, 0.00184645,\n",
            "       0.02091253, 0.00768645, 0.01006937, 0.01575708, 0.00915226,\n",
            "       0.01253517, 0.03290566, 0.02915535, 0.01228694, 0.00590084,\n",
            "       0.00283656, 0.02044364, 0.0105655 , 0.01461983, 0.02743239,\n",
            "       0.00685809, 0.00345594, 0.01575264, 0.01922078, 0.022438  ,\n",
            "       0.05810875, 0.01718331, 0.02085914, 0.00858403, 0.00646577,\n",
            "       0.00200223, 0.00800603, 0.01050323, 0.00148718, 0.02392838,\n",
            "       0.01971625, 0.03107411, 0.01707107, 0.03735195, 0.00581273,\n",
            "       0.05641627, 0.00574583, 0.00452259, 0.00564093, 0.01012709,\n",
            "       0.05430751, 0.01820016, 0.02157351, 0.00788215, 0.01213794,\n",
            "       0.00394957, 0.00844941, 0.02101899, 0.00340333, 0.01751252,\n",
            "       0.02189018, 0.00368525, 0.02189146, 0.00531534, 0.05040688,\n",
            "       0.00445823, 0.00591675, 0.00365116, 0.01660922, 0.02084897,\n",
            "       0.01186705, 0.02088815, 0.00208028, 0.03326824, 0.04981982,\n",
            "       0.00809666, 0.02971326, 0.01969867, 0.03129654, 0.00411911,\n",
            "       0.0077686 , 0.00796782, 0.0126703 , 0.02141953, 0.00153069,\n",
            "       0.00238499, 0.01293867, 0.03362942, 0.01415112, 0.03063551,\n",
            "       0.00810466, 0.01277913, 0.03272768, 0.00522747, 0.01010682,\n",
            "       0.05868334, 0.00461752, 0.00090848, 0.00583442, 0.01469301,\n",
            "       0.00633559, 0.00107941, 0.03395186, 0.00251059, 0.02405295,\n",
            "       0.04025661, 0.01486489, 0.00357506, 0.00516966, 0.02572108,\n",
            "       0.01004704, 0.01648135, 0.01148922, 0.04076905, 0.00936112,\n",
            "       0.02489004, 0.03542971, 0.02610738, 0.0282567 , 0.00915191,\n",
            "       0.0441288 , 0.0019358 , 0.01226158, 0.0035997 , 0.01854806,\n",
            "       0.02887074, 0.00365396, 0.03408238, 0.03745478, 0.00909584,\n",
            "       0.03798684, 0.00895854, 0.0211787 , 0.02933914, 0.00289639,\n",
            "       0.01059332, 0.01744826, 0.03992721, 0.02620059, 0.01114722,\n",
            "       0.01614991, 0.02266286, 0.01417642, 0.00246281, 0.044927  ,\n",
            "       0.02029383, 0.00766073, 0.00410813, 0.00509179, 0.01160544,\n",
            "       0.00902825, 0.00654794, 0.00782593, 0.01665798, 0.01518173,\n",
            "       0.01604401, 0.01125835, 0.01083664, 0.01565139, 0.00557326],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 318, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.54094567e-04, 1.21098354e-04, 2.64269456e-05, 3.21974832e-04,\n",
            "       1.07464322e-04, 1.76717207e-04, 1.60393203e-04, 2.21430546e-05,\n",
            "       1.24910977e-04, 8.05682939e-05, 9.23652988e-05, 1.59225401e-05,\n",
            "       3.43043095e-04, 1.77586935e-05, 1.01564103e-04, 1.19433316e-04,\n",
            "       6.50384900e-05, 1.19018005e-04, 1.44663820e-04, 2.87149851e-05,\n",
            "       9.21946557e-05, 1.31006032e-04, 8.05368327e-05, 1.89531565e-04,\n",
            "       1.63722289e-04, 4.40570111e-05, 2.04080294e-04, 4.39919168e-05,\n",
            "       3.34392971e-05, 3.33444594e-04, 8.61985754e-05, 2.19545793e-04,\n",
            "       9.54629286e-05, 2.36217456e-04, 1.12231166e-04, 2.65502866e-04,\n",
            "       5.93941440e-05, 9.90346889e-05, 9.70780457e-05, 2.77027648e-05,\n",
            "       2.18364439e-04, 7.53676795e-05, 2.75525439e-04, 1.50576685e-04,\n",
            "       2.00939758e-04, 3.80559941e-05, 2.28650999e-04, 2.65018025e-04,\n",
            "       2.48052413e-04, 2.68589647e-04, 9.59161480e-05, 1.65560574e-04,\n",
            "       3.73987750e-05, 2.57524280e-05, 1.20178833e-04, 1.08574604e-04,\n",
            "       3.80502679e-05, 9.73656279e-05, 3.01527161e-05, 3.11396398e-05,\n",
            "       1.46665203e-04, 3.80320198e-05, 1.82098651e-04, 9.45948341e-05,\n",
            "       2.41030775e-05, 1.22712503e-04, 2.24332718e-04, 2.51248159e-04,\n",
            "       6.40479411e-05, 6.45993423e-05, 3.04150541e-04, 2.51670554e-05,\n",
            "       3.52783863e-05, 2.17753277e-05, 1.40532589e-04, 1.16104886e-04,\n",
            "       1.89145750e-04, 5.40007786e-05, 3.97466247e-05, 8.81307496e-05,\n",
            "       1.06392326e-04, 1.44354810e-04, 6.35923498e-05, 1.03966158e-04,\n",
            "       5.13986015e-05, 3.16744590e-05, 1.79607392e-04, 2.66151736e-04,\n",
            "       4.97832261e-05, 3.05772322e-04, 2.62782152e-04, 1.04197235e-04,\n",
            "       2.01293326e-04, 3.77838332e-05, 2.30466001e-04, 1.86215984e-04,\n",
            "       7.12253241e-05, 2.89267300e-05, 2.62061367e-05, 1.27163585e-04,\n",
            "       2.47874006e-04, 4.30435066e-05, 6.48278001e-05, 1.57804519e-04,\n",
            "       5.40986948e-05, 1.59004849e-04, 2.19535228e-04, 1.03162150e-04,\n",
            "       1.22679456e-04, 3.96404030e-05, 3.69782501e-05, 1.79351991e-04,\n",
            "       1.28358195e-04, 1.90437320e-04, 8.98824728e-05, 1.49966319e-04,\n",
            "       9.04084955e-05, 9.25549029e-05, 2.03163989e-04, 7.01391691e-05,\n",
            "       5.89944357e-05, 3.00057491e-05, 1.95195826e-04, 4.73174841e-05,\n",
            "       1.44523117e-04, 6.65999250e-05, 1.64454352e-04, 1.38448435e-04,\n",
            "       1.46791193e-04, 5.28131968e-05, 3.29305585e-05, 3.94216950e-05,\n",
            "       1.75602909e-04, 2.19167880e-04, 1.80916744e-04, 3.65933483e-05,\n",
            "       2.47794815e-05, 6.79431905e-05, 2.03557662e-04, 4.37175950e-05,\n",
            "       7.69430044e-05, 2.70196033e-04, 1.10240770e-04, 1.42565405e-04,\n",
            "       2.29439629e-05, 2.67759257e-04, 1.82014293e-04, 2.94689700e-04,\n",
            "       1.92328502e-04, 2.15105581e-04, 1.42959718e-04, 1.49678483e-04,\n",
            "       2.18481349e-04, 1.37837313e-04, 3.27879497e-05, 5.52387100e-05,\n",
            "       1.18918048e-04, 1.41097495e-04, 2.61810328e-05, 4.69502338e-05,\n",
            "       1.65246427e-04, 9.87308667e-05, 1.79209150e-04, 1.59152169e-05,\n",
            "       1.73842083e-04, 8.17186883e-05, 3.18187267e-05, 8.31600555e-05,\n",
            "       1.82130127e-04, 2.93251105e-05, 1.05367464e-04, 1.99359085e-04,\n",
            "       3.21969565e-05, 7.38214367e-05, 2.05413860e-04, 3.76411481e-05,\n",
            "       1.82214411e-04, 3.65474203e-04, 1.48557898e-04, 1.33774156e-04,\n",
            "       1.42882534e-04, 3.86507367e-04, 3.13988858e-05, 2.01049930e-04,\n",
            "       1.26727115e-04, 2.73598253e-05, 2.81822664e-04, 1.45412181e-04,\n",
            "       1.68233164e-04, 6.67397253e-05, 9.52958217e-05, 3.22171363e-05,\n",
            "       7.97553075e-05, 4.60498522e-05, 1.98256370e-04, 2.41003363e-05,\n",
            "       4.50048465e-05, 3.01019645e-05, 2.51064466e-05, 1.70089494e-04,\n",
            "       4.20660508e-05, 1.99125861e-04, 2.36174761e-04, 6.42839877e-05,\n",
            "       4.40206823e-05, 2.13463369e-04, 1.11386769e-04, 2.08127967e-05,\n",
            "       3.03779179e-05, 2.05859309e-04, 3.88496192e-05, 6.21463623e-05,\n",
            "       1.60818643e-04, 1.19332239e-04, 1.25256964e-04, 1.71993874e-04,\n",
            "       2.76043225e-04, 1.07360407e-04, 3.84895247e-05, 4.04212042e-05,\n",
            "       1.78657065e-04, 1.57201284e-04, 4.99603448e-05, 2.20185757e-04,\n",
            "       4.37024937e-05, 1.15932431e-04, 2.52956554e-04, 1.07940868e-04,\n",
            "       1.75431051e-04, 1.59398274e-04, 1.92118794e-04, 8.29551500e-05,\n",
            "       1.70770552e-04, 1.81560565e-04, 6.06625108e-05, 1.45021520e-04,\n",
            "       1.82479154e-04, 1.75273657e-04, 4.76855930e-05, 1.36556540e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 319, 'shape': array([240,   1,   1,  72], dtype=int32), 'shape_signature': array([240,   1,   1,  72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.86772406e-04, 1.46778897e-04, 3.20311374e-05, 3.90253961e-04,\n",
            "       1.30253582e-04, 2.14192478e-04, 1.94406748e-04, 2.68387885e-05,\n",
            "       1.51400032e-04, 9.76538940e-05, 1.11952606e-04, 1.92991301e-05,\n",
            "       4.15790011e-04, 2.15246655e-05, 1.23102145e-04, 1.44760765e-04,\n",
            "       7.88307807e-05, 1.44257385e-04, 1.75341731e-04, 3.48043868e-05,\n",
            "       1.11745780e-04, 1.58787632e-04, 9.76157535e-05, 2.29724305e-04,\n",
            "       1.98441820e-04, 5.33998973e-05, 2.47358286e-04, 5.33209968e-05,\n",
            "       4.05305509e-05, 4.04156046e-04, 1.04478153e-04, 2.66103452e-04,\n",
            "       1.15707131e-04, 2.86310562e-04, 1.36031304e-04, 3.21806350e-04,\n",
            "       7.19894742e-05, 1.20036333e-04, 1.17664757e-04, 3.35775112e-05,\n",
            "       2.64671573e-04, 9.13504191e-05, 3.33954318e-04, 1.82508506e-04,\n",
            "       2.43551753e-04, 4.61262825e-05, 2.77139538e-04, 3.21218686e-04,\n",
            "       3.00655287e-04, 3.25547706e-04, 1.16256466e-04, 2.00669936e-04,\n",
            "       4.53296925e-05, 3.12135780e-05, 1.45664380e-04, 1.31599314e-04,\n",
            "       4.61193413e-05, 1.18013326e-04, 3.65470078e-05, 3.77432225e-05,\n",
            "       1.77767550e-04, 4.60972224e-05, 2.20715126e-04, 1.14654948e-04,\n",
            "       2.92144614e-05, 1.48735344e-04, 2.71905505e-04, 3.04528716e-04,\n",
            "       7.76301749e-05, 7.82985080e-05, 3.68649780e-04, 3.05040703e-05,\n",
            "       4.27596460e-05, 2.63930797e-05, 1.70334431e-04, 1.40726494e-04,\n",
            "       2.29256664e-04, 6.54523756e-05, 4.81754323e-05, 1.06820065e-04,\n",
            "       1.28954256e-04, 1.74967194e-04, 7.70779661e-05, 1.26013590e-04,\n",
            "       6.22983716e-05, 3.83914557e-05, 2.17695560e-04, 3.22592794e-04,\n",
            "       6.03404333e-05, 3.70615482e-04, 3.18508653e-04, 1.26293671e-04,\n",
            "       2.43980292e-04, 4.57964052e-05, 2.79339438e-04, 2.25705604e-04,\n",
            "       8.63296154e-05, 3.50610353e-05, 3.17635022e-05, 1.54130335e-04,\n",
            "       3.00439046e-04, 5.21714646e-05, 7.85754091e-05, 1.91269108e-04,\n",
            "       6.55710537e-05, 1.92723979e-04, 2.66090647e-04, 1.25039078e-04,\n",
            "       1.48695297e-04, 4.80466879e-05, 4.48199899e-05, 2.17386012e-04,\n",
            "       1.55578295e-04, 2.30822130e-04, 1.08943270e-04, 1.81768701e-04,\n",
            "       1.09580840e-04, 1.12182424e-04, 2.46247655e-04, 8.50131255e-05,\n",
            "       7.15050046e-05, 3.63688741e-05, 2.36589738e-04, 5.73517973e-05,\n",
            "       1.75171197e-04, 8.07233373e-05, 1.99329123e-04, 1.67808306e-04,\n",
            "       1.77920258e-04, 6.40129510e-05, 3.99139280e-05, 4.77815993e-05,\n",
            "       2.12841886e-04, 2.65645387e-04, 2.19282592e-04, 4.43534627e-05,\n",
            "       3.00343054e-05, 8.23514638e-05, 2.46724812e-04, 5.29885001e-05,\n",
            "       9.32598050e-05, 3.27494752e-04, 1.33618814e-04, 1.72798318e-04,\n",
            "       2.78095395e-05, 3.24541237e-04, 2.20612885e-04, 3.57182638e-04,\n",
            "       2.33114362e-04, 2.60721630e-04, 1.73276261e-04, 1.81419833e-04,\n",
            "       2.64813280e-04, 1.67067570e-04, 3.97410768e-05, 6.69528235e-05,\n",
            "       1.44136226e-04, 1.71019128e-04, 3.17330741e-05, 5.69066651e-05,\n",
            "       2.00289171e-04, 1.19668082e-04, 2.17212873e-04, 1.92902535e-05,\n",
            "       2.10707643e-04, 9.90482367e-05, 3.85663188e-05, 1.00795267e-04,\n",
            "       2.20753282e-04, 3.55438970e-05, 1.27712061e-04, 2.41635877e-04,\n",
            "       3.90247551e-05, 8.94762707e-05, 2.48974655e-04, 4.56234629e-05,\n",
            "       2.20855436e-04, 4.42977936e-04, 1.80061616e-04, 1.62142780e-04,\n",
            "       1.73182707e-04, 4.68471495e-04, 3.80574456e-05, 2.43685281e-04,\n",
            "       1.53601315e-04, 3.31618467e-05, 3.41586972e-04, 1.76248795e-04,\n",
            "       2.03909280e-04, 8.08927871e-05, 1.15504590e-04, 3.90492169e-05,\n",
            "       9.66684966e-05, 5.58153442e-05, 2.40299312e-04, 2.92111381e-05,\n",
            "       5.45487310e-05, 3.64854932e-05, 3.04306086e-05, 2.06159268e-04,\n",
            "       5.09867277e-05, 2.41353191e-04, 2.86258815e-04, 7.79162801e-05,\n",
            "       5.33558632e-05, 2.58731161e-04, 1.35007838e-04, 2.52264326e-05,\n",
            "       3.68199653e-05, 2.49514560e-04, 4.70882078e-05, 7.53253407e-05,\n",
            "       1.94922410e-04, 1.44638252e-04, 1.51819404e-04, 2.08467507e-04,\n",
            "       3.34581913e-04, 1.30127635e-04, 4.66517486e-05, 4.89930680e-05,\n",
            "       2.16543704e-04, 1.90537947e-04, 6.05551104e-05, 2.66879128e-04,\n",
            "       5.29701974e-05, 1.40517470e-04, 3.06599395e-04, 1.30831191e-04,\n",
            "       2.12633575e-04, 1.93200831e-04, 2.32860184e-04, 1.00546909e-04,\n",
            "       2.06984754e-04, 2.20062939e-04, 7.35268186e-05, 1.75775291e-04,\n",
            "       2.21176320e-04, 2.12442799e-04, 5.77979663e-05, 1.65515201e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/rezero/mul', 'index': 320, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.008551683276891708, 127), 'quantization_parameters': {'scales': array([0.00855168], dtype=float32), 'zero_points': array([127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 321, 'shape': array([72], dtype=int32), 'shape_signature': array([72], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00041499, 0.00048559, 0.00034244, 0.00035153, 0.00049701,\n",
            "       0.00039849, 0.00039349, 0.00051749, 0.00063224, 0.00043653,\n",
            "       0.00041388, 0.00033849, 0.00039798, 0.00030151, 0.00034684,\n",
            "       0.00034668, 0.00043218, 0.00038436, 0.00043018, 0.00046712,\n",
            "       0.0003068 , 0.00037393, 0.00045274, 0.00039553, 0.00069538,\n",
            "       0.00059335, 0.00033862, 0.00029128, 0.00051934, 0.0003789 ,\n",
            "       0.00047667, 0.00065052, 0.000458  , 0.0003952 , 0.0004848 ,\n",
            "       0.00037242, 0.00044101, 0.00055156, 0.00043331, 0.00043998,\n",
            "       0.00039581, 0.0004504 , 0.00100563, 0.0004893 , 0.00049603,\n",
            "       0.00031758, 0.00052203, 0.00037478, 0.00034198, 0.00052979,\n",
            "       0.00034516, 0.00050928, 0.00047487, 0.00027802, 0.00050954,\n",
            "       0.00046701, 0.00060985, 0.00039221, 0.00080194, 0.00039953,\n",
            "       0.00032136, 0.0006888 , 0.00053684, 0.00037305, 0.00033447,\n",
            "       0.00039809, 0.00045736, 0.00045554, 0.00035002, 0.00034601,\n",
            "       0.0004172 , 0.00044572], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 322, 'shape': array([ 72,   1,   1, 240], dtype=int32), 'shape_signature': array([ 72,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01120896, 0.01311591, 0.00924933, 0.00949487, 0.01342454,\n",
            "       0.01076334, 0.01062821, 0.01397761, 0.01707716, 0.01179075,\n",
            "       0.01117914, 0.00914272, 0.01074973, 0.0081438 , 0.00936834,\n",
            "       0.00936402, 0.01167342, 0.01038166, 0.01161937, 0.01261709,\n",
            "       0.00828673, 0.01010001, 0.01222877, 0.01068344, 0.01878255,\n",
            "       0.01602659, 0.00914623, 0.00786754, 0.01402771, 0.0102343 ,\n",
            "       0.01287517, 0.01757078, 0.01237081, 0.01067457, 0.01309479,\n",
            "       0.01005917, 0.01191182, 0.01489795, 0.01170396, 0.011884  ,\n",
            "       0.010691  , 0.0121654 , 0.02716252, 0.01321622, 0.01339803,\n",
            "       0.00857789, 0.01410032, 0.01012293, 0.00923704, 0.01430976,\n",
            "       0.009323  , 0.01375596, 0.01282639, 0.00750938, 0.01376286,\n",
            "       0.01261424, 0.01647244, 0.0105938 , 0.02166069, 0.01079156,\n",
            "       0.00868019, 0.01860488, 0.01450031, 0.01007634, 0.00903411,\n",
            "       0.01075254, 0.01235359, 0.01230426, 0.00945419, 0.00934592,\n",
            "       0.01126867, 0.01203902], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block3_layer1/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block3_layer1/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block3_layer1/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer1/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 323, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.11099357e-05, 1.13053120e-05, 1.62501328e-05, 5.41188783e-05,\n",
            "       2.09290574e-05, 1.16798265e-05, 4.10624598e-05, 1.94528948e-05,\n",
            "       1.44521755e-05, 3.89564702e-05, 1.96006131e-05, 2.74399190e-05,\n",
            "       1.73250628e-05, 1.82327913e-05, 1.45635777e-05, 1.40304192e-05,\n",
            "       1.75657879e-05, 1.03786906e-05, 1.32231689e-05, 1.76151007e-05,\n",
            "       4.43807876e-05, 3.15758007e-05, 1.35646160e-05, 1.97623885e-05,\n",
            "       1.02036029e-05, 3.95044081e-05, 3.92416296e-05, 2.14473621e-05,\n",
            "       1.78143018e-05, 1.11662921e-05, 1.86168745e-05, 2.96546768e-05,\n",
            "       2.38542489e-05, 1.49346042e-05, 1.68748538e-05, 5.91000708e-06,\n",
            "       2.10334347e-05, 1.34653756e-05, 2.26011525e-05, 7.53416180e-06,\n",
            "       1.68634069e-05, 1.23996233e-05, 1.79871477e-05, 1.93353480e-05,\n",
            "       3.59737824e-05, 7.63958542e-06, 1.71168285e-05, 1.81207724e-05,\n",
            "       1.18133958e-05, 2.29434208e-05, 1.47267447e-05, 1.37430452e-05,\n",
            "       2.13433286e-05, 2.36922260e-05, 1.38959649e-05, 1.04902147e-05,\n",
            "       1.41712762e-05, 2.68043095e-05, 1.55136895e-05, 2.21717874e-05,\n",
            "       8.39854874e-06, 2.41897087e-05, 1.52888770e-05, 2.57369811e-05,\n",
            "       1.56948954e-05, 5.70912307e-05, 1.66333066e-05, 2.10078560e-05,\n",
            "       3.17103477e-05, 1.71382617e-05, 2.10916078e-05, 1.42247918e-05,\n",
            "       1.18104126e-05, 3.52867064e-05, 1.84171640e-05, 1.38218829e-05,\n",
            "       1.26790919e-05, 1.51115582e-05, 7.10960921e-06, 1.87817750e-05,\n",
            "       2.88374777e-05, 3.40060033e-05, 8.68581265e-06, 3.16044752e-05,\n",
            "       2.03918953e-05, 2.92333461e-05, 1.58079056e-05, 1.58449657e-05,\n",
            "       1.35965292e-05, 1.33318063e-05, 4.41692027e-05, 1.80262032e-05,\n",
            "       1.48120953e-05, 2.18156329e-05, 4.09982385e-05, 2.27788514e-05,\n",
            "       3.61045422e-05, 3.44868968e-05, 2.42290971e-05, 1.02883505e-05,\n",
            "       1.00436091e-05, 1.54605787e-05, 1.66590617e-05, 2.16974731e-05,\n",
            "       8.97686550e-06, 4.04069397e-05, 2.42333808e-05, 1.31538809e-05,\n",
            "       1.35084401e-05, 1.63392742e-05, 2.30006608e-05, 1.66994178e-05,\n",
            "       8.86144335e-06, 1.22078955e-05, 1.19634487e-05, 1.77601978e-05,\n",
            "       2.01410930e-05, 1.25985025e-05, 3.70024864e-05, 2.49053974e-05,\n",
            "       2.35001280e-05, 2.51682904e-05, 2.88690826e-05, 1.36622666e-05,\n",
            "       1.31037459e-05, 1.31906136e-05, 1.00941443e-05, 4.67455829e-05,\n",
            "       4.22260928e-05, 1.66886821e-05, 2.63475322e-05, 1.49203770e-05,\n",
            "       1.31558718e-05, 6.70670806e-06, 1.75445093e-05, 2.10556409e-05,\n",
            "       1.20932236e-05, 2.68019085e-05, 4.45151054e-05, 1.75220575e-05,\n",
            "       1.76871235e-05, 1.82189960e-05, 1.08127088e-05, 2.32150251e-05,\n",
            "       1.64485446e-05, 2.46024720e-05, 1.02867534e-05, 1.28093297e-05,\n",
            "       5.05103981e-06, 6.89774788e-06, 1.66594145e-05, 3.44091823e-05,\n",
            "       2.49060340e-05, 1.78864520e-05, 1.48845775e-05, 1.75841287e-05,\n",
            "       1.57300074e-05, 2.32656075e-05, 1.38030400e-05, 2.11205897e-05,\n",
            "       1.31757233e-05, 5.16821674e-05, 2.75128805e-05, 5.21139154e-05,\n",
            "       5.55465522e-05, 1.62976721e-05, 2.64807495e-05, 1.10143355e-05,\n",
            "       3.82844264e-05, 1.32273835e-05, 1.38342593e-05, 1.04515375e-05,\n",
            "       6.54990654e-05, 2.33060127e-05, 9.95340815e-06, 2.85059687e-05,\n",
            "       1.98564612e-05, 1.92692169e-05, 2.68227559e-05, 1.40466555e-05,\n",
            "       2.12142659e-05, 1.34964812e-05, 1.72136388e-05, 2.51870060e-05,\n",
            "       1.95455887e-05, 2.80117038e-05, 1.15569328e-05, 2.01069051e-05,\n",
            "       2.74470913e-05, 2.25174681e-05, 1.79036870e-05, 1.74167562e-05,\n",
            "       1.02474387e-05, 1.31526167e-05, 1.51757395e-05, 1.76781523e-05,\n",
            "       7.43313194e-06, 1.00111210e-05, 1.24017897e-05, 1.93515043e-05,\n",
            "       1.75510449e-05, 1.32380010e-05, 1.81674932e-05, 1.81389678e-05,\n",
            "       2.66316893e-05, 2.93930570e-05, 1.69847499e-05, 1.20080249e-05,\n",
            "       6.39688078e-05, 2.02112387e-05, 2.66732422e-05, 5.66247036e-05,\n",
            "       1.35691271e-05, 1.54159843e-05, 4.40416261e-05, 4.11250476e-05,\n",
            "       1.82423137e-05, 2.01767380e-05, 1.40977381e-05, 8.12200597e-06,\n",
            "       3.52608440e-05, 3.46106826e-05, 1.48911731e-05, 9.04774879e-06,\n",
            "       1.04422379e-05, 1.11690715e-05, 2.73987935e-05, 1.19043789e-05,\n",
            "       1.88545182e-05, 5.49871511e-05, 1.72780001e-05, 1.64714074e-05,\n",
            "       2.42374645e-05, 2.82747314e-05, 1.63513232e-05, 1.40899028e-05,\n",
            "       2.32257698e-05, 4.32235138e-05, 1.66133686e-05, 2.01865514e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 324, 'shape': array([240,   1,   1, 120], dtype=int32), 'shape_signature': array([240,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00125168, 0.00045486, 0.00065381, 0.00217743, 0.00084206,\n",
            "       0.00046993, 0.00165211, 0.00078267, 0.00058147, 0.00156738,\n",
            "       0.00078861, 0.00110402, 0.00069706, 0.00073358, 0.00058595,\n",
            "       0.0005645 , 0.00070674, 0.00041758, 0.00053202, 0.00070873,\n",
            "       0.00178562, 0.00127042, 0.00054576, 0.00079512, 0.00041053,\n",
            "       0.00158943, 0.00157885, 0.00086292, 0.00071674, 0.00044927,\n",
            "       0.00074903, 0.00119313, 0.00095975, 0.00060088, 0.00067894,\n",
            "       0.00023778, 0.00084626, 0.00054177, 0.00090934, 0.00030313,\n",
            "       0.00067848, 0.00049889, 0.0007237 , 0.00077794, 0.00144737,\n",
            "       0.00030737, 0.00068868, 0.00072907, 0.0004753 , 0.00092311,\n",
            "       0.00059252, 0.00055294, 0.00085873, 0.00095324, 0.00055909,\n",
            "       0.00042206, 0.00057017, 0.00107845, 0.00062418, 0.00089206,\n",
            "       0.00033791, 0.00097325, 0.00061513, 0.0010355 , 0.00063147,\n",
            "       0.00229702, 0.00066923, 0.00084523, 0.00127584, 0.00068954,\n",
            "       0.0008486 , 0.00057232, 0.00047518, 0.00141973, 0.000741  ,\n",
            "       0.00055611, 0.00051013, 0.000608  , 0.00028605, 0.00075567,\n",
            "       0.00116025, 0.0013682 , 0.00034947, 0.00127158, 0.00082045,\n",
            "       0.00117618, 0.00063602, 0.00063751, 0.00054704, 0.00053639,\n",
            "       0.00177711, 0.00072527, 0.00059595, 0.00087773, 0.00164953,\n",
            "       0.00091649, 0.00145263, 0.00138755, 0.00097484, 0.00041394,\n",
            "       0.0004041 , 0.00062204, 0.00067026, 0.00087298, 0.00036118,\n",
            "       0.00162574, 0.00097501, 0.00052923, 0.0005435 , 0.0006574 ,\n",
            "       0.00092541, 0.00067189, 0.00035653, 0.00049117, 0.00048134,\n",
            "       0.00071457, 0.00081036, 0.00050689, 0.00148876, 0.00100205,\n",
            "       0.00094551, 0.00101262, 0.00116152, 0.00054969, 0.00052722,\n",
            "       0.00053071, 0.00040613, 0.00188077, 0.00169893, 0.00067145,\n",
            "       0.00106007, 0.00060031, 0.00052931, 0.00026984, 0.00070589,\n",
            "       0.00084716, 0.00048656, 0.00107835, 0.00179103, 0.00070498,\n",
            "       0.00071163, 0.00073303, 0.00043504, 0.00093404, 0.00066179,\n",
            "       0.00098986, 0.00041388, 0.00051537, 0.00020322, 0.00027752,\n",
            "       0.00067028, 0.00138442, 0.00100207, 0.00071965, 0.00059887,\n",
            "       0.00070748, 0.00063288, 0.00093607, 0.00055535, 0.00084977,\n",
            "       0.00053011, 0.00207939, 0.00110696, 0.00209676, 0.00223487,\n",
            "       0.00065572, 0.00106543, 0.00044315, 0.00154034, 0.00053219,\n",
            "       0.00055661, 0.00042051, 0.0026353 , 0.0009377 , 0.00040047,\n",
            "       0.00114691, 0.00079891, 0.00077528, 0.00107919, 0.00056515,\n",
            "       0.00085354, 0.00054302, 0.00069258, 0.00101338, 0.0007864 ,\n",
            "       0.00112703, 0.00046498, 0.00080898, 0.00110431, 0.00090597,\n",
            "       0.00072034, 0.00070075, 0.0004123 , 0.00052918, 0.00061058,\n",
            "       0.00071126, 0.00029907, 0.00040279, 0.00049898, 0.00077859,\n",
            "       0.00070615, 0.00053262, 0.00073095, 0.00072981, 0.0010715 ,\n",
            "       0.0011826 , 0.00068337, 0.00048313, 0.00257373, 0.00081318,\n",
            "       0.00107317, 0.00227825, 0.00054594, 0.00062025, 0.00177198,\n",
            "       0.00165463, 0.00073396, 0.00081179, 0.00056721, 0.00032678,\n",
            "       0.00141869, 0.00139253, 0.00059913, 0.00036403, 0.00042013,\n",
            "       0.00044938, 0.00110237, 0.00047896, 0.0007586 , 0.00221236,\n",
            "       0.00069517, 0.00066271, 0.00097517, 0.00113761, 0.00065788,\n",
            "       0.00056689, 0.00093447, 0.00173906, 0.00066842, 0.00081219],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 325, 'shape': array([120], dtype=int32), 'shape_signature': array([120], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.9923141e-05, 9.4532603e-05, 6.1628394e-05, 3.2497450e-05,\n",
            "       1.7055341e-05, 5.9802845e-05, 1.1462426e-05, 2.4214542e-05,\n",
            "       3.3431996e-05, 2.3577282e-05, 1.6019034e-05, 5.4066153e-05,\n",
            "       8.1427715e-05, 1.0427297e-05, 9.9515717e-05, 1.1836908e-04,\n",
            "       7.1595845e-05, 3.8549220e-05, 2.4398236e-05, 5.1445368e-05,\n",
            "       5.0949307e-05, 6.5347696e-05, 8.9111549e-05, 1.4774550e-05,\n",
            "       5.2498399e-05, 2.4274017e-05, 1.8945699e-05, 3.6807454e-05,\n",
            "       2.5454257e-05, 2.7622302e-05, 8.8058790e-05, 1.2311319e-04,\n",
            "       9.1982052e-05, 2.4412233e-05, 8.0865902e-05, 1.1413562e-04,\n",
            "       4.2631440e-05, 4.8960654e-05, 2.0652396e-05, 8.6687483e-05,\n",
            "       3.5708836e-05, 2.7360073e-05, 1.1655615e-05, 2.5288304e-05,\n",
            "       3.8327289e-05, 1.0238039e-05, 1.4625114e-04, 3.8066599e-05,\n",
            "       8.5031774e-05, 4.1495205e-05, 7.8604244e-06, 1.0002224e-04,\n",
            "       1.6892573e-04, 2.2352800e-05, 1.7020322e-05, 1.0017537e-04,\n",
            "       1.4435987e-04, 1.9681014e-05, 1.7145030e-05, 3.5586891e-05,\n",
            "       2.1799629e-05, 3.8759143e-05, 1.1219067e-04, 3.8226626e-05,\n",
            "       2.7451635e-05, 1.7714523e-05, 1.4905845e-04, 4.8719819e-05,\n",
            "       8.6304128e-05, 6.7780587e-05, 7.5573766e-06, 5.6059409e-05,\n",
            "       2.9707784e-05, 4.3540836e-05, 6.5611246e-05, 4.0450475e-05,\n",
            "       3.7254242e-05, 2.0638963e-05, 2.1703265e-05, 6.5470272e-06,\n",
            "       7.5153803e-05, 2.5958063e-05, 1.0592778e-04, 1.8185085e-05,\n",
            "       9.5253439e-05, 4.1432333e-05, 9.8833283e-05, 9.3028117e-05,\n",
            "       1.9140889e-05, 1.5232978e-05, 1.1487489e-05, 3.2056101e-05,\n",
            "       8.3475941e-05, 5.1239564e-05, 3.4080214e-05, 1.6452374e-05,\n",
            "       1.1918659e-05, 7.2137809e-05, 2.5933008e-05, 2.6212967e-05,\n",
            "       1.3747478e-04, 3.2078660e-05, 8.5556603e-05, 4.1564781e-05,\n",
            "       1.7098238e-05, 8.7630824e-06, 3.0394574e-05, 2.9161887e-05,\n",
            "       1.0454760e-05, 6.6043067e-05, 2.8079688e-05, 1.8709567e-05,\n",
            "       2.6225576e-05, 5.1668339e-05, 3.9696795e-05, 3.8633647e-05,\n",
            "       2.4430177e-05, 3.2191751e-05, 4.6041743e-05, 7.7277082e-06],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 326, 'shape': array([120,   1,   1, 480], dtype=int32), 'shape_signature': array([120,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00070185, 0.00221728, 0.0014455 , 0.00076223, 0.00040004,\n",
            "       0.00140268, 0.00026885, 0.00056796, 0.00078415, 0.00055301,\n",
            "       0.00037573, 0.00126813, 0.0019099 , 0.00024457, 0.00233416,\n",
            "       0.00277636, 0.00167929, 0.00090418, 0.00057226, 0.00120666,\n",
            "       0.00119502, 0.00153274, 0.00209012, 0.00034654, 0.00123136,\n",
            "       0.00056935, 0.00044437, 0.00086332, 0.00059703, 0.00064788,\n",
            "       0.00206543, 0.00288764, 0.00215745, 0.00057259, 0.00189672,\n",
            "       0.00267707, 0.00099993, 0.00114838, 0.0004844 , 0.00203327,\n",
            "       0.00083756, 0.00064173, 0.00027338, 0.00059314, 0.00089897,\n",
            "       0.00024013, 0.00343034, 0.00089286, 0.00199443, 0.00097328,\n",
            "       0.00018437, 0.00234604, 0.00396218, 0.00052429, 0.00039921,\n",
            "       0.00234963, 0.00338598, 0.00046162, 0.00040214, 0.0008347 ,\n",
            "       0.00051131, 0.0009091 , 0.00263145, 0.00089661, 0.00064388,\n",
            "       0.0004155 , 0.00349619, 0.00114273, 0.00202428, 0.0015898 ,\n",
            "       0.00017726, 0.00131488, 0.0006968 , 0.00102126, 0.00153892,\n",
            "       0.00094877, 0.0008738 , 0.00048409, 0.00050905, 0.00015356,\n",
            "       0.00176274, 0.00060885, 0.00248455, 0.00042653, 0.00223418,\n",
            "       0.0009718 , 0.00231815, 0.00218199, 0.00044895, 0.00035729,\n",
            "       0.00026944, 0.00075188, 0.00195794, 0.00120183, 0.00079936,\n",
            "       0.00038589, 0.00027955, 0.001692  , 0.00060826, 0.00061483,\n",
            "       0.00322449, 0.00075241, 0.00200674, 0.00097491, 0.00040104,\n",
            "       0.00020554, 0.00071291, 0.000684  , 0.00024522, 0.00154905,\n",
            "       0.00065861, 0.00043884, 0.00061512, 0.00121189, 0.00093109,\n",
            "       0.00090616, 0.00057301, 0.00075506, 0.00107992, 0.00018125],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 327, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00300924, 0.00402196, 0.01025756, 0.01155879, 0.00899965,\n",
            "       0.0023896 , 0.0102932 , 0.001246  , 0.00226297, 0.00846978,\n",
            "       0.00248129, 0.00156313, 0.00697572, 0.00571401, 0.00090529,\n",
            "       0.00110855, 0.00109145, 0.00218116, 0.00547306, 0.00110101,\n",
            "       0.00162139, 0.00856697, 0.00050076, 0.00283651, 0.00349841,\n",
            "       0.00071827, 0.00527184, 0.00957835, 0.00060038, 0.0013689 ,\n",
            "       0.00385637, 0.00372624, 0.01417991, 0.01145042, 0.00234479,\n",
            "       0.00216415, 0.00376691, 0.00106702, 0.00644706, 0.0023575 ,\n",
            "       0.00468278, 0.00360563, 0.00720771, 0.01621475, 0.00114097,\n",
            "       0.00154169, 0.00149682, 0.00461174, 0.00426995, 0.00059161,\n",
            "       0.00703933, 0.00813246, 0.00740993, 0.00286942, 0.00064572,\n",
            "       0.00172969, 0.00059688, 0.00172894, 0.0024688 , 0.0053095 ,\n",
            "       0.00244702, 0.00459065, 0.00521885, 0.02366643, 0.00518926,\n",
            "       0.00075877, 0.00133803, 0.00200354, 0.01114874, 0.00122695,\n",
            "       0.0028415 , 0.00997839, 0.00285235, 0.00179184, 0.00395384,\n",
            "       0.00389445, 0.00310124, 0.00089609, 0.00215651, 0.00103041,\n",
            "       0.00227052, 0.00439876, 0.00092482, 0.00215452, 0.00057969,\n",
            "       0.00404343, 0.00425835, 0.00994726, 0.00489227, 0.00585326,\n",
            "       0.00911108, 0.00094757, 0.00891266, 0.00644486, 0.00203172,\n",
            "       0.00231879, 0.01074651, 0.0022851 , 0.00275133, 0.00508522,\n",
            "       0.00182559, 0.00084918, 0.00183435, 0.00456436, 0.00383697,\n",
            "       0.00573484, 0.01329991, 0.0059911 , 0.00245429, 0.00428985,\n",
            "       0.00273157, 0.00786624, 0.00653056, 0.00523701, 0.00189458,\n",
            "       0.00861544, 0.00848092, 0.00389714, 0.00779975, 0.00222997,\n",
            "       0.00700755, 0.00097108, 0.00282627, 0.00264035, 0.00440057,\n",
            "       0.00851008, 0.0080927 , 0.0051305 , 0.00454687, 0.00962668,\n",
            "       0.01478126, 0.00074675, 0.00235027, 0.0054715 , 0.0061719 ,\n",
            "       0.00526253, 0.00092359, 0.00425409, 0.0068819 , 0.00486296,\n",
            "       0.00173954, 0.00137586, 0.00622175, 0.00522434, 0.00082235,\n",
            "       0.00061743, 0.00256639, 0.00770147, 0.00156045, 0.00404631,\n",
            "       0.00425185, 0.00295875, 0.00715355, 0.00825919, 0.00526309,\n",
            "       0.00081728, 0.00171507, 0.00493252, 0.00142636, 0.00786241,\n",
            "       0.0054806 , 0.00965041, 0.00196238, 0.00149858, 0.00141987,\n",
            "       0.00101848, 0.01191916, 0.00274364, 0.00066515, 0.00332586,\n",
            "       0.00110918, 0.00294691, 0.00188568, 0.00088006, 0.00103709,\n",
            "       0.00387044, 0.00388481, 0.00683954, 0.00876268, 0.00364334,\n",
            "       0.00173009, 0.00693724, 0.00048758, 0.00122693, 0.00571279,\n",
            "       0.00398407, 0.00107022, 0.00052556, 0.00470949, 0.00923119,\n",
            "       0.0033499 , 0.0092975 , 0.00124761, 0.00323926, 0.00676238,\n",
            "       0.00126751, 0.00402629, 0.0048129 , 0.00296375, 0.0037653 ,\n",
            "       0.00326124, 0.00444211, 0.00601099, 0.00097824, 0.00161779,\n",
            "       0.00356657, 0.00576343, 0.00391202, 0.00994204, 0.00378479,\n",
            "       0.00726969, 0.00652017, 0.00465811, 0.00869549, 0.00352471,\n",
            "       0.00149757, 0.00876369, 0.00223458, 0.00070735, 0.00839341,\n",
            "       0.00388061, 0.00205507, 0.00064767, 0.00194611, 0.00343686,\n",
            "       0.00535835, 0.00277984, 0.00590362, 0.00600633, 0.01085535,\n",
            "       0.00640872, 0.0068459 , 0.00589192, 0.00324075, 0.00168188,\n",
            "       0.0011864 , 0.00214384, 0.00161166, 0.00494936, 0.00235172],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul', 'index': 328, 'shape': array([  1,   3,   1, 240], dtype=int32), 'shape_signature': array([  1,   3,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.02893192, 0.03866855, 0.09861977, 0.11113026, 0.08652577,\n",
            "       0.02297443, 0.0989624 , 0.01197944, 0.02175697, 0.08143141,\n",
            "       0.02385602, 0.01502843, 0.06706697, 0.05493649, 0.00870374,\n",
            "       0.01065795, 0.01049358, 0.02097045, 0.05261993, 0.01058546,\n",
            "       0.01558864, 0.08236586, 0.00481451, 0.02727122, 0.03363491,\n",
            "       0.00690571, 0.05068529, 0.09208958, 0.00577229, 0.01316111,\n",
            "       0.03707645, 0.03582542, 0.13633057, 0.1100883 , 0.02254362,\n",
            "       0.02080687, 0.03621643, 0.01025872, 0.06198425, 0.02266585,\n",
            "       0.04502185, 0.03466575, 0.06929746, 0.15589425, 0.01096973,\n",
            "       0.01482231, 0.01439095, 0.04433885, 0.04105283, 0.0056879 ,\n",
            "       0.06767862, 0.07818829, 0.07124162, 0.02758758, 0.00620817,\n",
            "       0.0166298 , 0.0057386 , 0.01662267, 0.02373587, 0.05104741,\n",
            "       0.02352654, 0.0441361 , 0.05017581, 0.22753733, 0.04989134,\n",
            "       0.00729511, 0.01286429, 0.01926271, 0.10718784, 0.01179631,\n",
            "       0.02731916, 0.09593577, 0.02742348, 0.01722739, 0.03801356,\n",
            "       0.03744261, 0.02981637, 0.00861537, 0.02073341, 0.00990673,\n",
            "       0.02182957, 0.04229123, 0.00889158, 0.02071435, 0.00557333,\n",
            "       0.03887492, 0.04094128, 0.09563646, 0.047036  , 0.05627526,\n",
            "       0.08759706, 0.0091103 , 0.08568946, 0.06196311, 0.01953363,\n",
            "       0.02229363, 0.10332066, 0.02196974, 0.02645227, 0.04889105,\n",
            "       0.01755185, 0.00816432, 0.01763612, 0.04388339, 0.03688993,\n",
            "       0.05513672, 0.12786996, 0.05760055, 0.02359642, 0.04124416,\n",
            "       0.02626227, 0.07562875, 0.06278712, 0.05035048, 0.01821518,\n",
            "       0.08283188, 0.08153856, 0.0374685 , 0.0749895 , 0.02143974,\n",
            "       0.06737306, 0.00933631, 0.02717273, 0.02538526, 0.0423086 ,\n",
            "       0.08181886, 0.07780608, 0.0493264 , 0.04371522, 0.09255429,\n",
            "       0.14211221, 0.00717948, 0.02259631, 0.0526049 , 0.05933877,\n",
            "       0.05059581, 0.0088797 , 0.04090026, 0.06616501, 0.04675419,\n",
            "       0.01672451, 0.01322801, 0.05981811, 0.05022862, 0.00790633,\n",
            "       0.00593622, 0.02467417, 0.07404462, 0.01500276, 0.03890265,\n",
            "       0.04087878, 0.02844645, 0.06877675, 0.07940672, 0.05060119,\n",
            "       0.00785766, 0.01648927, 0.04742296, 0.01371349, 0.07559193,\n",
            "       0.05269237, 0.09278238, 0.018867  , 0.01440784, 0.01365109,\n",
            "       0.009792  , 0.11459494, 0.02637832, 0.00639503, 0.03197596,\n",
            "       0.01066401, 0.02833263, 0.01812957, 0.00846118, 0.0099709 ,\n",
            "       0.03721181, 0.0373499 , 0.0657577 , 0.08424751, 0.03502832,\n",
            "       0.01663369, 0.06669707, 0.00468774, 0.01179618, 0.05492476,\n",
            "       0.03830422, 0.01028946, 0.0050529 , 0.04527871, 0.08875187,\n",
            "       0.03220708, 0.08938941, 0.01199496, 0.0311434 , 0.06501585,\n",
            "       0.01218629, 0.03871015, 0.04627286, 0.02849449, 0.03620089,\n",
            "       0.03135472, 0.04270801, 0.05779174, 0.00940519, 0.01555399,\n",
            "       0.03429025, 0.05541161, 0.03761151, 0.0955862 , 0.03638827,\n",
            "       0.06989338, 0.06268721, 0.04478473, 0.08360147, 0.03388781,\n",
            "       0.01439814, 0.08425721, 0.02148405, 0.00680072, 0.08069718,\n",
            "       0.03730958, 0.01975813, 0.00622696, 0.01871061, 0.03304318,\n",
            "       0.05151705, 0.02672639, 0.05675943, 0.05774695, 0.10436711,\n",
            "       0.06161568, 0.0658189 , 0.05664694, 0.03115775, 0.01617013,\n",
            "       0.01140644, 0.02061164, 0.01549508, 0.0475849 , 0.02261024],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 329, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.15605762e-04, 2.00834067e-04, 1.05664390e-03, 3.07053451e-05,\n",
            "       3.82005790e-04, 2.05200678e-03, 1.28412124e-04, 5.19151986e-03,\n",
            "       1.62289850e-03, 2.11198159e-04, 1.52918670e-04, 3.88241227e-04,\n",
            "       2.67816894e-03, 3.90602229e-03, 2.21697567e-03, 7.21940363e-04,\n",
            "       9.21984087e-04, 1.29198690e-03, 7.97566550e-04, 8.25948024e-04,\n",
            "       9.71383124e-04, 5.75215054e-05, 2.35549896e-03, 1.84590725e-04,\n",
            "       3.88307869e-03, 1.35909102e-03, 2.81374814e-04, 1.45163751e-04,\n",
            "       8.74566671e-04, 3.36970406e-04, 6.89679175e-04, 1.10107404e-03,\n",
            "       1.06296298e-04, 6.33894524e-04, 6.53532567e-04, 6.59198209e-04,\n",
            "       6.66642794e-04, 9.14107426e-04, 4.71392879e-04, 6.95114373e-04,\n",
            "       3.20999738e-04, 1.49635412e-03, 1.75629440e-03, 1.15665502e-03,\n",
            "       9.68071399e-04, 3.33830103e-04, 7.70569895e-04, 2.88654584e-03,\n",
            "       2.88520678e-04, 8.39459244e-04, 1.54980633e-03, 2.35362048e-03,\n",
            "       6.86842250e-04, 1.90431287e-03, 1.71849830e-03, 2.19168677e-03,\n",
            "       1.11439230e-03, 7.29171792e-04, 1.26401230e-03, 1.90360224e-04,\n",
            "       2.05011398e-04, 9.45570937e-05, 9.67783271e-04, 9.68838984e-04,\n",
            "       2.03937711e-03, 8.24408315e-04, 6.68361026e-04, 6.84490427e-04,\n",
            "       9.59115496e-05, 1.37335935e-03, 1.06459693e-03, 1.75140216e-03,\n",
            "       1.52598065e-03, 2.88522861e-04, 4.91981918e-04, 2.99248123e-03,\n",
            "       3.07011069e-03, 1.05879502e-03, 2.77851010e-04, 2.17597978e-03,\n",
            "       6.44864398e-04, 4.18202690e-04, 2.32177423e-04, 7.25071644e-04,\n",
            "       1.66092988e-03, 4.56254988e-04, 7.95592554e-04, 3.65705549e-04,\n",
            "       2.53238715e-03, 1.67583901e-04, 8.30519537e-04, 6.90623012e-04,\n",
            "       1.48484320e-03, 3.51855328e-04, 8.08776706e-04, 3.00115003e-04,\n",
            "       1.71359294e-04, 3.43684515e-04, 4.17677860e-04, 1.14583410e-03,\n",
            "       9.46069893e-04, 1.47476583e-03, 2.79426837e-04, 6.51913651e-05,\n",
            "       7.50262232e-04, 9.65575979e-04, 1.18947506e-03, 1.34774877e-04,\n",
            "       1.89546298e-03, 1.21285913e-04, 1.65798439e-04, 2.10479670e-03,\n",
            "       7.22960976e-04, 1.53057452e-04, 1.14614540e-03, 2.00430723e-03,\n",
            "       4.16521507e-04, 3.08958464e-04, 3.57824116e-04, 5.07880352e-04,\n",
            "       1.73028710e-03, 4.73796594e-04, 1.38183023e-04, 7.99985952e-04,\n",
            "       2.04883618e-04, 1.46775285e-03, 4.20704921e-04, 2.08139047e-03,\n",
            "       7.27770894e-05, 8.79805011e-04, 6.85664243e-04, 1.07316358e-03,\n",
            "       7.48050865e-04, 2.07760517e-04, 1.08930492e-03, 2.13515974e-04,\n",
            "       7.84134201e-04, 9.23913089e-04, 2.01606061e-04, 6.96172006e-04,\n",
            "       2.62570474e-03, 1.00762770e-03, 1.04626443e-03, 4.31266526e-04,\n",
            "       6.21919578e-04, 1.29469438e-03, 1.19374345e-04, 2.94868601e-04,\n",
            "       1.32448738e-03, 1.11480278e-03, 1.99615560e-03, 2.00585404e-04,\n",
            "       4.25986691e-05, 1.30740390e-03, 1.36898272e-03, 2.03642529e-03,\n",
            "       6.07383612e-04, 2.90929456e-03, 8.76883219e-04, 8.86656999e-05,\n",
            "       1.16537107e-04, 2.76191247e-04, 9.47724213e-04, 5.49287361e-04,\n",
            "       1.88873906e-03, 7.65988429e-04, 3.24943772e-04, 6.41256338e-04,\n",
            "       2.89884338e-04, 7.90143735e-04, 1.01877586e-03, 5.11914084e-04,\n",
            "       8.82389722e-04, 3.62967578e-04, 8.42808629e-04, 1.65744917e-04,\n",
            "       1.71916647e-04, 3.37708421e-04, 1.89658545e-04, 2.28458026e-04,\n",
            "       5.37586224e-04, 1.73748564e-03, 7.38472852e-04, 2.99217354e-04,\n",
            "       3.07580712e-03, 2.73072073e-04, 7.63933698e-04, 6.15429715e-04,\n",
            "       1.22845988e-04, 2.33443046e-04, 1.40615914e-04, 1.29361486e-03,\n",
            "       3.43393564e-04, 1.95620861e-03, 9.51995025e-04, 8.43660557e-04,\n",
            "       1.67912658e-04, 9.81893536e-05, 3.63270607e-04, 9.57674274e-05,\n",
            "       1.64772006e-04, 6.06092624e-04, 1.46600520e-04, 7.78448069e-04,\n",
            "       2.66461691e-04, 9.42832557e-04, 2.34642788e-03, 3.35111050e-04,\n",
            "       3.90411005e-05, 2.35503912e-03, 1.52475049e-03, 1.60795331e-04,\n",
            "       5.77790663e-04, 1.73541065e-03, 4.49847139e-04, 1.77466625e-03,\n",
            "       8.82437278e-04, 2.22613904e-04, 1.04851392e-03, 9.95199662e-04,\n",
            "       1.11150963e-03, 1.14920076e-04, 2.28191633e-03, 2.39161425e-03,\n",
            "       9.56711010e-05, 3.41659237e-04, 1.10093504e-03, 3.43645690e-03,\n",
            "       1.62939937e-03, 6.43208798e-04, 1.84682396e-03, 9.18831094e-04,\n",
            "       2.11115097e-04, 5.48510056e-04, 1.81571348e-03, 1.28027561e-04,\n",
            "       3.69153684e-04, 5.01662435e-04, 7.60364113e-04, 2.83362664e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 330, 'shape': array([  1,   3,   3, 240], dtype=int32), 'shape_signature': array([  1,   3,   3, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00216091, 0.003754  , 0.01975084, 0.00057395, 0.00714047,\n",
            "       0.03835621, 0.00240029, 0.09704015, 0.0303353 , 0.00394773,\n",
            "       0.00285836, 0.00725702, 0.05006047, 0.07301156, 0.04143982,\n",
            "       0.01349454, 0.01723377, 0.02414988, 0.01490815, 0.01543866,\n",
            "       0.01815714, 0.00107519, 0.0440291 , 0.00345038, 0.0725827 ,\n",
            "       0.0254042 , 0.00525947, 0.00271341, 0.01634744, 0.00629867,\n",
            "       0.01289152, 0.02058133, 0.0019869 , 0.01184879, 0.01221586,\n",
            "       0.01232177, 0.01246092, 0.01708654, 0.0088113 , 0.01299311,\n",
            "       0.00600014, 0.02796992, 0.03282874, 0.02162025, 0.01809524,\n",
            "       0.00623997, 0.01440353, 0.05395546, 0.00539304, 0.01569121,\n",
            "       0.02896906, 0.04399399, 0.01283849, 0.03559551, 0.03212225,\n",
            "       0.04096712, 0.02083028, 0.01362971, 0.02362698, 0.00355822,\n",
            "       0.00383208, 0.00176747, 0.01808985, 0.01810959, 0.03812014,\n",
            "       0.01540988, 0.01249304, 0.01279453, 0.00179278, 0.0256709 ,\n",
            "       0.0198995 , 0.0327373 , 0.02852371, 0.00539308, 0.00919615,\n",
            "       0.05593561, 0.05738666, 0.01979105, 0.0051936 , 0.04067352,\n",
            "       0.01205384, 0.00781707, 0.00433987, 0.01355307, 0.03104618,\n",
            "       0.00852834, 0.01487126, 0.00683579, 0.04733551, 0.00313249,\n",
            "       0.01552411, 0.01290916, 0.02775476, 0.0065769 , 0.01511769,\n",
            "       0.00560976, 0.00320306, 0.00642417, 0.00780726, 0.02141799,\n",
            "       0.01768398, 0.0275664 , 0.00522306, 0.00121856, 0.01402394,\n",
            "       0.01804859, 0.02223373, 0.00251922, 0.03543009, 0.00226708,\n",
            "       0.00309911, 0.03934297, 0.01351362, 0.00286096, 0.02142381,\n",
            "       0.03746461, 0.00778564, 0.00577507, 0.00668847, 0.00949332,\n",
            "       0.03234261, 0.00885623, 0.00258292, 0.01495338, 0.00382969,\n",
            "       0.02743531, 0.00786384, 0.03890545, 0.00136035, 0.01644536,\n",
            "       0.01281647, 0.02005963, 0.0139826 , 0.00388347, 0.02036134,\n",
            "       0.00399105, 0.01465708, 0.01726983, 0.00376843, 0.01301288,\n",
            "       0.0490798 , 0.01883463, 0.01955683, 0.00806126, 0.01162495,\n",
            "       0.02420049, 0.00223135, 0.0055117 , 0.02475738, 0.02083795,\n",
            "       0.03731224, 0.00374935, 0.00079626, 0.02443806, 0.02558909,\n",
            "       0.03806496, 0.01135325, 0.05438068, 0.01639074, 0.00165734,\n",
            "       0.00217832, 0.00516258, 0.01771491, 0.01026731, 0.0353044 ,\n",
            "       0.01431789, 0.00607387, 0.0119864 , 0.00541853, 0.01476941,\n",
            "       0.01904301, 0.00956872, 0.01649367, 0.00678461, 0.01575382,\n",
            "       0.00309811, 0.00321347, 0.00631246, 0.00354511, 0.00427035,\n",
            "       0.01004859, 0.03247717, 0.01380357, 0.00559299, 0.05749314,\n",
            "       0.00510428, 0.01427949, 0.01150364, 0.00229624, 0.00436353,\n",
            "       0.0026284 , 0.02418031, 0.00641873, 0.03656555, 0.01779474,\n",
            "       0.01576974, 0.00313863, 0.00183536, 0.00679027, 0.00179009,\n",
            "       0.00307993, 0.01132911, 0.00274026, 0.01455079, 0.00498071,\n",
            "       0.01762347, 0.04385955, 0.00626391, 0.00072976, 0.04402051,\n",
            "       0.02850071, 0.00300559, 0.01080009, 0.03243838, 0.00840857,\n",
            "       0.03317215, 0.01649456, 0.00416111, 0.01959887, 0.01860232,\n",
            "       0.02077639, 0.00214809, 0.04265369, 0.04470417, 0.00178829,\n",
            "       0.00638631, 0.02057873, 0.06423442, 0.03045681, 0.01202289,\n",
            "       0.03452092, 0.01717484, 0.00394617, 0.01025278, 0.03393941,\n",
            "       0.0023931 , 0.00690024, 0.0093771 , 0.01421276, 0.00529663],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 331, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.07112758e-04, 1.71431384e-04, 3.68783985e-05, 1.59821735e-04,\n",
            "       9.66433727e-05, 3.54992699e-05, 3.18335748e-04, 4.90760067e-05,\n",
            "       7.62097843e-05, 1.79557319e-04, 2.01196031e-04, 1.76361151e-04,\n",
            "       2.53803028e-05, 3.22450178e-05, 1.29342632e-04, 2.02097159e-04,\n",
            "       1.38510848e-04, 1.11686422e-04, 5.03146184e-05, 1.37005292e-04,\n",
            "       1.51490080e-04, 1.06421925e-04, 1.60052732e-04, 1.26829284e-04,\n",
            "       3.15909601e-05, 1.29156062e-04, 8.34242601e-05, 2.00256356e-04,\n",
            "       2.51729478e-04, 3.76624928e-04, 1.04550316e-04, 4.00541321e-05,\n",
            "       1.05141648e-04, 4.34190297e-05, 1.07039086e-04, 2.71404453e-04,\n",
            "       2.04198204e-05, 2.12204555e-04, 2.30210935e-05, 1.33930589e-04,\n",
            "       1.11136651e-04, 5.15047177e-05, 4.37936396e-05, 5.05492862e-05,\n",
            "       1.74998233e-04, 1.52735258e-04, 1.63163335e-04, 2.84659454e-05,\n",
            "       2.35019426e-04, 1.74999426e-04, 2.86679442e-05, 2.73202422e-05,\n",
            "       2.38559260e-05, 4.29304855e-05, 2.30554651e-04, 4.78134098e-05,\n",
            "       2.53536680e-04, 1.22440673e-04, 6.69617293e-05, 1.60483673e-04,\n",
            "       2.53843580e-04, 2.75833561e-04, 5.46518459e-05, 4.64375153e-05,\n",
            "       3.56971104e-05, 3.03867506e-04, 2.15238906e-04, 3.77051649e-04,\n",
            "       1.86323305e-04, 1.69048348e-04, 1.18958596e-04, 2.47189328e-05,\n",
            "       5.17803128e-05, 1.37074734e-04, 1.78961505e-04, 1.45167060e-05,\n",
            "       2.49740424e-05, 1.32928035e-04, 1.71155712e-04, 2.72566813e-05,\n",
            "       2.75266881e-04, 6.96896022e-05, 2.31805985e-04, 3.36354678e-05,\n",
            "       1.56361493e-04, 7.37318696e-05, 4.01157013e-05, 8.28464108e-05,\n",
            "       2.67932592e-05, 1.69589839e-04, 6.50384682e-05, 2.68160831e-04,\n",
            "       3.66554086e-05, 4.67263853e-05, 2.01551913e-04, 9.29355374e-05,\n",
            "       2.69874930e-04, 2.11580205e-04, 1.00895995e-04, 4.00225981e-05,\n",
            "       1.27815336e-04, 1.62689379e-04, 1.81854732e-04, 2.94112950e-04,\n",
            "       1.57917209e-04, 6.02331311e-05, 4.39148243e-05, 1.41155877e-04,\n",
            "       6.00160929e-05, 1.84460587e-04, 1.79703740e-04, 3.18406346e-05,\n",
            "       2.38951525e-05, 1.75222551e-04, 1.11832102e-04, 2.50255071e-05,\n",
            "       2.28160643e-04, 1.63388308e-04, 1.17546020e-04, 1.29486289e-04,\n",
            "       1.97765949e-05, 2.44089300e-04, 2.37987275e-04, 1.25616585e-04,\n",
            "       2.43534698e-04, 2.29690540e-05, 8.06831449e-05, 1.69382711e-05,\n",
            "       3.70767724e-04, 4.25369071e-05, 2.10710277e-05, 1.70413128e-04,\n",
            "       1.22324680e-04, 1.35333757e-04, 4.53699977e-05, 1.85657220e-04,\n",
            "       2.66841875e-04, 7.65160148e-05, 1.34077214e-04, 1.29778258e-04,\n",
            "       3.89818015e-05, 9.49201276e-05, 4.82531177e-05, 1.74502668e-04,\n",
            "       1.95096960e-04, 4.20309603e-04, 1.44858626e-04, 3.42228923e-05,\n",
            "       4.40157928e-05, 4.74150947e-05, 2.69250777e-05, 1.19944489e-04,\n",
            "       1.86148769e-04, 2.66342831e-05, 6.20598657e-05, 1.19914839e-04,\n",
            "       9.39444726e-05, 2.63011079e-05, 1.25806415e-04, 1.09816894e-04,\n",
            "       2.75560364e-04, 3.62538085e-05, 1.22427184e-04, 2.26824966e-04,\n",
            "       5.14329295e-05, 2.76872277e-04, 4.55787485e-05, 8.15521998e-05,\n",
            "       1.97398273e-04, 1.13701593e-04, 1.34062997e-04, 5.60100016e-05,\n",
            "       4.51773558e-05, 2.49636709e-04, 1.48398030e-04, 2.88263720e-04,\n",
            "       2.42080903e-04, 9.54503630e-05, 1.47998435e-04, 7.98611509e-05,\n",
            "       1.87708167e-04, 4.03093072e-05, 1.68925515e-04, 2.15789245e-04,\n",
            "       3.73620824e-05, 1.58831914e-04, 2.31840095e-04, 1.96025459e-04,\n",
            "       2.33353931e-04, 7.15282731e-05, 2.12934436e-04, 1.83984903e-05,\n",
            "       1.61776916e-04, 5.15705469e-05, 8.43244343e-05, 2.44933646e-04,\n",
            "       1.24180704e-04, 1.44907259e-04, 2.02635594e-04, 2.58623360e-04,\n",
            "       1.21979967e-04, 1.19598793e-04, 2.88546871e-04, 1.36767470e-04,\n",
            "       1.15595241e-04, 2.81938683e-05, 2.48382166e-05, 1.58225521e-04,\n",
            "       2.42649039e-04, 2.56057465e-05, 2.12990217e-05, 1.56396854e-04,\n",
            "       6.58904173e-05, 3.11936528e-05, 9.30981696e-05, 1.79707611e-04,\n",
            "       1.48068666e-05, 2.33056737e-04, 2.36796754e-04, 2.43194627e-05,\n",
            "       1.88031390e-05, 3.91599839e-04, 1.35625072e-04, 7.39367897e-05,\n",
            "       2.34421677e-04, 9.67266897e-05, 2.43012895e-04, 1.86401194e-05,\n",
            "       8.44652532e-05, 2.90888947e-05, 3.75771888e-05, 6.76064228e-05,\n",
            "       1.04220337e-04, 1.00246973e-04, 3.74320771e-05, 2.79937871e-04,\n",
            "       2.33373590e-04, 2.09371181e-04, 9.31765171e-05, 1.40287084e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 332, 'shape': array([240,   1,   1,  72], dtype=int32), 'shape_signature': array([240,   1,   1,  72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.73690011e-04, 2.08595040e-04, 4.48730607e-05, 1.94468594e-04,\n",
            "       1.17594151e-04, 4.31949593e-05, 3.87345965e-04, 5.97149192e-05,\n",
            "       9.27308793e-05, 2.18482557e-04, 2.44812196e-04, 2.14593500e-04,\n",
            "       3.08823583e-05, 3.92352340e-05, 1.57382106e-04, 2.45908683e-04,\n",
            "       1.68537837e-04, 1.35898299e-04, 6.12220465e-05, 1.66705911e-04,\n",
            "       1.84330769e-04, 1.29492546e-04, 1.94749664e-04, 1.54323905e-04,\n",
            "       3.84393898e-05, 1.57155082e-04, 1.01509337e-04, 2.43668808e-04,\n",
            "       3.06300499e-04, 4.58271359e-04, 1.27215200e-04, 4.87372454e-05,\n",
            "       1.27934720e-04, 5.28316014e-05, 1.30243498e-04, 3.30240728e-04,\n",
            "       2.48465185e-05, 2.58207205e-04, 2.80117074e-05, 1.62964658e-04,\n",
            "       1.35229348e-04, 6.26701367e-05, 5.32874183e-05, 6.15075842e-05,\n",
            "       2.12935120e-04, 1.85845885e-04, 1.98534603e-04, 3.46369197e-05,\n",
            "       2.85967981e-04, 2.12936575e-04, 3.48827089e-05, 3.32428463e-05,\n",
            "       2.90275202e-05, 5.22371483e-05, 2.80535314e-04, 5.81786117e-05,\n",
            "       3.08499497e-04, 1.48983905e-04, 8.14779924e-05, 1.95274042e-04,\n",
            "       3.08872899e-04, 3.35630000e-04, 6.64995168e-05, 5.65044465e-05,\n",
            "       4.34356880e-05, 3.69741261e-04, 2.61899346e-04, 4.58790571e-04,\n",
            "       2.26715289e-04, 2.05695396e-04, 1.44746969e-04, 3.00776119e-05,\n",
            "       6.30054783e-05, 1.66790400e-04, 2.17757581e-04, 1.76637022e-05,\n",
            "       3.03880261e-05, 1.61744771e-04, 2.08259604e-04, 3.31655065e-05,\n",
            "       3.34940443e-04, 8.47972260e-05, 2.82057910e-04, 4.09271124e-05,\n",
            "       1.90258230e-04, 8.97157952e-05, 4.88121623e-05, 1.00806225e-04,\n",
            "       3.26016198e-05, 2.06354278e-04, 7.91377970e-05, 3.26293928e-04,\n",
            "       4.46017293e-05, 5.68559371e-05, 2.45245232e-04, 1.13082511e-04,\n",
            "       3.28379625e-04, 2.57447507e-04, 1.22768673e-04, 4.86988756e-05,\n",
            "       1.55523710e-04, 1.97957910e-04, 2.21278009e-04, 3.57872050e-04,\n",
            "       1.92151201e-04, 7.32907356e-05, 5.34348728e-05, 1.71756270e-04,\n",
            "       7.30266474e-05, 2.24448770e-04, 2.18660716e-04, 3.87431865e-05,\n",
            "       2.90752505e-05, 2.13208070e-04, 1.36075556e-04, 3.04506484e-05,\n",
            "       2.77622312e-04, 1.98808353e-04, 1.43028170e-04, 1.57556904e-04,\n",
            "       2.40638528e-05, 2.97004066e-04, 2.89579213e-04, 1.52848297e-04,\n",
            "       2.96329235e-04, 2.79483866e-05, 9.81739940e-05, 2.06102250e-05,\n",
            "       4.51144384e-04, 5.17582448e-05, 2.56388976e-05, 2.07356046e-04,\n",
            "       1.48842766e-04, 1.64672005e-04, 5.52055062e-05, 2.25904820e-04,\n",
            "       3.24689056e-04, 9.31034956e-05, 1.63143064e-04, 1.57912160e-04,\n",
            "       4.74324479e-05, 1.15497336e-04, 5.87136419e-05, 2.12332132e-04,\n",
            "       2.37390937e-04, 5.11426188e-04, 1.76261718e-04, 4.16418843e-05,\n",
            "       5.35577310e-05, 5.76939492e-05, 3.27620146e-05, 1.45946586e-04,\n",
            "       2.26502918e-04, 3.24081811e-05, 7.55134752e-05, 1.45910511e-04,\n",
            "       1.14310169e-04, 3.20027793e-05, 1.53079280e-04, 1.33623485e-04,\n",
            "       3.35297547e-04, 4.41130687e-05, 1.48967491e-04, 2.75997096e-04,\n",
            "       6.25827888e-05, 3.36893863e-04, 5.54595135e-05, 9.92314453e-05,\n",
            "       2.40191148e-04, 1.38350326e-04, 1.63125762e-04, 6.81520978e-05,\n",
            "       5.49711040e-05, 3.03754059e-04, 1.80568415e-04, 3.50754824e-04,\n",
            "       2.94560276e-04, 1.16142517e-04, 1.80082192e-04, 9.71738045e-05,\n",
            "       2.28400371e-04, 4.90477396e-05, 2.05545934e-04, 2.62568996e-04,\n",
            "       4.54616020e-05, 1.93264204e-04, 2.82099412e-04, 2.38520719e-04,\n",
            "       2.83941423e-04, 8.70344884e-05, 2.59095308e-04, 2.23869974e-05,\n",
            "       1.96847628e-04, 6.27502377e-05, 1.02604659e-04, 2.98031460e-04,\n",
            "       1.51101151e-04, 1.76320900e-04, 2.46563839e-04, 3.14688863e-04,\n",
            "       1.48423322e-04, 1.45525948e-04, 3.51099327e-04, 1.66416532e-04,\n",
            "       1.40654491e-04, 3.43058600e-05, 3.02227563e-05, 1.92526350e-04,\n",
            "       2.95251579e-04, 3.11566728e-05, 2.59163189e-05, 1.90301260e-04,\n",
            "       8.01744318e-05, 3.79559497e-05, 1.13280403e-04, 2.18665416e-04,\n",
            "       1.80167644e-05, 2.83579808e-04, 2.88130599e-04, 2.95915434e-05,\n",
            "       2.28793670e-05, 4.76492598e-04, 1.65026475e-04, 8.99651350e-05,\n",
            "       2.85240647e-04, 1.17695527e-04, 2.95694306e-04, 2.26810062e-05,\n",
            "       1.02776008e-04, 3.53949144e-05, 4.57233364e-05, 8.22624424e-05,\n",
            "       1.26813684e-04, 1.21978956e-04, 4.55467671e-05, 3.40624043e-04,\n",
            "       2.83965346e-04, 2.54759594e-04, 1.13375732e-04, 1.70699146e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/rezero/mul', 'index': 333, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.008161894977092743, 127), 'quantization_parameters': {'scales': array([0.00816189], dtype=float32), 'zero_points': array([127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 334, 'shape': array([72], dtype=int32), 'shape_signature': array([72], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00037316, 0.00043696, 0.00048804, 0.00035763, 0.0004117 ,\n",
            "       0.00051607, 0.00053598, 0.00047576, 0.00066802, 0.00049634,\n",
            "       0.00037671, 0.00043606, 0.00041103, 0.00029566, 0.00031302,\n",
            "       0.00038065, 0.00050239, 0.00035093, 0.00044552, 0.00036525,\n",
            "       0.00034138, 0.00051378, 0.00060393, 0.0006442 , 0.00055124,\n",
            "       0.00062659, 0.00051185, 0.00028   , 0.00072688, 0.00050219,\n",
            "       0.00071814, 0.00076985, 0.00061993, 0.0003986 , 0.00046036,\n",
            "       0.00038987, 0.00044498, 0.00058378, 0.00041173, 0.00039412,\n",
            "       0.00063236, 0.00041807, 0.00099742, 0.00062374, 0.00060248,\n",
            "       0.00030974, 0.00056109, 0.00048253, 0.00045835, 0.00041636,\n",
            "       0.0005732 , 0.00057654, 0.00063571, 0.00027031, 0.00068094,\n",
            "       0.0006339 , 0.00058827, 0.00033139, 0.00030011, 0.00038779,\n",
            "       0.00031917, 0.00070528, 0.00048405, 0.0003614 , 0.00040571,\n",
            "       0.0004257 , 0.00075278, 0.000363  , 0.0003884 , 0.00038065,\n",
            "       0.00046952, 0.00067075], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 335, 'shape': array([ 72,   1,   1, 240], dtype=int32), 'shape_signature': array([ 72,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01363157, 0.01596212, 0.01782798, 0.01306428, 0.0150393 ,\n",
            "       0.01885187, 0.01957932, 0.0173793 , 0.02440236, 0.01813114,\n",
            "       0.01376098, 0.01592928, 0.01501489, 0.01080031, 0.01143458,\n",
            "       0.01390518, 0.01835212, 0.01281946, 0.01627482, 0.01334236,\n",
            "       0.01247039, 0.01876836, 0.02206144, 0.02353253, 0.02013669,\n",
            "       0.02288929, 0.0186977 , 0.01022813, 0.02655253, 0.01834469,\n",
            "       0.0262334 , 0.02812232, 0.02264597, 0.01456072, 0.01681688,\n",
            "       0.01424177, 0.01625482, 0.02132514, 0.01504051, 0.01439698,\n",
            "       0.02309991, 0.01527179, 0.03643533, 0.02278505, 0.02200832,\n",
            "       0.01131466, 0.02049652, 0.01762673, 0.01674332, 0.01520956,\n",
            "       0.02093865, 0.02106072, 0.0232221 , 0.00987449, 0.02487463,\n",
            "       0.0231562 , 0.02148912, 0.01210568, 0.01096297, 0.01416599,\n",
            "       0.01165905, 0.02576357, 0.0176821 , 0.01320182, 0.0148206 ,\n",
            "       0.01555054, 0.0274986 , 0.01326044, 0.01418814, 0.013905  ,\n",
            "       0.01715147, 0.02450226], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block3_layer0/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block3_layer0/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block3_layer0/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer0/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 336, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([6.04160959e-06, 1.84916425e-05, 1.27811036e-05, 1.55464222e-05,\n",
            "       1.64961439e-05, 1.59238934e-05, 6.84903671e-06, 7.09216010e-06,\n",
            "       2.62604099e-05, 1.89926341e-05, 1.12957541e-05, 3.61417297e-05,\n",
            "       1.75078985e-05, 1.62568322e-05, 2.88278352e-05, 1.91520721e-05,\n",
            "       1.29083664e-05, 1.39630547e-05, 1.33902731e-05, 1.52575931e-05,\n",
            "       3.07830014e-05, 1.46385064e-05, 3.79355879e-05, 8.48390482e-06,\n",
            "       1.80590068e-05, 7.08201787e-06, 9.11198913e-06, 3.03472807e-05,\n",
            "       1.66447971e-05, 2.65387771e-05, 2.25259882e-05, 1.06061561e-05,\n",
            "       3.30005532e-05, 3.53771284e-05, 3.86858119e-05, 1.21766807e-05,\n",
            "       1.80924726e-05, 1.41068931e-05, 1.81640880e-05, 9.86418036e-06,\n",
            "       1.14931354e-05, 7.52486676e-06, 1.20409450e-05, 1.56787864e-05,\n",
            "       1.83767297e-05, 2.23073166e-05, 2.67892792e-05, 2.73126116e-05,\n",
            "       5.59472755e-05, 9.31435443e-06, 2.21427763e-05, 1.15879993e-05,\n",
            "       2.23388852e-05, 1.18696826e-05, 2.61991008e-05, 2.31309223e-05,\n",
            "       8.28941393e-06, 1.53676792e-05, 9.55297128e-06, 1.54833560e-05,\n",
            "       1.30225690e-05, 1.46570837e-05, 1.17917425e-05, 1.66555146e-05,\n",
            "       1.88443828e-05, 6.37300172e-06, 8.00896305e-06, 6.05290870e-06,\n",
            "       1.10630090e-05, 1.13020114e-05, 2.92563691e-05, 1.71081592e-05,\n",
            "       1.83002321e-05, 1.01069681e-05, 1.14274289e-05, 2.27777346e-05,\n",
            "       1.65305537e-05, 1.40470938e-05, 8.15387557e-06, 1.75321129e-05,\n",
            "       1.65061247e-05, 7.93721938e-06, 1.70719486e-05, 1.98711041e-05,\n",
            "       1.82050935e-05, 1.11479949e-05, 3.27799717e-05, 2.64457376e-05,\n",
            "       1.26056602e-05, 3.25207402e-05, 1.63054665e-05, 1.89426264e-05,\n",
            "       9.05991874e-06, 1.01690221e-05, 3.61235179e-05, 2.91808519e-05,\n",
            "       1.74221605e-05, 1.41493156e-05, 2.92859404e-05, 8.92751632e-06,\n",
            "       1.10308874e-05, 1.89420971e-05, 1.67358048e-05, 1.59067677e-05,\n",
            "       2.88472220e-05, 2.40826212e-05, 1.50985688e-05, 1.21782159e-05,\n",
            "       1.13010628e-05, 8.15919429e-06, 1.66638292e-05, 4.14787100e-05,\n",
            "       2.11216375e-05, 1.03473794e-05, 1.74554152e-05, 1.46187049e-05,\n",
            "       2.34422023e-05, 1.13774504e-05, 7.81931340e-06, 1.57237901e-05,\n",
            "       2.87270741e-05, 1.33377362e-05, 2.95861264e-05, 2.34882427e-05,\n",
            "       1.02459435e-05, 1.59034589e-05, 1.52438024e-05, 1.99874030e-05,\n",
            "       1.22617703e-05, 1.63569348e-05, 1.31754196e-05, 1.25637753e-05,\n",
            "       1.53611600e-05, 1.79891194e-05, 1.97080299e-05, 2.53103681e-05,\n",
            "       1.70386029e-05, 1.90044229e-05, 2.42129317e-05, 1.42809304e-05,\n",
            "       1.33571566e-05, 1.29665486e-05, 2.97508795e-05, 8.23645860e-06,\n",
            "       8.66673781e-06, 8.33145077e-06, 1.03800412e-05, 1.15569710e-05,\n",
            "       1.91154468e-05, 1.48429563e-05, 1.25642582e-05, 1.06881007e-05,\n",
            "       7.16912564e-06, 8.42502413e-06, 1.71284864e-05, 1.12257057e-05,\n",
            "       1.50809847e-05, 3.27366870e-05, 1.00486795e-05, 8.39671702e-06,\n",
            "       3.31334486e-05, 1.06411935e-05, 2.06774330e-05, 1.70970452e-05,\n",
            "       2.14843913e-05, 1.47036617e-05, 9.99021995e-06, 8.98552571e-06,\n",
            "       6.96326742e-06, 1.07812930e-05, 1.02911645e-05, 1.27225139e-05,\n",
            "       3.06296679e-05, 1.67510771e-05, 1.03203402e-05, 6.62769435e-06,\n",
            "       1.22971142e-05, 8.28737029e-06, 1.60129839e-05, 1.72892996e-05,\n",
            "       9.45355896e-06, 1.74858815e-05, 2.62859903e-05, 2.22950075e-05,\n",
            "       8.59883039e-06, 1.33123458e-05, 1.32572568e-05, 1.08479780e-05,\n",
            "       1.33869253e-05, 1.33758822e-05, 1.96355832e-05, 1.28236252e-05,\n",
            "       5.78905747e-06, 1.88332961e-05, 8.69349878e-06, 6.63966875e-06,\n",
            "       1.39520771e-05, 3.88765329e-05, 1.82994190e-05, 2.14327283e-05,\n",
            "       6.60578871e-06, 1.43053194e-05, 1.37937041e-05, 2.37536769e-05,\n",
            "       1.54379832e-05, 1.93758278e-05, 2.00881659e-05, 2.55441028e-05,\n",
            "       1.50904461e-05, 1.05015506e-05, 1.77945749e-05, 1.14608056e-05,\n",
            "       1.18712796e-05, 1.57886079e-05, 2.23196566e-05, 1.31945617e-05,\n",
            "       1.28614474e-05, 9.22701474e-06, 1.46213852e-05, 2.50428948e-05,\n",
            "       4.53478824e-05, 8.03835155e-06, 1.49608086e-05, 1.22364900e-05,\n",
            "       2.00471768e-05, 1.03774564e-05, 1.56495462e-05, 1.34347483e-05,\n",
            "       1.70875628e-05, 2.17605375e-05, 1.68427050e-05, 1.96438232e-05,\n",
            "       2.15141699e-05, 9.55794167e-06, 1.70099775e-05, 1.52873345e-05,\n",
            "       1.51569075e-05, 1.34330976e-05, 1.12833695e-05, 1.41854407e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 337, 'shape': array([240,   1,   1, 120], dtype=int32), 'shape_signature': array([240,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00045762, 0.00140066, 0.00096811, 0.00117757, 0.00124951,\n",
            "       0.00120616, 0.00051878, 0.0005372 , 0.00198911, 0.00143861,\n",
            "       0.0008556 , 0.00273757, 0.00132614, 0.00123138, 0.00218358,\n",
            "       0.00145068, 0.00097775, 0.00105764, 0.00101425, 0.00115569,\n",
            "       0.00233167, 0.0011088 , 0.00287345, 0.00064262, 0.00136789,\n",
            "       0.00053643, 0.00069019, 0.00229867, 0.00126077, 0.00201019,\n",
            "       0.00170624, 0.00080337, 0.00249964, 0.00267966, 0.00293028,\n",
            "       0.00092233, 0.00137042, 0.00106853, 0.00137585, 0.00074717,\n",
            "       0.00087055, 0.00056997, 0.00091205, 0.0011876 , 0.00139195,\n",
            "       0.00168968, 0.00202917, 0.00206881, 0.00423775, 0.00070552,\n",
            "       0.00167722, 0.00087774, 0.00169207, 0.00089908, 0.00198446,\n",
            "       0.00175206, 0.00062789, 0.00116403, 0.00072359, 0.00117279,\n",
            "       0.0009864 , 0.00111021, 0.00089317, 0.00126158, 0.00142738,\n",
            "       0.00048273, 0.00060664, 0.00045848, 0.00083797, 0.00085608,\n",
            "       0.00221604, 0.00129587, 0.00138616, 0.00076556, 0.00086558,\n",
            "       0.00172531, 0.00125212, 0.001064  , 0.00061762, 0.00132798,\n",
            "       0.00125026, 0.00060121, 0.00129312, 0.00150515, 0.00137895,\n",
            "       0.00084441, 0.00248294, 0.00200315, 0.00095482, 0.0024633 ,\n",
            "       0.00123507, 0.00143482, 0.00068625, 0.00077026, 0.00273619,\n",
            "       0.00221032, 0.00131965, 0.00107175, 0.00221828, 0.00067622,\n",
            "       0.00083554, 0.00143478, 0.00126766, 0.00120487, 0.00218505,\n",
            "       0.00182415, 0.00114365, 0.00092245, 0.000856  , 0.00061802,\n",
            "       0.00126221, 0.00314183, 0.00159987, 0.00078377, 0.00132217,\n",
            "       0.0011073 , 0.00177564, 0.00086179, 0.00059228, 0.00119101,\n",
            "       0.00217595, 0.00101027, 0.00224102, 0.00177913, 0.00077608,\n",
            "       0.00120462, 0.00115465, 0.00151396, 0.00092877, 0.00123896,\n",
            "       0.00099798, 0.00095165, 0.00116354, 0.00136259, 0.00149279,\n",
            "       0.00191715, 0.0012906 , 0.0014395 , 0.00183402, 0.00108172,\n",
            "       0.00101174, 0.00098216, 0.0022535 , 0.00062387, 0.00065647,\n",
            "       0.00063107, 0.00078624, 0.00087539, 0.00144791, 0.00112429,\n",
            "       0.00095169, 0.00080958, 0.00054303, 0.00063816, 0.00129741,\n",
            "       0.0008503 , 0.00114232, 0.00247966, 0.00076114, 0.00063601,\n",
            "       0.00250971, 0.00080602, 0.00156622, 0.00129502, 0.00162735,\n",
            "       0.00111374, 0.00075671, 0.00068061, 0.00052744, 0.00081663,\n",
            "       0.00077951, 0.00096367, 0.00232006, 0.00126882, 0.00078172,\n",
            "       0.00050202, 0.00093145, 0.00062773, 0.00121291, 0.00130959,\n",
            "       0.00071606, 0.00132448, 0.00199105, 0.00168875, 0.00065132,\n",
            "       0.00100835, 0.00100418, 0.00082169, 0.001014  , 0.00101316,\n",
            "       0.00148731, 0.00097133, 0.0004385 , 0.00142654, 0.00065849,\n",
            "       0.00050293, 0.00105681, 0.00294472, 0.0013861 , 0.00162343,\n",
            "       0.00050036, 0.00108356, 0.00104481, 0.00179923, 0.00116936,\n",
            "       0.00146763, 0.00152159, 0.00193485, 0.00114303, 0.00079545,\n",
            "       0.00134786, 0.0008681 , 0.0008992 , 0.00119592, 0.00169061,\n",
            "       0.00099943, 0.0009742 , 0.0006989 , 0.0011075 , 0.00189689,\n",
            "       0.0034349 , 0.00060887, 0.00113321, 0.00092686, 0.00151848,\n",
            "       0.00078605, 0.00118538, 0.00101762, 0.00129431, 0.00164826,\n",
            "       0.00127576, 0.00148793, 0.0016296 , 0.00072397, 0.00128843,\n",
            "       0.00115795, 0.00114807, 0.0010175 , 0.00085466, 0.00107448],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 338, 'shape': array([120], dtype=int32), 'shape_signature': array([120], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([7.15093265e-05, 3.74419760e-05, 1.07482330e-04, 4.75827947e-05,\n",
            "       2.83717673e-05, 6.66433625e-05, 2.00408685e-05, 4.04189777e-05,\n",
            "       5.26449367e-05, 3.66622589e-05, 5.18529050e-05, 4.37912713e-05,\n",
            "       3.52407260e-05, 8.11664577e-05, 2.41756661e-05, 5.55086663e-05,\n",
            "       1.66851114e-05, 3.57025747e-05, 7.01608178e-06, 3.57168610e-05,\n",
            "       7.39080642e-05, 7.06427090e-05, 4.65246158e-05, 3.36132616e-05,\n",
            "       2.25437507e-05, 1.05214112e-05, 3.82481267e-05, 2.49828590e-05,\n",
            "       4.73556393e-05, 3.90074420e-05, 4.24289028e-05, 1.06146988e-04,\n",
            "       5.17955305e-05, 2.81210432e-05, 3.07444825e-05, 4.33918649e-05,\n",
            "       3.11516524e-05, 3.34058568e-05, 6.79127743e-06, 6.18363265e-05,\n",
            "       4.03568920e-05, 4.10556822e-05, 3.55325792e-05, 7.48174280e-05,\n",
            "       7.58126989e-05, 1.32874102e-05, 5.44739996e-05, 6.44792672e-05,\n",
            "       2.20035054e-05, 6.54393079e-05, 3.02885765e-05, 5.04507516e-05,\n",
            "       4.75130291e-05, 5.25571559e-05, 8.36601175e-05, 2.80877466e-05,\n",
            "       3.15085163e-05, 5.28821256e-05, 3.40899533e-05, 3.57489262e-05,\n",
            "       2.50474095e-05, 4.93389707e-05, 2.44115599e-05, 9.09741721e-06,\n",
            "       9.52827304e-06, 1.82544627e-05, 1.59546362e-05, 4.39381838e-05,\n",
            "       2.41706493e-05, 5.03765004e-05, 4.49603031e-05, 3.67475659e-05,\n",
            "       1.71890006e-05, 6.56202683e-05, 5.16361943e-05, 1.58888033e-05,\n",
            "       4.51492924e-05, 4.79717528e-05, 2.19679023e-05, 3.68811488e-05,\n",
            "       3.76131320e-05, 2.91714368e-05, 5.65507798e-05, 1.63177883e-05,\n",
            "       5.06650940e-05, 5.00988717e-05, 4.11719011e-05, 3.29032955e-05,\n",
            "       2.12936484e-05, 3.48159956e-05, 1.24133385e-05, 3.22171836e-05,\n",
            "       3.91632711e-05, 8.47384217e-05, 5.74662845e-05, 2.14825977e-05,\n",
            "       2.69742704e-05, 2.60879606e-05, 3.21616062e-05, 3.82571016e-05,\n",
            "       3.07790106e-05, 4.30578766e-05, 7.76413253e-06, 8.05753152e-05,\n",
            "       4.17541924e-05, 3.84847772e-05, 2.20086822e-05, 2.95204718e-05,\n",
            "       1.52573375e-05, 1.94012864e-05, 3.58799189e-05, 2.13666026e-05,\n",
            "       8.08527602e-06, 1.67464805e-05, 3.72321920e-05, 2.13276380e-05,\n",
            "       2.45725896e-05, 1.70748372e-05, 3.21945190e-05, 3.41566847e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 339, 'shape': array([120,   1,   1, 480], dtype=int32), 'shape_signature': array([120,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00318221, 0.00166619, 0.00478304, 0.00211747, 0.00126256,\n",
            "       0.00296568, 0.00089183, 0.00179867, 0.00234274, 0.0016315 ,\n",
            "       0.00230749, 0.00194874, 0.00156824, 0.00361196, 0.00107583,\n",
            "       0.00247017, 0.0007425 , 0.00158879, 0.00031222, 0.00158943,\n",
            "       0.00328896, 0.00314365, 0.00207038, 0.00149581, 0.00100321,\n",
            "       0.00046821, 0.00170207, 0.00111175, 0.00210736, 0.00173586,\n",
            "       0.00188812, 0.00472361, 0.00230494, 0.00125141, 0.00136815,\n",
            "       0.00193097, 0.00138627, 0.00148658, 0.00030222, 0.00275176,\n",
            "       0.00179591, 0.00182701, 0.00158122, 0.00332943, 0.00337372,\n",
            "       0.0005913 , 0.00242413, 0.00286937, 0.00097917, 0.00291209,\n",
            "       0.00134786, 0.00224509, 0.00211436, 0.00233883, 0.00372293,\n",
            "       0.00124992, 0.00140215, 0.00235329, 0.00151703, 0.00159085,\n",
            "       0.00111463, 0.00219562, 0.00108633, 0.00040484, 0.00042401,\n",
            "       0.00081234, 0.00070999, 0.00195528, 0.00107561, 0.00224179,\n",
            "       0.00200076, 0.00163529, 0.00076492, 0.00292015, 0.00229785,\n",
            "       0.00070706, 0.00200917, 0.00213478, 0.00097759, 0.00164124,\n",
            "       0.00167381, 0.00129815, 0.00251655, 0.00072615, 0.00225463,\n",
            "       0.00222943, 0.00183218, 0.00146422, 0.00094758, 0.00154934,\n",
            "       0.0005524 , 0.00143369, 0.00174279, 0.00377092, 0.00255729,\n",
            "       0.00095599, 0.00120037, 0.00116093, 0.00143121, 0.00170247,\n",
            "       0.00136969, 0.00191611, 0.00034551, 0.00358566, 0.00185809,\n",
            "       0.0017126 , 0.0009794 , 0.00131368, 0.00067896, 0.00086337,\n",
            "       0.00159668, 0.00095083, 0.0003598 , 0.00074523, 0.00165686,\n",
            "       0.00094909, 0.0010935 , 0.00075984, 0.00143268, 0.00152   ],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 340, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00149462, 0.00408329, 0.00116109, 0.00290432, 0.00346995,\n",
            "       0.00153713, 0.00295203, 0.00171325, 0.01672845, 0.0065266 ,\n",
            "       0.00090207, 0.00087608, 0.00991671, 0.00164423, 0.00087885,\n",
            "       0.00548417, 0.00304232, 0.00073445, 0.00829629, 0.00205735,\n",
            "       0.00386451, 0.00107415, 0.00147777, 0.00420754, 0.00846655,\n",
            "       0.0020025 , 0.00446167, 0.00093025, 0.00388508, 0.00377738,\n",
            "       0.00372735, 0.00164379, 0.00066932, 0.00074343, 0.00030059,\n",
            "       0.00092674, 0.00104557, 0.00016576, 0.00196007, 0.00102219,\n",
            "       0.00117964, 0.00112121, 0.00902255, 0.00082299, 0.00084448,\n",
            "       0.00708859, 0.00352683, 0.00380349, 0.00404261, 0.00594106,\n",
            "       0.00949054, 0.0047788 , 0.00479063, 0.00927624, 0.01328381,\n",
            "       0.00302531, 0.00218441, 0.00068998, 0.00397193, 0.00162836,\n",
            "       0.00280069, 0.00151089, 0.00659651, 0.00729357, 0.00553146,\n",
            "       0.00146451, 0.00364532, 0.00262993, 0.0006173 , 0.00359816,\n",
            "       0.00907567, 0.00092461, 0.00051686, 0.00375125, 0.00151033,\n",
            "       0.00551408, 0.00122784, 0.00985615, 0.00111497, 0.00064883,\n",
            "       0.00745382, 0.00233645, 0.00340966, 0.00168759, 0.00158955,\n",
            "       0.0064545 , 0.00068483, 0.00292324, 0.00069151, 0.00077602,\n",
            "       0.00125032, 0.00932056, 0.00205162, 0.0024074 , 0.00086113,\n",
            "       0.00064734, 0.00695233, 0.00188756, 0.00028489, 0.0093508 ,\n",
            "       0.00492328, 0.00254057, 0.00160896, 0.00061776, 0.00136093,\n",
            "       0.00096186, 0.00460619, 0.00291562, 0.00323021, 0.00242608,\n",
            "       0.0054976 , 0.00396671, 0.00085857, 0.00158889, 0.00165106,\n",
            "       0.00611175, 0.00066582, 0.00047064, 0.00119378, 0.00066056,\n",
            "       0.00708588, 0.00109622, 0.01266564, 0.00075925, 0.00068962,\n",
            "       0.00442027, 0.00163926, 0.00486805, 0.00609604, 0.0043344 ,\n",
            "       0.00235468, 0.0010335 , 0.008001  , 0.0071161 , 0.00155506,\n",
            "       0.00280923, 0.00994941, 0.0011094 , 0.0003288 , 0.00110405,\n",
            "       0.00740153, 0.00061921, 0.00111716, 0.0003106 , 0.00191278,\n",
            "       0.00919067, 0.00115993, 0.00161585, 0.0060574 , 0.00945252,\n",
            "       0.00358903, 0.00384161, 0.00118062, 0.00093208, 0.00166411,\n",
            "       0.00162942, 0.00965949, 0.00738926, 0.00216451, 0.00145283,\n",
            "       0.00094476, 0.00112883, 0.00065312, 0.01375633, 0.01104302,\n",
            "       0.00148661, 0.00149241, 0.00466691, 0.00317476, 0.00050321,\n",
            "       0.00133941, 0.00263645, 0.01312432, 0.00221304, 0.00100578,\n",
            "       0.0019786 , 0.00198059, 0.00217667, 0.00816002, 0.00056491,\n",
            "       0.00087583, 0.00083783, 0.00080241, 0.00405768, 0.00129213,\n",
            "       0.0113455 , 0.00253167, 0.00189093, 0.00681903, 0.00864553,\n",
            "       0.00123946, 0.00676278, 0.00077535, 0.00130378, 0.00204113,\n",
            "       0.00040421, 0.01111492, 0.00074647, 0.01783884, 0.00109602,\n",
            "       0.00168923, 0.00187944, 0.00152835, 0.00060632, 0.00286056,\n",
            "       0.01128971, 0.00948196, 0.00638471, 0.00125657, 0.00149179,\n",
            "       0.00127222, 0.01012529, 0.00559428, 0.01083306, 0.00645948,\n",
            "       0.00115021, 0.00253779, 0.00244218, 0.00086407, 0.00189607,\n",
            "       0.00495272, 0.00105937, 0.00120071, 0.00508051, 0.00064328,\n",
            "       0.00779604, 0.00790111, 0.0095562 , 0.00250947, 0.00287647,\n",
            "       0.00927675, 0.00262338, 0.00305043, 0.0034021 , 0.00079044,\n",
            "       0.00079861, 0.00084578, 0.00900044, 0.00915805, 0.00163166],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul', 'index': 341, 'shape': array([  1,   5,   1, 240], dtype=int32), 'shape_signature': array([  1,   5,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01801747, 0.04922363, 0.01399682, 0.0350113 , 0.04182992,\n",
            "       0.01853001, 0.03558645, 0.020653  , 0.20165974, 0.0786775 ,\n",
            "       0.01087437, 0.01056109, 0.11954498, 0.01982105, 0.01059443,\n",
            "       0.06611112, 0.03667487, 0.00885376, 0.10001098, 0.02480113,\n",
            "       0.04658623, 0.0129488 , 0.0178144 , 0.05072143, 0.10206345,\n",
            "       0.02413995, 0.05378493, 0.01121407, 0.04683423, 0.04553593,\n",
            "       0.04493278, 0.0198157 , 0.00806858, 0.00896195, 0.00362362,\n",
            "       0.01117172, 0.01260422, 0.00199817, 0.02362847, 0.01232245,\n",
            "       0.01422041, 0.01351602, 0.10876597, 0.00992104, 0.01018011,\n",
            "       0.0854522 , 0.04251562, 0.04585063, 0.04873325, 0.07161888,\n",
            "       0.11440746, 0.05760798, 0.05775056, 0.11182417, 0.16013506,\n",
            "       0.03646978, 0.02633289, 0.00831768, 0.04788121, 0.01962969,\n",
            "       0.03376203, 0.01821367, 0.07952021, 0.08792328, 0.06668123,\n",
            "       0.01765448, 0.04394393, 0.03170354, 0.00744155, 0.04337549,\n",
            "       0.10940631, 0.01114602, 0.00623068, 0.045221  , 0.01820685,\n",
            "       0.0664717 , 0.0148015 , 0.11881486, 0.01344084, 0.00782159,\n",
            "       0.08985507, 0.02816565, 0.04110308, 0.0203437 , 0.01916186,\n",
            "       0.0778084 , 0.00825553, 0.03523939, 0.00833605, 0.0093548 ,\n",
            "       0.01507251, 0.11235841, 0.02473202, 0.02902098, 0.0103808 ,\n",
            "       0.00780361, 0.08380959, 0.02275429, 0.00343432, 0.11272293,\n",
            "       0.05934962, 0.03062629, 0.0193959 , 0.00744698, 0.01640586,\n",
            "       0.01159511, 0.05552718, 0.03514749, 0.03893984, 0.02924609,\n",
            "       0.06627301, 0.04781824, 0.01035002, 0.01915387, 0.01990342,\n",
            "       0.07367653, 0.00802645, 0.00567348, 0.01439093, 0.00796294,\n",
            "       0.08541957, 0.01321484, 0.15268297, 0.00915263, 0.00831328,\n",
            "       0.0532859 , 0.01976112, 0.05868384, 0.07348721, 0.05225073,\n",
            "       0.02838544, 0.01245871, 0.09645123, 0.08578385, 0.01874605,\n",
            "       0.03386502, 0.11993916, 0.01337369, 0.00396361, 0.01330926,\n",
            "       0.08922468, 0.00746452, 0.01346726, 0.00374419, 0.02305834,\n",
            "       0.11079265, 0.01398286, 0.01947893, 0.07302134, 0.11394915,\n",
            "       0.04326537, 0.04631017, 0.01423222, 0.01123618, 0.02006068,\n",
            "       0.01964246, 0.11644418, 0.08907682, 0.02609291, 0.01751366,\n",
            "       0.011389  , 0.01360788, 0.00787325, 0.16583122, 0.13312249,\n",
            "       0.01792098, 0.01799082, 0.05625919, 0.03827139, 0.00606616,\n",
            "       0.01614642, 0.03178215, 0.15821242, 0.02667796, 0.0121246 ,\n",
            "       0.02385186, 0.0238758 , 0.02623955, 0.09836822, 0.00680992,\n",
            "       0.01055805, 0.0100999 , 0.00967298, 0.04891493, 0.01557653,\n",
            "       0.13676889, 0.03051898, 0.022795  , 0.08220278, 0.10422094,\n",
            "       0.01494152, 0.08152463, 0.00934674, 0.01571691, 0.02460558,\n",
            "       0.00487276, 0.13398921, 0.00899866, 0.21504538, 0.01321246,\n",
            "       0.02036353, 0.02265647, 0.01842416, 0.00730917, 0.03448378,\n",
            "       0.13609631, 0.11430412, 0.07696704, 0.01514781, 0.01798337,\n",
            "       0.01533649, 0.12205932, 0.06743847, 0.13059148, 0.07786839,\n",
            "       0.01386571, 0.03059284, 0.02944019, 0.01041622, 0.02285696,\n",
            "       0.0597046 , 0.01277062, 0.01447443, 0.06124502, 0.00775463,\n",
            "       0.09398049, 0.09524708, 0.11519904, 0.03025144, 0.03467558,\n",
            "       0.11183025, 0.03162457, 0.03677266, 0.04101193, 0.00952864,\n",
            "       0.00962722, 0.01019576, 0.10849946, 0.11039933, 0.01966951],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 342, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([7.27251754e-04, 1.58829454e-04, 4.54806141e-04, 6.14327786e-04,\n",
            "       2.76378880e-04, 4.28353465e-04, 5.83830581e-04, 4.58121207e-03,\n",
            "       1.46715756e-04, 9.81711637e-05, 5.04234224e-04, 1.34016198e-04,\n",
            "       4.68229468e-04, 2.16740486e-03, 1.84941292e-03, 5.59388900e-05,\n",
            "       2.56349478e-04, 1.59800786e-03, 2.20912951e-03, 3.83870979e-03,\n",
            "       1.75624108e-03, 1.05750060e-03, 9.96693852e-04, 1.28487562e-04,\n",
            "       5.96320970e-05, 2.83092726e-04, 1.44761492e-04, 1.11652131e-03,\n",
            "       3.31933290e-04, 4.40335274e-03, 4.96906650e-05, 9.66264168e-04,\n",
            "       9.40095808e-04, 1.05474354e-03, 6.03427063e-04, 4.23658360e-03,\n",
            "       6.92143629e-04, 1.30403426e-03, 1.22620771e-03, 8.97662132e-04,\n",
            "       1.03324035e-03, 7.18563853e-04, 1.57024595e-03, 3.71569069e-04,\n",
            "       2.81791086e-03, 1.11583700e-04, 5.20104513e-05, 4.84461925e-04,\n",
            "       2.17648526e-03, 3.24040971e-04, 1.00784477e-04, 1.75858382e-04,\n",
            "       1.95146087e-04, 2.23469315e-03, 1.00002007e-03, 2.73170270e-04,\n",
            "       3.38834245e-04, 3.57433979e-04, 6.53536845e-05, 3.11979529e-04,\n",
            "       3.36317200e-04, 1.74171885e-03, 3.19176819e-04, 1.26034766e-03,\n",
            "       1.13477057e-04, 1.72709499e-03, 1.35152100e-03, 1.95439346e-03,\n",
            "       1.82957528e-03, 2.37026339e-04, 6.14270335e-04, 6.03484863e-04,\n",
            "       8.06686294e-04, 1.05733794e-04, 1.85513450e-03, 2.16685221e-04,\n",
            "       9.51068709e-04, 1.19739176e-04, 8.46910989e-04, 5.05460193e-04,\n",
            "       1.06481901e-04, 2.21524431e-04, 3.15276440e-04, 4.51245718e-03,\n",
            "       1.77817384e-03, 7.65413279e-05, 1.04142423e-03, 1.00475946e-03,\n",
            "       1.25458441e-03, 1.40271301e-03, 1.28087075e-03, 7.31487671e-05,\n",
            "       6.21515792e-04, 1.82314264e-03, 2.88006268e-03, 6.81983074e-04,\n",
            "       5.55227802e-04, 2.58142012e-03, 3.40693514e-03, 4.77032416e-04,\n",
            "       1.24555454e-03, 9.79043893e-04, 4.46345715e-04, 7.27142324e-04,\n",
            "       6.88229105e-04, 2.20507639e-03, 2.42202615e-04, 1.93100015e-04,\n",
            "       1.28436391e-03, 2.34165316e-04, 3.09788302e-04, 2.04564931e-04,\n",
            "       3.02592386e-03, 1.18656972e-04, 2.93209392e-04, 3.59879783e-03,\n",
            "       1.94495311e-03, 1.15878182e-03, 3.29140545e-04, 1.31817814e-03,\n",
            "       1.06766471e-04, 5.34310704e-04, 7.30075350e-04, 1.98546494e-03,\n",
            "       1.12331484e-03, 1.54204899e-04, 5.79036539e-04, 1.08773098e-03,\n",
            "       8.20861780e-04, 1.71114589e-04, 3.12758633e-03, 4.98250651e-04,\n",
            "       5.32632403e-04, 3.56026983e-04, 1.69943052e-03, 3.28161172e-04,\n",
            "       1.96152541e-04, 6.46528497e-04, 3.11209634e-03, 1.78654236e-03,\n",
            "       4.63739598e-05, 1.53363415e-03, 1.62636003e-04, 8.99917330e-04,\n",
            "       5.28698554e-04, 1.09698693e-03, 3.36099096e-04, 7.50989711e-04,\n",
            "       1.21022145e-04, 7.31335676e-05, 3.55970161e-03, 6.00175059e-04,\n",
            "       2.18246435e-03, 1.17270928e-03, 8.15187232e-04, 6.40224898e-04,\n",
            "       3.48756462e-03, 8.23740047e-05, 1.85055862e-04, 2.92517291e-03,\n",
            "       2.65451381e-03, 7.29167659e-04, 1.25039183e-03, 9.26996581e-05,\n",
            "       9.53148628e-05, 2.16763048e-03, 3.82470898e-03, 2.04217038e-04,\n",
            "       1.48870214e-03, 8.33614613e-04, 4.15411021e-04, 4.74102038e-04,\n",
            "       1.68252343e-04, 4.69706865e-04, 5.60425571e-04, 2.14575834e-04,\n",
            "       3.96867655e-03, 2.36646272e-04, 2.02589948e-03, 8.93713150e-04,\n",
            "       5.96102618e-04, 4.77593014e-04, 2.29803714e-04, 7.12719775e-05,\n",
            "       1.75156817e-03, 5.63350972e-04, 5.75867482e-04, 9.94720031e-04,\n",
            "       1.26636005e-04, 1.22308533e-03, 7.73283362e-04, 1.79951114e-03,\n",
            "       1.40663201e-03, 3.30126990e-04, 1.80049232e-04, 9.51341295e-04,\n",
            "       1.37687940e-03, 5.42056514e-04, 4.41032724e-04, 3.14671872e-03,\n",
            "       9.78817465e-04, 1.18470960e-03, 8.39593878e-04, 1.61571975e-03,\n",
            "       9.44183266e-04, 4.80455434e-04, 2.20196249e-04, 1.14662410e-03,\n",
            "       6.33949472e-04, 2.61025433e-03, 3.80878599e-04, 3.67400062e-04,\n",
            "       1.93426124e-04, 6.25573884e-05, 1.27138759e-04, 5.65862923e-04,\n",
            "       2.14813277e-03, 7.02622579e-04, 8.08769546e-04, 1.38600136e-03,\n",
            "       8.68210991e-05, 8.86883237e-04, 1.68577291e-03, 1.22879894e-04,\n",
            "       4.79581393e-03, 2.07450567e-03, 6.05138775e-04, 9.78665426e-04,\n",
            "       7.09660817e-04, 1.55028130e-04, 1.25255785e-04, 4.01229644e-03,\n",
            "       5.07819714e-05, 3.26857460e-03, 1.47734047e-03, 4.71213786e-03,\n",
            "       6.50691509e-04, 4.18080279e-04, 1.42451725e-03, 5.14917541e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 343, 'shape': array([  1,   3,   3, 240], dtype=int32), 'shape_signature': array([  1,   3,   3, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01138322, 0.00248606, 0.0071188 , 0.0096157 , 0.00432599,\n",
            "       0.00670475, 0.00913834, 0.07170689, 0.00229645, 0.00153661,\n",
            "       0.00789247, 0.00209767, 0.00732891, 0.03392506, 0.02894772,\n",
            "       0.00087558, 0.00401248, 0.02501263, 0.03457814, 0.06008496,\n",
            "       0.02748936, 0.01655241, 0.01560064, 0.00201114, 0.00093338,\n",
            "       0.00443108, 0.00226586, 0.01747622, 0.00519555, 0.06892297,\n",
            "       0.00077778, 0.01512434, 0.01471474, 0.01650925, 0.00944507,\n",
            "       0.06631263, 0.0108337 , 0.02041125, 0.01919308, 0.01405055,\n",
            "       0.01617268, 0.01124724, 0.02457809, 0.00581594, 0.04410702,\n",
            "       0.00174655, 0.00081409, 0.00758298, 0.03406718, 0.00507201,\n",
            "       0.00157752, 0.0027526 , 0.0030545 , 0.03497828, 0.0156527 ,\n",
            "       0.00427577, 0.00530356, 0.00559469, 0.00102294, 0.00488322,\n",
            "       0.00526417, 0.02726205, 0.00499588, 0.01972745, 0.00177619,\n",
            "       0.02703316, 0.02115453, 0.03059092, 0.02863722, 0.00371003,\n",
            "       0.0096148 , 0.00944598, 0.01262656, 0.00165499, 0.02903728,\n",
            "       0.00339164, 0.01488649, 0.0018742 , 0.01325618, 0.00791166,\n",
            "       0.0016667 , 0.00346739, 0.00493483, 0.07063071, 0.02783266,\n",
            "       0.00119805, 0.01630077, 0.01572688, 0.01963724, 0.0219558 ,\n",
            "       0.02004868, 0.00114495, 0.0097282 , 0.02853653, 0.04507985,\n",
            "       0.01067466, 0.00869064, 0.04040538, 0.05332666, 0.00746669,\n",
            "       0.0194959 , 0.01532437, 0.00698637, 0.01138151, 0.01077243,\n",
            "       0.0345147 , 0.00379105, 0.00302248, 0.02010336, 0.00366525,\n",
            "       0.00484893, 0.00320193, 0.04736292, 0.00185726, 0.00458943,\n",
            "       0.05632977, 0.03044315, 0.0181377 , 0.00515183, 0.02063263,\n",
            "       0.00167115, 0.00836324, 0.01142742, 0.03107726, 0.01758256,\n",
            "       0.00241367, 0.0090633 , 0.01702558, 0.01284844, 0.00267835,\n",
            "       0.04895419, 0.00779881, 0.00833697, 0.00557267, 0.02660014,\n",
            "       0.0051365 , 0.00307026, 0.01011971, 0.04871173, 0.02796365,\n",
            "       0.00072586, 0.02400503, 0.00254564, 0.01408585, 0.00827539,\n",
            "       0.01717046, 0.00526075, 0.01175478, 0.00189429, 0.00114471,\n",
            "       0.05571782, 0.00939417, 0.03416077, 0.0183557 , 0.01275962,\n",
            "       0.01002105, 0.0545887 , 0.00128935, 0.00289657, 0.04578593,\n",
            "       0.04154947, 0.01141321, 0.01957161, 0.00145097, 0.0014919 ,\n",
            "       0.03392859, 0.05986582, 0.00319648, 0.02330174, 0.01304806,\n",
            "       0.00650217, 0.00742083, 0.00263355, 0.00735203, 0.008772  ,\n",
            "       0.00335862, 0.06211925, 0.00370408, 0.03171016, 0.01398874,\n",
            "       0.00933043, 0.00747547, 0.00359698, 0.00111558, 0.02741622,\n",
            "       0.00881779, 0.0090137 , 0.01556974, 0.00198216, 0.0191442 ,\n",
            "       0.01210373, 0.02816664, 0.02201715, 0.00516727, 0.0028182 ,\n",
            "       0.01489076, 0.02155145, 0.00848448, 0.00690321, 0.04925365,\n",
            "       0.01532083, 0.01854353, 0.01314165, 0.02528987, 0.01477872,\n",
            "       0.00752027, 0.0034466 , 0.0179474 , 0.00992282, 0.0408567 ,\n",
            "       0.00596166, 0.00575069, 0.00302758, 0.00097917, 0.00199002,\n",
            "       0.0088571 , 0.0336234 , 0.01099772, 0.01265917, 0.02169423,\n",
            "       0.00135896, 0.01388184, 0.02638637, 0.00192336, 0.07506593,\n",
            "       0.03247096, 0.00947187, 0.01531845, 0.01110788, 0.00242656,\n",
            "       0.00196055, 0.06280201, 0.00079486, 0.05116099, 0.0231239 ,\n",
            "       0.0737562 , 0.01018487, 0.00654395, 0.02229709, 0.08059687],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 344, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.17668620e-04, 3.29654315e-04, 2.53888516e-04, 7.10430904e-05,\n",
            "       1.09724147e-04, 1.34182439e-04, 5.97058097e-05, 3.65318374e-05,\n",
            "       2.21139388e-04, 3.88814893e-04, 3.50754737e-04, 2.63021124e-04,\n",
            "       2.92526965e-05, 3.35481564e-05, 1.36017741e-04, 1.56508700e-04,\n",
            "       2.11079765e-04, 2.34052641e-04, 3.04945552e-05, 1.47053925e-05,\n",
            "       5.29845165e-05, 1.66786107e-04, 1.09906119e-04, 3.19048355e-04,\n",
            "       4.98748850e-04, 2.89651303e-04, 2.60977657e-04, 2.43459377e-04,\n",
            "       1.11880930e-04, 2.56494386e-05, 2.46105163e-04, 2.12190251e-04,\n",
            "       1.96266381e-04, 2.61007590e-05, 1.19459532e-04, 5.82073153e-05,\n",
            "       3.59609461e-04, 1.56440408e-04, 5.30594334e-05, 1.98684327e-04,\n",
            "       2.30384714e-04, 1.73387700e-04, 2.45791562e-05, 3.03706271e-04,\n",
            "       1.11844965e-04, 1.60601645e-04, 3.32258525e-04, 9.67417072e-05,\n",
            "       3.02504886e-05, 3.51472590e-05, 1.44093690e-04, 8.70173681e-05,\n",
            "       1.14069124e-04, 2.57123829e-05, 3.14322569e-05, 1.18428834e-04,\n",
            "       1.40735923e-04, 2.69274547e-04, 2.20640053e-04, 1.91660249e-04,\n",
            "       1.04160928e-04, 8.32867445e-05, 1.15440875e-04, 4.45174301e-05,\n",
            "       3.00903193e-04, 5.55807492e-05, 6.25715766e-05, 5.62528476e-05,\n",
            "       2.06944605e-04, 1.90895735e-04, 2.25660770e-05, 2.07282093e-04,\n",
            "       2.85639020e-04, 3.45097273e-04, 3.69358531e-05, 1.98274822e-04,\n",
            "       1.65094869e-04, 3.32988187e-04, 1.71516804e-04, 2.68195668e-04,\n",
            "       1.63715915e-04, 1.53300338e-04, 2.32485254e-04, 3.31802221e-05,\n",
            "       4.53760913e-05, 2.77859450e-04, 2.24487056e-04, 4.81521674e-05,\n",
            "       2.70542339e-04, 5.93680452e-05, 1.55801754e-04, 2.59287015e-04,\n",
            "       2.40808891e-04, 6.34505705e-05, 2.41618363e-05, 7.15655406e-05,\n",
            "       2.42305505e-05, 3.98840057e-05, 1.49617976e-04, 9.94316215e-05,\n",
            "       4.44685065e-05, 4.24839891e-05, 1.53676228e-04, 2.21780661e-04,\n",
            "       8.39580171e-05, 9.49736204e-05, 8.20097412e-05, 6.64376494e-05,\n",
            "       1.04172526e-04, 2.32117047e-04, 9.70550391e-05, 1.99295508e-04,\n",
            "       9.49277601e-05, 4.23869293e-04, 1.73456778e-04, 2.93597859e-05,\n",
            "       1.77499940e-04, 2.17898021e-04, 4.07016807e-04, 1.60776661e-04,\n",
            "       3.17124999e-04, 2.38883324e-04, 4.88063852e-05, 1.63487130e-04,\n",
            "       2.59018707e-04, 2.41034897e-04, 1.13354894e-04, 8.80761290e-05,\n",
            "       6.41560982e-05, 1.97801288e-04, 2.75738021e-05, 1.65312478e-04,\n",
            "       6.02290929e-05, 5.67511815e-05, 9.45233478e-05, 1.16276278e-04,\n",
            "       1.72508328e-04, 1.57426301e-04, 1.40803444e-04, 8.69065043e-05,\n",
            "       2.22676172e-04, 1.91819825e-04, 3.67063680e-04, 2.92189128e-04,\n",
            "       1.44704914e-04, 4.03937629e-05, 1.81131196e-04, 1.97244313e-04,\n",
            "       6.86323547e-05, 9.85238366e-05, 3.77526121e-05, 1.80097239e-04,\n",
            "       5.90007621e-05, 2.21471622e-04, 1.47108702e-04, 2.14657135e-04,\n",
            "       2.29959296e-05, 5.03906282e-04, 8.68273928e-05, 5.16719738e-05,\n",
            "       4.80711351e-05, 1.81935087e-04, 8.27773911e-05, 2.58560845e-04,\n",
            "       2.33923827e-04, 2.13087915e-05, 4.59899566e-05, 1.49917803e-04,\n",
            "       5.38521563e-05, 2.88743671e-04, 3.28775088e-04, 1.44631180e-04,\n",
            "       4.85499040e-05, 1.49383923e-04, 1.24669401e-04, 2.12777653e-04,\n",
            "       4.06716208e-05, 2.35806176e-04, 3.53495416e-05, 3.11353273e-04,\n",
            "       2.87850242e-04, 2.28914534e-04, 3.79493751e-04, 2.47069722e-04,\n",
            "       8.80717271e-05, 1.87915466e-05, 1.01238140e-04, 5.80345622e-05,\n",
            "       2.05986929e-04, 6.98416115e-05, 2.47593271e-04, 1.95187149e-05,\n",
            "       2.00455397e-04, 1.13924951e-04, 2.42141294e-04, 1.58404364e-04,\n",
            "       3.16281876e-05, 3.97212316e-05, 1.03995771e-04, 4.53016764e-05,\n",
            "       4.61002310e-05, 2.46468611e-04, 2.43732618e-04, 7.94819061e-05,\n",
            "       6.86177882e-05, 5.09467318e-05, 4.55464651e-05, 3.00192278e-05,\n",
            "       1.51259446e-04, 4.78074508e-05, 1.70245316e-04, 7.32657791e-05,\n",
            "       6.42787782e-05, 1.55480870e-04, 2.25783137e-04, 1.88825812e-04,\n",
            "       3.49855982e-05, 3.99291348e-05, 3.08308663e-04, 1.97772151e-05,\n",
            "       3.16080725e-04, 1.24849903e-04, 2.14522413e-04, 1.75441455e-04,\n",
            "       3.33979624e-05, 3.26989575e-05, 3.68414803e-05, 4.72484207e-05,\n",
            "       1.70406449e-04, 2.36688269e-04, 2.87870993e-04, 3.81100945e-05,\n",
            "       2.86377210e-04, 2.83820009e-05, 1.55197791e-04, 1.03174832e-04,\n",
            "       2.73238955e-04, 2.63546408e-05, 2.64222926e-05, 3.53401556e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 345, 'shape': array([240,   1,   1,  72], dtype=int32), 'shape_signature': array([240,   1,   1,  72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.48016014e-04, 4.14673996e-04, 3.19367769e-04, 8.93654942e-05,\n",
            "       1.38022617e-04, 1.68788829e-04, 7.51042680e-05, 4.59536022e-05,\n",
            "       2.78172462e-04, 4.89092432e-04, 4.41216340e-04, 3.30855750e-04,\n",
            "       3.67971297e-05, 4.22004123e-05, 1.71097476e-04, 1.96873167e-04,\n",
            "       2.65518407e-04, 2.94416124e-04, 3.83592705e-05, 1.84979945e-05,\n",
            "       6.66495180e-05, 2.09801176e-04, 1.38251518e-04, 4.01332683e-04,\n",
            "       6.27378933e-04, 3.64353997e-04, 3.28285241e-04, 3.06248898e-04,\n",
            "       1.40735647e-04, 3.22645719e-05, 3.09577066e-04, 2.66915304e-04,\n",
            "       2.46884563e-04, 3.28322894e-05, 1.50268810e-04, 7.32193075e-05,\n",
            "       4.52354754e-04, 1.96787267e-04, 6.67437562e-05, 2.49926117e-04,\n",
            "       2.89802207e-04, 2.18105342e-04, 3.09182578e-05, 3.82033817e-04,\n",
            "       1.40690405e-04, 2.02021707e-04, 4.17949836e-04, 1.21691934e-04,\n",
            "       3.80522579e-05, 4.42119344e-05, 1.81256255e-04, 1.09459630e-04,\n",
            "       1.43488185e-04, 3.23437489e-05, 3.95388088e-05, 1.48972293e-04,\n",
            "       1.77032503e-04, 3.38721933e-04, 2.77544343e-04, 2.41090500e-04,\n",
            "       1.31024615e-04, 1.04766863e-04, 1.45213722e-04, 5.59987238e-05,\n",
            "       3.78507801e-04, 6.99153316e-05, 7.87091340e-05, 7.07607687e-05,\n",
            "       2.60316767e-04, 2.40128807e-04, 2.83859936e-05, 2.60741304e-04,\n",
            "       3.59306898e-04, 4.34099784e-04, 4.64618133e-05, 2.49411009e-04,\n",
            "       2.07673758e-04, 4.18867683e-04, 2.15751934e-04, 3.37364821e-04,\n",
            "       2.05939155e-04, 1.92837339e-04, 2.92444485e-04, 4.17375850e-05,\n",
            "       5.70788361e-05, 3.49520938e-04, 2.82383524e-04, 6.05708810e-05,\n",
            "       3.40316707e-04, 7.46793958e-05, 1.95983885e-04, 3.26158566e-04,\n",
            "       3.02914850e-04, 7.98148249e-05, 3.03933084e-05, 9.00226951e-05,\n",
            "       3.04797450e-05, 5.01703144e-05, 1.88205275e-04, 1.25075589e-04,\n",
            "       5.59371802e-05, 5.34408464e-05, 1.93310174e-04, 2.78979132e-04,\n",
            "       1.05611260e-04, 1.19467848e-04, 1.03160506e-04, 8.35722894e-05,\n",
            "       1.31039196e-04, 2.91981327e-04, 1.22086072e-04, 2.50694924e-04,\n",
            "       1.19410157e-04, 5.33187529e-04, 2.18192246e-04, 3.69318368e-05,\n",
            "       2.23278155e-04, 2.74095131e-04, 5.11988706e-04, 2.02241848e-04,\n",
            "       3.98913311e-04, 3.00492655e-04, 6.13938246e-05, 2.05651362e-04,\n",
            "       3.25821078e-04, 3.03199136e-04, 1.42589750e-04, 1.10791450e-04,\n",
            "       8.07023098e-05, 2.48815340e-04, 3.46852394e-05, 2.07947480e-04,\n",
            "       7.57625094e-05, 7.13876289e-05, 1.18901444e-04, 1.46264574e-04,\n",
            "       2.16999193e-04, 1.98027425e-04, 1.77117428e-04, 1.09320172e-04,\n",
            "       2.80105596e-04, 2.41291229e-04, 4.61731455e-04, 3.67546338e-04,\n",
            "       1.82025120e-04, 5.08115409e-05, 2.27845943e-04, 2.48114724e-04,\n",
            "       8.63330206e-05, 1.23933685e-04, 4.74892222e-05, 2.26545322e-04,\n",
            "       7.42173870e-05, 2.78590393e-04, 1.85048848e-04, 2.70018412e-04,\n",
            "       2.89267082e-05, 6.33866526e-04, 1.09220658e-04, 6.49984649e-05,\n",
            "       6.04689485e-05, 2.28857156e-04, 1.04126142e-04, 3.25245142e-04,\n",
            "       2.94254074e-04, 2.68044478e-05, 5.78510226e-05, 1.88582431e-04,\n",
            "       6.77409262e-05, 3.63212253e-04, 4.13568021e-04, 1.81932366e-04,\n",
            "       6.10711941e-05, 1.87910860e-04, 1.56822338e-04, 2.67654192e-04,\n",
            "       5.11610560e-05, 2.96621904e-04, 4.44663856e-05, 3.91653011e-04,\n",
            "       3.62088409e-04, 2.87952862e-04, 4.77367314e-04, 3.10790376e-04,\n",
            "       1.10785913e-04, 2.36379910e-05, 1.27348016e-04, 7.30019965e-05,\n",
            "       2.59112101e-04, 8.78541468e-05, 3.11448937e-04, 2.45527008e-05,\n",
            "       2.52153957e-04, 1.43306825e-04, 3.04590882e-04, 1.99257731e-04,\n",
            "       3.97852709e-05, 4.99655580e-05, 1.30816858e-04, 5.69852309e-05,\n",
            "       5.79897351e-05, 3.10034229e-04, 3.06592614e-04, 9.99807307e-05,\n",
            "       8.63146997e-05, 6.40861763e-05, 5.72931531e-05, 3.77613542e-05,\n",
            "       1.90270104e-04, 6.01372594e-05, 2.14152533e-04, 9.21614264e-05,\n",
            "       8.08566328e-05, 1.95580258e-04, 2.84013862e-04, 2.37525033e-04,\n",
            "       4.40085787e-05, 5.02270814e-05, 3.87823180e-04, 2.48778688e-05,\n",
            "       3.97599710e-04, 1.57049391e-04, 2.69848941e-04, 2.20688788e-04,\n",
            "       4.20114811e-05, 4.11321998e-05, 4.63431024e-05, 5.94340527e-05,\n",
            "       2.14355226e-04, 2.97731487e-04, 3.62114515e-04, 4.79388982e-05,\n",
            "       3.60235485e-04, 3.57018762e-05, 1.95224158e-04, 1.29784195e-04,\n",
            "       3.43708816e-04, 3.31516494e-05, 3.32367490e-05, 4.44545803e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/rezero/mul', 'index': 346, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00784603226929903, -128), 'quantization_parameters': {'scales': array([0.00784603], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 347, 'shape': array([72], dtype=int32), 'shape_signature': array([72], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00052071, 0.0009008 , 0.00056283, 0.00047145, 0.00042497,\n",
            "       0.00056774, 0.00044043, 0.00044779, 0.0007937 , 0.0005063 ,\n",
            "       0.00054074, 0.00086673, 0.00066078, 0.00047917, 0.00071936,\n",
            "       0.00043049, 0.00041805, 0.00047236, 0.00048142, 0.00039733,\n",
            "       0.0005375 , 0.00049014, 0.00056556, 0.00049932, 0.00067172,\n",
            "       0.00053638, 0.00037835, 0.00040452, 0.00054599, 0.00046195,\n",
            "       0.00062857, 0.0006751 , 0.00065216, 0.00042374, 0.00087288,\n",
            "       0.0006176 , 0.00042048, 0.0007531 , 0.00055327, 0.00059108,\n",
            "       0.00057741, 0.00059805, 0.00167541, 0.00046174, 0.00056389,\n",
            "       0.00034517, 0.00076075, 0.00058099, 0.0005525 , 0.00039846,\n",
            "       0.00083236, 0.00053364, 0.00048923, 0.00050576, 0.0007205 ,\n",
            "       0.00055621, 0.00061144, 0.000454  , 0.00124698, 0.00045084,\n",
            "       0.00038435, 0.00069958, 0.00076675, 0.00049908, 0.00044743,\n",
            "       0.00063583, 0.00065505, 0.00053859, 0.0005391 , 0.0007255 ,\n",
            "       0.00062201, 0.00056738], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 348, 'shape': array([ 72,   1,   1, 240], dtype=int32), 'shape_signature': array([ 72,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01365663, 0.02362517, 0.01476131, 0.01236476, 0.01114555,\n",
            "       0.01488997, 0.01155116, 0.01174414, 0.02081615, 0.01327865,\n",
            "       0.01418189, 0.02273167, 0.01733004, 0.01256722, 0.01886653,\n",
            "       0.01129034, 0.01096414, 0.01238861, 0.01262625, 0.0104208 ,\n",
            "       0.01409694, 0.01285477, 0.0148329 , 0.0130955 , 0.01761713,\n",
            "       0.01406754, 0.00992292, 0.0106092 , 0.0143197 , 0.01211546,\n",
            "       0.01648549, 0.01770563, 0.01710417, 0.01111338, 0.02289294,\n",
            "       0.01619773, 0.01102779, 0.01975137, 0.01451056, 0.01550209,\n",
            "       0.01514364, 0.01568503, 0.0439408 , 0.01210989, 0.01478902,\n",
            "       0.00905263, 0.01995201, 0.01523751, 0.01449022, 0.01045044,\n",
            "       0.02183024, 0.01399577, 0.01283102, 0.01326448, 0.01889653,\n",
            "       0.01458768, 0.01603614, 0.01190686, 0.03270427, 0.0118241 ,\n",
            "       0.01008033, 0.01834773, 0.02010941, 0.01308941, 0.01173474,\n",
            "       0.01667575, 0.01717992, 0.01412554, 0.01413896, 0.0190277 ,\n",
            "       0.01631344, 0.01488055], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block2_layer4/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block2_layer4/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block2_layer4/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer4/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 349, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.6853530e-05, 2.7258471e-05, 1.8289154e-05, 3.7781745e-05,\n",
            "       1.6393480e-05, 3.1676733e-05, 5.1231353e-05, 2.3490398e-05,\n",
            "       3.3224398e-05, 2.5064768e-05, 3.0242580e-05, 2.3925215e-05,\n",
            "       1.8887189e-05, 2.6526426e-05, 2.4947411e-05, 2.5440491e-05,\n",
            "       2.3849316e-05, 2.5718102e-05, 2.0292238e-05, 2.4656991e-05,\n",
            "       2.1181866e-05, 1.2069055e-05, 2.1466885e-05, 2.0967776e-05,\n",
            "       1.8234779e-05, 1.7969247e-05, 5.5876968e-05, 1.6249131e-05,\n",
            "       2.0800788e-05, 1.4850927e-05, 3.0263753e-05, 2.3803728e-05,\n",
            "       1.8696408e-04, 1.6708822e-05, 2.8059798e-05, 1.9965515e-05,\n",
            "       3.1277377e-05, 1.0603636e-04, 1.8823537e-05, 1.0426476e-04,\n",
            "       4.4209453e-05, 2.2010208e-05, 2.6541527e-05, 5.0805207e-05,\n",
            "       2.6126903e-05, 3.4456509e-05, 2.2028273e-05, 2.0934987e-05,\n",
            "       4.2484215e-05, 5.2019906e-05, 3.3211596e-05, 2.9910847e-05,\n",
            "       1.3419589e-04, 2.0563470e-05, 2.1812022e-05, 3.7452766e-05,\n",
            "       3.1530079e-05, 3.9792496e-05, 2.5396999e-05, 2.4111649e-05,\n",
            "       1.9693931e-05, 1.6881801e-05, 5.1814957e-05, 2.0203606e-05,\n",
            "       2.0050271e-05, 1.7933735e-05, 2.2860364e-05, 6.5178589e-05,\n",
            "       2.3284272e-05, 1.4424663e-05, 3.4174824e-05, 2.1496136e-05,\n",
            "       2.0590556e-05, 1.9911986e-05, 1.8775230e-05, 2.3428132e-05,\n",
            "       2.8243820e-05, 1.5836731e-05, 1.8046620e-05, 2.0416297e-05,\n",
            "       2.9242256e-05, 3.0523901e-05, 1.1709591e-05, 2.9193234e-05,\n",
            "       2.3605120e-05, 3.3723867e-05, 2.7859343e-05, 2.4402460e-05,\n",
            "       4.5173496e-05, 2.3021370e-05, 2.9419196e-05, 2.9505305e-05,\n",
            "       4.0290957e-05, 2.2463237e-05, 6.6045031e-05, 3.0029363e-05,\n",
            "       2.0527594e-05, 1.5285181e-05, 1.3663110e-05, 1.9092919e-05,\n",
            "       3.2363845e-05, 3.0217281e-05, 2.1460046e-05, 2.8919179e-05,\n",
            "       2.3647548e-05, 2.3909541e-05, 3.2221971e-05, 4.0302948e-05,\n",
            "       3.3401229e-05, 1.4870684e-05, 8.0679216e-05, 3.0977797e-05,\n",
            "       6.0577488e-05, 5.5201024e-05, 1.7947517e-05, 2.6869850e-05,\n",
            "       4.5732588e-05, 1.8181483e-05, 2.1635089e-05, 2.5964186e-05,\n",
            "       4.2894917e-05, 1.6857146e-05, 1.7880560e-05, 2.4144421e-05,\n",
            "       1.2754662e-05, 1.3731550e-05, 1.8016697e-05, 2.4854087e-05,\n",
            "       1.5566418e-05, 1.5232435e-05, 1.7146434e-05, 2.3641736e-05,\n",
            "       2.2528648e-05, 1.1884593e-05, 2.1395523e-05, 7.7466007e-05,\n",
            "       6.4281841e-05, 2.1967329e-05, 3.7820908e-05, 4.1164920e-05,\n",
            "       1.6431108e-05, 7.9047444e-05, 1.7463184e-05, 1.6776297e-05,\n",
            "       3.7276994e-05, 1.4458506e-05, 4.3637185e-05, 2.9247771e-05,\n",
            "       2.6236654e-05, 2.6888014e-05, 3.0657407e-05, 2.1554106e-05,\n",
            "       3.0777544e-05, 2.9540328e-05, 2.2334858e-05, 2.8053226e-05,\n",
            "       2.4252788e-05, 8.5789761e-05, 1.7884644e-05, 2.3415545e-05,\n",
            "       2.6777376e-05, 4.3305165e-05, 3.7186965e-05, 2.2480006e-05,\n",
            "       4.1071064e-05, 2.5892436e-05, 4.8501948e-05, 1.8510613e-05,\n",
            "       1.8633669e-05, 9.3817962e-06, 3.4716992e-05, 1.5822960e-05,\n",
            "       4.5797253e-05, 3.8855669e-05, 2.5637020e-05, 2.1024804e-05,\n",
            "       1.4809020e-05, 2.1955617e-05, 3.2117892e-05, 1.6157624e-05,\n",
            "       4.3774889e-05, 2.3538032e-05, 2.9435714e-05, 1.8643308e-05,\n",
            "       2.5451111e-05, 9.3911862e-05, 2.2184417e-05, 2.3862847e-05,\n",
            "       6.5750392e-05, 4.0224219e-05, 1.8474464e-05, 2.7440045e-05,\n",
            "       1.3951093e-05, 3.8906761e-05, 1.3331149e-05, 1.4926425e-05,\n",
            "       1.3242953e-05, 2.2095757e-05, 3.5589022e-05, 2.7990898e-05,\n",
            "       2.4946650e-05, 5.5242117e-06, 1.2141541e-05, 2.0582964e-05,\n",
            "       2.5182935e-05, 1.6162432e-05, 2.4133165e-05, 3.5027464e-05,\n",
            "       4.2990076e-05, 5.5697514e-05, 3.2577038e-05, 4.2622942e-05,\n",
            "       4.6888512e-05, 7.4736206e-05, 2.0669619e-05, 1.4973867e-05,\n",
            "       1.9586352e-05, 2.1329835e-05, 2.2074206e-05, 6.2975152e-05,\n",
            "       1.9242549e-05, 3.7032154e-05, 2.2227887e-05, 1.9959984e-05,\n",
            "       1.7051732e-05, 1.7437593e-05, 6.4513217e-05, 3.9392871e-05,\n",
            "       3.1752763e-05, 1.7889053e-05, 2.4168889e-05, 1.4516313e-05,\n",
            "       2.1043536e-05, 3.4430792e-05, 2.7508533e-05, 2.1599295e-05,\n",
            "       2.2425134e-05, 1.8923409e-05, 3.4665609e-05, 1.6308208e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 350, 'shape': array([240,   1,   1, 120], dtype=int32), 'shape_signature': array([240,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00130472, 0.00132439, 0.00088861, 0.00183568, 0.0007965 ,\n",
            "       0.00153906, 0.00248915, 0.00114132, 0.00161426, 0.00121781,\n",
            "       0.00146938, 0.00116244, 0.00091766, 0.00128883, 0.00121211,\n",
            "       0.00123606, 0.00115875, 0.00124955, 0.00098593, 0.001198  ,\n",
            "       0.00102915, 0.00058639, 0.001043  , 0.00101875, 0.00088596,\n",
            "       0.00087306, 0.00271487, 0.00078949, 0.00101064, 0.00072155,\n",
            "       0.00147041, 0.00115654, 0.00908393, 0.00081182, 0.00136333,\n",
            "       0.00097005, 0.00151966, 0.00515193, 0.00091457, 0.00506586,\n",
            "       0.00214798, 0.0010694 , 0.00128956, 0.00246845, 0.00126941,\n",
            "       0.00167412, 0.00107028, 0.00101716, 0.00206416, 0.00252746,\n",
            "       0.00161363, 0.00145326, 0.00652011, 0.00099911, 0.00105977,\n",
            "       0.0018197 , 0.00153194, 0.00193338, 0.00123395, 0.0011715 ,\n",
            "       0.00095686, 0.00082023, 0.00251751, 0.00098162, 0.00097417,\n",
            "       0.00087134, 0.0011107 , 0.0031668 , 0.0011313 , 0.00070084,\n",
            "       0.00166043, 0.00104442, 0.00100042, 0.00096745, 0.00091222,\n",
            "       0.00113829, 0.00137227, 0.00076945, 0.00087682, 0.00099196,\n",
            "       0.00142078, 0.00148305, 0.00056893, 0.0014184 , 0.00114689,\n",
            "       0.00163852, 0.00135359, 0.00118563, 0.00219482, 0.00111853,\n",
            "       0.00142938, 0.00143356, 0.0019576 , 0.00109141, 0.0032089 ,\n",
            "       0.00145902, 0.00099736, 0.00074265, 0.00066384, 0.00092766,\n",
            "       0.00157245, 0.00146815, 0.00104267, 0.00140508, 0.00114895,\n",
            "       0.00116168, 0.00156555, 0.00195818, 0.00162285, 0.00072251,\n",
            "       0.00391992, 0.0015051 , 0.00294325, 0.00268202, 0.00087201,\n",
            "       0.00130551, 0.00222199, 0.00088337, 0.00105117, 0.00126151,\n",
            "       0.00208411, 0.00081903, 0.00086875, 0.00117309, 0.0006197 ,\n",
            "       0.00066717, 0.00087537, 0.00120757, 0.00075632, 0.00074009,\n",
            "       0.00083309, 0.00114867, 0.00109459, 0.00057743, 0.00103953,\n",
            "       0.0037638 , 0.00312323, 0.00106732, 0.00183759, 0.00200006,\n",
            "       0.00079833, 0.00384064, 0.00084847, 0.0008151 , 0.00181116,\n",
            "       0.00070249, 0.00212018, 0.00142105, 0.00127475, 0.00130639,\n",
            "       0.00148954, 0.00104724, 0.00149537, 0.00143526, 0.00108517,\n",
            "       0.00136301, 0.00117836, 0.00416822, 0.00086895, 0.00113768,\n",
            "       0.00130102, 0.00210405, 0.00180678, 0.00109222, 0.0019955 ,\n",
            "       0.00125802, 0.00235654, 0.00089937, 0.00090534, 0.00045583,\n",
            "       0.00168678, 0.00076878, 0.00222513, 0.00188786, 0.00124561,\n",
            "       0.00102152, 0.00071952, 0.00106675, 0.0015605 , 0.00078504,\n",
            "       0.00212687, 0.00114363, 0.00143018, 0.00090581, 0.00123658,\n",
            "       0.00456285, 0.00107786, 0.00115941, 0.00319458, 0.00195435,\n",
            "       0.00089761, 0.00133322, 0.00067783, 0.00189034, 0.00064771,\n",
            "       0.00072522, 0.00064343, 0.00107356, 0.00172915, 0.00135998,\n",
            "       0.00121207, 0.0002684 , 0.00058991, 0.00100005, 0.00122355,\n",
            "       0.00078528, 0.00117255, 0.00170186, 0.00208874, 0.00270615,\n",
            "       0.0015828 , 0.0020709 , 0.00227815, 0.00363117, 0.00100426,\n",
            "       0.00072753, 0.00095163, 0.00103634, 0.00107251, 0.00305974,\n",
            "       0.00093493, 0.00179926, 0.00107998, 0.00096979, 0.00082848,\n",
            "       0.00084723, 0.00313447, 0.00191396, 0.00154276, 0.00086917,\n",
            "       0.00117428, 0.0007053 , 0.00102243, 0.00167287, 0.00133654,\n",
            "       0.00104943, 0.00108956, 0.00091942, 0.00168428, 0.00079236],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 351, 'shape': array([120], dtype=int32), 'shape_signature': array([120], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([5.20303001e-05, 1.39679309e-04, 9.88511383e-05, 5.74679143e-05,\n",
            "       1.60724027e-04, 8.75211408e-05, 7.67322636e-05, 2.30402060e-04,\n",
            "       2.67961368e-05, 7.02534526e-05, 6.78091528e-05, 1.91108702e-05,\n",
            "       6.47917695e-05, 7.11860339e-05, 3.48229732e-05, 1.46922423e-04,\n",
            "       6.22088555e-05, 1.96907480e-04, 1.07628548e-04, 9.21934188e-05,\n",
            "       4.19687567e-05, 6.60941878e-05, 8.64826725e-05, 7.82938587e-05,\n",
            "       2.29640267e-04, 1.14379858e-04, 5.10312675e-05, 1.98813257e-04,\n",
            "       1.22719401e-04, 1.37376031e-04, 8.35716273e-05, 1.02146660e-04,\n",
            "       1.17802010e-05, 6.30315917e-05, 8.55249236e-05, 5.82500652e-05,\n",
            "       1.57434315e-05, 1.62550481e-04, 1.11973444e-04, 9.72779162e-05,\n",
            "       1.23668782e-04, 6.15652534e-05, 2.50163648e-05, 6.81122037e-05,\n",
            "       5.39115827e-05, 6.20779756e-05, 5.31943733e-05, 7.06324572e-05,\n",
            "       5.47209638e-05, 3.31406227e-05, 3.66451422e-05, 4.90512830e-05,\n",
            "       2.48243050e-05, 5.45595940e-05, 1.46190083e-04, 6.96439456e-05,\n",
            "       2.94860307e-04, 6.79993245e-05, 1.88505612e-04, 6.89141816e-05,\n",
            "       9.41889230e-05, 7.34673376e-05, 1.00076337e-04, 2.93057499e-04,\n",
            "       7.97192479e-05, 9.95648152e-05, 4.83420881e-05, 1.63190314e-04,\n",
            "       5.66840354e-05, 1.56150694e-04, 5.86274109e-05, 5.68376163e-05,\n",
            "       8.59475695e-05, 9.93494323e-05, 8.10620913e-05, 2.07999474e-05,\n",
            "       8.89072689e-05, 5.72211138e-05, 8.64853355e-05, 5.41742629e-05,\n",
            "       7.93007639e-05, 9.23146581e-05, 1.06191801e-04, 1.29506006e-04,\n",
            "       6.19441707e-05, 1.71002423e-04, 5.69011463e-05, 5.62425957e-05,\n",
            "       6.90093948e-05, 1.05207968e-04, 1.80723568e-04, 8.01435526e-05,\n",
            "       7.37797163e-05, 5.21617039e-05, 5.30573561e-05, 6.99178199e-05,\n",
            "       7.26343933e-05, 1.72029118e-04, 8.67099225e-05, 1.84060918e-05,\n",
            "       2.24876130e-05, 7.36434667e-05, 1.27796593e-04, 9.49321839e-05,\n",
            "       5.89217379e-05, 4.42413402e-05, 1.94340872e-04, 8.05205782e-05,\n",
            "       5.16893742e-05, 5.83531910e-05, 4.82545474e-05, 8.28445627e-05,\n",
            "       2.09018617e-04, 3.60366903e-05, 1.15844508e-04, 5.04292730e-05,\n",
            "       1.59723844e-04, 9.82793717e-05, 4.57258102e-05, 2.08089514e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 352, 'shape': array([120,   1,   1, 480], dtype=int32), 'shape_signature': array([120,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00111575, 0.00299531, 0.00211978, 0.00123235, 0.00344659,\n",
            "       0.00187682, 0.00164546, 0.00494078, 0.00057462, 0.00150653,\n",
            "       0.00145411, 0.00040982, 0.00138941, 0.00152653, 0.00074675,\n",
            "       0.00315063, 0.00133402, 0.00422252, 0.00230801, 0.00197701,\n",
            "       0.00089999, 0.00141734, 0.00185455, 0.00167895, 0.00492445,\n",
            "       0.00245278, 0.00109432, 0.00426339, 0.00263162, 0.00294592,\n",
            "       0.00179212, 0.00219045, 0.00025262, 0.00135166, 0.00183401,\n",
            "       0.00124912, 0.0003376 , 0.00348576, 0.00240118, 0.00208604,\n",
            "       0.00265198, 0.00132022, 0.00053646, 0.00146061, 0.00115609,\n",
            "       0.00133121, 0.00114071, 0.00151465, 0.00117345, 0.00071067,\n",
            "       0.00078582, 0.00105186, 0.00053234, 0.00116999, 0.00313493,\n",
            "       0.00149346, 0.00632304, 0.00145819, 0.00404235, 0.00147781,\n",
            "       0.0020198 , 0.00157545, 0.00214605, 0.00628438, 0.00170951,\n",
            "       0.00213509, 0.00103666, 0.00349948, 0.00121554, 0.00334852,\n",
            "       0.00125722, 0.00121884, 0.00184307, 0.00213047, 0.00173831,\n",
            "       0.00044604, 0.00190654, 0.00122706, 0.00185461, 0.00116172,\n",
            "       0.00170054, 0.00197961, 0.0022772 , 0.00277715, 0.00132834,\n",
            "       0.00366701, 0.0012202 , 0.00120608, 0.00147985, 0.0022561 ,\n",
            "       0.00387547, 0.00171861, 0.00158215, 0.00111856, 0.00113777,\n",
            "       0.00149933, 0.00155758, 0.00368902, 0.00185942, 0.0003947 ,\n",
            "       0.00048223, 0.00157922, 0.00274049, 0.00203574, 0.00126353,\n",
            "       0.00094872, 0.00416748, 0.0017267 , 0.00110844, 0.00125134,\n",
            "       0.00103478, 0.00177653, 0.00448223, 0.00077278, 0.00248419,\n",
            "       0.00108141, 0.00342515, 0.00210752, 0.00098055, 0.00044623],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 353, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00089354, 0.00796074, 0.00636562, 0.00056162, 0.00701933,\n",
            "       0.01343766, 0.00323095, 0.01047964, 0.00131345, 0.00460127,\n",
            "       0.00626302, 0.01122425, 0.00298586, 0.00167014, 0.01025006,\n",
            "       0.00115671, 0.01217654, 0.00829935, 0.00681765, 0.01010155,\n",
            "       0.00381722, 0.00143736, 0.00717746, 0.0010328 , 0.00282961,\n",
            "       0.00263103, 0.00055217, 0.00149621, 0.00113198, 0.00081512,\n",
            "       0.00135311, 0.00691071, 0.00182286, 0.00288321, 0.00974947,\n",
            "       0.00473242, 0.00075369, 0.0005983 , 0.00148741, 0.00425218,\n",
            "       0.00088765, 0.00187701, 0.01079262, 0.00087804, 0.00262802,\n",
            "       0.00407504, 0.00189306, 0.00297502, 0.00116792, 0.00080575,\n",
            "       0.00083344, 0.00986628, 0.00417854, 0.00716826, 0.01115614,\n",
            "       0.00165132, 0.00108592, 0.01406414, 0.00274437, 0.00312643,\n",
            "       0.00621241, 0.00423843, 0.00187209, 0.00215653, 0.00148841,\n",
            "       0.00647591, 0.00130569, 0.00082954, 0.00131375, 0.00357318,\n",
            "       0.00282781, 0.00037454, 0.00297656, 0.01253777, 0.00087722,\n",
            "       0.00261621, 0.01375707, 0.00112432, 0.00418915, 0.00898634,\n",
            "       0.00544898, 0.00513182, 0.00524348, 0.00173637, 0.00089972,\n",
            "       0.00384203, 0.00522548, 0.00102264, 0.00166024, 0.00852861,\n",
            "       0.0062043 , 0.00138369, 0.00317347, 0.00140824, 0.00365279,\n",
            "       0.01074324, 0.00071258, 0.00473193, 0.0037095 , 0.00837041,\n",
            "       0.00085773, 0.00159021, 0.01068254, 0.00149891, 0.00124742,\n",
            "       0.00839492, 0.00556588, 0.00239822, 0.00306645, 0.00186509,\n",
            "       0.00178434, 0.00333668, 0.00156267, 0.00100558, 0.00169233,\n",
            "       0.01367926, 0.00110481, 0.00475928, 0.0082721 , 0.00421321,\n",
            "       0.0087739 , 0.00559838, 0.00156679, 0.00286673, 0.00547803,\n",
            "       0.00815252, 0.0019198 , 0.00836196, 0.00425312, 0.00182399,\n",
            "       0.00220198, 0.00357724, 0.0079624 , 0.00429729, 0.00383201,\n",
            "       0.00439742, 0.01228737, 0.0019833 , 0.00554943, 0.00112105,\n",
            "       0.0005908 , 0.01291802, 0.00133387, 0.00294615, 0.00628169,\n",
            "       0.00066979, 0.00675508, 0.00167782, 0.01401365, 0.00199925,\n",
            "       0.00201765, 0.00902108, 0.00247262, 0.00824551, 0.00372507,\n",
            "       0.00482698, 0.01199064, 0.00387928, 0.00205324, 0.0092842 ,\n",
            "       0.00054579, 0.00091574, 0.0081739 , 0.00378739, 0.01274124,\n",
            "       0.0019817 , 0.00726941, 0.00948644, 0.00205759, 0.00647958,\n",
            "       0.0234681 , 0.00568015, 0.00088247, 0.00078554, 0.00880502,\n",
            "       0.00809748, 0.00644806, 0.01016118, 0.00081351, 0.00225168,\n",
            "       0.00672993, 0.00117321, 0.00216802, 0.00082682, 0.00524415,\n",
            "       0.00095874, 0.00327998, 0.00831741, 0.00086266, 0.00150706,\n",
            "       0.0025056 , 0.00437681, 0.00201951, 0.00140499, 0.00618845,\n",
            "       0.00217576, 0.00516027, 0.00582431, 0.00815081, 0.0021371 ,\n",
            "       0.00879943, 0.00557153, 0.00111724, 0.00090837, 0.0098155 ,\n",
            "       0.00262379, 0.00967148, 0.01290274, 0.02220539, 0.00109985,\n",
            "       0.00083007, 0.00542021, 0.00098281, 0.00288307, 0.00455617,\n",
            "       0.00226413, 0.00814431, 0.00083481, 0.00119415, 0.00449954,\n",
            "       0.001951  , 0.00238294, 0.00156861, 0.00647915, 0.00312687,\n",
            "       0.00427302, 0.00500629, 0.00073838, 0.00165183, 0.00750796,\n",
            "       0.00172575, 0.00117439, 0.00145781, 0.00101707, 0.00438662,\n",
            "       0.00082386, 0.00181887, 0.01030926, 0.0065206 , 0.00772614],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul', 'index': 354, 'shape': array([  1,   3,   1, 240], dtype=int32), 'shape_signature': array([  1,   3,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00900022, 0.08018448, 0.06411764, 0.00565688, 0.07070214,\n",
            "       0.13535078, 0.03254372, 0.10555612, 0.01322972, 0.04634625,\n",
            "       0.06308421, 0.11305624, 0.03007511, 0.01682247, 0.10324364,\n",
            "       0.01165098, 0.12264813, 0.08359517, 0.06867079, 0.10174787,\n",
            "       0.03844895, 0.01447781, 0.07229497, 0.01040292, 0.02850119,\n",
            "       0.02650107, 0.00556174, 0.01507061, 0.01140183, 0.00821027,\n",
            "       0.01362916, 0.06960808, 0.01836074, 0.02904112, 0.09820146,\n",
            "       0.04766732, 0.00759156, 0.00602634, 0.01498193, 0.04283005,\n",
            "       0.00894082, 0.01890622, 0.10870859, 0.00884406, 0.02647076,\n",
            "       0.04104579, 0.01906787, 0.02996583, 0.01176391, 0.00811587,\n",
            "       0.00839482, 0.0993781 , 0.04208835, 0.07220224, 0.11237013,\n",
            "       0.01663292, 0.01093789, 0.14166099, 0.02764263, 0.03149099,\n",
            "       0.06257451, 0.04269157, 0.01885665, 0.02172163, 0.014992  ,\n",
            "       0.06522856, 0.01315157, 0.00835558, 0.0132327 , 0.03599086,\n",
            "       0.02848314, 0.00377252, 0.02998143, 0.12628669, 0.00883579,\n",
            "       0.0263518 , 0.13856803, 0.0113247 , 0.04219524, 0.09051486,\n",
            "       0.0548848 , 0.05169019, 0.05281495, 0.01748962, 0.00906242,\n",
            "       0.03869884, 0.05263366, 0.01030054, 0.01672278, 0.08590437,\n",
            "       0.06249279, 0.01393717, 0.03196475, 0.01418451, 0.03679273,\n",
            "       0.10821122, 0.00717743, 0.04766231, 0.03736395, 0.0843109 ,\n",
            "       0.00863944, 0.01601737, 0.10759982, 0.01509774, 0.01256459,\n",
            "       0.08455783, 0.05606233, 0.02415601, 0.0308868 , 0.01878609,\n",
            "       0.0179728 , 0.0336087 , 0.01573998, 0.01012865, 0.01704596,\n",
            "       0.13778427, 0.01112822, 0.04793779, 0.0833207 , 0.04243751,\n",
            "       0.08837505, 0.05638969, 0.01578153, 0.02887512, 0.05517745,\n",
            "       0.08211625, 0.01933717, 0.0842258 , 0.04283952, 0.01837214,\n",
            "       0.02217948, 0.03603173, 0.08020128, 0.04328445, 0.03859786,\n",
            "       0.04429295, 0.12376453, 0.01997678, 0.05589659, 0.01129173,\n",
            "       0.00595082, 0.13011675, 0.01343541, 0.02967505, 0.06327233,\n",
            "       0.00674646, 0.06804047, 0.0168998 , 0.14115246, 0.02013744,\n",
            "       0.02032281, 0.09086481, 0.02490546, 0.08305285, 0.03752077,\n",
            "       0.04861973, 0.12077571, 0.03907404, 0.02068123, 0.09351502,\n",
            "       0.00549743, 0.00922379, 0.08233157, 0.03814846, 0.12833613,\n",
            "       0.01996068, 0.07322107, 0.09555209, 0.02072508, 0.06526554,\n",
            "       0.2363823 , 0.05721332, 0.00888872, 0.00791231, 0.08868854,\n",
            "       0.08156188, 0.06494803, 0.10234845, 0.00819409, 0.02268005,\n",
            "       0.06778718, 0.01181715, 0.0218374 , 0.00832817, 0.05282171,\n",
            "       0.00965689, 0.03303756, 0.08377706, 0.00868918, 0.01517988,\n",
            "       0.02523769, 0.04408542, 0.0203415 , 0.01415178, 0.06233311,\n",
            "       0.0219153 , 0.0519768 , 0.05866536, 0.08209903, 0.02152595,\n",
            "       0.08863222, 0.05611919, 0.01125344, 0.00914951, 0.09886659,\n",
            "       0.02642812, 0.09741589, 0.12996282, 0.22366366, 0.01107827,\n",
            "       0.00836092, 0.05459505, 0.00989933, 0.02903967, 0.04589197,\n",
            "       0.0228054 , 0.08203356, 0.00840861, 0.01202803, 0.04532164,\n",
            "       0.01965142, 0.02400219, 0.01579985, 0.06526116, 0.03149543,\n",
            "       0.04303997, 0.05042582, 0.00743728, 0.01663808, 0.07562391,\n",
            "       0.01738261, 0.01182907, 0.01468382, 0.01024439, 0.04418426,\n",
            "       0.00829834, 0.01832059, 0.10383995, 0.06567875, 0.07782149],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 355, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([7.40449352e-04, 1.63402280e-03, 6.07595837e-04, 6.59005425e-04,\n",
            "       2.83626025e-04, 1.08454423e-03, 6.19698607e-04, 7.81248964e-04,\n",
            "       5.77088771e-03, 6.52590941e-04, 9.78859462e-05, 1.05265505e-03,\n",
            "       7.66953395e-04, 2.57078279e-03, 1.57932146e-03, 1.11188844e-03,\n",
            "       1.58731360e-03, 2.19024182e-03, 2.17282656e-03, 8.17810127e-04,\n",
            "       3.73283023e-04, 6.29591406e-04, 1.13684020e-03, 1.23943808e-03,\n",
            "       8.62670597e-04, 3.38631158e-04, 1.90188619e-03, 8.56925151e-04,\n",
            "       1.51280069e-03, 1.76978367e-03, 3.21350084e-03, 1.53012667e-03,\n",
            "       2.65552220e-03, 5.05159842e-04, 2.31305326e-04, 2.35310523e-04,\n",
            "       3.61422222e-04, 4.80629242e-04, 1.32977683e-03, 1.02867489e-03,\n",
            "       7.09936663e-04, 8.16178450e-04, 1.61998114e-03, 1.78871315e-03,\n",
            "       3.06980830e-04, 8.35633036e-05, 3.82103462e-04, 2.08776430e-04,\n",
            "       3.96023388e-04, 5.28609613e-04, 1.38904352e-03, 1.48685052e-04,\n",
            "       1.48605776e-03, 2.07571336e-03, 1.17732876e-03, 1.27215486e-03,\n",
            "       5.98500308e-04, 9.74602532e-04, 4.17213701e-03, 8.41303408e-05,\n",
            "       9.86361265e-05, 1.03437318e-03, 2.00566254e-03, 6.96306117e-04,\n",
            "       7.57731555e-04, 1.61286633e-04, 7.61678908e-04, 3.04196583e-04,\n",
            "       1.02212373e-03, 6.71008602e-04, 1.53227116e-03, 2.70236656e-03,\n",
            "       1.99533286e-04, 9.49609908e-04, 9.66271735e-04, 2.43771775e-03,\n",
            "       9.81307472e-04, 2.71498901e-03, 2.38358829e-04, 2.51033995e-03,\n",
            "       9.28386362e-05, 6.37079240e-04, 1.24991595e-04, 3.83265462e-04,\n",
            "       6.41697494e-04, 2.37659621e-03, 1.47370636e-04, 2.49684963e-04,\n",
            "       2.60492391e-03, 9.44174171e-05, 3.23968544e-03, 3.91641981e-04,\n",
            "       1.37588871e-03, 1.40641909e-03, 1.11413690e-04, 1.38330553e-03,\n",
            "       1.18597772e-03, 4.93277214e-04, 1.38125368e-04, 2.27149716e-03,\n",
            "       9.81881400e-04, 1.16025296e-03, 2.22521368e-03, 3.03867622e-04,\n",
            "       2.23983731e-03, 1.38555639e-04, 8.97904392e-04, 8.55500402e-04,\n",
            "       1.51472457e-03, 4.19500459e-04, 1.37248426e-03, 1.50603912e-04,\n",
            "       1.04623730e-03, 2.63463915e-03, 3.68837820e-04, 2.32496037e-04,\n",
            "       1.05980551e-03, 7.05940241e-04, 1.16944569e-03, 2.27029988e-04,\n",
            "       1.14499230e-03, 1.79309805e-04, 8.93641147e-04, 8.06033320e-04,\n",
            "       2.12137611e-03, 2.62216618e-03, 5.56104002e-04, 6.30282331e-04,\n",
            "       9.83627979e-04, 7.73300126e-04, 2.37423670e-03, 1.38166430e-03,\n",
            "       1.80644623e-04, 1.11180496e-04, 9.27194778e-05, 4.80893505e-04,\n",
            "       1.56921466e-04, 8.17444234e-04, 1.41363780e-04, 1.19105796e-03,\n",
            "       1.34823227e-03, 3.34545985e-05, 6.30406663e-04, 4.41204989e-04,\n",
            "       1.01144899e-04, 2.87259533e-03, 1.14425020e-04, 4.80861927e-04,\n",
            "       1.74119516e-04, 7.47706392e-04, 6.92769361e-04, 1.89087109e-03,\n",
            "       9.53806564e-04, 5.10125887e-04, 7.03537511e-03, 2.78586813e-04,\n",
            "       3.23179062e-04, 1.45407964e-03, 8.57079111e-04, 5.34166393e-05,\n",
            "       3.86138883e-04, 1.26184430e-03, 7.35989772e-04, 4.38407122e-04,\n",
            "       9.93518988e-05, 8.52537982e-04, 6.37272969e-05, 1.85552612e-03,\n",
            "       6.58273988e-04, 5.87126880e-04, 1.48643297e-03, 2.43060611e-04,\n",
            "       1.11505408e-02, 7.22543860e-04, 9.62036953e-04, 1.41852055e-04,\n",
            "       5.53567021e-04, 1.95829500e-03, 8.26826959e-04, 2.33054627e-03,\n",
            "       7.07393629e-05, 5.84920519e-04, 2.32034537e-04, 1.82097347e-03,\n",
            "       6.10754243e-04, 1.74076215e-03, 2.45136674e-04, 2.12538568e-03,\n",
            "       3.58065078e-03, 1.12541940e-03, 8.09417106e-04, 2.65443960e-04,\n",
            "       5.45951305e-04, 3.35976802e-04, 4.08458407e-04, 2.79778638e-03,\n",
            "       1.95538532e-03, 2.91504432e-04, 5.44394890e-04, 4.86206613e-04,\n",
            "       2.16729520e-03, 1.03768332e-04, 8.36193387e-04, 7.22925528e-04,\n",
            "       1.88431225e-03, 2.86350492e-03, 1.71199979e-04, 1.47489685e-04,\n",
            "       1.04945051e-04, 3.34783713e-03, 1.23970746e-03, 4.55559872e-04,\n",
            "       2.10963911e-03, 2.44148774e-04, 7.22763769e-04, 1.07985456e-03,\n",
            "       4.58011811e-04, 5.99019404e-04, 5.05407690e-04, 1.35684456e-03,\n",
            "       1.14881445e-03, 3.68110463e-03, 1.03631185e-03, 8.53172445e-04,\n",
            "       2.16739252e-03, 6.42232073e-04, 1.06445001e-03, 2.77458166e-04,\n",
            "       7.64413038e-04, 9.46520187e-04, 5.03747538e-03, 7.40922056e-04,\n",
            "       4.26108367e-04, 1.11320068e-03, 9.28934780e-04, 2.35145073e-03,\n",
            "       2.37770588e-03, 1.09816936e-03, 4.55729896e-04, 1.91799609e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 356, 'shape': array([  1,   3,   3, 240], dtype=int32), 'shape_signature': array([  1,   3,   3, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01126452, 0.02485853, 0.00924341, 0.01002551, 0.00431483,\n",
            "       0.01649927, 0.00942753, 0.01188521, 0.08779302, 0.00992792,\n",
            "       0.00148915, 0.01601413, 0.01166773, 0.03910955, 0.02402636,\n",
            "       0.01691526, 0.02414794, 0.03332034, 0.0330554 , 0.01244142,\n",
            "       0.00567879, 0.00957803, 0.01729485, 0.01885568, 0.01312388,\n",
            "       0.00515163, 0.02893356, 0.01303648, 0.02301437, 0.02692387,\n",
            "       0.04888727, 0.02327795, 0.04039869, 0.00768504, 0.00351887,\n",
            "       0.0035798 , 0.00549835, 0.00731185, 0.02023001, 0.01564932,\n",
            "       0.01080033, 0.01241659, 0.02464492, 0.02721185, 0.00467013,\n",
            "       0.00127126, 0.00581297, 0.00317613, 0.00602474, 0.00804178,\n",
            "       0.02113164, 0.00226196, 0.02260753, 0.03157801, 0.01791081,\n",
            "       0.0193534 , 0.00910504, 0.01482671, 0.06347109, 0.00127988,\n",
            "       0.00150056, 0.01573601, 0.03051232, 0.01059297, 0.01152744,\n",
            "       0.00245367, 0.01158749, 0.00462777, 0.01554966, 0.01020811,\n",
            "       0.02331058, 0.04111134, 0.00303552, 0.0144465 , 0.01469998,\n",
            "       0.03708522, 0.01492872, 0.04130337, 0.00362617, 0.03819002,\n",
            "       0.00141236, 0.00969194, 0.00190151, 0.00583065, 0.0097622 ,\n",
            "       0.03615537, 0.00224196, 0.00379848, 0.03962894, 0.00143638,\n",
            "       0.04928562, 0.00595808, 0.02093152, 0.02139598, 0.00169495,\n",
            "       0.02104435, 0.01804238, 0.00750427, 0.00210131, 0.03455649,\n",
            "       0.01493745, 0.01765103, 0.03385237, 0.00462276, 0.03407484,\n",
            "       0.00210786, 0.0136599 , 0.0130148 , 0.02304364, 0.0063819 ,\n",
            "       0.02087972, 0.00229115, 0.0159165 , 0.040081  , 0.00561116,\n",
            "       0.00353698, 0.01612291, 0.01073953, 0.01779088, 0.00345383,\n",
            "       0.01741887, 0.00272786, 0.01359504, 0.01226226, 0.03227268,\n",
            "       0.03989125, 0.00846006, 0.00958854, 0.01496402, 0.01176428,\n",
            "       0.03611947, 0.02101938, 0.00274816, 0.0016914 , 0.00141055,\n",
            "       0.00731588, 0.00238726, 0.01243585, 0.00215058, 0.01811967,\n",
            "       0.02051078, 0.00050895, 0.00959043, 0.00671209, 0.00153873,\n",
            "       0.04370105, 0.00174076, 0.00731539, 0.0026489 , 0.01137492,\n",
            "       0.01053916, 0.02876599, 0.01451034, 0.00776059, 0.10702978,\n",
            "       0.00423817, 0.00491655, 0.02212104, 0.01303882, 0.00081263,\n",
            "       0.00587436, 0.01919655, 0.01119668, 0.00666953, 0.00151145,\n",
            "       0.01296974, 0.00096949, 0.02822828, 0.01001438, 0.00893201,\n",
            "       0.02261323, 0.0036977 , 0.16963416, 0.01099212, 0.01463555,\n",
            "       0.00215801, 0.00842146, 0.02979171, 0.01257859, 0.03545481,\n",
            "       0.00107616, 0.00889845, 0.00352996, 0.02770263, 0.00929146,\n",
            "       0.02648237, 0.00372929, 0.03233368, 0.05447276, 0.0171211 ,\n",
            "       0.01231373, 0.00403822, 0.00830561, 0.00511124, 0.00621391,\n",
            "       0.04256297, 0.02974745, 0.00443468, 0.00828193, 0.0073967 ,\n",
            "       0.03297125, 0.00157864, 0.01272108, 0.01099793, 0.02866621,\n",
            "       0.04356275, 0.00260448, 0.00224377, 0.00159654, 0.05093094,\n",
            "       0.01885978, 0.00693047, 0.03209412, 0.00371426, 0.01099547,\n",
            "       0.01642792, 0.00696777, 0.00911293, 0.00768881, 0.0206418 ,\n",
            "       0.01747702, 0.05600097, 0.0157655 , 0.01297939, 0.03297273,\n",
            "       0.00977033, 0.01619357, 0.004221  , 0.01162908, 0.01439949,\n",
            "       0.07663555, 0.01127171, 0.00648242, 0.01693522, 0.01413197,\n",
            "       0.03577283, 0.03617225, 0.01670655, 0.00693306, 0.02917864],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 357, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.56771901e-04, 2.38774228e-05, 4.79417686e-05, 2.61722773e-04,\n",
            "       5.55118386e-05, 3.96539472e-05, 3.08529125e-04, 2.91652868e-05,\n",
            "       9.87580133e-05, 1.83692668e-04, 5.07907127e-04, 3.60370504e-05,\n",
            "       5.58740139e-05, 2.04359152e-04, 1.57178874e-05, 1.73772671e-04,\n",
            "       3.68925721e-05, 3.93669143e-05, 3.52648967e-05, 2.40229037e-05,\n",
            "       1.88254824e-04, 3.19883169e-04, 2.14030206e-05, 2.36369247e-04,\n",
            "       2.77520972e-04, 1.71984429e-04, 1.26502942e-04, 6.64012405e-05,\n",
            "       2.62467598e-04, 1.54485751e-04, 5.65338196e-05, 2.33080391e-05,\n",
            "       5.35793770e-05, 1.78740665e-04, 1.21237186e-04, 2.32408289e-04,\n",
            "       2.65269511e-04, 3.48393223e-04, 1.29868538e-04, 6.02784748e-05,\n",
            "       3.99586104e-04, 2.77043029e-04, 5.40636174e-05, 2.14238884e-04,\n",
            "       2.33094339e-04, 2.80873966e-04, 2.10435595e-04, 1.44861275e-04,\n",
            "       2.16549815e-04, 4.42757300e-04, 1.93045445e-04, 1.90042585e-04,\n",
            "       9.72972557e-05, 2.52641184e-05, 5.85091911e-05, 1.78466231e-04,\n",
            "       1.74266679e-04, 6.70815352e-05, 2.02288666e-05, 1.23857346e-04,\n",
            "       4.07496380e-04, 1.37686526e-04, 2.22806575e-05, 2.41668458e-04,\n",
            "       1.52674140e-04, 2.20101079e-04, 2.94606230e-04, 2.87295610e-04,\n",
            "       2.35862724e-04, 1.85774581e-04, 1.25131803e-04, 1.59103147e-04,\n",
            "       1.70618951e-04, 1.89145994e-05, 2.78303516e-04, 1.52078746e-05,\n",
            "       8.96607453e-05, 4.52936947e-05, 1.16496136e-04, 3.43681386e-05,\n",
            "       5.78014005e-04, 7.34206769e-05, 2.68326985e-04, 1.70836007e-04,\n",
            "       2.35985048e-04, 3.51741255e-05, 1.93940534e-04, 3.46409273e-04,\n",
            "       4.49186846e-05, 1.45503756e-04, 3.46613342e-05, 1.42322184e-04,\n",
            "       1.34472954e-04, 1.47917497e-04, 3.03385372e-04, 4.50628286e-05,\n",
            "       2.35610627e-04, 1.09765992e-04, 1.90634615e-04, 2.62180329e-05,\n",
            "       2.55911436e-04, 9.35812495e-05, 4.74941298e-05, 2.47177260e-04,\n",
            "       5.28286218e-05, 1.52098743e-04, 7.32964618e-05, 1.69721665e-04,\n",
            "       8.15313470e-05, 1.28454412e-04, 5.58801876e-05, 2.17993336e-04,\n",
            "       1.22785365e-04, 1.26644984e-04, 3.06051195e-04, 6.24388704e-05,\n",
            "       5.42345981e-04, 6.02562541e-05, 4.23073870e-05, 1.57255141e-04,\n",
            "       3.57332246e-05, 1.22345387e-04, 2.13088875e-04, 1.65051417e-04,\n",
            "       1.66276441e-05, 3.75719392e-05, 5.31764235e-05, 5.71414530e-05,\n",
            "       1.09544919e-04, 6.99895099e-05, 1.15637486e-04, 3.04278110e-05,\n",
            "       1.46302962e-04, 3.16352642e-04, 4.63049248e-04, 1.04087936e-04,\n",
            "       1.85373399e-04, 2.94401572e-04, 2.29933212e-04, 1.93455940e-04,\n",
            "       1.78421411e-04, 3.31767660e-04, 2.91212462e-04, 4.85259297e-05,\n",
            "       3.10810137e-04, 1.08718377e-04, 1.69248757e-04, 1.19437362e-04,\n",
            "       1.84788674e-04, 1.35270631e-04, 1.21898454e-04, 1.80390252e-05,\n",
            "       1.92113541e-04, 1.09852197e-04, 3.03636589e-05, 1.14055161e-04,\n",
            "       7.80817936e-05, 4.28934109e-05, 1.77202804e-04, 1.85652243e-04,\n",
            "       4.16694762e-04, 2.14237865e-04, 1.29908542e-04, 1.36632167e-04,\n",
            "       1.52858527e-04, 2.15726264e-04, 3.29450006e-04, 3.18464699e-05,\n",
            "       3.09942261e-04, 2.12945488e-05, 3.12992197e-05, 1.58818555e-04,\n",
            "       3.63096660e-05, 4.58898692e-04, 3.62567807e-05, 2.43888062e-04,\n",
            "       3.23411005e-05, 6.56807024e-05, 3.73496936e-04, 4.12248592e-05,\n",
            "       4.68803541e-04, 2.29197991e-04, 2.37174812e-04, 1.56850030e-04,\n",
            "       4.99288726e-05, 1.43384314e-04, 1.55547561e-04, 4.08444321e-05,\n",
            "       1.49310712e-04, 1.34759044e-04, 1.06432744e-04, 1.65389094e-04,\n",
            "       1.62893732e-04, 1.47256200e-04, 9.37760415e-05, 3.99940654e-05,\n",
            "       3.67699940e-05, 1.62831915e-04, 5.54655235e-05, 9.85194638e-05,\n",
            "       2.36502146e-05, 1.56505645e-04, 1.79801340e-04, 1.93612999e-04,\n",
            "       3.17027698e-05, 4.11306610e-05, 2.78072053e-04, 1.51944230e-04,\n",
            "       1.97742091e-04, 4.77180911e-05, 1.20896373e-04, 2.04313430e-04,\n",
            "       1.78480273e-04, 1.07355692e-04, 1.17083226e-04, 1.47175117e-04,\n",
            "       9.63688872e-05, 2.59629625e-04, 2.81937508e-04, 4.72302199e-05,\n",
            "       2.12937899e-04, 3.58083089e-05, 2.75288126e-04, 2.78219050e-05,\n",
            "       1.07981548e-04, 5.60526059e-05, 1.83481243e-04, 4.14569542e-04,\n",
            "       1.51115542e-04, 1.19952747e-04, 3.38432983e-05, 8.97347854e-05,\n",
            "       1.29932989e-04, 3.41401639e-04, 5.38371387e-05, 6.26719702e-05,\n",
            "       7.02520920e-05, 1.84216369e-05, 2.74088467e-04, 3.06736983e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 358, 'shape': array([240,   1,   1,  72], dtype=int32), 'shape_signature': array([240,   1,   1,  72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.1087778e-04, 3.2118114e-05, 6.4487664e-05, 3.5204980e-04,\n",
            "       7.4670352e-05, 5.3339510e-05, 4.1501017e-04, 3.9230952e-05,\n",
            "       1.3284186e-04, 2.4708957e-04, 6.8319851e-04, 4.8474332e-05,\n",
            "       7.5157521e-05, 2.7488856e-04, 2.1142521e-05, 2.3374593e-04,\n",
            "       4.9625116e-05, 5.2953412e-05, 4.7435689e-05, 3.2313805e-05,\n",
            "       2.5322623e-04, 4.3028279e-04, 2.8789735e-05, 3.1794613e-04,\n",
            "       3.7330037e-04, 2.3134053e-04, 1.7016225e-04, 8.9317953e-05,\n",
            "       3.5305167e-04, 2.0780262e-04, 7.6045042e-05, 3.1352221e-05,\n",
            "       7.2070950e-05, 2.4042850e-04, 1.6307915e-04, 3.1261815e-04,\n",
            "       3.5682062e-04, 4.6863238e-04, 1.7468940e-04, 8.1082071e-05,\n",
            "       5.3749321e-04, 3.7265747e-04, 7.2722316e-05, 2.8817804e-04,\n",
            "       3.1354098e-04, 3.7781056e-04, 2.8306214e-04, 1.9485650e-04,\n",
            "       2.9128653e-04, 5.9556385e-04, 2.5967023e-04, 2.5563099e-04,\n",
            "       1.3087696e-04, 3.3983393e-05, 7.8702164e-05, 2.4005937e-04,\n",
            "       2.3441044e-04, 9.0233043e-05, 2.7210352e-05, 1.6660358e-04,\n",
            "       5.4813351e-04, 1.8520556e-04, 2.9970266e-05, 3.2507424e-04,\n",
            "       2.0536578e-04, 2.9606343e-04, 3.9628215e-04, 3.8644846e-04,\n",
            "       3.1726481e-04, 2.4989000e-04, 1.6831790e-04, 2.1401359e-04,\n",
            "       2.2950378e-04, 2.5442498e-05, 3.7435297e-04, 2.0456489e-05,\n",
            "       1.2060490e-04, 6.0925671e-05, 1.5670185e-04, 4.6229437e-05,\n",
            "       7.7750097e-04, 9.8759971e-05, 3.6093328e-04, 2.2979575e-04,\n",
            "       3.1742934e-04, 4.7313591e-05, 2.6087422e-04, 4.6596371e-04,\n",
            "       6.0421240e-05, 1.9572071e-04, 4.6623823e-05, 1.9144111e-04,\n",
            "       1.8088291e-04, 1.9896749e-04, 4.0809120e-04, 6.0615130e-05,\n",
            "       3.1692570e-04, 1.4764896e-04, 2.5642736e-04, 3.5266527e-05,\n",
            "       3.4423283e-04, 1.2587846e-04, 6.3885534e-05, 3.3248428e-04,\n",
            "       7.1061091e-05, 2.0459179e-04, 9.8592893e-05, 2.2829682e-04,\n",
            "       1.0966984e-04, 1.7278721e-04, 7.5165830e-05, 2.9322825e-04,\n",
            "       1.6516163e-04, 1.7035331e-04, 4.1167706e-04, 8.3988074e-05,\n",
            "       7.2952302e-04, 8.1052181e-05, 5.6908717e-05, 2.1152779e-04,\n",
            "       4.8065649e-05, 1.6456982e-04, 2.8663114e-04, 2.2201476e-04,\n",
            "       2.2366257e-05, 5.0538947e-05, 7.1528928e-05, 7.6862387e-05,\n",
            "       1.4735159e-04, 9.4144627e-05, 1.5554685e-04, 4.0929204e-05,\n",
            "       1.9679575e-04, 4.2553380e-04, 6.2285905e-04, 1.4001127e-04,\n",
            "       2.4935036e-04, 3.9600686e-04, 3.0928888e-04, 2.6022238e-04,\n",
            "       2.3999906e-04, 4.4626891e-04, 3.9171713e-04, 6.5273431e-05,\n",
            "       4.1807845e-04, 1.4623979e-04, 2.2766070e-04, 1.6065816e-04,\n",
            "       2.4856383e-04, 1.8195588e-04, 1.6396864e-04, 2.4264740e-05,\n",
            "       2.5841669e-04, 1.4776492e-04, 4.0842911e-05, 1.5341843e-04,\n",
            "       1.0502976e-04, 5.7696994e-05, 2.3835989e-04, 2.4972545e-04,\n",
            "       5.6050648e-04, 2.8817667e-04, 1.7474320e-04, 1.8378733e-04,\n",
            "       2.0561380e-04, 2.9017875e-04, 4.4315137e-04, 4.2837477e-05,\n",
            "       4.1691103e-04, 2.8643826e-05, 4.2101357e-05, 2.1363079e-04,\n",
            "       4.8841033e-05, 6.1727600e-04, 4.8769896e-05, 3.2805989e-04,\n",
            "       4.3502816e-05, 8.8348745e-05, 5.0239998e-04, 5.5452583e-05,\n",
            "       6.3059927e-04, 3.0829990e-04, 3.1902973e-04, 2.1098286e-04,\n",
            "       6.7160567e-05, 1.9286980e-04, 2.0923089e-04, 5.4940861e-05,\n",
            "       2.0084155e-04, 1.8126774e-04, 1.4316532e-04, 2.2246898e-04,\n",
            "       2.1911241e-04, 1.9807796e-04, 1.2614048e-04, 5.3797008e-05,\n",
            "       4.9460232e-05, 2.1902926e-04, 7.4608055e-05, 1.3252097e-04,\n",
            "       3.1812491e-05, 2.1051963e-04, 2.4185525e-04, 2.6043365e-04,\n",
            "       4.2644180e-05, 5.5325872e-05, 3.7404161e-04, 2.0438395e-04,\n",
            "       2.6598779e-04, 6.4186788e-05, 1.6262071e-04, 2.7482706e-04,\n",
            "       2.4007824e-04, 1.4440680e-04, 1.5749155e-04, 1.9796891e-04,\n",
            "       1.2962818e-04, 3.4923427e-04, 3.7924116e-04, 6.3530541e-05,\n",
            "       2.8642805e-04, 4.8166643e-05, 3.7029688e-04, 3.7423935e-05,\n",
            "       1.4524866e-04, 7.5397751e-05, 2.4680517e-04, 5.5764779e-04,\n",
            "       2.0326927e-04, 1.6135142e-04, 4.5523459e-05, 1.2070449e-04,\n",
            "       1.7477610e-04, 4.5922783e-04, 7.2417672e-05, 8.4301624e-05,\n",
            "       9.4497831e-05, 2.4779401e-05, 3.6868319e-04, 4.1259951e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/rezero/mul', 'index': 359, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0072466651909053326, -128), 'quantization_parameters': {'scales': array([0.00724667], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 360, 'shape': array([72], dtype=int32), 'shape_signature': array([72], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00049277, 0.00058085, 0.00049786, 0.00059271, 0.00055965,\n",
            "       0.0006158 , 0.00052752, 0.00047201, 0.00055167, 0.00059844,\n",
            "       0.00058212, 0.00070911, 0.00062918, 0.00027956, 0.00048609,\n",
            "       0.00060925, 0.00042492, 0.00055048, 0.00068875, 0.00043836,\n",
            "       0.00037784, 0.00044957, 0.00044419, 0.00054313, 0.00050644,\n",
            "       0.00067135, 0.00031269, 0.00033777, 0.00056855, 0.00052866,\n",
            "       0.00060469, 0.00067267, 0.00054903, 0.00040543, 0.00075779,\n",
            "       0.00050698, 0.00049252, 0.00054088, 0.0003977 , 0.00046752,\n",
            "       0.00057904, 0.00046082, 0.00131792, 0.00048331, 0.00062568,\n",
            "       0.00048549, 0.00095438, 0.00040789, 0.00040648, 0.00044274,\n",
            "       0.0004466 , 0.0004575 , 0.0004544 , 0.00035419, 0.00059338,\n",
            "       0.0005662 , 0.00060934, 0.00043141, 0.00081337, 0.00043448,\n",
            "       0.00046311, 0.00084191, 0.00094659, 0.00040697, 0.00039289,\n",
            "       0.00051186, 0.00056387, 0.00043812, 0.00062134, 0.0006185 ,\n",
            "       0.00050195, 0.00066719], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 361, 'shape': array([ 72,   1,   1, 192], dtype=int32), 'shape_signature': array([ 72,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01316916, 0.01552318, 0.01330529, 0.01584024, 0.01495659,\n",
            "       0.01645726, 0.01409786, 0.01261444, 0.01474335, 0.01599336,\n",
            "       0.01555719, 0.01895102, 0.01681482, 0.00747116, 0.01299065,\n",
            "       0.01628207, 0.01135608, 0.01471148, 0.01840681, 0.01171524,\n",
            "       0.01009782, 0.01201483, 0.01187091, 0.0145151 , 0.0135346 ,\n",
            "       0.01794184, 0.00835663, 0.00902693, 0.01519443, 0.01412848,\n",
            "       0.01616022, 0.01797708, 0.01467286, 0.010835  , 0.02025198,\n",
            "       0.01354902, 0.01316259, 0.01445498, 0.01062843, 0.01249433,\n",
            "       0.01547481, 0.01231546, 0.03522145, 0.01291636, 0.01672137,\n",
            "       0.0129748 , 0.02550578, 0.01090074, 0.01086312, 0.01183234,\n",
            "       0.01193526, 0.01222675, 0.01214383, 0.00946565, 0.01585796,\n",
            "       0.01513166, 0.01628461, 0.01152937, 0.02173738, 0.01161145,\n",
            "       0.01237654, 0.02250011, 0.02529757, 0.01087637, 0.01050001,\n",
            "       0.01367956, 0.01506945, 0.01170875, 0.01660538, 0.0165294 ,\n",
            "       0.01341466, 0.01783062], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 362, 'shape': array([192], dtype=int32), 'shape_signature': array([192], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.51601905e-05, 1.65165766e-05, 1.07679361e-05, 1.12813295e-05,\n",
            "       1.63531149e-05, 1.46254479e-05, 1.36935423e-05, 1.83190259e-05,\n",
            "       1.16013662e-05, 1.26615059e-05, 1.67965391e-05, 1.83438533e-05,\n",
            "       1.22682768e-05, 2.45762458e-05, 7.73089141e-06, 1.17361433e-05,\n",
            "       1.81929681e-05, 5.14180210e-05, 2.49620462e-05, 1.59262745e-05,\n",
            "       8.93453307e-06, 1.71799420e-05, 1.49168254e-05, 8.26251835e-06,\n",
            "       1.73528661e-05, 4.24566060e-05, 1.63783370e-05, 1.88271842e-05,\n",
            "       1.58148578e-05, 8.93926062e-06, 2.06431268e-05, 2.54421266e-05,\n",
            "       1.11451991e-05, 1.28557904e-05, 1.56174519e-05, 1.32094929e-05,\n",
            "       1.11415939e-05, 1.87089227e-05, 2.07217417e-05, 2.58544133e-05,\n",
            "       2.12760842e-05, 1.28934944e-05, 1.12510234e-05, 1.80865172e-05,\n",
            "       1.86746474e-05, 1.24758471e-05, 2.72409943e-05, 2.22649251e-05,\n",
            "       1.77731217e-05, 4.36050868e-05, 1.83072516e-05, 4.40632211e-05,\n",
            "       1.46895927e-05, 1.36292620e-05, 3.21156003e-05, 3.31721921e-08,\n",
            "       1.96544152e-05, 1.64038265e-05, 2.07031862e-05, 1.04994115e-05,\n",
            "       2.46312411e-05, 1.52286175e-05, 1.07680680e-05, 1.58429903e-05,\n",
            "       1.26338618e-05, 1.37728621e-05, 2.70207911e-05, 1.69820014e-05,\n",
            "       1.24749704e-05, 1.03184411e-05, 1.09502707e-05, 5.91690605e-06,\n",
            "       9.83786140e-06, 2.58644777e-05, 2.13390176e-05, 1.25583847e-05,\n",
            "       1.88977974e-05, 1.21518524e-05, 3.43708743e-05, 2.35039715e-05,\n",
            "       1.57168470e-05, 1.16349256e-05, 1.86367506e-05, 2.95735499e-05,\n",
            "       4.29592801e-05, 1.28846414e-05, 6.95853305e-06, 1.99291298e-05,\n",
            "       2.38300436e-05, 3.37252350e-05, 1.03640241e-05, 1.79013387e-05,\n",
            "       1.17184445e-05, 1.33979865e-05, 1.73153858e-05, 1.09315606e-05,\n",
            "       1.47485844e-05, 1.54146201e-05, 1.73306726e-05, 5.59615619e-05,\n",
            "       3.38306127e-05, 1.76552785e-05, 1.03240527e-05, 4.02650840e-05,\n",
            "       1.36725366e-05, 8.45727573e-06, 1.91003328e-05, 1.56190526e-05,\n",
            "       3.46520937e-05, 1.69001651e-05, 1.06687557e-05, 1.97402278e-05,\n",
            "       1.48998406e-05, 3.54514668e-05, 3.62158171e-05, 3.45096050e-05,\n",
            "       2.40134887e-05, 1.46718603e-05, 1.02767635e-05, 3.57517420e-05,\n",
            "       1.15589091e-05, 1.36178987e-05, 1.87526803e-05, 1.04002822e-04,\n",
            "       1.69943814e-05, 1.37960342e-05, 1.29608452e-05, 1.90719202e-05,\n",
            "       1.04708588e-05, 2.28324461e-05, 1.69111081e-05, 1.69565410e-05,\n",
            "       1.81834494e-05, 1.49151019e-05, 1.47962646e-05, 2.00344730e-05,\n",
            "       1.24920252e-05, 1.16576712e-05, 1.49434327e-05, 1.20933255e-05,\n",
            "       1.39341573e-05, 1.27202593e-05, 1.44146270e-05, 3.86037973e-05,\n",
            "       1.44447395e-05, 3.43264255e-05, 1.51473478e-05, 1.52498214e-05,\n",
            "       1.35034152e-05, 1.74677698e-05, 2.43722279e-05, 1.32135337e-05,\n",
            "       1.82283202e-05, 1.55681137e-05, 1.75914665e-05, 1.04084947e-05,\n",
            "       1.40946504e-05, 3.84576306e-05, 2.51226993e-05, 1.52507873e-05,\n",
            "       2.17803245e-05, 9.53958715e-06, 2.27650380e-05, 4.20922224e-05,\n",
            "       1.52826251e-05, 2.03250238e-05, 2.35004263e-05, 2.15835917e-05,\n",
            "       1.52847842e-05, 1.92762855e-05, 1.08119993e-05, 2.39324600e-05,\n",
            "       1.16314604e-05, 2.16473982e-05, 3.59298247e-05, 1.48429353e-05,\n",
            "       9.96027484e-06, 1.47854162e-05, 1.05715626e-05, 2.08776746e-05,\n",
            "       1.41837418e-05, 1.34841921e-05, 1.42785793e-05, 9.81003814e-06,\n",
            "       2.03762593e-05, 9.36801007e-06, 4.04721468e-05, 1.72453492e-05,\n",
            "       1.97478439e-05, 2.53266790e-05, 1.64633639e-05, 4.36719092e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 363, 'shape': array([192,   1,   1,  96], dtype=int32), 'shape_signature': array([192,   1,   1,  96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.2007420e-03, 7.8823516e-04, 5.1388773e-04, 5.3838885e-04,\n",
            "       7.8043411e-04, 6.9798314e-04, 6.5350899e-04, 8.7425503e-04,\n",
            "       5.5366225e-04, 6.0425623e-04, 8.0159603e-04, 8.7543990e-04,\n",
            "       5.8548979e-04, 1.1728739e-03, 3.6894815e-04, 5.6009431e-04,\n",
            "       8.6823903e-04, 2.4538676e-03, 1.1912858e-03, 7.6006365e-04,\n",
            "       4.2639062e-04, 8.1989350e-04, 7.1188883e-04, 3.9431948e-04,\n",
            "       8.2814612e-04, 2.0261940e-03, 7.8163785e-04, 8.9850632e-04,\n",
            "       7.5474643e-04, 4.2661623e-04, 9.8517013e-04, 1.2141970e-03,\n",
            "       5.3189218e-04, 6.1352825e-04, 7.4532547e-04, 6.3040829e-04,\n",
            "       5.3172011e-04, 8.9286244e-04, 9.8892197e-04, 1.2338730e-03,\n",
            "       1.0153773e-03, 6.1532762e-04, 5.3694251e-04, 8.6315884e-04,\n",
            "       8.9122663e-04, 5.9539586e-04, 1.3000460e-03, 1.0625686e-03,\n",
            "       8.4820238e-04, 2.0810040e-03, 8.7369309e-04, 2.1028679e-03,\n",
            "       7.0104440e-04, 6.5044127e-04, 1.5326812e-03, 1.5831058e-06,\n",
            "       9.3798502e-04, 7.8285427e-04, 9.8803639e-04, 5.0107267e-04,\n",
            "       1.1754985e-03, 7.2676875e-04, 5.1389402e-04, 7.5608899e-04,\n",
            "       6.0293695e-04, 6.5729447e-04, 1.2895371e-03, 8.1044703e-04,\n",
            "       5.9535401e-04, 4.9243605e-04, 5.2258943e-04, 2.8237773e-04,\n",
            "       4.6950093e-04, 1.2343533e-03, 1.0183807e-03, 5.9933489e-04,\n",
            "       9.0187625e-04, 5.7993358e-04, 1.6403116e-03, 1.1217007e-03,\n",
            "       7.5006892e-04, 5.5526383e-04, 8.8941812e-04, 1.4113646e-03,\n",
            "       2.0501837e-03, 6.1490509e-04, 3.3208821e-04, 9.5109548e-04,\n",
            "       1.1372622e-03, 1.6094991e-03, 4.9461145e-04, 8.5432141e-04,\n",
            "       5.5924966e-04, 6.3940394e-04, 8.2635746e-04, 5.2169652e-04,\n",
            "       7.0385973e-04, 7.3564553e-04, 8.2708697e-04, 2.6707030e-03,\n",
            "       1.6145281e-03, 8.4257848e-04, 4.9270387e-04, 1.9216061e-03,\n",
            "       6.5250654e-04, 4.0361402e-04, 9.1154204e-04, 7.4540183e-04,\n",
            "       1.6537325e-03, 8.0654147e-04, 5.0915446e-04, 9.4208034e-04,\n",
            "       7.1107823e-04, 1.6918816e-03, 1.7283594e-03, 1.6469323e-03,\n",
            "       1.1460169e-03, 7.0019811e-04, 4.9044704e-04, 1.7062119e-03,\n",
            "       5.5163604e-04, 6.4989901e-04, 8.9495070e-04, 4.9634185e-03,\n",
            "       8.1103790e-04, 6.5840030e-04, 6.1854185e-04, 9.1018609e-04,\n",
            "       4.9971003e-04, 1.0896530e-03, 8.0706377e-04, 8.0923201e-04,\n",
            "       8.6778478e-04, 7.1180658e-04, 7.0613518e-04, 9.5612282e-04,\n",
            "       5.9616793e-04, 5.5634935e-04, 7.1315863e-04, 5.7714042e-04,\n",
            "       6.6499208e-04, 6.0706015e-04, 6.8792194e-04, 1.8423231e-03,\n",
            "       6.8935903e-04, 1.6381904e-03, 7.2289025e-04, 7.2778069e-04,\n",
            "       6.4443541e-04, 8.3362981e-04, 1.1631374e-03, 6.3060113e-04,\n",
            "       8.6992624e-04, 7.4297079e-04, 8.3953311e-04, 4.9673376e-04,\n",
            "       6.7265145e-04, 1.8353475e-03, 1.1989528e-03, 7.2782679e-04,\n",
            "       1.0394417e-03, 4.5526613e-04, 1.0864360e-03, 2.0088044e-03,\n",
            "       7.2934624e-04, 9.6998905e-04, 1.1215316e-03, 1.0300528e-03,\n",
            "       7.2944921e-04, 9.1993919e-04, 5.1599060e-04, 1.1421499e-03,\n",
            "       5.5509846e-04, 1.0330979e-03, 1.7147107e-03, 7.0836250e-04,\n",
            "       4.7534297e-04, 7.0561748e-04, 5.0451601e-04, 9.9636370e-04,\n",
            "       6.7690323e-04, 6.4351800e-04, 6.8142923e-04, 4.6817309e-04,\n",
            "       9.7243424e-04, 4.4707782e-04, 1.9314879e-03, 8.2301506e-04,\n",
            "       9.4244379e-04, 1.2086874e-03, 7.8569568e-04, 2.0841931e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 364, 'shape': array([96], dtype=int32), 'shape_signature': array([96], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([5.13200648e-05, 7.49886840e-06, 5.54856961e-05, 5.99342566e-05,\n",
            "       4.44517827e-05, 9.07511730e-06, 1.59546744e-05, 2.22325889e-05,\n",
            "       7.21572869e-05, 5.91422868e-05, 4.08017731e-05, 2.16768603e-05,\n",
            "       3.11144759e-05, 3.97500480e-05, 2.06148015e-05, 2.31379072e-05,\n",
            "       3.48044778e-05, 4.40026852e-05, 2.05424676e-05, 1.06222888e-05,\n",
            "       2.22340441e-05, 2.92192199e-05, 1.64215962e-05, 1.35254431e-05,\n",
            "       9.14702014e-06, 8.65911352e-05, 2.80399345e-05, 1.37489933e-05,\n",
            "       2.30303085e-05, 1.31645247e-05, 3.78799341e-05, 2.77632662e-05,\n",
            "       1.17744194e-05, 3.46345187e-05, 2.54304814e-05, 3.12220072e-05,\n",
            "       7.32684521e-06, 3.24911598e-05, 1.61286771e-05, 9.35015032e-06,\n",
            "       8.52867815e-05, 1.25226816e-05, 1.81545729e-05, 7.75642984e-05,\n",
            "       1.46381535e-05, 4.77927242e-05, 3.20371873e-05, 2.75660641e-05,\n",
            "       3.04581663e-05, 1.82559816e-05, 2.85403694e-05, 3.16903388e-05,\n",
            "       2.36182605e-05, 6.11986325e-05, 1.90759620e-05, 1.75143614e-05,\n",
            "       3.83954284e-05, 3.25703077e-05, 1.05915933e-04, 8.33844460e-05,\n",
            "       2.85191545e-05, 2.76102364e-05, 5.75421873e-05, 2.12503728e-05,\n",
            "       1.47005367e-05, 6.49667491e-05, 6.22515363e-05, 5.75252270e-05,\n",
            "       1.18273947e-05, 4.08005944e-05, 3.90877067e-05, 4.05082319e-05,\n",
            "       1.09281555e-05, 1.46565571e-05, 1.12659854e-05, 1.27956619e-05,\n",
            "       4.31816079e-05, 3.87125656e-05, 5.91320804e-06, 2.22589861e-05,\n",
            "       2.49203167e-05, 2.86710547e-05, 3.04144960e-05, 3.63610561e-05,\n",
            "       1.26181885e-05, 4.16063594e-05, 9.72513681e-06, 2.30145324e-05,\n",
            "       4.62763492e-05, 3.81939535e-05, 3.04150817e-05, 3.43674001e-05,\n",
            "       3.04387468e-05, 3.68444016e-05, 3.59630176e-05, 9.16484987e-06],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 365, 'shape': array([ 96,   1,   1, 384], dtype=int32), 'shape_signature': array([ 96,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00196841, 0.00028762, 0.00212819, 0.00229881, 0.00170497,\n",
            "       0.00034808, 0.00061195, 0.00085274, 0.00276763, 0.00226844,\n",
            "       0.00156498, 0.00083143, 0.00119341, 0.00152464, 0.00079069,\n",
            "       0.00088747, 0.00133495, 0.00168775, 0.00078792, 0.00040742,\n",
            "       0.0008528 , 0.00112072, 0.00062986, 0.00051878, 0.00035084,\n",
            "       0.00332125, 0.00107549, 0.00052735, 0.00088334, 0.00050493,\n",
            "       0.00145291, 0.00106488, 0.00045161, 0.00132843, 0.0009754 ,\n",
            "       0.00119754, 0.00028103, 0.00124622, 0.00061862, 0.00035863,\n",
            "       0.00327122, 0.00048031, 0.00069633, 0.00297502, 0.00056145,\n",
            "       0.00183312, 0.0012288 , 0.00105731, 0.00116824, 0.00070022,\n",
            "       0.00109468, 0.0012155 , 0.00090589, 0.00234731, 0.00073167,\n",
            "       0.00067177, 0.00147268, 0.00124925, 0.00406247, 0.00319826,\n",
            "       0.00109387, 0.00105901, 0.00220706, 0.00081507, 0.00056385,\n",
            "       0.00249184, 0.00238769, 0.00220641, 0.00045365, 0.00156493,\n",
            "       0.00149923, 0.00155372, 0.00041916, 0.00056216, 0.00043211,\n",
            "       0.00049079, 0.00165626, 0.00148484, 0.0002268 , 0.00085376,\n",
            "       0.00095583, 0.00109969, 0.00116657, 0.00139465, 0.00048398,\n",
            "       0.00159584, 0.00037301, 0.00088274, 0.00177496, 0.00146495,\n",
            "       0.00116659, 0.00131818, 0.0011675 , 0.00141319, 0.00137938,\n",
            "       0.00035152], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 366, 'shape': array([192], dtype=int32), 'shape_signature': array([192], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00243493, 0.00481204, 0.00881627, 0.0033076 , 0.00671645,\n",
            "       0.00302668, 0.00507205, 0.00172187, 0.01117384, 0.00392375,\n",
            "       0.0099635 , 0.00753494, 0.00611011, 0.00102952, 0.00070143,\n",
            "       0.00503634, 0.00435297, 0.02262261, 0.00831957, 0.01282421,\n",
            "       0.00750113, 0.00230146, 0.00378418, 0.00077627, 0.00118938,\n",
            "       0.00136776, 0.01062528, 0.00450321, 0.00357762, 0.01401183,\n",
            "       0.01235244, 0.02966287, 0.01182116, 0.00883127, 0.00058986,\n",
            "       0.00984141, 0.01621109, 0.00129862, 0.00380966, 0.00260203,\n",
            "       0.0042441 , 0.01057525, 0.00214441, 0.01684886, 0.02096396,\n",
            "       0.01018006, 0.0069429 , 0.00244501, 0.00422656, 0.00151279,\n",
            "       0.00151942, 0.00288642, 0.00107426, 0.01219576, 0.00394732,\n",
            "       0.00995952, 0.00100315, 0.00075564, 0.00878836, 0.00236759,\n",
            "       0.00114968, 0.01413439, 0.00117405, 0.00399235, 0.00742471,\n",
            "       0.00421953, 0.01226529, 0.0015482 , 0.00090637, 0.01028876,\n",
            "       0.0019463 , 0.00429503, 0.00543677, 0.00193863, 0.00219696,\n",
            "       0.00158722, 0.01076187, 0.00053704, 0.00152514, 0.00171562,\n",
            "       0.00651254, 0.00343834, 0.00726695, 0.0048803 , 0.00976287,\n",
            "       0.00083126, 0.00324245, 0.00108781, 0.00431302, 0.00196617,\n",
            "       0.00324643, 0.00306623, 0.00219939, 0.01008159, 0.00399487,\n",
            "       0.00142912, 0.01243892, 0.00224382, 0.00142892, 0.0106492 ,\n",
            "       0.00558543, 0.0020263 , 0.00910206, 0.01551003, 0.01067088,\n",
            "       0.00679933, 0.00232874, 0.00120935, 0.00496936, 0.00207672,\n",
            "       0.00410707, 0.00097851, 0.0090491 , 0.01107197, 0.00176477,\n",
            "       0.01328783, 0.0026052 , 0.00662338, 0.00124302, 0.02006227,\n",
            "       0.00813962, 0.00109129, 0.01135206, 0.00100088, 0.00344113,\n",
            "       0.0080315 , 0.00143021, 0.00162163, 0.01017414, 0.00302953,\n",
            "       0.00386668, 0.00087136, 0.00962   , 0.00653723, 0.00721031,\n",
            "       0.00992537, 0.00336293, 0.00424018, 0.01339987, 0.00098552,\n",
            "       0.00121434, 0.01017733, 0.00381822, 0.00153008, 0.01298732,\n",
            "       0.01567779, 0.01236132, 0.00175556, 0.00418757, 0.00171163,\n",
            "       0.00485857, 0.00442038, 0.00194021, 0.00141116, 0.00833073,\n",
            "       0.00911142, 0.0069142 , 0.01034486, 0.0057144 , 0.00121774,\n",
            "       0.00231919, 0.00604093, 0.00773553, 0.01406287, 0.00186875,\n",
            "       0.0091914 , 0.00491231, 0.00181578, 0.00390478, 0.00078846,\n",
            "       0.00066163, 0.00277896, 0.00485454, 0.04258794, 0.00196248,\n",
            "       0.0078946 , 0.00422269, 0.01095231, 0.00236316, 0.00561383,\n",
            "       0.00874138, 0.00125842, 0.00163107, 0.00083167, 0.00519097,\n",
            "       0.00815353, 0.00854544, 0.00074596, 0.0160562 , 0.00205481,\n",
            "       0.00100277, 0.01550773], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul', 'index': 367, 'shape': array([  1,   3,   1, 192], dtype=int32), 'shape_signature': array([  1,   3,   1, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01818393, 0.03593604, 0.06583934, 0.02470091, 0.05015802,\n",
            "       0.02260304, 0.03787774, 0.01285884, 0.08344553, 0.0293023 ,\n",
            "       0.0744068 , 0.05627048, 0.04562989, 0.0076884 , 0.00523826,\n",
            "       0.03761109, 0.03250773, 0.1689442 , 0.06213005, 0.09577038,\n",
            "       0.05601797, 0.01718714, 0.02826005, 0.0057971 , 0.00888219,\n",
            "       0.01021435, 0.0793489 , 0.03362968, 0.02671747, 0.10463944,\n",
            "       0.09224726, 0.22152044, 0.08827967, 0.06595137, 0.00440506,\n",
            "       0.07349504, 0.12106342, 0.00969803, 0.02845028, 0.01943183,\n",
            "       0.03169466, 0.07897527, 0.01601432, 0.12582621, 0.15655755,\n",
            "       0.076024  , 0.05184916, 0.01825915, 0.03156366, 0.01129739,\n",
            "       0.0113469 , 0.0215556 , 0.0080225 , 0.09107713, 0.02947836,\n",
            "       0.07437706, 0.00749146, 0.0056431 , 0.06563095, 0.01768099,\n",
            "       0.00858574, 0.10555477, 0.0087677 , 0.02981465, 0.05544724,\n",
            "       0.03151117, 0.09159641, 0.01156185, 0.00676875, 0.07683583,\n",
            "       0.01453482, 0.03207503, 0.04060144, 0.01447758, 0.01640673,\n",
            "       0.01185327, 0.08036899, 0.0040106 , 0.01138967, 0.01281215,\n",
            "       0.04863524, 0.02567734, 0.0542691 , 0.03644577, 0.07290849,\n",
            "       0.00620779, 0.02421442, 0.00812368, 0.03220935, 0.01468326,\n",
            "       0.02424416, 0.02289839, 0.01642489, 0.07528871, 0.02983341,\n",
            "       0.01067261, 0.09289309, 0.01675674, 0.01067108, 0.07952756,\n",
            "       0.04171164, 0.01513227, 0.06797363, 0.1158279 , 0.07968943,\n",
            "       0.050777  , 0.0173909 , 0.00903138, 0.03711083, 0.01550884,\n",
            "       0.03067133, 0.00730748, 0.06757808, 0.08268479, 0.01317919,\n",
            "       0.09923265, 0.01945544, 0.04946298, 0.00928281, 0.14982377,\n",
            "       0.06078618, 0.00814969, 0.08477645, 0.0074745 , 0.02569816,\n",
            "       0.0599787 , 0.01068069, 0.01211025, 0.07597984, 0.02262434,\n",
            "       0.02887616, 0.00650729, 0.07184158, 0.04881959, 0.05384614,\n",
            "       0.07412203, 0.02511415, 0.03166541, 0.10006939, 0.00735977,\n",
            "       0.00906863, 0.07600365, 0.02851422, 0.01142655, 0.0969885 ,\n",
            "       0.11708076, 0.09231353, 0.01311044, 0.03127253, 0.01278235,\n",
            "       0.03628347, 0.03301115, 0.01448936, 0.01053844, 0.06221339,\n",
            "       0.06804347, 0.05163478, 0.07725479, 0.04267481, 0.00909402,\n",
            "       0.01731958, 0.04511327, 0.05776848, 0.10502065, 0.01395571,\n",
            "       0.06864077, 0.03668484, 0.01356015, 0.02916061, 0.0058882 ,\n",
            "       0.00494104, 0.02075308, 0.03625336, 0.318044  , 0.01465568,\n",
            "       0.0589564 , 0.0315348 , 0.08179118, 0.01764794, 0.0419237 ,\n",
            "       0.06528009, 0.00939783, 0.01218073, 0.00621086, 0.03876586,\n",
            "       0.06089007, 0.06381678, 0.00557077, 0.11990671, 0.01534516,\n",
            "       0.00748859, 0.11581072], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 368, 'shape': array([192], dtype=int32), 'shape_signature': array([192], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.09678173e-04, 6.82418817e-04, 2.05434742e-03, 8.36286999e-05,\n",
            "       1.00380348e-04, 1.49503408e-04, 4.02586348e-03, 2.90509575e-04,\n",
            "       2.37103217e-04, 4.46178921e-04, 1.60045701e-03, 2.20016623e-03,\n",
            "       9.25151689e-04, 4.16800322e-04, 5.61843975e-04, 1.47907806e-04,\n",
            "       1.76407950e-04, 9.50593268e-04, 1.37382653e-04, 8.05396703e-04,\n",
            "       6.85723498e-05, 7.01972051e-04, 2.32230034e-03, 6.42126368e-04,\n",
            "       1.68954500e-03, 1.24056183e-03, 9.14459466e-04, 3.33865260e-04,\n",
            "       2.47319904e-03, 1.20667813e-04, 1.94531240e-04, 3.88475637e-05,\n",
            "       1.58419178e-04, 9.78274402e-05, 2.14798329e-03, 1.24793884e-03,\n",
            "       4.76346650e-05, 1.40351578e-04, 1.18368138e-04, 3.30702774e-03,\n",
            "       1.96205825e-03, 2.06557754e-03, 1.44597457e-03, 7.62132462e-04,\n",
            "       1.92555657e-03, 5.33103943e-04, 7.48198712e-04, 5.75622602e-04,\n",
            "       2.26544740e-04, 6.50069036e-04, 7.77010515e-04, 5.02194511e-04,\n",
            "       6.93851907e-04, 9.32970943e-05, 2.55261868e-04, 9.48348839e-04,\n",
            "       2.40453379e-03, 1.07152644e-03, 3.43371939e-04, 2.55160296e-04,\n",
            "       5.50280791e-04, 1.89210440e-03, 1.43926509e-03, 4.23952611e-03,\n",
            "       3.11312987e-03, 8.70499134e-05, 1.18480188e-04, 3.70495836e-03,\n",
            "       9.58214339e-04, 6.24723209e-04, 3.25667381e-04, 4.95850749e-04,\n",
            "       2.33801850e-03, 9.43693973e-04, 9.85757215e-04, 1.23894250e-03,\n",
            "       1.40956763e-04, 2.70158960e-03, 3.15098441e-04, 1.48634077e-03,\n",
            "       2.65733153e-03, 1.19653437e-03, 9.25015949e-04, 7.84449512e-04,\n",
            "       1.15460914e-03, 1.26042822e-03, 2.33041370e-04, 2.02094018e-03,\n",
            "       2.53750663e-03, 3.47821065e-03, 1.27345760e-04, 3.24230362e-03,\n",
            "       2.23039606e-04, 5.86675480e-04, 1.58781273e-04, 1.02695485e-03,\n",
            "       1.81361349e-04, 2.72960431e-04, 1.37663085e-03, 1.59488904e-04,\n",
            "       8.78659950e-04, 8.98755854e-04, 5.98175277e-04, 9.33429037e-05,\n",
            "       6.09275303e-04, 2.83770700e-04, 7.03170488e-04, 1.09842070e-03,\n",
            "       8.57487088e-04, 4.94624139e-04, 1.70137919e-03, 1.09006034e-03,\n",
            "       1.30073342e-03, 5.11940336e-04, 9.68309760e-04, 9.63959028e-04,\n",
            "       1.94611945e-04, 2.18083058e-03, 1.11274701e-03, 4.91179992e-04,\n",
            "       3.77267046e-04, 7.19504955e-04, 1.12022867e-03, 3.73564125e-03,\n",
            "       2.10767801e-04, 8.58845669e-05, 1.31229311e-03, 5.77766798e-04,\n",
            "       7.23816222e-04, 9.23209242e-04, 9.09712689e-04, 2.87200732e-04,\n",
            "       2.11710157e-03, 1.15178234e-04, 5.21699476e-05, 3.82174512e-05,\n",
            "       2.50796526e-04, 2.30298101e-04, 5.89093252e-04, 9.00070008e-04,\n",
            "       1.17750547e-03, 2.50074198e-04, 2.40833775e-04, 3.06943228e-04,\n",
            "       1.22011593e-03, 1.55373637e-04, 1.11633824e-04, 5.11682068e-04,\n",
            "       9.66679727e-05, 7.06449733e-04, 2.52254517e-03, 3.32247675e-03,\n",
            "       5.26034739e-04, 3.92971141e-03, 5.49003598e-04, 2.90233147e-04,\n",
            "       8.88143259e-05, 7.92764477e-05, 3.43329215e-04, 7.20194366e-04,\n",
            "       1.34454237e-03, 2.00274051e-03, 1.10296554e-04, 4.82032374e-05,\n",
            "       2.01531861e-04, 1.79541457e-04, 6.74883719e-04, 1.10638246e-03,\n",
            "       5.89178817e-04, 1.17891806e-03, 1.05978933e-03, 5.14861487e-04,\n",
            "       3.96279182e-04, 3.05042602e-04, 7.85082695e-04, 4.25634498e-04,\n",
            "       1.43060158e-03, 2.62706680e-03, 1.32428133e-04, 7.29491469e-04,\n",
            "       3.58282268e-05, 5.50913392e-04, 9.92296729e-04, 7.77483510e-04,\n",
            "       3.29721894e-04, 3.45585693e-04, 4.85919241e-04, 8.58401065e-04,\n",
            "       1.50989654e-04, 7.07912666e-04, 3.67655477e-04, 1.06645806e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 369, 'shape': array([  1,   3,   3, 192], dtype=int32), 'shape_signature': array([  1,   3,   3, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00595748, 0.01312813, 0.0395208 , 0.00160882, 0.00193108,\n",
            "       0.00287609, 0.07744811, 0.00558872, 0.00456131, 0.00858343,\n",
            "       0.03078901, 0.042326  , 0.01779773, 0.00801825, 0.01080855,\n",
            "       0.0028454 , 0.00339367, 0.01828717, 0.00264292, 0.01549393,\n",
            "       0.00131917, 0.01350429, 0.04467557, 0.012353  , 0.03250286,\n",
            "       0.02386548, 0.01759204, 0.00642278, 0.04757851, 0.00232136,\n",
            "       0.00374232, 0.00074734, 0.00304761, 0.00188197, 0.04132213,\n",
            "       0.0240074 , 0.00091638, 0.00270003, 0.00227712, 0.06361941,\n",
            "       0.03774537, 0.03973683, 0.02781714, 0.01466163, 0.03704316,\n",
            "       0.01025566, 0.01439358, 0.01107362, 0.00435819, 0.01250579,\n",
            "       0.01494785, 0.00966104, 0.01334807, 0.00179482, 0.00491064,\n",
            "       0.01824399, 0.04625756, 0.02061364, 0.00660567, 0.00490868,\n",
            "       0.0105861 , 0.03639962, 0.02768806, 0.08155847, 0.05988927,\n",
            "       0.00167463, 0.00227928, 0.07127465, 0.01843378, 0.0120182 ,\n",
            "       0.00626507, 0.009539  , 0.04497796, 0.01815444, 0.01896364,\n",
            "       0.02383433, 0.00271168, 0.05197221, 0.00606175, 0.02859369,\n",
            "       0.05112078, 0.0230185 , 0.01779512, 0.01509096, 0.02221195,\n",
            "       0.02424766, 0.00448317, 0.03887812, 0.04881564, 0.06691256,\n",
            "       0.00244983, 0.06237427, 0.00429076, 0.01128625, 0.00305458,\n",
            "       0.01975619, 0.00348896, 0.00525111, 0.02648313, 0.00306819,\n",
            "       0.01690334, 0.01728994, 0.01150748, 0.0017957 , 0.01172102,\n",
            "       0.00545908, 0.01352734, 0.02113102, 0.01649603, 0.0095154 ,\n",
            "       0.03273052, 0.02097019, 0.02502304, 0.00984852, 0.01862799,\n",
            "       0.0185443 , 0.00374387, 0.04195403, 0.02140663, 0.00944914,\n",
            "       0.00725773, 0.01384158, 0.02155055, 0.07186492, 0.00405467,\n",
            "       0.00165222, 0.02524542, 0.01111487, 0.01392452, 0.01776037,\n",
            "       0.01750072, 0.00552506, 0.04072804, 0.00221576, 0.00100363,\n",
            "       0.00073521, 0.00482473, 0.00443039, 0.01133276, 0.01731522,\n",
            "       0.02265242, 0.00481084, 0.00463307, 0.00590486, 0.02347215,\n",
            "       0.00298902, 0.00214757, 0.00984356, 0.00185966, 0.01359043,\n",
            "       0.04852781, 0.06391661, 0.01011967, 0.07559837, 0.01056153,\n",
            "       0.0055834 , 0.00170858, 0.00152509, 0.00660484, 0.01385484,\n",
            "       0.02586582, 0.038528  , 0.00212185, 0.00092732, 0.003877  ,\n",
            "       0.00345395, 0.01298317, 0.02128419, 0.01133441, 0.0226796 ,\n",
            "       0.02038785, 0.00990472, 0.00762348, 0.0058683 , 0.01510314,\n",
            "       0.0081882 , 0.0275214 , 0.05053856, 0.0025476 , 0.01403369,\n",
            "       0.00068925, 0.01059827, 0.01908945, 0.01495695, 0.00634307,\n",
            "       0.00664825, 0.00934794, 0.01651361, 0.00290468, 0.01361857,\n",
            "       0.00707282, 0.00205161], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 370, 'shape': array([192], dtype=int32), 'shape_signature': array([192], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.50785607e-04, 8.62512388e-05, 1.93017295e-05, 2.49326637e-04,\n",
            "       1.87891681e-04, 1.98995738e-04, 1.88715276e-05, 1.94640219e-04,\n",
            "       1.78211223e-04, 1.18644188e-04, 5.09475467e-05, 2.85405913e-05,\n",
            "       9.83926002e-05, 2.25552503e-04, 1.98668728e-04, 2.95245845e-04,\n",
            "       1.54362628e-04, 2.38261600e-05, 1.71964202e-04, 5.84716181e-05,\n",
            "       2.61695473e-04, 1.04526422e-04, 5.59621803e-05, 1.48831372e-04,\n",
            "       1.88908452e-04, 2.02238924e-04, 1.64170597e-05, 1.65124351e-04,\n",
            "       2.34466697e-05, 6.65057232e-05, 1.12360009e-04, 2.70521239e-04,\n",
            "       8.72591263e-05, 7.64056604e-05, 9.81570265e-05, 7.99853224e-05,\n",
            "       2.68022675e-04, 3.42951098e-04, 2.12247527e-04, 2.97939077e-05,\n",
            "       5.76127168e-05, 1.87125679e-05, 4.47121747e-05, 3.66528984e-05,\n",
            "       2.29996022e-05, 2.83996833e-05, 1.36793213e-04, 1.90444145e-04,\n",
            "       1.41083976e-04, 2.97130115e-04, 1.19125783e-04, 1.85735698e-04,\n",
            "       2.58188200e-04, 2.58287793e-04, 1.50746084e-04, 2.25925796e-05,\n",
            "       1.44118865e-04, 1.55014903e-04, 6.18561462e-05, 2.29038298e-04,\n",
            "       2.61833891e-04, 5.91607895e-05, 1.39238036e-04, 2.04923381e-05,\n",
            "       2.16028784e-05, 2.43458446e-04, 1.27421095e-04, 2.17098641e-05,\n",
            "       1.82027652e-04, 4.05470309e-05, 1.22688230e-04, 1.16066498e-04,\n",
            "       2.32943494e-05, 3.33382719e-04, 7.12199253e-05, 1.65350473e-04,\n",
            "       1.99441551e-04, 1.64572455e-04, 1.96646011e-04, 1.40364689e-04,\n",
            "       1.55638372e-05, 1.26615298e-04, 2.22456802e-05, 1.33884474e-04,\n",
            "       1.99662518e-05, 1.77622744e-04, 1.75186709e-04, 4.75285633e-05,\n",
            "       3.78345867e-05, 7.82505740e-05, 3.84747953e-04, 3.52745083e-05,\n",
            "       3.61754559e-04, 2.32452676e-05, 4.44550707e-04, 1.09461944e-04,\n",
            "       8.70169679e-05, 1.24600236e-04, 1.75105059e-04, 1.50837295e-04,\n",
            "       8.51222794e-05, 2.66985619e-04, 6.93484180e-05, 1.61000266e-04,\n",
            "       3.91824869e-05, 1.24182712e-04, 1.72622065e-04, 1.41959856e-04,\n",
            "       5.40839865e-05, 2.11544917e-04, 3.98114935e-05, 1.83484895e-04,\n",
            "       2.47550070e-05, 1.08475477e-04, 5.87656941e-05, 6.68415814e-05,\n",
            "       2.55144725e-04, 2.06379937e-05, 1.50160617e-04, 5.90409254e-05,\n",
            "       6.15854442e-05, 1.61318807e-04, 3.76427852e-05, 2.45563842e-05,\n",
            "       1.42072997e-04, 1.28809392e-04, 7.57551534e-05, 1.92752414e-04,\n",
            "       3.52817333e-05, 1.91311425e-04, 4.42485471e-05, 2.39067274e-04,\n",
            "       4.06113431e-05, 1.87185680e-04, 1.29922773e-04, 3.56068049e-04,\n",
            "       1.06521562e-04, 1.48322302e-04, 7.70147381e-05, 1.09028151e-04,\n",
            "       2.04050724e-04, 6.57981873e-05, 1.57370203e-04, 2.49427540e-04,\n",
            "       4.88799305e-05, 1.37644383e-04, 1.36233357e-04, 1.12837733e-04,\n",
            "       2.58260057e-04, 2.88213079e-04, 1.39336607e-05, 2.24722935e-05,\n",
            "       1.76896749e-04, 2.48461234e-04, 7.66981029e-05, 4.61792624e-05,\n",
            "       2.40535272e-04, 2.47031625e-04, 2.33619212e-04, 1.69239313e-04,\n",
            "       1.57637078e-05, 3.62010578e-05, 1.52529552e-04, 3.06917529e-04,\n",
            "       1.82940974e-04, 1.13489259e-04, 1.35110473e-04, 7.50778709e-05,\n",
            "       1.16305047e-04, 1.37449446e-04, 1.92231339e-04, 2.07853343e-04,\n",
            "       8.94127661e-05, 9.26869616e-05, 1.98658017e-04, 1.26320447e-04,\n",
            "       9.41960243e-05, 3.29328395e-05, 2.15914726e-04, 8.85906484e-05,\n",
            "       2.18737230e-04, 2.35580810e-04, 1.94177454e-04, 1.82641059e-04,\n",
            "       9.01618187e-05, 5.50713667e-05, 2.92199002e-05, 1.50062551e-04,\n",
            "       2.30294972e-04, 2.32035309e-04, 2.25038690e-04, 2.69934564e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 371, 'shape': array([192,   1,   1,  72], dtype=int32), 'shape_signature': array([192,   1,   1,  72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.33247600e-04, 1.33420530e-04, 2.98575051e-05, 3.85678984e-04,\n",
            "       2.90646334e-04, 3.07823007e-04, 2.91920351e-05, 3.01085529e-04,\n",
            "       2.75671802e-04, 1.83528609e-04, 7.88098623e-05, 4.41489392e-05,\n",
            "       1.52201785e-04, 3.48903210e-04, 3.07317154e-04, 4.56710608e-04,\n",
            "       2.38780834e-04, 3.68562687e-05, 2.66008399e-04, 9.04487169e-05,\n",
            "       4.04812105e-04, 1.61690084e-04, 8.65669135e-05, 2.30224628e-04,\n",
            "       2.92219163e-04, 3.12839838e-04, 2.53952603e-05, 2.55427964e-04,\n",
            "       3.62692408e-05, 1.02876533e-04, 1.73807726e-04, 4.18464537e-04,\n",
            "       1.34979608e-04, 1.18190575e-04, 1.51837376e-04, 1.23727892e-04,\n",
            "       4.14599577e-04, 5.30505029e-04, 3.28321970e-04, 4.60876727e-05,\n",
            "       8.91200980e-05, 2.89461423e-05, 6.91644746e-05, 5.66977214e-05,\n",
            "       3.55776792e-05, 4.39309697e-05, 2.11603023e-04, 2.94594705e-04,\n",
            "       2.18240311e-04, 4.59625357e-04, 1.84273580e-04, 2.87311297e-04,\n",
            "       3.99386801e-04, 3.99540848e-04, 2.33186467e-04, 3.49480651e-05,\n",
            "       2.22934934e-04, 2.39789835e-04, 9.56841832e-05, 3.54295305e-04,\n",
            "       4.05026221e-04, 9.15147830e-05, 2.15384862e-04, 3.16992373e-05,\n",
            "       3.34171127e-05, 3.76601587e-04, 1.97105444e-04, 3.35826080e-05,\n",
            "       2.81575369e-04, 6.27214904e-05, 1.89784259e-04, 1.79541224e-04,\n",
            "       3.60336198e-05, 5.15703869e-04, 1.10168847e-04, 2.55777733e-04,\n",
            "       3.08512623e-04, 2.54574232e-04, 3.04188259e-04, 2.17127672e-04,\n",
            "       2.40754271e-05, 1.95858986e-04, 3.44114524e-05, 2.07103541e-04,\n",
            "       3.08854433e-05, 2.74761493e-04, 2.70993245e-04, 7.35210997e-05,\n",
            "       5.85256566e-05, 1.21044439e-04, 5.95159829e-04, 5.45655166e-05,\n",
            "       5.59591746e-04, 3.59576952e-05, 6.87667693e-04, 1.69324761e-04,\n",
            "       1.34605012e-04, 1.92741922e-04, 2.70866934e-04, 2.33327562e-04,\n",
            "       1.31674155e-04, 4.12995345e-04, 1.07273845e-04, 2.49048491e-04,\n",
            "       6.06106987e-05, 1.92096049e-04, 2.67026044e-04, 2.19595211e-04,\n",
            "       8.36615654e-05, 3.27235117e-04, 6.15836980e-05, 2.83829548e-04,\n",
            "       3.82930848e-05, 1.67798804e-04, 9.09036171e-05, 1.03396065e-04,\n",
            "       3.94678907e-04, 3.19245482e-05, 2.32280814e-04, 9.13293698e-05,\n",
            "       9.52654445e-05, 2.49541219e-04, 5.82289613e-05, 3.79858393e-05,\n",
            "       2.19770212e-04, 1.99252972e-04, 1.17184311e-04, 2.98165309e-04,\n",
            "       5.45766925e-05, 2.95936276e-04, 6.84472980e-05, 3.69808957e-04,\n",
            "       6.28209746e-05, 2.89554242e-04, 2.00975250e-04, 5.50795405e-04,\n",
            "       1.64776327e-04, 2.29437166e-04, 1.19132746e-04, 1.68653729e-04,\n",
            "       3.15642479e-04, 1.01782054e-04, 2.43433198e-04, 3.85835068e-04,\n",
            "       7.56115041e-05, 2.12919680e-04, 2.10736980e-04, 1.74546702e-04,\n",
            "       3.99497920e-04, 4.45831742e-04, 2.15537348e-05, 3.47619971e-05,\n",
            "       2.73638463e-04, 3.84340296e-04, 1.18642951e-04, 7.14338894e-05,\n",
            "       3.72079783e-04, 3.82128870e-04, 3.61381448e-04, 2.61793321e-04,\n",
            "       2.43846025e-05, 5.59987820e-05, 2.35945277e-04, 4.74765344e-04,\n",
            "       2.82988185e-04, 1.75554538e-04, 2.09000005e-04, 1.16136638e-04,\n",
            "       1.79910232e-04, 2.12618135e-04, 2.97359278e-04, 3.21524683e-04,\n",
            "       1.38311036e-04, 1.43375830e-04, 3.07300594e-04, 1.95402885e-04,\n",
            "       1.45710175e-04, 5.09432284e-05, 3.33994685e-04, 1.37039315e-04,\n",
            "       3.38360784e-04, 3.64415813e-04, 3.00369691e-04, 2.82524241e-04,\n",
            "       1.39469732e-04, 8.51889272e-05, 4.51997512e-05, 2.32129125e-04,\n",
            "       3.56239238e-04, 3.58931342e-04, 3.48108384e-04, 4.17557021e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/rezero/mul', 'index': 372, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.007421455346047878, 127), 'quantization_parameters': {'scales': array([0.00742146], dtype=float32), 'zero_points': array([127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 373, 'shape': array([72], dtype=int32), 'shape_signature': array([72], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00032647, 0.00045994, 0.00025232, 0.00034143, 0.00043673,\n",
            "       0.00053013, 0.00045463, 0.00038449, 0.000379  , 0.00038429,\n",
            "       0.00035821, 0.00048178, 0.00031572, 0.00034307, 0.00041766,\n",
            "       0.00037172, 0.00035095, 0.00029082, 0.00042595, 0.00028729,\n",
            "       0.00027269, 0.00042232, 0.00038543, 0.0003605 , 0.00036981,\n",
            "       0.0004221 , 0.00025095, 0.00031759, 0.00037651, 0.00050861,\n",
            "       0.00047211, 0.00041816, 0.00036932, 0.00035825, 0.0003766 ,\n",
            "       0.00031302, 0.00033505, 0.0003138 , 0.00029773, 0.0003376 ,\n",
            "       0.00039345, 0.0004151 , 0.00095462, 0.00036796, 0.00041684,\n",
            "       0.00024634, 0.00034802, 0.00041719, 0.0002892 , 0.00039896,\n",
            "       0.00028355, 0.00046441, 0.00034887, 0.00028182, 0.00046449,\n",
            "       0.0003654 , 0.00061437, 0.00035861, 0.00042106, 0.00027496,\n",
            "       0.00029945, 0.0004352 , 0.00041824, 0.00030046, 0.00031938,\n",
            "       0.00037263, 0.00057677, 0.0002799 , 0.00032461, 0.00028614,\n",
            "       0.00036152, 0.00036876], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 374, 'shape': array([ 72,   1,   1, 240], dtype=int32), 'shape_signature': array([ 72,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01048755, 0.01477513, 0.00810568, 0.01096809, 0.01402946,\n",
            "       0.01702998, 0.01460466, 0.01235143, 0.01217504, 0.01234485,\n",
            "       0.01150719, 0.01547665, 0.01014231, 0.01102086, 0.01341701,\n",
            "       0.01194111, 0.01127395, 0.00934236, 0.01368313, 0.0092288 ,\n",
            "       0.00875975, 0.01356668, 0.0123814 , 0.01158071, 0.01187964,\n",
            "       0.01355964, 0.00806151, 0.01020219, 0.0120951 , 0.01633845,\n",
            "       0.01516597, 0.01343284, 0.0118641 , 0.01150856, 0.0120979 ,\n",
            "       0.0100555 , 0.01076305, 0.01008048, 0.00956436, 0.01084522,\n",
            "       0.01263929, 0.01333455, 0.03066614, 0.01182052, 0.01339042,\n",
            "       0.00791346, 0.01117985, 0.01340192, 0.00929025, 0.01281611,\n",
            "       0.00910881, 0.01491865, 0.01120716, 0.00905322, 0.01492121,\n",
            "       0.01173797, 0.01973607, 0.01152016, 0.01352605, 0.00883278,\n",
            "       0.00961941, 0.01398031, 0.01343548, 0.00965189, 0.01025967,\n",
            "       0.01197039, 0.01852813, 0.00899166, 0.01042766, 0.00919189,\n",
            "       0.0116136 , 0.01184601], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block2_layer2/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block2_layer2/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block2_layer2/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer2/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 375, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.42469671e-05, 1.07393034e-05, 1.67895651e-05, 1.62913202e-05,\n",
            "       1.56880324e-05, 2.21635601e-05, 7.21720289e-06, 1.35686969e-05,\n",
            "       2.98503237e-05, 7.86370401e-06, 2.32311850e-05, 2.99080657e-05,\n",
            "       2.41986854e-05, 2.95957980e-05, 2.14022657e-05, 2.33616138e-05,\n",
            "       2.39990459e-05, 1.59638967e-05, 2.57617157e-05, 2.48909291e-05,\n",
            "       2.38700686e-05, 2.18530276e-05, 2.84350353e-05, 2.29521866e-05,\n",
            "       1.50338565e-05, 1.32609885e-05, 3.13566743e-05, 1.39865988e-05,\n",
            "       1.31641109e-05, 3.04374516e-05, 2.95885675e-05, 1.86642555e-05,\n",
            "       3.58994985e-05, 2.95952268e-05, 1.15673674e-05, 1.48941172e-05,\n",
            "       1.32982104e-05, 2.18502573e-05, 2.71834560e-05, 2.54007282e-05,\n",
            "       1.39423591e-05, 1.12684756e-05, 3.08865892e-05, 3.21808620e-05,\n",
            "       1.52412731e-05, 3.00391839e-05, 2.24541782e-05, 2.01798684e-05,\n",
            "       1.57520353e-05, 2.03063883e-05, 1.64460998e-05, 2.04776534e-05,\n",
            "       1.18213075e-05, 2.60014094e-05, 3.13196178e-05, 1.41621176e-05,\n",
            "       1.98376529e-05, 1.85617082e-05, 3.98230950e-05, 1.60315212e-05,\n",
            "       2.91738761e-05, 3.17534868e-05, 1.37530224e-05, 9.53664676e-06,\n",
            "       1.87911628e-05, 2.20700240e-05, 1.87818550e-05, 1.71263364e-05,\n",
            "       1.99912483e-05, 1.41757091e-05, 1.34225411e-05, 2.60180805e-05,\n",
            "       1.79941053e-05, 1.25265642e-05, 1.87127516e-05, 1.04941419e-05,\n",
            "       1.35870359e-05, 1.34351812e-05, 2.48109063e-05, 2.44703260e-05,\n",
            "       2.12822943e-05, 2.36349988e-05, 7.18691399e-06, 1.86848956e-05,\n",
            "       2.48279357e-05, 2.04183743e-05, 2.16688059e-05, 2.46355157e-05,\n",
            "       2.46795680e-05, 1.91782729e-05, 9.05774414e-06, 1.00940597e-05,\n",
            "       1.14042841e-05, 1.49046955e-05, 3.75980890e-05, 1.62398610e-05,\n",
            "       1.62336146e-05, 2.42932383e-05, 2.72781745e-05, 2.44799303e-05,\n",
            "       1.41631672e-05, 1.23651098e-05, 1.02691292e-05, 2.82732817e-05,\n",
            "       1.62196193e-05, 1.68708575e-05, 1.58563616e-05, 2.77515355e-05,\n",
            "       1.36138260e-05, 2.11268070e-05, 1.79156796e-05, 1.10631936e-05,\n",
            "       2.24979703e-05, 1.07654951e-05, 1.20537752e-05, 2.19041085e-05,\n",
            "       1.25089746e-05, 1.39762124e-05, 2.30780533e-05, 1.31419256e-05,\n",
            "       2.13815001e-05, 1.63146324e-05, 8.01687474e-06, 2.90274602e-05,\n",
            "       1.21047842e-05, 1.95213142e-05, 1.70452258e-05, 1.75764835e-05,\n",
            "       1.71751017e-05, 2.74514259e-05, 1.95784596e-05, 1.12920952e-05,\n",
            "       1.48825902e-05, 1.99764054e-05, 2.01096063e-05, 1.28903112e-05,\n",
            "       2.11896986e-05, 1.35220243e-05, 1.65685324e-05, 1.30173776e-05,\n",
            "       1.99907081e-05, 2.23929492e-05, 1.49516873e-05, 2.45927495e-05,\n",
            "       1.35160162e-05, 1.65784404e-05, 3.86554675e-05, 2.01206403e-05,\n",
            "       1.71973406e-05, 2.45789088e-05, 3.35665900e-05, 2.14719494e-05,\n",
            "       3.26768823e-05, 2.93771827e-05, 1.55234356e-05, 2.36879096e-05,\n",
            "       9.42764746e-06, 2.02715528e-05, 2.35380267e-05, 1.48190356e-05,\n",
            "       1.69257255e-05, 1.47130786e-05, 2.07714456e-05, 2.01717357e-05,\n",
            "       1.38336109e-05, 1.22241090e-05, 1.04024211e-05, 1.44779879e-05,\n",
            "       2.54222705e-05, 1.39959047e-05, 8.05989293e-06, 2.50409339e-05,\n",
            "       1.96002729e-05, 1.57706854e-05, 2.68792683e-05, 1.70549702e-05,\n",
            "       1.35928021e-05, 1.93074047e-05, 2.30293135e-05, 1.57847280e-05,\n",
            "       3.42386120e-05, 2.62264966e-05, 2.17177512e-05, 2.02635183e-05,\n",
            "       1.23223926e-05, 1.00608004e-05, 2.59039280e-05, 1.89569582e-05,\n",
            "       1.40496904e-05, 1.37786074e-05, 1.96120563e-05, 3.20949766e-05,\n",
            "       1.37998477e-05, 1.05594654e-05, 9.95360188e-06, 8.21383128e-06,\n",
            "       2.85279912e-05, 6.98458389e-05, 1.74152465e-05, 1.68204606e-05,\n",
            "       2.74692829e-05, 2.50534631e-05, 9.17955731e-06, 3.06727998e-05,\n",
            "       2.05742763e-05, 1.52036109e-05, 1.93455435e-05, 2.95582649e-05,\n",
            "       2.84505786e-05, 2.45877654e-05, 1.88774393e-05, 2.17136239e-05,\n",
            "       1.52823850e-05, 2.46741038e-05, 2.69797292e-05, 1.53313322e-05,\n",
            "       1.70818130e-05, 2.33203591e-05, 1.29576783e-05, 4.72419852e-05,\n",
            "       1.93257802e-05, 2.26255761e-05, 1.88441481e-05, 3.14143108e-05,\n",
            "       1.89169896e-05, 1.33147814e-05, 2.00975846e-05, 2.68719559e-05,\n",
            "       1.33174772e-05, 2.53979124e-05, 1.73469853e-05, 4.46080194e-05,\n",
            "       1.92559146e-05, 1.32652094e-05, 1.44852020e-05, 5.18479901e-05,\n",
            "       3.42186177e-05, 3.75583695e-05, 2.26331631e-05, 2.45685424e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 376, 'shape': array([240,   1,   1, 120], dtype=int32), 'shape_signature': array([240,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.0007132 , 0.00053761, 0.00084049, 0.00081554, 0.00078534,\n",
            "       0.00110951, 0.00036129, 0.00067925, 0.00149431, 0.00039366,\n",
            "       0.00116295, 0.0014972 , 0.00121139, 0.00148156, 0.0010714 ,\n",
            "       0.00116948, 0.00120139, 0.00079915, 0.00128963, 0.00124604,\n",
            "       0.00119494, 0.00109396, 0.00142346, 0.00114899, 0.00075259,\n",
            "       0.00066384, 0.00156971, 0.00070017, 0.000659  , 0.0015237 ,\n",
            "       0.0014812 , 0.00093433, 0.00179713, 0.00148154, 0.00057906,\n",
            "       0.0007456 , 0.00066571, 0.00109382, 0.0013608 , 0.00127156,\n",
            "       0.00069795, 0.0005641 , 0.00154618, 0.00161097, 0.00076298,\n",
            "       0.00150376, 0.00112406, 0.0010102 , 0.00078855, 0.00101654,\n",
            "       0.00082329, 0.00102511, 0.00059177, 0.00130163, 0.00156786,\n",
            "       0.00070896, 0.00099307, 0.0009292 , 0.00199354, 0.00080254,\n",
            "       0.00146044, 0.00158958, 0.00068848, 0.0004774 , 0.00094069,\n",
            "       0.00110482, 0.00094022, 0.00085734, 0.00100076, 0.00070964,\n",
            "       0.00067193, 0.00130246, 0.00090078, 0.00062708, 0.00093676,\n",
            "       0.00052534, 0.00068017, 0.00067256, 0.00124203, 0.00122498,\n",
            "       0.00106539, 0.00118317, 0.00035978, 0.00093537, 0.00124289,\n",
            "       0.00102214, 0.00108474, 0.00123325, 0.00123546, 0.00096006,\n",
            "       0.00045343, 0.00050531, 0.0005709 , 0.00074613, 0.00188216,\n",
            "       0.00081297, 0.00081265, 0.00121612, 0.00136554, 0.00122546,\n",
            "       0.00070901, 0.000619  , 0.00051407, 0.00141536, 0.00081195,\n",
            "       0.00084455, 0.00079377, 0.00138924, 0.00068151, 0.00105761,\n",
            "       0.00089686, 0.00055382, 0.00112625, 0.00053892, 0.00060341,\n",
            "       0.00109652, 0.0006262 , 0.00069965, 0.00115529, 0.00065788,\n",
            "       0.00107036, 0.00081671, 0.00040132, 0.00145311, 0.00060597,\n",
            "       0.00097724, 0.00085328, 0.00087988, 0.00085979, 0.00137422,\n",
            "       0.0009801 , 0.00056528, 0.00074502, 0.00100002, 0.00100669,\n",
            "       0.00064529, 0.00106076, 0.00067691, 0.00082942, 0.00065165,\n",
            "       0.00100073, 0.00112099, 0.00074848, 0.00123111, 0.00067661,\n",
            "       0.00082992, 0.00193509, 0.00100724, 0.0008609 , 0.00123042,\n",
            "       0.00168034, 0.00107489, 0.0016358 , 0.00147062, 0.0007771 ,\n",
            "       0.00118582, 0.00047195, 0.00101479, 0.00117831, 0.00074184,\n",
            "       0.0008473 , 0.00073654, 0.00103982, 0.0010098 , 0.00069251,\n",
            "       0.00061194, 0.00052074, 0.00072477, 0.00127264, 0.00070063,\n",
            "       0.00040348, 0.00125355, 0.00098119, 0.00078948, 0.00134558,\n",
            "       0.00085377, 0.00068046, 0.00096653, 0.00115285, 0.00079018,\n",
            "       0.00171398, 0.0013129 , 0.00108719, 0.00101439, 0.00061686,\n",
            "       0.00050364, 0.00129675, 0.00094898, 0.00070333, 0.00068976,\n",
            "       0.00098178, 0.00160667, 0.00069082, 0.00052861, 0.00049828,\n",
            "       0.00041118, 0.00142811, 0.00349648, 0.00087181, 0.00084203,\n",
            "       0.00137511, 0.00125418, 0.00045953, 0.00153548, 0.00102995,\n",
            "       0.00076109, 0.00096844, 0.00147969, 0.00142424, 0.00123086,\n",
            "       0.000945  , 0.00108698, 0.00076504, 0.00123519, 0.0013506 ,\n",
            "       0.00076749, 0.00085512, 0.00116742, 0.00064866, 0.00236493,\n",
            "       0.00096745, 0.00113264, 0.00094334, 0.0015726 , 0.00094698,\n",
            "       0.00066654, 0.00100608, 0.00134521, 0.00066667, 0.00127142,\n",
            "       0.00086839, 0.00223308, 0.00096395, 0.00066406, 0.00072513,\n",
            "       0.00259551, 0.00171298, 0.00188017, 0.00113302, 0.0012299 ],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 377, 'shape': array([120], dtype=int32), 'shape_signature': array([120], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.8166395e-05, 2.3430659e-05, 9.3838178e-05, 7.9066820e-05,\n",
            "       1.2563357e-04, 2.8129953e-05, 9.4170340e-05, 1.3341313e-05,\n",
            "       8.3009727e-05, 4.0475556e-05, 3.0677274e-05, 1.1912131e-05,\n",
            "       4.2444713e-05, 5.7274516e-05, 1.5027079e-05, 7.1158422e-05,\n",
            "       3.6307167e-05, 3.4402943e-05, 3.9072776e-05, 6.3158230e-05,\n",
            "       3.9242062e-05, 6.2264873e-05, 5.2306972e-05, 4.4562210e-05,\n",
            "       2.8227818e-05, 3.1733660e-05, 8.3265491e-05, 1.0804348e-05,\n",
            "       4.8152971e-05, 6.4264896e-05, 3.1165015e-05, 8.2231847e-05,\n",
            "       1.6706925e-05, 2.5863046e-05, 2.1936787e-05, 4.8655162e-05,\n",
            "       9.1699963e-05, 2.7638976e-05, 3.7795668e-05, 2.4791538e-05,\n",
            "       3.6640897e-05, 4.4214510e-05, 3.9861254e-05, 2.8205681e-05,\n",
            "       2.6544511e-05, 2.4245293e-05, 6.2224746e-05, 6.3617343e-05,\n",
            "       1.1302350e-04, 1.7425358e-05, 2.7941504e-05, 1.4604284e-05,\n",
            "       3.2094067e-05, 1.8993076e-05, 8.0178594e-05, 6.6599401e-05,\n",
            "       1.5234862e-05, 3.4022312e-05, 4.4739798e-05, 5.2299813e-05,\n",
            "       7.3501840e-05, 1.7416934e-05, 6.0034268e-05, 4.9853657e-05,\n",
            "       2.9334067e-05, 3.4428820e-05, 1.4084529e-05, 7.4875570e-05,\n",
            "       1.1396880e-04, 4.9563532e-05, 4.5050390e-05, 3.0584823e-05,\n",
            "       4.7156838e-05, 5.2002906e-05, 3.7904589e-05, 1.6590293e-05,\n",
            "       4.1684169e-05, 5.2297084e-05, 3.7919413e-05, 5.8244816e-05,\n",
            "       2.1321883e-05, 1.1286033e-04, 5.1702937e-05, 8.7476867e-05,\n",
            "       4.5100274e-05, 1.4296353e-04, 7.1270719e-05, 2.5873625e-05,\n",
            "       2.4550774e-05, 5.7155157e-05, 2.7847545e-05, 4.8791699e-05,\n",
            "       6.4540684e-05, 6.0932296e-05, 3.4529279e-05, 5.6700770e-05,\n",
            "       3.6530582e-05, 1.7141123e-05, 5.1634921e-05, 3.5912657e-05,\n",
            "       1.0523125e-04, 4.1269970e-05, 2.2658500e-05, 4.7261587e-05,\n",
            "       3.7678292e-05, 3.6975842e-05, 4.3123982e-05, 3.4607718e-05,\n",
            "       4.9082762e-05, 2.1602218e-05, 6.8403562e-05, 2.6645163e-05,\n",
            "       3.6342572e-05, 3.7334150e-05, 2.8703114e-05, 8.4080792e-05,\n",
            "       3.3601726e-05, 2.6984177e-05, 3.0635249e-05, 8.8349138e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 378, 'shape': array([120,   1,   1, 480], dtype=int32), 'shape_signature': array([120,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00050422, 0.00065033, 0.00260454, 0.00219456, 0.00348705,\n",
            "       0.00078077, 0.00261376, 0.0003703 , 0.00230399, 0.00112343,\n",
            "       0.00085147, 0.00033063, 0.00117808, 0.00158969, 0.00041709,\n",
            "       0.00197505, 0.00100773, 0.00095488, 0.00108449, 0.001753  ,\n",
            "       0.00108919, 0.00172821, 0.00145182, 0.00123686, 0.00078348,\n",
            "       0.00088079, 0.00231109, 0.00029988, 0.00133652, 0.00178372,\n",
            "       0.00086501, 0.0022824 , 0.00046371, 0.00071785, 0.00060887,\n",
            "       0.00135046, 0.0025452 , 0.00076714, 0.00104905, 0.00068811,\n",
            "       0.00101699, 0.0012272 , 0.00110638, 0.00078287, 0.00073676,\n",
            "       0.00067295, 0.00172709, 0.00176574, 0.00313705, 0.00048365,\n",
            "       0.00077554, 0.00040535, 0.00089079, 0.00052717, 0.00222541,\n",
            "       0.00184851, 0.00042285, 0.00094431, 0.00124178, 0.00145162,\n",
            "       0.0020401 , 0.00048342, 0.00166629, 0.00138372, 0.00081419,\n",
            "       0.0009556 , 0.00039093, 0.00207822, 0.00316328, 0.00137567,\n",
            "       0.00125041, 0.0008489 , 0.00130887, 0.00144338, 0.00105207,\n",
            "       0.00046048, 0.00115697, 0.00145154, 0.00105248, 0.00161663,\n",
            "       0.0005918 , 0.00313252, 0.00143505, 0.00242798, 0.00125179,\n",
            "       0.00396805, 0.00197817, 0.00071814, 0.00068142, 0.00158638,\n",
            "       0.00077293, 0.00135425, 0.00179137, 0.00169122, 0.00095838,\n",
            "       0.00157377, 0.00101393, 0.00047576, 0.00143316, 0.00099678,\n",
            "       0.00292077, 0.00114548, 0.0006289 , 0.00131178, 0.00104579,\n",
            "       0.00102629, 0.00119694, 0.00096056, 0.00136233, 0.00059958,\n",
            "       0.00189859, 0.00073956, 0.00100871, 0.00103624, 0.00079668,\n",
            "       0.00233372, 0.00093264, 0.00074896, 0.0008503 , 0.00245219],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 379, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00389972, 0.00149128, 0.00104087, 0.00671628, 0.0054282 ,\n",
            "       0.00133873, 0.00545444, 0.00057241, 0.01054865, 0.00106223,\n",
            "       0.00894848, 0.00365977, 0.00589215, 0.01296088, 0.00143225,\n",
            "       0.00125143, 0.00187861, 0.00248006, 0.00154078, 0.00488467,\n",
            "       0.00348267, 0.009413  , 0.00608898, 0.00137852, 0.00157358,\n",
            "       0.00120599, 0.00240863, 0.00119847, 0.00608818, 0.00110616,\n",
            "       0.00246997, 0.01064462, 0.0101916 , 0.00662163, 0.00572769,\n",
            "       0.00282444, 0.00333382, 0.00104609, 0.00254426, 0.00598716,\n",
            "       0.00063222, 0.00075437, 0.00120675, 0.00094715, 0.00301336,\n",
            "       0.00212171, 0.00516857, 0.00510428, 0.00085043, 0.00185684,\n",
            "       0.00124993, 0.01206464, 0.00329172, 0.00278578, 0.00324324,\n",
            "       0.00150383, 0.00697954, 0.00472669, 0.00306251, 0.00126137,\n",
            "       0.00125813, 0.00856203, 0.0054452 , 0.00116738, 0.00225305,\n",
            "       0.0034356 , 0.00096555, 0.00794121, 0.00454703, 0.00142256,\n",
            "       0.00143825, 0.00655082, 0.00148865, 0.00260663, 0.00174125,\n",
            "       0.00073556, 0.00387781, 0.00145896, 0.00142864, 0.00620744,\n",
            "       0.0124679 , 0.0026004 , 0.00210403, 0.00085555, 0.00281301,\n",
            "       0.01071489, 0.00166135, 0.0008892 , 0.00512763, 0.0007548 ,\n",
            "       0.00183794, 0.00644796, 0.0006347 , 0.00063367, 0.00801557,\n",
            "       0.00062272, 0.00090554, 0.0098885 , 0.00289456, 0.00752975,\n",
            "       0.00248667, 0.01360727, 0.00454712, 0.0012707 , 0.01278798,\n",
            "       0.0083556 , 0.00069567, 0.00869631, 0.00539213, 0.01086771,\n",
            "       0.00089265, 0.00217979, 0.00211622, 0.00178944, 0.01207573,\n",
            "       0.00324575, 0.0043834 , 0.00867337, 0.00502685, 0.00420467,\n",
            "       0.00376754, 0.01479459, 0.00630457, 0.00100745, 0.00807239,\n",
            "       0.00801119, 0.00074474, 0.00629692, 0.00222832, 0.00054271,\n",
            "       0.01350892, 0.00887151, 0.0088631 , 0.00405726, 0.00182943,\n",
            "       0.0022096 , 0.00089711, 0.00068295, 0.00571431, 0.00111605,\n",
            "       0.00975702, 0.01170741, 0.00128205, 0.01813787, 0.00579288,\n",
            "       0.00294377, 0.00300971, 0.01177053, 0.01298759, 0.00081197,\n",
            "       0.00086504, 0.01491176, 0.00177154, 0.01080745, 0.00290616,\n",
            "       0.00686546, 0.0043325 , 0.00255292, 0.00913817, 0.01194823,\n",
            "       0.00769119, 0.00129296, 0.00236206, 0.00967119, 0.00535283,\n",
            "       0.0053869 , 0.00067401, 0.0105667 , 0.00066685, 0.00110706,\n",
            "       0.00114565, 0.00125853, 0.01053724, 0.00552534, 0.00451055,\n",
            "       0.00252082, 0.00189818, 0.00109756, 0.00277108, 0.0021052 ,\n",
            "       0.00255533, 0.00077235, 0.00127965, 0.00316771, 0.00398551,\n",
            "       0.00434663, 0.00100869, 0.00821686, 0.01191177, 0.00151968,\n",
            "       0.0008438 , 0.00140367, 0.00354066, 0.00094033, 0.00771817,\n",
            "       0.00116513, 0.00387878, 0.00232306, 0.00198954, 0.00482058,\n",
            "       0.0132471 , 0.00127553, 0.00167057, 0.00813233, 0.00769708,\n",
            "       0.00127888, 0.00153593, 0.00940696, 0.00272446, 0.00133603,\n",
            "       0.00969713, 0.00123589, 0.00672444, 0.00188995, 0.00245128,\n",
            "       0.01545394, 0.00077911, 0.00207346, 0.00121715, 0.00481231,\n",
            "       0.00100353, 0.00296305, 0.00734566, 0.00090773, 0.00105735,\n",
            "       0.00079815, 0.00098156, 0.00110021, 0.00847184, 0.0044821 ,\n",
            "       0.00124784, 0.00813472, 0.00177586, 0.00301528, 0.0018498 ,\n",
            "       0.0028881 , 0.01141211, 0.00500577, 0.00211583, 0.00629864],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul', 'index': 380, 'shape': array([  1,   3,   1, 240], dtype=int32), 'shape_signature': array([  1,   3,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.03664543, 0.01401345, 0.00978095, 0.06311244, 0.05100851,\n",
            "       0.01258001, 0.05125503, 0.00537887, 0.09912504, 0.00998172,\n",
            "       0.08408833, 0.03439062, 0.05536823, 0.12179262, 0.01345874,\n",
            "       0.01175959, 0.0176532 , 0.023305  , 0.01447861, 0.04590097,\n",
            "       0.03272643, 0.0884534 , 0.05721777, 0.01295384, 0.01478686,\n",
            "       0.01133265, 0.02263377, 0.01126192, 0.0572103 , 0.01039456,\n",
            "       0.02321011, 0.10002685, 0.09576987, 0.06222303, 0.05382279,\n",
            "       0.02654113, 0.03132774, 0.00983001, 0.02390827, 0.05626096,\n",
            "       0.00594089, 0.00708878, 0.01133977, 0.00890027, 0.02831639,\n",
            "       0.01993755, 0.04856873, 0.04796462, 0.00799144, 0.01744859,\n",
            "       0.0117455 , 0.11337071, 0.03093214, 0.02617783, 0.03047649,\n",
            "       0.01413137, 0.06558629, 0.04441647, 0.02877818, 0.01185305,\n",
            "       0.01182257, 0.08045686, 0.05116818, 0.01096976, 0.02117173,\n",
            "       0.03228417, 0.00907325, 0.07462303, 0.04272822, 0.01336774,\n",
            "       0.0135152 , 0.06155764, 0.01398878, 0.02449431, 0.01636239,\n",
            "       0.006912  , 0.03643956, 0.0137098 , 0.01342482, 0.05833098,\n",
            "       0.11716013, 0.02443577, 0.01977144, 0.00803956, 0.0264337 ,\n",
            "       0.10068717, 0.01561156, 0.0083558 , 0.04818405, 0.00709285,\n",
            "       0.01727097, 0.06059108, 0.0059642 , 0.00595452, 0.07532182,\n",
            "       0.00585163, 0.00850928, 0.09292161, 0.02720003, 0.07075664,\n",
            "       0.02336712, 0.12786667, 0.04272905, 0.01194074, 0.1201679 ,\n",
            "       0.07851712, 0.00653719, 0.08171871, 0.05066948, 0.10212319,\n",
            "       0.00838821, 0.02048339, 0.01988599, 0.01681523, 0.11347491,\n",
            "       0.03050014, 0.04119053, 0.08150312, 0.04723698, 0.03951099,\n",
            "       0.03540333, 0.13902391, 0.05924365, 0.00946698, 0.07585574,\n",
            "       0.07528066, 0.00699828, 0.0591718 , 0.02093937, 0.00509979,\n",
            "       0.12694252, 0.08336508, 0.08328602, 0.03812583, 0.01719103,\n",
            "       0.02076345, 0.0084301 , 0.00641768, 0.05369706, 0.01048744,\n",
            "       0.09168612, 0.11001384, 0.01204739, 0.17044051, 0.05443531,\n",
            "       0.02766242, 0.02828203, 0.11060692, 0.12204362, 0.00763006,\n",
            "       0.00812871, 0.14012493, 0.01664702, 0.10155697, 0.02730906,\n",
            "       0.06451428, 0.04071226, 0.02398967, 0.08587087, 0.11227681,\n",
            "       0.07227369, 0.01214989, 0.02219613, 0.0908796 , 0.0503002 ,\n",
            "       0.05062041, 0.00633366, 0.09929465, 0.00626634, 0.01040297,\n",
            "       0.0107656 , 0.01182633, 0.09901778, 0.05192132, 0.04238537,\n",
            "       0.02368798, 0.01783709, 0.01031373, 0.02603967, 0.01978244,\n",
            "       0.02401231, 0.00725777, 0.01202477, 0.02976674, 0.0374516 ,\n",
            "       0.040845  , 0.00947858, 0.07721338, 0.11193416, 0.01428032,\n",
            "       0.00792909, 0.01319024, 0.03327139, 0.00883619, 0.07252721,\n",
            "       0.01094864, 0.03644868, 0.0218297 , 0.01869555, 0.04529872,\n",
            "       0.12448219, 0.01198605, 0.01569826, 0.076419  , 0.07232903,\n",
            "       0.01201753, 0.01443308, 0.08839668, 0.02560158, 0.01255463,\n",
            "       0.09112334, 0.01161355, 0.06318915, 0.01775979, 0.02303449,\n",
            "       0.14521973, 0.00732126, 0.0194842 , 0.01143753, 0.04522103,\n",
            "       0.00943015, 0.02784362, 0.06902668, 0.00852992, 0.00993585,\n",
            "       0.00750013, 0.00922364, 0.01033863, 0.07960939, 0.04211804,\n",
            "       0.01172589, 0.07644151, 0.01668767, 0.02833442, 0.01738243,\n",
            "       0.02713932, 0.10723893, 0.04703888, 0.01988231, 0.05918795],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 381, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.1137581e-03, 4.8179557e-03, 2.5728652e-03, 1.0274681e-03,\n",
            "       9.5512914e-03, 2.7227683e-03, 1.2532862e-04, 1.7662040e-03,\n",
            "       7.2748220e-04, 1.0991059e-03, 7.8436924e-04, 5.6490689e-03,\n",
            "       1.1529517e-03, 3.3298822e-03, 5.4760785e-03, 1.5911313e-03,\n",
            "       1.1009724e-03, 5.9205852e-04, 1.2988561e-03, 2.4003329e-04,\n",
            "       3.8652826e-04, 1.0001620e-04, 3.2494534e-03, 2.3616683e-03,\n",
            "       7.1622391e-04, 8.8640506e-04, 3.7911381e-03, 1.8871553e-03,\n",
            "       1.3007422e-03, 1.0261341e-03, 1.3658153e-03, 1.8787609e-03,\n",
            "       8.7170505e-05, 1.4871783e-03, 4.5854245e-05, 1.9345760e-04,\n",
            "       8.4361498e-04, 1.0734620e-03, 6.8778393e-04, 1.7421937e-04,\n",
            "       1.6005026e-03, 4.4548282e-04, 2.0995877e-04, 2.5416815e-03,\n",
            "       5.4588658e-04, 2.4864573e-03, 3.6159580e-04, 2.0411378e-03,\n",
            "       1.6746374e-03, 3.1107415e-03, 7.2281802e-04, 4.8850995e-04,\n",
            "       5.6656479e-04, 5.2952452e-04, 2.3082495e-04, 3.1384828e-03,\n",
            "       8.9768530e-04, 2.9080636e-03, 1.3312155e-03, 7.7924132e-04,\n",
            "       5.6522456e-04, 1.2462059e-04, 1.9269914e-03, 8.1316207e-04,\n",
            "       4.2296905e-04, 1.4518529e-04, 4.3388459e-04, 2.3903009e-03,\n",
            "       3.5059152e-03, 7.7696005e-04, 3.3634488e-04, 1.2680715e-04,\n",
            "       5.8290260e-03, 4.5854938e-03, 1.5055480e-03, 1.4777252e-03,\n",
            "       4.3024942e-03, 1.3856855e-03, 1.8370969e-03, 1.6546508e-04,\n",
            "       3.2985844e-03, 3.8595335e-04, 7.5972406e-04, 1.4625035e-03,\n",
            "       4.1115435e-04, 4.0612833e-04, 4.6981478e-04, 2.4894844e-03,\n",
            "       1.2341290e-03, 2.3436106e-03, 3.4891674e-04, 2.2610411e-04,\n",
            "       1.0648138e-03, 2.0518850e-03, 1.1023541e-03, 1.4947656e-03,\n",
            "       1.5267049e-03, 5.1116187e-04, 4.2554835e-04, 8.9926162e-04,\n",
            "       5.2733463e-04, 1.5688658e-04, 5.3900415e-03, 8.0829865e-04,\n",
            "       9.3032158e-04, 2.7336678e-04, 5.6241057e-03, 1.0962141e-03,\n",
            "       2.6884666e-04, 4.4236984e-03, 1.6086698e-03, 3.9585102e-03,\n",
            "       8.7857823e-04, 7.4481900e-04, 1.5358641e-03, 8.6404977e-04,\n",
            "       1.6336315e-04, 1.7681279e-03, 7.3963788e-04, 5.9853599e-04,\n",
            "       5.9365702e-04, 1.6116700e-03, 1.8150992e-04, 3.3535296e-03,\n",
            "       1.8859800e-04, 2.8795528e-03, 5.5880891e-03, 3.3574612e-03,\n",
            "       4.7785896e-04, 4.6732160e-04, 2.0191395e-04, 1.8446175e-04,\n",
            "       2.4482023e-03, 5.4368703e-04, 9.6722407e-04, 2.3105873e-03,\n",
            "       6.5811523e-03, 1.6520995e-03, 1.8536097e-04, 2.6236929e-03,\n",
            "       1.3506591e-03, 2.6530956e-03, 3.1599514e-03, 5.8226526e-04,\n",
            "       8.5370295e-04, 2.3657677e-04, 5.1235745e-04, 2.2876367e-03,\n",
            "       1.6997352e-03, 5.2735917e-03, 2.5076151e-04, 2.0964118e-04,\n",
            "       4.5232911e-04, 7.9929281e-04, 6.3015788e-04, 9.2768001e-05,\n",
            "       3.1570511e-04, 2.0364658e-03, 2.2605513e-04, 1.5335034e-04,\n",
            "       1.3351899e-03, 3.6407805e-03, 5.1001804e-03, 1.8062333e-04,\n",
            "       1.3741870e-04, 5.3045939e-04, 1.2059651e-03, 1.7820873e-04,\n",
            "       7.6880638e-04, 5.2621769e-04, 6.0177216e-04, 9.2626346e-04,\n",
            "       3.4026960e-03, 4.4663823e-03, 1.2237816e-03, 5.5769761e-03,\n",
            "       3.9647857e-04, 4.5080759e-04, 4.7092782e-03, 3.1906420e-03,\n",
            "       5.7453837e-04, 1.4345192e-03, 2.0074057e-03, 1.0787470e-03,\n",
            "       4.3082025e-04, 4.0172256e-04, 1.8717070e-03, 2.6898901e-04,\n",
            "       1.1293027e-03, 7.8198715e-04, 1.8634483e-03, 2.0512480e-03,\n",
            "       6.7815059e-03, 5.4630014e-04, 1.4739392e-04, 7.4855605e-04,\n",
            "       2.6715113e-04, 9.1977476e-04, 3.7516896e-03, 1.2572693e-04,\n",
            "       2.7096912e-04, 1.0276218e-03, 6.0578901e-04, 1.0202117e-04,\n",
            "       4.2532454e-04, 1.5039047e-03, 1.2077171e-03, 2.0821474e-04,\n",
            "       1.7931272e-03, 2.4808040e-03, 1.0883065e-03, 2.6377656e-03,\n",
            "       8.0807455e-05, 1.0128138e-03, 5.8372845e-03, 1.2817339e-04,\n",
            "       1.9802351e-03, 5.4408173e-04, 2.6194449e-03, 1.4106845e-04,\n",
            "       2.6977167e-03, 2.1620833e-03, 1.8991166e-03, 4.0813261e-03,\n",
            "       2.7032553e-03, 1.9393554e-03, 3.1647948e-03, 8.4623077e-04,\n",
            "       1.9151108e-04, 1.4774244e-04, 7.5003142e-03, 4.6692984e-04,\n",
            "       7.8597077e-04, 7.4482878e-04, 4.9100094e-04, 1.5764425e-03,\n",
            "       1.9057740e-04, 1.6376917e-04, 3.2545107e-03, 2.5815639e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 382, 'shape': array([  1,   3,   3, 240], dtype=int32), 'shape_signature': array([  1,   3,   3, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.03602747, 0.05574574, 0.02976912, 0.01188823, 0.1105124 ,\n",
            "       0.03150356, 0.0014501 , 0.02043571, 0.00841727, 0.01271711,\n",
            "       0.00907548, 0.06536207, 0.01334013, 0.03852811, 0.0633605 ,\n",
            "       0.01841005, 0.01273871, 0.00685036, 0.0150283 , 0.00277728,\n",
            "       0.00447229, 0.00115723, 0.03759752, 0.02732548, 0.00828701,\n",
            "       0.01025607, 0.04386504, 0.02183517, 0.01505013, 0.0118728 ,\n",
            "       0.01580305, 0.02173804, 0.0010086 , 0.01720727, 0.00053055,\n",
            "       0.00223838, 0.00976097, 0.0124204 , 0.00795794, 0.00201579,\n",
            "       0.01851848, 0.00515442, 0.00242931, 0.02940831, 0.00631613,\n",
            "       0.02876934, 0.00418381, 0.02361681, 0.01937625, 0.03599257,\n",
            "       0.0083633 , 0.00565226, 0.00655539, 0.00612682, 0.00267074,\n",
            "       0.03631354, 0.01038659, 0.0336475 , 0.01540271, 0.00901615,\n",
            "       0.00653988, 0.00144191, 0.02229609, 0.00940862, 0.00489393,\n",
            "       0.00167985, 0.00502022, 0.02765677, 0.04056489, 0.00898975,\n",
            "       0.00389165, 0.00146721, 0.06744424, 0.05305606, 0.01741981,\n",
            "       0.01709789, 0.04978164, 0.01603295, 0.02125597, 0.0019145 ,\n",
            "       0.03816599, 0.00446564, 0.00879032, 0.01692177, 0.00475723,\n",
            "       0.00469907, 0.00543595, 0.02880437, 0.01427938, 0.02711654,\n",
            "       0.00403711, 0.00261612, 0.01232034, 0.02374116, 0.01275469,\n",
            "       0.01729506, 0.01766461, 0.00591435, 0.00492377, 0.01040483,\n",
            "       0.00610148, 0.00181524, 0.06236501, 0.00935235, 0.01076421,\n",
            "       0.00316297, 0.06507323, 0.01268365, 0.00311067, 0.05118402,\n",
            "       0.01861298, 0.0458016 , 0.01016551, 0.00861786, 0.01777058,\n",
            "       0.00999741, 0.00189018, 0.02045797, 0.00855792, 0.00692531,\n",
            "       0.00686886, 0.01864769, 0.00210014, 0.03880173, 0.00218216,\n",
            "       0.03331762, 0.0646565 , 0.03884722, 0.00552903, 0.0054071 ,\n",
            "       0.00233623, 0.0021343 , 0.02832671, 0.00629068, 0.01119118,\n",
            "       0.02673445, 0.07614665, 0.01911548, 0.0021447 , 0.03035721,\n",
            "       0.01562768, 0.03069741, 0.03656195, 0.00673705, 0.0098777 ,\n",
            "       0.00273729, 0.00592819, 0.0264689 , 0.01966664, 0.06101764,\n",
            "       0.00290141, 0.00242564, 0.00523364, 0.00924815, 0.00729119,\n",
            "       0.00107336, 0.00365284, 0.02356275, 0.00261555, 0.00177433,\n",
            "       0.0154487 , 0.04212534, 0.0590112 , 0.00208989, 0.00158999,\n",
            "       0.00613764, 0.01395352, 0.00206195, 0.00889541, 0.00608856,\n",
            "       0.00696275, 0.01071725, 0.0393706 , 0.05167789, 0.01415966,\n",
            "       0.06452792, 0.00458742, 0.00521603, 0.0544883 , 0.03691705,\n",
            "       0.00664765, 0.01659798, 0.02322651, 0.01248155, 0.00498477,\n",
            "       0.0046481 , 0.02165643, 0.00311231, 0.0130665 , 0.00904792,\n",
            "       0.02156087, 0.02373379, 0.07846483, 0.00632092, 0.00170541,\n",
            "       0.0086611 , 0.00309105, 0.01064217, 0.0434086 , 0.00145471,\n",
            "       0.00313523, 0.01189001, 0.00700923, 0.00118043, 0.00492118,\n",
            "       0.0174008 , 0.01397379, 0.00240913, 0.02074722, 0.02870393,\n",
            "       0.01259216, 0.03052004, 0.00093498, 0.01171867, 0.0675398 ,\n",
            "       0.00148302, 0.02291214, 0.00629525, 0.03030806, 0.00163222,\n",
            "       0.0312137 , 0.0250162 , 0.02197357, 0.04722263, 0.03127778,\n",
            "       0.02243914, 0.03661799, 0.00979124, 0.00221586, 0.00170944,\n",
            "       0.08678174, 0.00540257, 0.00909401, 0.00861798, 0.00568108,\n",
            "       0.01824009, 0.00220506, 0.00189488, 0.03765604, 0.00298698],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 383, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.32210038e-05, 1.95932207e-05, 1.35389098e-04, 1.29190783e-04,\n",
            "       2.82943984e-05, 1.29203545e-04, 2.96853454e-04, 2.62319751e-04,\n",
            "       6.99168304e-05, 1.93841057e-04, 2.10201295e-04, 4.54465226e-05,\n",
            "       9.87956446e-05, 2.85284077e-05, 2.81841913e-05, 1.50026171e-04,\n",
            "       8.30056306e-05, 1.97483751e-04, 2.64766772e-04, 1.70277752e-04,\n",
            "       9.07780923e-05, 3.95915995e-04, 1.68818406e-05, 1.69353982e-04,\n",
            "       1.59938194e-04, 1.64528028e-04, 5.59161308e-05, 1.46411287e-04,\n",
            "       9.89752007e-05, 2.52312195e-04, 1.73500215e-04, 8.57995910e-05,\n",
            "       3.72364273e-04, 2.02609372e-05, 3.97853117e-04, 2.01701754e-04,\n",
            "       2.02309471e-04, 4.53624380e-04, 2.14014828e-04, 1.59407195e-04,\n",
            "       2.29893136e-04, 2.22256596e-04, 2.99469102e-04, 1.32266316e-04,\n",
            "       7.46105143e-05, 4.90052225e-05, 2.53083505e-04, 7.58723982e-05,\n",
            "       1.68205210e-04, 1.39769923e-04, 1.58206647e-04, 1.50349282e-04,\n",
            "       1.68968851e-04, 1.74360292e-04, 9.11462485e-05, 1.55251328e-05,\n",
            "       4.13754497e-05, 4.74100889e-05, 7.39734751e-05, 2.96124897e-04,\n",
            "       1.94925757e-04, 2.44248164e-04, 4.91550309e-05, 7.66771846e-04,\n",
            "       1.87467143e-04, 6.25477231e-04, 1.80617324e-04, 7.48884340e-05,\n",
            "       2.57496049e-05, 2.16933462e-04, 2.79701751e-04, 3.52944451e-04,\n",
            "       1.47936502e-04, 4.54956462e-05, 1.25808161e-04, 3.33245320e-04,\n",
            "       1.64596186e-05, 1.45064419e-04, 1.78001879e-04, 1.59890231e-04,\n",
            "       2.84151774e-05, 1.48063176e-04, 1.32857196e-04, 4.83033044e-04,\n",
            "       1.79650830e-04, 1.16486444e-04, 2.47682183e-04, 1.67176346e-04,\n",
            "       3.17420381e-05, 2.33913059e-04, 3.30020179e-04, 2.39991234e-04,\n",
            "       2.64121976e-04, 2.07330537e-04, 3.15326943e-05, 2.88866286e-04,\n",
            "       3.21257103e-04, 2.31975922e-04, 3.74112773e-04, 8.69124560e-05,\n",
            "       1.59171002e-04, 2.28486228e-04, 2.51775491e-05, 3.69921181e-04,\n",
            "       4.18015297e-05, 1.73241249e-04, 8.84973924e-05, 6.79125878e-05,\n",
            "       2.34789884e-04, 2.84878370e-05, 1.88976046e-04, 8.20330388e-05,\n",
            "       1.14420392e-04, 1.84811885e-04, 2.89137497e-05, 1.57093644e-04,\n",
            "       1.73123422e-04, 5.81445856e-05, 2.00049690e-04, 1.42984980e-04,\n",
            "       1.90177932e-04, 3.74322190e-05, 1.27867184e-04, 2.50803190e-04,\n",
            "       1.95056957e-04, 5.72429781e-05, 1.87529484e-04, 2.09048285e-05,\n",
            "       1.20666344e-04, 3.80768644e-04, 1.71600303e-04, 2.79157161e-04,\n",
            "       3.97402910e-05, 2.19479378e-04, 2.16940272e-04, 4.20390170e-05,\n",
            "       2.83107238e-05, 2.31035112e-04, 1.91131621e-04, 7.56262089e-05,\n",
            "       3.78034529e-05, 2.68437598e-05, 4.68032413e-05, 5.19375935e-05,\n",
            "       7.55221117e-05, 2.33537459e-04, 2.37845190e-04, 5.61307716e-05,\n",
            "       3.76383578e-05, 1.00981670e-04, 2.84931622e-04, 9.81667690e-05,\n",
            "       3.32031428e-04, 1.09334105e-04, 2.11684877e-04, 3.16592836e-04,\n",
            "       3.47965310e-04, 1.17813048e-04, 1.44432299e-04, 2.06360681e-04,\n",
            "       9.61681435e-05, 6.17831683e-05, 1.94634049e-05, 2.68086587e-04,\n",
            "       1.99268397e-04, 6.29252900e-05, 3.05391120e-04, 2.58559623e-04,\n",
            "       3.50294547e-04, 4.68198472e-04, 3.98226373e-04, 1.96222230e-04,\n",
            "       1.79056406e-05, 4.07805128e-05, 8.17411783e-05, 2.13406202e-05,\n",
            "       6.12458040e-04, 1.92703214e-04, 2.77441104e-05, 4.10592475e-05,\n",
            "       1.44128659e-04, 2.36650914e-04, 1.81107069e-04, 8.76675258e-05,\n",
            "       1.47348619e-04, 2.17240711e-04, 7.35908907e-05, 2.97643157e-04,\n",
            "       3.47371169e-05, 3.63583589e-04, 1.94280816e-04, 1.64090961e-04,\n",
            "       4.20195502e-05, 5.20324218e-04, 2.18560352e-04, 7.80418195e-05,\n",
            "       1.06591862e-04, 1.18634896e-04, 6.42737286e-05, 3.30015726e-04,\n",
            "       1.70422994e-04, 1.82595875e-04, 3.51672352e-04, 4.26775601e-04,\n",
            "       1.66770638e-04, 1.27356165e-04, 3.14623583e-04, 1.24966376e-04,\n",
            "       1.24942075e-04, 1.26636500e-04, 3.20958279e-05, 1.57136950e-04,\n",
            "       1.93230284e-04, 1.37686031e-04, 3.10045070e-05, 1.57670860e-04,\n",
            "       1.90112216e-04, 2.29336219e-04, 1.42274454e-04, 3.61765560e-04,\n",
            "       1.65024438e-04, 6.66169872e-05, 2.02808205e-05, 1.88993596e-04,\n",
            "       1.78705115e-04, 4.78980743e-04, 1.75517984e-04, 2.29339479e-04,\n",
            "       3.54384305e-04, 5.74685459e-04, 4.12090667e-05, 4.98615154e-05,\n",
            "       1.94214081e-04, 3.26278678e-04, 3.19898565e-04, 1.28823522e-04,\n",
            "       1.67406411e-04, 2.32594350e-04, 6.16831821e-05, 2.96962127e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 384, 'shape': array([240,   1,   1,  72], dtype=int32), 'shape_signature': array([240,   1,   1,  72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([4.73189539e-05, 2.79079686e-05, 1.92843989e-04, 1.84015284e-04,\n",
            "       4.03016529e-05, 1.84033473e-04, 4.22828714e-04, 3.73640010e-04,\n",
            "       9.95873415e-05, 2.76101113e-04, 2.99404113e-04, 6.47326015e-05,\n",
            "       1.40721415e-04, 4.06349682e-05, 4.01446778e-05, 2.13692576e-04,\n",
            "       1.18230615e-04, 2.81289656e-04, 3.77125456e-04, 2.42538285e-04,\n",
            "       1.29301465e-04, 5.63930313e-04, 2.40459631e-05, 2.41222500e-04,\n",
            "       2.27810946e-04, 2.34348554e-04, 7.96451786e-05, 2.08543643e-04,\n",
            "       1.40977165e-04, 3.59385565e-04, 2.47128250e-04, 1.22210244e-04,\n",
            "       5.30383957e-04, 2.88590418e-05, 5.66689472e-04, 2.87297647e-04,\n",
            "       2.88163254e-04, 6.46128319e-04, 3.04835994e-04, 2.27054610e-04,\n",
            "       3.27452552e-04, 3.16575315e-04, 4.26554383e-04, 1.88395978e-04,\n",
            "       1.06272870e-04, 6.98014992e-05, 3.60484206e-04, 1.08070257e-04,\n",
            "       2.39586225e-04, 1.99083879e-04, 2.25344585e-04, 2.14152795e-04,\n",
            "       2.40673922e-04, 2.48353317e-04, 1.29825858e-04, 2.21135106e-05,\n",
            "       5.89338888e-05, 6.75294432e-05, 1.05365492e-04, 4.21790988e-04,\n",
            "       2.77646119e-04, 3.47899419e-04, 7.00148812e-05, 1.09216571e-03,\n",
            "       2.67022318e-04, 8.90910102e-04, 2.57265638e-04, 1.06668733e-04,\n",
            "       3.66769273e-05, 3.08993214e-04, 3.98398377e-04, 5.02722978e-04,\n",
            "       2.10716098e-04, 6.48025671e-05, 1.79197203e-04, 4.74664150e-04,\n",
            "       2.34445633e-05, 2.06625205e-04, 2.53540289e-04, 2.27742625e-04,\n",
            "       4.04736857e-05, 2.10896527e-04, 1.89237617e-04, 6.88017113e-04,\n",
            "       2.55888997e-04, 1.65919628e-04, 3.52790725e-04, 2.38120745e-04,\n",
            "       4.52123604e-05, 3.33178410e-04, 4.70070372e-04, 3.41835985e-04,\n",
            "       3.76207056e-04, 2.95315112e-04, 4.49141771e-05, 4.11452056e-04,\n",
            "       4.57588525e-04, 3.30419221e-04, 5.32874488e-04, 1.23795369e-04,\n",
            "       2.26718184e-04, 3.25448607e-04, 3.58621110e-05, 5.26904128e-04,\n",
            "       5.95407837e-05, 2.46759388e-04, 1.26052910e-04, 9.67325541e-05,\n",
            "       3.34427343e-04, 4.05771789e-05, 2.69171549e-04, 1.16845287e-04,\n",
            "       1.62976808e-04, 2.63240247e-04, 4.11838373e-05, 2.23759242e-04,\n",
            "       2.46591575e-04, 8.28193224e-05, 2.84944486e-04, 2.03663323e-04,\n",
            "       2.70883465e-04, 5.33172752e-05, 1.82129996e-04, 3.57236189e-04,\n",
            "       2.77832994e-04, 8.15351013e-05, 2.67111114e-04, 2.97761817e-05,\n",
            "       1.71873355e-04, 5.42354886e-04, 2.44422088e-04, 3.97622673e-04,\n",
            "       5.66048220e-05, 3.12619522e-04, 3.09002906e-04, 5.98790539e-05,\n",
            "       4.03249069e-05, 3.29079165e-04, 2.72241887e-04, 1.07719599e-04,\n",
            "       5.38460517e-05, 3.82354083e-05, 6.66650667e-05, 7.39782772e-05,\n",
            "       1.07571323e-04, 3.32643423e-04, 3.38779209e-04, 7.99509071e-05,\n",
            "       5.36108928e-05, 1.43835117e-04, 4.05847648e-04, 1.39825657e-04,\n",
            "       4.72935149e-04, 1.55732065e-04, 3.01517284e-04, 4.50944906e-04,\n",
            "       4.95630840e-04, 1.67809209e-04, 2.05724835e-04, 2.93933670e-04,\n",
            "       1.36978881e-04, 8.80020016e-05, 2.77230629e-05, 3.81854101e-04,\n",
            "       2.83831643e-04, 8.96288038e-05, 4.34989517e-04, 3.68284207e-04,\n",
            "       4.98948561e-04, 6.66887208e-04, 5.67221141e-04, 2.79492786e-04,\n",
            "       2.55042323e-05, 5.80864835e-05, 1.16429568e-04, 3.03969100e-05,\n",
            "       8.72365956e-04, 2.74480408e-04, 3.95178395e-05, 5.84835034e-05,\n",
            "       2.05292337e-04, 3.37078120e-04, 2.57963227e-04, 1.24870872e-04,\n",
            "       2.09878737e-04, 3.09430849e-04, 1.04820552e-04, 4.23953548e-04,\n",
            "       4.94784581e-05, 5.17877052e-04, 2.76727485e-04, 2.33726008e-04,\n",
            "       5.98513252e-05, 7.41133466e-04, 3.11310490e-04, 1.11160312e-04,\n",
            "       1.51826098e-04, 1.68979823e-04, 9.15494820e-05, 4.70064027e-04,\n",
            "       2.42745155e-04, 2.60083820e-04, 5.00911032e-04, 6.07885770e-04,\n",
            "       2.37542859e-04, 1.81402123e-04, 4.48139937e-04, 1.77998183e-04,\n",
            "       1.77963564e-04, 1.80377057e-04, 4.57162896e-05, 2.23820942e-04,\n",
            "       2.75231141e-04, 1.96115667e-04, 4.41618467e-05, 2.24581425e-04,\n",
            "       2.70789867e-04, 3.26659298e-04, 2.02651267e-04, 5.15287509e-04,\n",
            "       2.35055631e-04, 9.48871457e-05, 2.88873634e-05, 2.69196549e-04,\n",
            "       2.54541956e-04, 6.82245125e-04, 2.50002311e-04, 3.26663954e-04,\n",
            "       5.04773867e-04, 8.18563916e-04, 5.86968999e-05, 7.10211752e-05,\n",
            "       2.76632432e-04, 4.64741112e-04, 4.55653470e-04, 1.83492186e-04,\n",
            "       2.38448425e-04, 3.31300078e-04, 8.78595893e-05, 4.22983518e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/rezero/mul', 'index': 385, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.006975128781050444, -128), 'quantization_parameters': {'scales': array([0.00697513], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 386, 'shape': array([72], dtype=int32), 'shape_signature': array([72], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00048468, 0.00053012, 0.00036793, 0.00031746, 0.00036558,\n",
            "       0.00047798, 0.00038581, 0.00050817, 0.00036302, 0.00041257,\n",
            "       0.00035213, 0.0004382 , 0.00034581, 0.0004458 , 0.00036486,\n",
            "       0.00034677, 0.00035849, 0.00043553, 0.00037279, 0.00036588,\n",
            "       0.00034245, 0.00065614, 0.00047336, 0.00040439, 0.00043495,\n",
            "       0.00052062, 0.00024975, 0.00035913, 0.00034261, 0.00041371,\n",
            "       0.00046727, 0.00059995, 0.00049003, 0.00037399, 0.00048459,\n",
            "       0.00032421, 0.00047379, 0.00043658, 0.0003761 , 0.00043588,\n",
            "       0.00063788, 0.00037702, 0.0006832 , 0.00027075, 0.00057697,\n",
            "       0.00032143, 0.00035711, 0.00039043, 0.00029786, 0.00035717,\n",
            "       0.0002864 , 0.00032953, 0.00065123, 0.00032378, 0.00085234,\n",
            "       0.00048185, 0.00045317, 0.00028622, 0.00062635, 0.00038657,\n",
            "       0.00037979, 0.0004516 , 0.00061643, 0.00047617, 0.0004141 ,\n",
            "       0.00040426, 0.00056563, 0.00033797, 0.0003004 , 0.00039802,\n",
            "       0.00037696, 0.00048985], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 387, 'shape': array([ 72,   1,   1, 160], dtype=int32), 'shape_signature': array([ 72,   1,   1, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01832168, 0.02003925, 0.01390832, 0.01200054, 0.01381938,\n",
            "       0.01806813, 0.01458396, 0.01920958, 0.01372257, 0.01559552,\n",
            "       0.01331076, 0.01656456, 0.01307216, 0.01685181, 0.01379213,\n",
            "       0.01310835, 0.01355144, 0.01646343, 0.01409201, 0.01383068,\n",
            "       0.01294503, 0.02480306, 0.01789361, 0.01528648, 0.01644178,\n",
            "       0.01967995, 0.00944101, 0.01357551, 0.01295119, 0.01563883,\n",
            "       0.01766326, 0.02267875, 0.01852371, 0.01413724, 0.01831819,\n",
            "       0.01225557, 0.01790997, 0.01650323, 0.01421696, 0.01647686,\n",
            "       0.02411269, 0.01425188, 0.02582576, 0.01023481, 0.02181031,\n",
            "       0.0121505 , 0.01349921, 0.01475888, 0.01125937, 0.01350146,\n",
            "       0.01082625, 0.01245673, 0.02461726, 0.01223921, 0.03221948,\n",
            "       0.01821446, 0.01713038, 0.0108194 , 0.02367667, 0.01461281,\n",
            "       0.01435645, 0.01707114, 0.02330201, 0.01799997, 0.01565349,\n",
            "       0.01528163, 0.02138139, 0.01277569, 0.0113556 , 0.01504556,\n",
            "       0.01424937, 0.01851688], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 388, 'shape': array([160], dtype=int32), 'shape_signature': array([160], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.64040084e-05, 1.82156073e-05, 1.47479786e-05, 1.39351032e-05,\n",
            "       1.69801715e-05, 1.69809682e-05, 7.93384424e-06, 2.45337760e-05,\n",
            "       2.35830885e-05, 3.93529590e-05, 2.43632694e-05, 6.30805789e-06,\n",
            "       2.57322718e-05, 3.21133593e-05, 1.29918044e-05, 1.03663042e-05,\n",
            "       1.31387933e-05, 2.05619654e-05, 2.05642973e-05, 1.86448124e-05,\n",
            "       2.10503731e-05, 1.00652351e-05, 7.59511795e-06, 2.28667486e-05,\n",
            "       2.10533653e-05, 3.32679519e-05, 2.24658306e-05, 2.58235468e-05,\n",
            "       1.35319015e-05, 1.19838751e-05, 3.64152183e-05, 5.13521336e-05,\n",
            "       2.52081754e-05, 3.79795310e-05, 1.50951446e-05, 1.13484020e-05,\n",
            "       1.08313989e-05, 1.21368248e-05, 2.75312213e-05, 1.54958907e-05,\n",
            "       1.58748608e-05, 1.61875996e-05, 1.53933433e-05, 1.07542264e-05,\n",
            "       1.04583914e-05, 3.39766084e-05, 3.05085669e-05, 1.37389825e-05,\n",
            "       8.96817892e-06, 2.71984427e-05, 3.31359915e-05, 1.39712101e-05,\n",
            "       1.79514354e-05, 1.30276239e-05, 2.91812230e-05, 2.77143845e-05,\n",
            "       6.63893707e-06, 2.67739488e-05, 3.81232639e-05, 3.79875928e-05,\n",
            "       2.41815487e-05, 3.14027566e-05, 3.47718269e-05, 1.09009088e-05,\n",
            "       4.42094533e-05, 1.89242746e-05, 2.33080355e-05, 3.58629914e-05,\n",
            "       1.77367237e-05, 8.37823700e-06, 3.56228120e-05, 1.46627217e-05,\n",
            "       3.17684717e-05, 1.65534511e-05, 7.29349540e-06, 2.71172994e-05,\n",
            "       1.36473782e-05, 2.43443938e-05, 8.93175002e-06, 1.53546225e-05,\n",
            "       1.08550748e-05, 3.57467325e-05, 1.20715913e-05, 2.79320884e-05,\n",
            "       3.67136672e-05, 1.57646155e-05, 1.78115715e-05, 1.56091519e-05,\n",
            "       1.60050349e-05, 1.98161397e-05, 2.48338765e-05, 2.46061518e-05,\n",
            "       1.36032595e-05, 1.19313681e-05, 9.00825580e-06, 1.31563529e-05,\n",
            "       1.41318851e-05, 2.27627443e-05, 4.67204300e-05, 1.76394078e-05,\n",
            "       1.20465247e-05, 1.36030994e-05, 3.54390504e-05, 2.76914179e-05,\n",
            "       1.76292524e-05, 8.93103334e-06, 2.77283143e-05, 2.46817326e-05,\n",
            "       8.89285366e-06, 2.94342390e-05, 1.23740247e-05, 1.85764620e-05,\n",
            "       2.51057154e-05, 2.80264612e-05, 8.79445633e-06, 1.53158671e-05,\n",
            "       2.46809686e-05, 2.39904093e-05, 1.27053154e-05, 1.94846252e-05,\n",
            "       7.52200822e-06, 1.12813932e-05, 2.54286606e-05, 3.98829907e-05,\n",
            "       1.29287282e-05, 3.29701761e-05, 9.39713209e-06, 3.80664751e-05,\n",
            "       3.20245344e-05, 1.95262655e-05, 1.20090699e-05, 2.01687271e-05,\n",
            "       2.91696415e-05, 2.79667092e-05, 8.04533920e-06, 1.08543072e-05,\n",
            "       8.45732029e-06, 1.56870956e-05, 6.59060106e-06, 5.16867076e-05,\n",
            "       3.49914990e-05, 4.53146058e-05, 3.37753918e-05, 9.72488670e-06,\n",
            "       5.22962873e-05, 2.41174621e-05, 3.22779342e-05, 1.52121729e-05,\n",
            "       2.01314069e-05, 1.72991313e-05, 1.33869817e-05, 2.36596807e-05,\n",
            "       8.28812517e-06, 1.27136782e-05, 1.41616438e-05, 3.46340603e-05,\n",
            "       1.98634007e-05, 9.33856427e-06, 3.17092636e-05, 8.05208674e-06],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 389, 'shape': array([160,   1,   1,  80], dtype=int32), 'shape_signature': array([160,   1,   1,  80], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00098258, 0.00109109, 0.00088339, 0.00083469, 0.00101709,\n",
            "       0.00101714, 0.00047523, 0.00146954, 0.0014126 , 0.00235719,\n",
            "       0.00145933, 0.00037784, 0.00154133, 0.00192355, 0.00077819,\n",
            "       0.00062093, 0.000787  , 0.00123164, 0.00123178, 0.0011168 ,\n",
            "       0.00126089, 0.00060289, 0.00045494, 0.00136969, 0.00126107,\n",
            "       0.00199271, 0.00134567, 0.0015468 , 0.00081054, 0.00071782,\n",
            "       0.00218123, 0.00307593, 0.00150994, 0.00227493, 0.00090418,\n",
            "       0.00067975, 0.00064879, 0.00072698, 0.00164909, 0.00092818,\n",
            "       0.00095088, 0.00096962, 0.00092204, 0.00064416, 0.00062644,\n",
            "       0.00203516, 0.00182742, 0.00082295, 0.00053718, 0.00162915,\n",
            "       0.0019848 , 0.00083686, 0.00107527, 0.00078034, 0.00174792,\n",
            "       0.00166006, 0.00039766, 0.00160373, 0.00228353, 0.00227541,\n",
            "       0.00144844, 0.00188099, 0.00208279, 0.00065295, 0.00264809,\n",
            "       0.00113354, 0.00139612, 0.00214815, 0.00106241, 0.00050185,\n",
            "       0.00213376, 0.00087828, 0.00190289, 0.00099153, 0.00043687,\n",
            "       0.00162429, 0.00081746, 0.0014582 , 0.000535  , 0.00091972,\n",
            "       0.00065021, 0.00214118, 0.00072307, 0.0016731 , 0.0021991 ,\n",
            "       0.00094428, 0.00106689, 0.00093497, 0.00095868, 0.00118696,\n",
            "       0.00148752, 0.00147388, 0.00081482, 0.00071467, 0.00053958,\n",
            "       0.00078805, 0.00084648, 0.00136346, 0.00279849, 0.00105658,\n",
            "       0.00072157, 0.00081481, 0.00212275, 0.00165868, 0.00105597,\n",
            "       0.00053496, 0.00166089, 0.0014784 , 0.00053267, 0.00176307,\n",
            "       0.00074119, 0.00111271, 0.0015038 , 0.00167875, 0.00052678,\n",
            "       0.0009174 , 0.00147836, 0.00143699, 0.00076103, 0.0011671 ,\n",
            "       0.00045056, 0.00067574, 0.00152314, 0.00238894, 0.00077441,\n",
            "       0.00197487, 0.00056288, 0.00228013, 0.00191823, 0.0011696 ,\n",
            "       0.00071933, 0.00120808, 0.00174722, 0.00167517, 0.00048191,\n",
            "       0.00065016, 0.00050658, 0.00093964, 0.00039477, 0.00309597,\n",
            "       0.00209595, 0.00271429, 0.0020231 , 0.00058251, 0.00313248,\n",
            "       0.00144461, 0.00193341, 0.00091119, 0.00120585, 0.0010362 ,\n",
            "       0.00080186, 0.00141718, 0.00049645, 0.00076153, 0.00084826,\n",
            "       0.00207454, 0.00118979, 0.00055937, 0.00189934, 0.00048231],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 390, 'shape': array([80], dtype=int32), 'shape_signature': array([80], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([9.0104768e-05, 4.1276853e-05, 1.7422855e-05, 5.5321601e-05,\n",
            "       8.9090383e-05, 3.6877165e-05, 4.7351485e-05, 5.8392747e-05,\n",
            "       1.0796733e-04, 2.8508975e-05, 3.2867432e-05, 2.1787704e-05,\n",
            "       7.7747478e-05, 3.4008743e-05, 3.9201004e-05, 1.3934651e-04,\n",
            "       6.9212860e-05, 3.2327949e-05, 2.9886343e-05, 4.4480334e-05,\n",
            "       2.4553325e-05, 8.7703309e-05, 2.0466288e-05, 1.1359181e-04,\n",
            "       2.8500202e-05, 9.2630871e-05, 4.5608900e-05, 2.4318133e-05,\n",
            "       6.1930841e-05, 3.0875166e-05, 5.1690651e-05, 2.6819349e-05,\n",
            "       4.4618249e-05, 7.9403944e-05, 3.2566637e-05, 3.3721844e-05,\n",
            "       2.5188545e-05, 2.2261147e-05, 4.9563980e-05, 2.9724712e-05,\n",
            "       2.1975222e-05, 7.1473049e-05, 4.0486790e-05, 4.5959885e-05,\n",
            "       7.0898735e-05, 1.2290508e-04, 3.2873169e-05, 2.8131924e-05,\n",
            "       2.7864020e-05, 1.7685363e-05, 2.8274446e-05, 7.5005191e-05,\n",
            "       5.0398645e-05, 1.2237644e-04, 5.3001922e-06, 1.6587395e-04,\n",
            "       8.8513792e-05, 1.5835397e-04, 3.2264543e-05, 5.0697188e-05,\n",
            "       3.3922664e-05, 2.1523398e-05, 8.1463761e-05, 4.1588377e-05,\n",
            "       4.2868149e-05, 4.0796120e-05, 5.0236718e-05, 1.1998114e-04,\n",
            "       4.1945030e-05, 6.0647191e-05, 2.8913382e-05, 1.2316825e-04,\n",
            "       6.7436144e-05, 7.3151423e-05, 3.0537922e-05, 2.5411940e-05,\n",
            "       4.2545464e-05, 5.9427959e-05, 6.9037676e-05, 4.3627468e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 391, 'shape': array([ 80,   1,   1, 320], dtype=int32), 'shape_signature': array([ 80,   1,   1, 320], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00235219, 0.00107753, 0.00045482, 0.00144417, 0.00232571,\n",
            "       0.00096268, 0.00123611, 0.00152434, 0.00281849, 0.00074423,\n",
            "       0.00085801, 0.00056877, 0.0020296 , 0.0008878 , 0.00102334,\n",
            "       0.00363764, 0.0018068 , 0.00084392, 0.00078018, 0.00116116,\n",
            "       0.00064097, 0.0022895 , 0.00053427, 0.00296532, 0.000744  ,\n",
            "       0.00241813, 0.00119062, 0.00063483, 0.00161671, 0.000806  ,\n",
            "       0.00134939, 0.00070012, 0.00116476, 0.00207284, 0.00085015,\n",
            "       0.00088031, 0.00065755, 0.00058113, 0.00129387, 0.00077596,\n",
            "       0.00057366, 0.00186581, 0.00105691, 0.00119978, 0.00185081,\n",
            "       0.00320844, 0.00085815, 0.00073438, 0.00072739, 0.00046168,\n",
            "       0.00073811, 0.00195801, 0.00131566, 0.00319464, 0.00013836,\n",
            "       0.00433014, 0.00231065, 0.00413383, 0.00084227, 0.00132345,\n",
            "       0.00088555, 0.00056187, 0.00212661, 0.00108567, 0.00111907,\n",
            "       0.00106498, 0.00131143, 0.00313211, 0.00109498, 0.0015832 ,\n",
            "       0.00075478, 0.00321531, 0.00176042, 0.00190962, 0.00079719,\n",
            "       0.00066338, 0.00111065, 0.00155137, 0.00180223, 0.0011389 ],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 392, 'shape': array([160], dtype=int32), 'shape_signature': array([160], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00166407, 0.00361344, 0.00108539, 0.00298083, 0.00203658,\n",
            "       0.00087342, 0.00083799, 0.00043612, 0.00279365, 0.00082374,\n",
            "       0.00574833, 0.00789203, 0.00090262, 0.00083261, 0.00141927,\n",
            "       0.01267565, 0.00075856, 0.01065473, 0.00065359, 0.00198297,\n",
            "       0.00384818, 0.00885967, 0.00064756, 0.00377468, 0.00413121,\n",
            "       0.00307641, 0.00210713, 0.00101635, 0.00847375, 0.00146007,\n",
            "       0.01320037, 0.00096023, 0.00048267, 0.00509327, 0.00111628,\n",
            "       0.0022461 , 0.00490464, 0.01116206, 0.00081144, 0.001061  ,\n",
            "       0.00402922, 0.00217473, 0.00143409, 0.00133596, 0.00364274,\n",
            "       0.00071288, 0.00148446, 0.00066519, 0.00859599, 0.00122723,\n",
            "       0.00320493, 0.00372408, 0.00085345, 0.00093038, 0.00069717,\n",
            "       0.00307392, 0.00270814, 0.00068895, 0.00682522, 0.00316573,\n",
            "       0.00242424, 0.00112429, 0.0007685 , 0.00625872, 0.00660467,\n",
            "       0.00198955, 0.00450932, 0.00460048, 0.00138018, 0.00183292,\n",
            "       0.0014987 , 0.00301076, 0.00901437, 0.00530426, 0.00414173,\n",
            "       0.00081671, 0.00487604, 0.00189838, 0.00851403, 0.00109434,\n",
            "       0.00463759, 0.00259022, 0.00107269, 0.00332539, 0.00082287,\n",
            "       0.00428197, 0.0120884 , 0.00237984, 0.00358829, 0.00107631,\n",
            "       0.00101013, 0.00452291, 0.0028468 , 0.0059476 , 0.0022966 ,\n",
            "       0.00726737, 0.00303059, 0.00225322, 0.00110307, 0.00156473,\n",
            "       0.01268118, 0.00430143, 0.00349078, 0.00205982, 0.00718078,\n",
            "       0.00425821, 0.00066602, 0.01787928, 0.003784  , 0.00045331,\n",
            "       0.00457336, 0.0016521 , 0.00411741, 0.00822265, 0.00463627,\n",
            "       0.00856422, 0.0025453 , 0.00223254, 0.00333593, 0.00069643,\n",
            "       0.00215535, 0.00082977, 0.00109735, 0.00085603, 0.00523743,\n",
            "       0.00177826, 0.00524144, 0.00040724, 0.00118718, 0.00923935,\n",
            "       0.00477669, 0.00149867, 0.00093449, 0.01063509, 0.00790404,\n",
            "       0.00940704, 0.00084313, 0.00613528, 0.00298506, 0.00140474,\n",
            "       0.00382892, 0.00796236, 0.0016615 , 0.00298964, 0.00846917,\n",
            "       0.00493334, 0.01466736, 0.00070241, 0.00796824, 0.00151645,\n",
            "       0.00097349, 0.00427733, 0.00110096, 0.00643155, 0.00136513,\n",
            "       0.00763964, 0.00260045, 0.00273444, 0.00153832, 0.0007127 ],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul', 'index': 393, 'shape': array([  1,   3,   1, 160], dtype=int32), 'shape_signature': array([  1,   3,   1, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01339631, 0.02908945, 0.00873776, 0.02399675, 0.01639517,\n",
            "       0.00703134, 0.00674608, 0.00351089, 0.02248986, 0.00663142,\n",
            "       0.04627606, 0.06353361, 0.00726636, 0.00670278, 0.01142562,\n",
            "       0.10204337, 0.0061067 , 0.08577429, 0.00526163, 0.01596359,\n",
            "       0.03097918, 0.07132343, 0.00521305, 0.0303875 , 0.03325766,\n",
            "       0.0247662 , 0.01696314, 0.00818195, 0.06821662, 0.01175405,\n",
            "       0.10626753, 0.00773019, 0.00388567, 0.04100255, 0.00898644,\n",
            "       0.01808191, 0.03948408, 0.08985848, 0.00653236, 0.00854139,\n",
            "       0.03243662, 0.01750736, 0.01154494, 0.01075492, 0.02932529,\n",
            "       0.00573896, 0.01195043, 0.00535502, 0.06920066, 0.00987964,\n",
            "       0.02580082, 0.02998011, 0.00687056, 0.00748991, 0.00561247,\n",
            "       0.02474608, 0.02180144, 0.00554632, 0.0549454 , 0.02548522,\n",
            "       0.01951598, 0.00905088, 0.00618666, 0.05038484, 0.05316988,\n",
            "       0.01601657, 0.03630161, 0.03703543, 0.01111095, 0.01475565,\n",
            "       0.01206506, 0.02423766, 0.07256877, 0.04270112, 0.03334237,\n",
            "       0.00657483, 0.0392538 , 0.01528259, 0.06854091, 0.00880982,\n",
            "       0.03733422, 0.02085219, 0.00863552, 0.02677051, 0.00662438,\n",
            "       0.03447133, 0.0973158 , 0.01915852, 0.02888696, 0.00866464,\n",
            "       0.00813188, 0.03641102, 0.02291776, 0.04788022, 0.0184884 ,\n",
            "       0.05850482, 0.02439726, 0.01813919, 0.00888013, 0.0125966 ,\n",
            "       0.10208789, 0.03462803, 0.02810195, 0.01658225, 0.05780779,\n",
            "       0.03428003, 0.00536166, 0.14393438, 0.03046248, 0.0036493 ,\n",
            "       0.03681717, 0.01329999, 0.0331466 , 0.06619514, 0.03732357,\n",
            "       0.06894496, 0.02049053, 0.01797269, 0.02685536, 0.00560649,\n",
            "       0.01735131, 0.0066799 , 0.00883401, 0.00689133, 0.04216312,\n",
            "       0.01431565, 0.04219539, 0.00327845, 0.00955721, 0.07437995,\n",
            "       0.03845402, 0.01206481, 0.00752295, 0.08561613, 0.06363025,\n",
            "       0.07572989, 0.0067875 , 0.04939109, 0.02403073, 0.01130861,\n",
            "       0.03082414, 0.06409971, 0.01337562, 0.02406765, 0.06817971,\n",
            "       0.03971513, 0.11807735, 0.00565466, 0.0641471 , 0.01220793,\n",
            "       0.00783696, 0.03443396, 0.00886312, 0.05177619, 0.01098979,\n",
            "       0.06150175, 0.02093454, 0.02201321, 0.01238397, 0.00573749],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 394, 'shape': array([160], dtype=int32), 'shape_signature': array([160], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([4.9950095e-04, 4.3171717e-04, 1.2528582e-03, 9.3394530e-04,\n",
            "       1.6015721e-03, 3.4419223e-04, 3.6477842e-03, 1.7712829e-03,\n",
            "       7.3786266e-03, 6.9304649e-03, 3.1898660e-04, 1.6446979e-04,\n",
            "       4.8843226e-03, 5.1065125e-03, 2.2901529e-03, 9.3186658e-04,\n",
            "       6.0008088e-04, 7.6939852e-04, 3.7595383e-03, 2.2684474e-04,\n",
            "       6.3955196e-04, 9.2774816e-04, 9.3461428e-04, 1.5272142e-04,\n",
            "       4.5405515e-04, 5.6999894e-03, 1.2143373e-03, 8.9992746e-04,\n",
            "       1.6171536e-04, 1.6661959e-03, 2.1515766e-03, 2.9111365e-03,\n",
            "       1.3127403e-03, 2.3936732e-04, 6.4042275e-04, 6.5154996e-04,\n",
            "       2.2722903e-04, 5.9633527e-04, 9.3862396e-03, 3.7954433e-04,\n",
            "       9.8755676e-04, 3.1755026e-04, 6.1493376e-03, 2.5028388e-03,\n",
            "       4.1196967e-04, 4.7184625e-03, 6.4617570e-04, 3.6988680e-03,\n",
            "       1.7042074e-04, 1.1864303e-03, 2.6563110e-03, 1.8498865e-04,\n",
            "       3.9389005e-04, 1.2013247e-02, 2.4142948e-03, 3.0498095e-03,\n",
            "       9.5814437e-05, 1.3773929e-03, 8.0043951e-04, 7.4702259e-03,\n",
            "       3.3745644e-04, 1.0077984e-03, 4.9566063e-03, 9.7282478e-05,\n",
            "       3.5096682e-04, 3.8844522e-03, 5.9216167e-04, 1.1588243e-04,\n",
            "       1.1154175e-02, 2.4696573e-04, 7.1357843e-04, 5.9743418e-04,\n",
            "       5.8585621e-04, 3.0102851e-04, 8.7501721e-05, 8.6350407e-04,\n",
            "       2.6642493e-04, 3.0928992e-03, 1.0613345e-04, 3.4336855e-03,\n",
            "       5.8870518e-04, 2.8684565e-03, 8.1589620e-04, 2.0423222e-03,\n",
            "       1.3475780e-03, 4.4318920e-04, 1.0101472e-03, 3.0470081e-04,\n",
            "       1.5910801e-03, 1.2082122e-03, 9.9654356e-04, 1.2517639e-03,\n",
            "       1.2905331e-04, 3.8515724e-04, 2.8155250e-03, 6.4812927e-04,\n",
            "       2.8128995e-04, 3.3296421e-03, 1.2753764e-03, 2.9311937e-04,\n",
            "       2.5531675e-03, 1.9928963e-04, 5.1374766e-03, 8.8866864e-04,\n",
            "       1.8462721e-04, 2.8717965e-03, 9.9202699e-04, 1.4951844e-04,\n",
            "       5.1905969e-03, 5.3159753e-03, 5.6590867e-05, 4.6102691e-04,\n",
            "       2.1916823e-04, 3.6100801e-03, 2.8252180e-03, 7.3726776e-05,\n",
            "       4.7053985e-04, 9.3591138e-04, 1.5560907e-04, 2.1696736e-03,\n",
            "       1.7298640e-04, 4.7967758e-04, 1.7341624e-03, 4.6296115e-03,\n",
            "       4.5792467e-04, 4.7170601e-04, 4.9996591e-04, 2.0480750e-03,\n",
            "       5.5439776e-04, 1.9171068e-03, 1.5989360e-03, 5.9758866e-04,\n",
            "       2.7518056e-03, 5.2828207e-05, 7.4400258e-04, 2.1473144e-03,\n",
            "       2.8244552e-04, 1.1392962e-04, 5.3343951e-04, 2.7289367e-03,\n",
            "       2.2804751e-03, 9.9826639e-04, 8.5619010e-04, 1.7209162e-04,\n",
            "       1.9959763e-04, 3.5439403e-04, 7.8749799e-05, 2.6723829e-03,\n",
            "       2.0162098e-04, 8.9837681e-04, 3.1452198e-03, 3.3058885e-03,\n",
            "       1.7060040e-03, 1.7975646e-04, 7.7311485e-04, 3.6570147e-04,\n",
            "       1.7695514e-03, 8.7295071e-04, 3.3486160e-04, 2.3816165e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 395, 'shape': array([  1,   3,   3, 160], dtype=int32), 'shape_signature': array([  1,   3,   3, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00844221, 0.00729658, 0.02117492, 0.01578488, 0.02706864,\n",
            "       0.00581729, 0.06165227, 0.02993697, 0.12470833, 0.11713383,\n",
            "       0.00539129, 0.00277975, 0.08255138, 0.08630667, 0.03870655,\n",
            "       0.01574975, 0.01014214, 0.01300383, 0.06354106, 0.00383397,\n",
            "       0.01080926, 0.01568014, 0.01579619, 0.00258119, 0.00767412,\n",
            "       0.09633719, 0.02052387, 0.01520994, 0.0027332 , 0.02816087,\n",
            "       0.03636443, 0.04920197, 0.02218701, 0.00404562, 0.01082397,\n",
            "       0.01101204, 0.00384046, 0.01007884, 0.1586396 , 0.00641479,\n",
            "       0.01669099, 0.00536701, 0.10393176, 0.04230122, 0.00696282,\n",
            "       0.07974812, 0.01092121, 0.06251565, 0.00288033, 0.02005221,\n",
            "       0.04489509, 0.00312655, 0.00665725, 0.20303942, 0.04080471,\n",
            "       0.05154572, 0.00161939, 0.02327972, 0.01352846, 0.12625648,\n",
            "       0.00570345, 0.0170331 , 0.08377306, 0.0016442 , 0.00593179,\n",
            "       0.06565227, 0.0100083 , 0.00195856, 0.18851998, 0.00417404,\n",
            "       0.0120604 , 0.01009741, 0.00990173, 0.00508777, 0.00147889,\n",
            "       0.01459434, 0.00450293, 0.052274  , 0.00179379, 0.05803373,\n",
            "       0.00994988, 0.04848063, 0.0137897 , 0.03451789, 0.02277581,\n",
            "       0.00749047, 0.01707279, 0.00514984, 0.02689131, 0.02042035,\n",
            "       0.01684288, 0.02115643, 0.00218117, 0.00650966, 0.04758602,\n",
            "       0.01095422, 0.00475416, 0.05627526, 0.02155551, 0.0049541 ,\n",
            "       0.04315183, 0.00336825, 0.08683   , 0.01501965, 0.00312044,\n",
            "       0.04853708, 0.01676654, 0.00252706, 0.0877278 , 0.08984686,\n",
            "       0.00095646, 0.00779195, 0.00370423, 0.06101502, 0.04774984,\n",
            "       0.00124608, 0.00795273, 0.01581811, 0.00262999, 0.03667029,\n",
            "       0.00292369, 0.00810717, 0.02930959, 0.07824642, 0.00773952,\n",
            "       0.00797244, 0.00845007, 0.03461512, 0.00937004, 0.03240158,\n",
            "       0.02702409, 0.01010002, 0.04650908, 0.00089287, 0.01257461,\n",
            "       0.03629239, 0.00477369, 0.00192556, 0.00901582, 0.04612256,\n",
            "       0.03854298, 0.01687199, 0.01447072, 0.00290857, 0.00337346,\n",
            "       0.00598972, 0.00133097, 0.04516673, 0.00340766, 0.01518373,\n",
            "       0.05315828, 0.05587379, 0.02883367, 0.00303812, 0.01306664,\n",
            "       0.00618083, 0.02990771, 0.014754  , 0.00565959, 0.0402524 ],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 396, 'shape': array([160], dtype=int32), 'shape_signature': array([160], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.73520690e-04, 6.96742936e-05, 5.03315241e-05, 5.64748225e-05,\n",
            "       2.75212242e-05, 2.00757509e-04, 4.50865955e-05, 2.08066413e-04,\n",
            "       1.84409892e-05, 1.10665249e-04, 5.64359252e-05, 2.21819500e-04,\n",
            "       1.39849129e-04, 1.09584573e-04, 1.91820236e-05, 2.68114109e-05,\n",
            "       3.19467799e-04, 3.58572470e-05, 7.20321186e-05, 3.75872696e-05,\n",
            "       1.04524246e-04, 3.78565092e-05, 1.37000330e-04, 1.68967570e-04,\n",
            "       1.71604101e-04, 2.22495764e-05, 1.45100610e-04, 1.73439039e-04,\n",
            "       2.71474797e-04, 1.27611042e-04, 2.30663372e-05, 3.35582117e-05,\n",
            "       2.15106149e-04, 5.77821629e-04, 1.45674363e-04, 4.56249909e-05,\n",
            "       1.85785393e-04, 3.96494943e-05, 9.03305408e-05, 2.43537099e-04,\n",
            "       5.31484038e-05, 2.00704351e-04, 3.73493785e-05, 2.99770491e-05,\n",
            "       2.10647166e-04, 4.93843399e-05, 1.42710109e-04, 1.68540471e-04,\n",
            "       2.68000847e-04, 1.74348548e-04, 1.39586031e-04, 1.38971969e-04,\n",
            "       2.91796314e-04, 2.07794419e-05, 1.72417378e-04, 7.12850015e-05,\n",
            "       2.15845168e-04, 2.86816707e-04, 9.00849191e-05, 4.17938172e-05,\n",
            "       1.50073669e-04, 2.76505249e-04, 1.04482046e-04, 1.46933584e-04,\n",
            "       2.36923384e-04, 4.39361029e-05, 6.22878433e-05, 3.78722529e-04,\n",
            "       1.64695120e-05, 2.81868910e-04, 1.64702593e-04, 2.27906872e-04,\n",
            "       1.30951157e-04, 1.49493513e-04, 2.17647466e-04, 1.49920481e-04,\n",
            "       1.79506504e-04, 4.46002305e-05, 1.33815614e-04, 2.71798253e-05,\n",
            "       3.78674995e-05, 1.33917099e-04, 2.77263724e-04, 1.57313771e-05,\n",
            "       2.75024300e-04, 1.05070736e-04, 1.90353512e-05, 8.73933022e-05,\n",
            "       4.80419912e-05, 2.43170391e-04, 5.78863328e-05, 1.70586398e-04,\n",
            "       3.88724817e-04, 4.56759990e-05, 2.59688986e-05, 4.47858001e-05,\n",
            "       1.63004428e-04, 1.45768827e-05, 3.16055928e-04, 1.90594408e-04,\n",
            "       2.43100822e-05, 2.11512132e-04, 2.20243182e-05, 2.15861408e-04,\n",
            "       1.52654364e-04, 5.18952329e-05, 1.68765706e-04, 9.35217613e-05,\n",
            "       3.41975792e-05, 1.08285552e-04, 2.00912749e-04, 1.10650602e-04,\n",
            "       1.22659927e-04, 3.09459283e-05, 2.72809502e-05, 3.20931926e-04,\n",
            "       2.45639618e-04, 5.13015220e-05, 2.83453934e-04, 1.82362783e-04,\n",
            "       2.41375339e-04, 5.03700925e-04, 2.76156294e-04, 7.36895017e-05,\n",
            "       6.33897434e-05, 3.17317666e-04, 9.99514668e-05, 1.46903330e-04,\n",
            "       2.99102743e-04, 2.26413849e-05, 7.67049278e-05, 3.79000732e-04,\n",
            "       1.53546818e-04, 3.83638660e-04, 2.69181437e-05, 3.46371016e-05,\n",
            "       3.28522030e-04, 2.92538665e-04, 1.44142396e-04, 1.03484686e-04,\n",
            "       2.83016998e-05, 9.75379662e-05, 1.73478591e-04, 2.35248037e-04,\n",
            "       1.88964070e-04, 1.70411047e-04, 3.15545331e-04, 4.11163273e-05,\n",
            "       1.69137100e-04, 6.75445699e-05, 1.27954016e-04, 1.61064509e-05,\n",
            "       5.08699413e-05, 2.33703380e-04, 1.04016741e-04, 7.65452714e-05,\n",
            "       2.03443069e-05, 1.41878991e-04, 2.74070102e-04, 7.50033360e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 397, 'shape': array([160,   1,   1,  72], dtype=int32), 'shape_signature': array([160,   1,   1,  72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.76717852e-04, 1.11111360e-04, 8.02649593e-05, 9.00618325e-05,\n",
            "       4.38887946e-05, 3.20153107e-04, 7.19007367e-05, 3.31808784e-04,\n",
            "       2.94083147e-05, 1.76480680e-04, 8.99998049e-05, 3.53741198e-04,\n",
            "       2.23020950e-04, 1.74757297e-04, 3.05900612e-05, 4.27568375e-05,\n",
            "       5.09463425e-04, 5.71824603e-05, 1.14871451e-04, 5.99413761e-05,\n",
            "       1.66687474e-04, 6.03707340e-05, 2.18477915e-04, 2.69456883e-04,\n",
            "       2.73661426e-04, 3.54819640e-05, 2.31395621e-04, 2.76587642e-04,\n",
            "       4.32927773e-04, 2.03504562e-04, 3.67844732e-05, 5.35161344e-05,\n",
            "       3.43035237e-04, 9.21466853e-04, 2.32310616e-04, 7.27593288e-05,\n",
            "       2.96276674e-04, 6.32300580e-05, 1.44052407e-04, 3.88374785e-04,\n",
            "       8.47571064e-05, 3.20068328e-04, 5.95620004e-05, 4.78051625e-05,\n",
            "       3.35924386e-04, 7.87544632e-05, 2.27583427e-04, 2.68775766e-04,\n",
            "       4.27387742e-04, 2.78038060e-04, 2.22601389e-04, 2.21622133e-04,\n",
            "       4.65335004e-04, 3.31375049e-05, 2.74958380e-04, 1.13679998e-04,\n",
            "       3.44213768e-04, 4.57393879e-04, 1.43660713e-04, 6.66496635e-05,\n",
            "       2.39326298e-04, 4.40949952e-04, 1.66620172e-04, 2.34318708e-04,\n",
            "       3.77827731e-04, 7.00660166e-05, 9.93320064e-05, 6.03958440e-04,\n",
            "       2.62643480e-05, 4.49503510e-04, 2.62655405e-04, 3.63448868e-04,\n",
            "       2.08831145e-04, 2.38401102e-04, 3.47087946e-04, 2.39082001e-04,\n",
            "       2.86263588e-04, 7.11251196e-05, 2.13399166e-04, 4.33443565e-05,\n",
            "       6.03882654e-05, 2.13560998e-04, 4.42159479e-04, 2.50872272e-05,\n",
            "       4.38588235e-04, 1.67558974e-04, 3.03561574e-05, 1.39368320e-04,\n",
            "       7.66137819e-05, 3.87790002e-04, 9.23128027e-05, 2.72038451e-04,\n",
            "       6.19909319e-04, 7.28406740e-05, 4.14132628e-05, 7.14210546e-05,\n",
            "       2.59947294e-04, 2.32461243e-05, 5.04022406e-04, 3.03945737e-04,\n",
            "       3.87679065e-05, 3.37303762e-04, 3.51227391e-05, 3.44239670e-04,\n",
            "       2.43441798e-04, 8.27586482e-05, 2.69134965e-04, 1.49141531e-04,\n",
            "       5.45357470e-05, 1.72685715e-04, 3.20400664e-04, 1.76457324e-04,\n",
            "       1.95608911e-04, 4.93502594e-05, 4.35056245e-05, 5.11798309e-04,\n",
            "       3.91727750e-04, 8.18118424e-05, 4.52031207e-04, 2.90818571e-04,\n",
            "       3.84927378e-04, 8.03264673e-04, 4.40393458e-04, 1.17514515e-04,\n",
            "       1.01089230e-04, 5.06034528e-04, 1.59395146e-04, 2.34270483e-04,\n",
            "       4.76986752e-04, 3.61067905e-05, 1.22323298e-04, 6.04402099e-04,\n",
            "       2.44865019e-04, 6.11798314e-04, 4.29270476e-05, 5.52366655e-05,\n",
            "       5.23902418e-04, 4.66518861e-04, 2.29867539e-04, 1.65029662e-04,\n",
            "       4.51334381e-05, 1.55546266e-04, 2.76650710e-04, 3.75156029e-04,\n",
            "       3.01345804e-04, 2.71758821e-04, 5.03208139e-04, 6.55692493e-05,\n",
            "       2.69727228e-04, 1.07715045e-04, 2.04051525e-04, 2.56853673e-05,\n",
            "       8.11235877e-05, 3.72692710e-04, 1.65878140e-04, 1.22068690e-04,\n",
            "       3.24435823e-05, 2.26258038e-04, 4.37066570e-04, 1.19609729e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/rezero/mul', 'index': 398, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.008186418563127518, 127), 'quantization_parameters': {'scales': array([0.00818642], dtype=float32), 'zero_points': array([127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 399, 'shape': array([72], dtype=int32), 'shape_signature': array([72], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00058516, 0.00037305, 0.00034737, 0.0004319 , 0.00044545,\n",
            "       0.00057078, 0.00051262, 0.00046833, 0.00051284, 0.00056419,\n",
            "       0.00036623, 0.00047508, 0.00040694, 0.000382  , 0.00069817,\n",
            "       0.00043817, 0.00054242, 0.00058587, 0.00042534, 0.0003249 ,\n",
            "       0.00046795, 0.00086682, 0.00069888, 0.00041639, 0.00040643,\n",
            "       0.0003808 , 0.00062325, 0.00042057, 0.00043641, 0.00039334,\n",
            "       0.00055659, 0.00044403, 0.00037498, 0.00046024, 0.00038806,\n",
            "       0.0004222 , 0.00046612, 0.00044321, 0.00041959, 0.00063273,\n",
            "       0.00053268, 0.0004795 , 0.00075418, 0.00064085, 0.00039323,\n",
            "       0.00051917, 0.00088467, 0.00056333, 0.00058958, 0.00063061,\n",
            "       0.0003872 , 0.00046252, 0.00058466, 0.00055856, 0.00036037,\n",
            "       0.00035228, 0.00050458, 0.00055361, 0.00081744, 0.00050647,\n",
            "       0.00055439, 0.00039807, 0.00043199, 0.00058386, 0.00040092,\n",
            "       0.00041447, 0.00048332, 0.0004415 , 0.00074018, 0.00033628,\n",
            "       0.00048838, 0.00048109], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 400, 'shape': array([ 72,   1,   1, 240], dtype=int32), 'shape_signature': array([ 72,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01003536, 0.00639775, 0.00595727, 0.00740704, 0.00763925,\n",
            "       0.00978863, 0.00879126, 0.00803165, 0.008795  , 0.00967561,\n",
            "       0.00628077, 0.00814756, 0.00697887, 0.00655116, 0.01197337,\n",
            "       0.00751444, 0.00930226, 0.01004747, 0.00729447, 0.005572  ,\n",
            "       0.00802528, 0.01486571, 0.01198566, 0.0071409 , 0.00697015,\n",
            "       0.00653057, 0.01068853, 0.00721263, 0.00748431, 0.00674564,\n",
            "       0.00954532, 0.0076149 , 0.00643088, 0.00789303, 0.0066551 ,\n",
            "       0.00724061, 0.00799382, 0.0076009 , 0.00719582, 0.01085115,\n",
            "       0.00913524, 0.00822321, 0.01293389, 0.01099037, 0.00674378,\n",
            "       0.00890366, 0.01517182, 0.00966099, 0.01011113, 0.01081475,\n",
            "       0.0066403 , 0.00793206, 0.01002682, 0.00957917, 0.00618016,\n",
            "       0.00604157, 0.00865332, 0.0094943 , 0.01401893, 0.00868583,\n",
            "       0.00950761, 0.00682683, 0.00740848, 0.01001304, 0.00687567,\n",
            "       0.00710799, 0.00828884, 0.00757159, 0.0126939 , 0.00576718,\n",
            "       0.00837552, 0.00825058], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 401, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.40851787e-05, 2.77117724e-05, 1.81983669e-05, 2.27535111e-05,\n",
            "       2.97371735e-05, 1.96777892e-05, 1.63465502e-05, 5.99531195e-05,\n",
            "       1.84604560e-05, 5.80990818e-05, 1.73468397e-05, 3.62546270e-05,\n",
            "       3.77581237e-05, 2.13403655e-05, 2.16786084e-05, 4.09304303e-05,\n",
            "       3.05166177e-05, 1.78466198e-05, 1.84262190e-05, 1.76739813e-05,\n",
            "       4.17958508e-05, 4.81078241e-05, 1.88621452e-05, 2.18494861e-05,\n",
            "       3.23094173e-05, 2.16115477e-05, 3.40157421e-05, 2.19772664e-05,\n",
            "       2.80317199e-05, 1.96880937e-05, 4.52428721e-05, 1.59882638e-05,\n",
            "       3.32278541e-05, 2.53297167e-05, 3.61524035e-05, 4.15417926e-05,\n",
            "       1.99669066e-05, 1.55332291e-05, 1.67965100e-05, 2.12019822e-05,\n",
            "       2.65468934e-05, 2.49903496e-05, 2.56037820e-05, 5.53257305e-05,\n",
            "       2.71101508e-05, 4.74304470e-05, 2.77846011e-05, 2.54077677e-05,\n",
            "       3.07368282e-05, 2.94674901e-05, 3.41507439e-05, 2.90067146e-05,\n",
            "       2.17841825e-05, 1.70044987e-05, 2.24412015e-05, 5.41585505e-05,\n",
            "       2.06785899e-05, 2.61719179e-05, 3.97706863e-05, 1.96753954e-05,\n",
            "       1.53845886e-05, 3.71509777e-05, 5.70542352e-06, 1.84307683e-05,\n",
            "       1.87735623e-05, 1.98070829e-05, 2.96575217e-05, 5.12458137e-05,\n",
            "       2.43914128e-05, 3.89042325e-05, 2.73803689e-05, 3.31692354e-05,\n",
            "       2.02353785e-05, 2.19887406e-05, 1.68004863e-05, 4.04375751e-05,\n",
            "       4.07909865e-05, 5.90537566e-05, 1.34570355e-05, 2.86759605e-05,\n",
            "       4.30142791e-05, 4.45994410e-05, 2.08206166e-05, 4.94916967e-05,\n",
            "       4.02617734e-05, 3.13405435e-05, 2.76926894e-05, 2.21556566e-05,\n",
            "       1.47370865e-05, 6.23368105e-05, 2.54412389e-05, 1.19807428e-05,\n",
            "       2.24017094e-05, 1.18057696e-05, 2.03131149e-05, 1.31568750e-05,\n",
            "       3.13749551e-05, 2.13862622e-05, 4.25393628e-05, 8.59490137e-06,\n",
            "       1.66259470e-05, 2.07891044e-05, 1.72819346e-05, 8.03758303e-06,\n",
            "       1.84523760e-05, 3.18681414e-05, 2.60060315e-05, 2.74731865e-05,\n",
            "       2.37561235e-05, 1.58183666e-05, 3.09868228e-05, 1.55325542e-05,\n",
            "       2.56576932e-05, 1.60532909e-05, 3.95890602e-05, 1.17222698e-05,\n",
            "       3.45161716e-05, 1.70428048e-05, 4.32351189e-05, 1.42346817e-05,\n",
            "       9.95540831e-05, 3.46815468e-05, 5.93342484e-05, 1.64958255e-05,\n",
            "       1.63282803e-05, 1.64440262e-05, 3.26166228e-05, 2.69475931e-05,\n",
            "       2.74841696e-05, 1.27386311e-05, 1.73608514e-05, 1.34778156e-05,\n",
            "       2.22441504e-05, 2.03364871e-05, 2.34477648e-05, 7.56018708e-05,\n",
            "       3.02222415e-05, 2.07676658e-05, 2.00276663e-05, 1.23052687e-05,\n",
            "       1.69027116e-05, 3.73482944e-05, 5.99246159e-05, 4.85562377e-05,\n",
            "       3.56899218e-05, 3.41312152e-05, 2.18769001e-05, 4.94387932e-05,\n",
            "       1.16949268e-05, 1.31421839e-05, 3.46851011e-05, 3.21565676e-05,\n",
            "       5.71955279e-05, 2.80388049e-05, 2.29742727e-05, 2.92145887e-05,\n",
            "       1.81273444e-05, 2.36330998e-05, 4.41578341e-05, 2.41696707e-05,\n",
            "       1.61884072e-05, 3.09847637e-05, 9.32536568e-05, 2.84411180e-05,\n",
            "       1.81470823e-05, 2.33572046e-05, 5.68838332e-05, 3.24174398e-05,\n",
            "       2.52841455e-05, 1.65550155e-05, 2.17395882e-05, 3.99207784e-05,\n",
            "       3.81909449e-05, 1.78855535e-05, 1.49604666e-05, 3.93279734e-05,\n",
            "       3.33272037e-05, 4.49803665e-05, 4.78445982e-05, 5.04883246e-05,\n",
            "       4.08158521e-05, 1.96874771e-05, 3.23963795e-05, 4.51555970e-05,\n",
            "       3.49008005e-05, 3.30016410e-05, 1.83404882e-05, 5.48472817e-05,\n",
            "       2.55185059e-05, 1.79781855e-05, 2.21307364e-05, 1.43363532e-05,\n",
            "       1.26642539e-04, 3.12512384e-05, 9.13495569e-06, 3.38964492e-05,\n",
            "       2.66036150e-05, 2.68130898e-05, 4.10871544e-05, 2.70973760e-05,\n",
            "       4.71646163e-05, 2.30688238e-05, 2.40151476e-05, 2.01959137e-05,\n",
            "       2.78475873e-05, 1.92468269e-05, 1.68073693e-05, 4.66281926e-05,\n",
            "       2.88525480e-05, 2.79244832e-05, 2.34656218e-05, 2.75697912e-05,\n",
            "       1.98573471e-05, 2.24112864e-05, 1.78102327e-05, 2.48895612e-05,\n",
            "       2.16916396e-05, 2.93582470e-05, 2.77286326e-05, 2.22312829e-05,\n",
            "       3.66646891e-05, 3.39959188e-05, 3.58548023e-05, 6.41609513e-05,\n",
            "       1.00493089e-05, 1.77939783e-05, 2.27110177e-05, 6.07586189e-05,\n",
            "       4.21752447e-05, 4.78287075e-05, 3.94594972e-05, 2.31625272e-05,\n",
            "       1.93540400e-05, 1.51817030e-05, 1.43711222e-05, 3.77183424e-05,\n",
            "       1.78856972e-05, 1.01769274e-05, 1.76253070e-05, 3.78659279e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 402, 'shape': array([240,   1,   1, 120], dtype=int32), 'shape_signature': array([240,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00099694, 0.00114705, 0.00075327, 0.00094182, 0.00123089,\n",
            "       0.00081451, 0.00067662, 0.0024816 , 0.00076412, 0.00240485,\n",
            "       0.00071803, 0.00150066, 0.0015629 , 0.00088333, 0.00089733,\n",
            "       0.0016942 , 0.00126315, 0.00073871, 0.0007627 , 0.00073157,\n",
            "       0.00173003, 0.00199129, 0.00078075, 0.0009044 , 0.00133736,\n",
            "       0.00089455, 0.00140799, 0.00090969, 0.0011603 , 0.00081494,\n",
            "       0.00187271, 0.00066179, 0.00137538, 0.00104846, 0.00149643,\n",
            "       0.00171951, 0.00082648, 0.00064296, 0.00069525, 0.0008776 ,\n",
            "       0.00109884, 0.00103441, 0.0010598 , 0.00229006, 0.00112215,\n",
            "       0.00196325, 0.00115007, 0.00105169, 0.00127227, 0.00121973,\n",
            "       0.00141358, 0.00120065, 0.0009017 , 0.00070386, 0.00092889,\n",
            "       0.00224175, 0.00085593, 0.00108332, 0.0016462 , 0.00081441,\n",
            "       0.0006368 , 0.00153776, 0.00023616, 0.00076289, 0.00077708,\n",
            "       0.00081986, 0.00122759, 0.00212118, 0.00100962, 0.00161034,\n",
            "       0.00113334, 0.00137295, 0.00083759, 0.00091016, 0.00069541,\n",
            "       0.0016738 , 0.00168843, 0.00244437, 0.00055702, 0.00118696,\n",
            "       0.00178046, 0.00184607, 0.00086181, 0.00204857, 0.00166653,\n",
            "       0.00129726, 0.00114626, 0.00091707, 0.00061   , 0.00258026,\n",
            "       0.00105307, 0.00049591, 0.00092726, 0.00048867, 0.00084081,\n",
            "       0.00054459, 0.00129868, 0.00088523, 0.0017608 , 0.00035576,\n",
            "       0.00068819, 0.00086051, 0.00071534, 0.00033269, 0.00076379,\n",
            "       0.0013191 , 0.00107645, 0.00113718, 0.00098332, 0.00065476,\n",
            "       0.00128262, 0.00064293, 0.00106203, 0.00066448, 0.00163868,\n",
            "       0.00048521, 0.0014287 , 0.00070544, 0.0017896 , 0.00058921,\n",
            "       0.00412077, 0.00143555, 0.00245598, 0.0006828 , 0.00067586,\n",
            "       0.00068066, 0.00135008, 0.00111542, 0.00113763, 0.00052728,\n",
            "       0.00071861, 0.00055788, 0.00092074, 0.00084177, 0.00097056,\n",
            "       0.00312933, 0.00125097, 0.00085962, 0.00082899, 0.00050934,\n",
            "       0.00069964, 0.00154593, 0.00248042, 0.00200985, 0.00147729,\n",
            "       0.00141277, 0.00090554, 0.00204639, 0.00048408, 0.00054399,\n",
            "       0.0014357 , 0.00133103, 0.00236745, 0.00116059, 0.00095096,\n",
            "       0.00120926, 0.00075033, 0.00097823, 0.00182779, 0.00100044,\n",
            "       0.00067008, 0.00128253, 0.00385998, 0.00117724, 0.00075115,\n",
            "       0.00096681, 0.00235455, 0.00134183, 0.00104657, 0.00068525,\n",
            "       0.00089985, 0.00165241, 0.00158081, 0.00074032, 0.00061925,\n",
            "       0.00162788, 0.00137949, 0.00186184, 0.0019804 , 0.00208983,\n",
            "       0.00168946, 0.00081491, 0.00134096, 0.00186909, 0.00144462,\n",
            "       0.00136601, 0.00075915, 0.00227025, 0.00105627, 0.00074416,\n",
            "       0.00091604, 0.00059341, 0.00524203, 0.00129356, 0.00037812,\n",
            "       0.00140305, 0.00110118, 0.00110986, 0.00170069, 0.00112162,\n",
            "       0.00195225, 0.00095487, 0.00099404, 0.00083596, 0.00115268,\n",
            "       0.00079667, 0.0006957 , 0.00193005, 0.00119427, 0.00115586,\n",
            "       0.0009713 , 0.00114118, 0.00082194, 0.00092765, 0.00073721,\n",
            "       0.00103024, 0.00089787, 0.00121521, 0.00114775, 0.0009202 ,\n",
            "       0.00151764, 0.00140717, 0.00148411, 0.00265577, 0.00041596,\n",
            "       0.00073653, 0.00094006, 0.00251494, 0.00174573, 0.00197974,\n",
            "       0.00163332, 0.00095875, 0.00080111, 0.00062841, 0.00059485,\n",
            "       0.00156125, 0.00074033, 0.00042125, 0.00072955, 0.00156736],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 403, 'shape': array([120], dtype=int32), 'shape_signature': array([120], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.73050279e-05, 2.35581538e-05, 8.02998256e-05, 2.96914750e-05,\n",
            "       4.32527777e-05, 4.01437828e-05, 2.92777131e-05, 4.46217964e-05,\n",
            "       2.74665454e-05, 3.46610614e-05, 2.67959804e-05, 3.42299172e-05,\n",
            "       7.15286515e-05, 5.75326121e-05, 2.24949235e-05, 3.93686751e-05,\n",
            "       3.92728798e-05, 1.08065669e-05, 1.43950028e-05, 7.54562207e-05,\n",
            "       5.08425619e-05, 5.70579723e-05, 1.50848073e-05, 4.53569955e-05,\n",
            "       2.13972253e-05, 3.15868419e-05, 3.02911503e-05, 3.47243767e-05,\n",
            "       3.46656489e-05, 5.62779715e-05, 3.34633114e-05, 5.75600861e-05,\n",
            "       3.17858758e-05, 2.95706141e-05, 5.37408669e-05, 4.61288364e-05,\n",
            "       3.70122980e-05, 1.85779500e-04, 4.06283871e-05, 3.19096325e-05,\n",
            "       6.15171666e-05, 3.78960758e-05, 9.10833478e-05, 3.16898804e-05,\n",
            "       3.85940220e-05, 3.77833021e-05, 2.34190193e-05, 8.32144869e-05,\n",
            "       4.12167319e-05, 4.99764865e-05, 2.96664712e-05, 3.43489119e-05,\n",
            "       5.09001693e-05, 4.25125872e-05, 5.24380994e-05, 3.80892852e-05,\n",
            "       5.49292308e-05, 4.45406658e-05, 6.38112324e-05, 5.47871459e-05,\n",
            "       3.67691246e-05, 5.08509693e-05, 3.88879125e-05, 2.60065608e-05,\n",
            "       6.67217319e-05, 2.79523938e-05, 2.78358730e-05, 2.69426564e-05,\n",
            "       2.51943911e-05, 2.94574929e-05, 3.12277152e-05, 2.59971221e-05,\n",
            "       4.26080478e-05, 8.47931660e-05, 4.09090280e-05, 4.72161701e-05,\n",
            "       1.72334749e-05, 4.30418695e-05, 6.06537542e-05, 4.85126839e-05,\n",
            "       1.03821294e-04, 3.57107019e-05, 6.27728732e-05, 1.88805188e-05,\n",
            "       5.32972845e-05, 2.34562394e-05, 5.43412389e-05, 3.84624072e-05,\n",
            "       4.90211241e-05, 5.99663763e-05, 9.44831118e-05, 3.97789117e-05,\n",
            "       5.67441493e-05, 3.77908764e-05, 4.01592697e-05, 3.94928466e-05,\n",
            "       3.39659528e-05, 2.73310507e-05, 2.59349235e-05, 1.53188885e-05,\n",
            "       4.82995274e-05, 4.17544725e-05, 2.94313722e-05, 6.18530830e-05,\n",
            "       6.33663003e-05, 3.56267992e-05, 3.58251091e-05, 5.08758712e-05,\n",
            "       6.14714081e-05, 2.35047919e-05, 5.76656275e-05, 3.22499218e-05,\n",
            "       5.95575329e-05, 6.31414514e-05, 5.19969035e-05, 2.95089994e-05,\n",
            "       3.13424898e-05, 4.21320219e-05, 4.27629820e-05, 3.88374574e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 404, 'shape': array([120,   1,   1, 480], dtype=int32), 'shape_signature': array([120,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.0014463 , 0.00091334, 0.00311319, 0.00115112, 0.00167689,\n",
            "       0.00155636, 0.00113508, 0.00172997, 0.00106487, 0.00134379,\n",
            "       0.00103887, 0.00132708, 0.00277313, 0.00223051, 0.00087212,\n",
            "       0.00152631, 0.00152259, 0.00041897, 0.00055809, 0.0029254 ,\n",
            "       0.00197114, 0.00221211, 0.00058483, 0.00175847, 0.00082956,\n",
            "       0.00122461, 0.00117437, 0.00134625, 0.00134397, 0.00218187,\n",
            "       0.00129736, 0.00223158, 0.00123232, 0.00114644, 0.00208351,\n",
            "       0.00178839, 0.00143495, 0.00720259, 0.00157514, 0.00123712,\n",
            "       0.00238499, 0.00146921, 0.00353126, 0.0012286 , 0.00149627,\n",
            "       0.00146484, 0.00090794, 0.00322619, 0.00159795, 0.00193757,\n",
            "       0.00115016, 0.00133169, 0.00197338, 0.00164819, 0.002033  ,\n",
            "       0.0014767 , 0.00212958, 0.00172682, 0.00247393, 0.00212407,\n",
            "       0.00142552, 0.00197147, 0.00150767, 0.00100826, 0.00258677,\n",
            "       0.0010837 , 0.00107918, 0.00104455, 0.00097677, 0.00114205,\n",
            "       0.00121068, 0.0010079 , 0.00165189, 0.00328739, 0.00158602,\n",
            "       0.00183055, 0.00066813, 0.00166871, 0.00235152, 0.00188081,\n",
            "       0.0040251 , 0.00138449, 0.00243368, 0.00073199, 0.00206631,\n",
            "       0.00090939, 0.00210678, 0.00149117, 0.00190053, 0.00232487,\n",
            "       0.00366307, 0.00154221, 0.00219994, 0.00146513, 0.00155696,\n",
            "       0.00153112, 0.00131684, 0.00105961, 0.00100549, 0.00059391,\n",
            "       0.00187255, 0.0016188 , 0.00114104, 0.00239802, 0.00245668,\n",
            "       0.00138123, 0.00138892, 0.00197243, 0.00238322, 0.00091127,\n",
            "       0.00223567, 0.00125031, 0.00230902, 0.00244797, 0.0020159 ,\n",
            "       0.00114405, 0.00121513, 0.00163344, 0.0016579 , 0.00150571],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 405, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01098674, 0.01141992, 0.00434254, 0.00213603, 0.00071371,\n",
            "       0.00626434, 0.0107051 , 0.00517042, 0.00679163, 0.00136109,\n",
            "       0.00996162, 0.01811376, 0.02261723, 0.00851661, 0.00093921,\n",
            "       0.0186433 , 0.01393729, 0.00667352, 0.00080438, 0.015734  ,\n",
            "       0.0023105 , 0.01159395, 0.01251405, 0.00665165, 0.00495717,\n",
            "       0.00157818, 0.01178747, 0.00982916, 0.00174663, 0.01114713,\n",
            "       0.00227447, 0.01112494, 0.00221238, 0.01119577, 0.00082791,\n",
            "       0.00492423, 0.00121722, 0.00897161, 0.01282649, 0.00176774,\n",
            "       0.00101935, 0.01593479, 0.00077841, 0.01915244, 0.01145091,\n",
            "       0.00108616, 0.00129032, 0.0077615 , 0.00605357, 0.00326723,\n",
            "       0.02428963, 0.00509383, 0.00175067, 0.01287321, 0.00114701,\n",
            "       0.00954653, 0.00080845, 0.00457531, 0.00540937, 0.00067645,\n",
            "       0.00208579, 0.00244241, 0.00284772, 0.01318531, 0.00089407,\n",
            "       0.00240805, 0.00572599, 0.00155212, 0.00342813, 0.00069952,\n",
            "       0.00639605, 0.00063282, 0.00054441, 0.00690251, 0.0115221 ,\n",
            "       0.01493353, 0.0016778 , 0.00127754, 0.00051707, 0.000636  ,\n",
            "       0.00209801, 0.01931703, 0.00901894, 0.00481326, 0.00116716,\n",
            "       0.01787549, 0.00299108, 0.00144496, 0.00380014, 0.00110689,\n",
            "       0.01163515, 0.00780789, 0.00122377, 0.01213347, 0.00056428,\n",
            "       0.0044317 , 0.00089132, 0.00707867, 0.00574837, 0.01155189,\n",
            "       0.00295722, 0.00125412, 0.0027161 , 0.00944353, 0.00059226,\n",
            "       0.00328269, 0.00657178, 0.00166498, 0.00860946, 0.0135405 ,\n",
            "       0.01886108, 0.00800488, 0.00099125, 0.00077752, 0.00321775,\n",
            "       0.00078897, 0.02050891, 0.00066326, 0.00860367, 0.0094587 ,\n",
            "       0.0008933 , 0.00107964, 0.00651587, 0.01315574, 0.00117905,\n",
            "       0.0101305 , 0.00225863, 0.00303004, 0.00191623, 0.00285372,\n",
            "       0.00746003, 0.00066094, 0.0057534 , 0.00805421, 0.00132476,\n",
            "       0.00030107, 0.00311209, 0.00153385, 0.01057877, 0.01355539,\n",
            "       0.01146329, 0.00113614, 0.0123611 , 0.00085781, 0.0073635 ,\n",
            "       0.0018802 , 0.01197755, 0.00456384, 0.0029147 , 0.0100954 ,\n",
            "       0.01714883, 0.01243106, 0.0008491 , 0.01341995, 0.00124465,\n",
            "       0.00125637, 0.01573127, 0.00222518, 0.03009066, 0.00045494,\n",
            "       0.01105531, 0.0087177 , 0.00063708, 0.0021659 , 0.00906048,\n",
            "       0.00437719, 0.00145611, 0.00105614, 0.00567338, 0.01363498,\n",
            "       0.0104243 , 0.0109403 , 0.00099177, 0.00086972, 0.00050607,\n",
            "       0.00088932, 0.01120166, 0.03033099, 0.00340137, 0.00190242,\n",
            "       0.00349233, 0.00054665, 0.00544965, 0.00783259, 0.00104051,\n",
            "       0.01468257, 0.01744799, 0.0059134 , 0.01077335, 0.0100382 ,\n",
            "       0.00545363, 0.00296263, 0.0003397 , 0.00061765, 0.00111468,\n",
            "       0.00071731, 0.00699391, 0.00687003, 0.00051822, 0.00969326,\n",
            "       0.02258398, 0.00840312, 0.00135739, 0.01251193, 0.0014019 ,\n",
            "       0.01470594, 0.00871368, 0.00070083, 0.00133787, 0.01777047,\n",
            "       0.00998816, 0.01783489, 0.00085524, 0.00842553, 0.00957839,\n",
            "       0.00245619, 0.00398979, 0.00089569, 0.00280551, 0.00618844,\n",
            "       0.00873857, 0.01519985, 0.00952039, 0.00373163, 0.01268381,\n",
            "       0.0036226 , 0.00155644, 0.00087149, 0.00742806, 0.00147805,\n",
            "       0.00063165, 0.00269785, 0.00061338, 0.01217314, 0.00141236,\n",
            "       0.00244976, 0.01211304, 0.00319575, 0.01198659, 0.00070634],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul', 'index': 406, 'shape': array([  1,   5,   1, 240], dtype=int32), 'shape_signature': array([  1,   5,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.09742206, 0.10126317, 0.0385063 , 0.01894072, 0.00632861,\n",
            "       0.05554742, 0.09492465, 0.0458473 , 0.06022297, 0.01206915,\n",
            "       0.088332  , 0.16061898, 0.20055234, 0.07551879, 0.00832818,\n",
            "       0.16531454, 0.12358525, 0.05917571, 0.00713263, 0.13951708,\n",
            "       0.02048775, 0.1028063 , 0.11096505, 0.05898175, 0.04395644,\n",
            "       0.01399412, 0.10452227, 0.08715751, 0.01548776, 0.09884422,\n",
            "       0.02016827, 0.09864748, 0.01961767, 0.09927555, 0.00734128,\n",
            "       0.04366427, 0.01079337, 0.07955343, 0.11373548, 0.01567496,\n",
            "       0.00903879, 0.14129755, 0.00690237, 0.16982923, 0.10153792,\n",
            "       0.00963121, 0.0114416 , 0.06882308, 0.05367848, 0.02897133,\n",
            "       0.21538194, 0.04516818, 0.0155236 , 0.11414976, 0.01017079,\n",
            "       0.08465135, 0.00716873, 0.04057037, 0.04796616, 0.00599824,\n",
            "       0.01849517, 0.02165738, 0.02525137, 0.11691724, 0.00792793,\n",
            "       0.02135271, 0.05077367, 0.013763  , 0.03039806, 0.00620281,\n",
            "       0.05671532, 0.0056114 , 0.00482737, 0.06120622, 0.10216923,\n",
            "       0.13241914, 0.01487746, 0.01132826, 0.00458502, 0.00563955,\n",
            "       0.01860352, 0.17128865, 0.07997305, 0.04268032, 0.01034951,\n",
            "       0.15850616, 0.02652263, 0.0128128 , 0.03369671, 0.00981502,\n",
            "       0.10317163, 0.06923439, 0.0108515 , 0.10759031, 0.00500364,\n",
            "       0.03929691, 0.00790357, 0.06276826, 0.05097217, 0.10243333,\n",
            "       0.02622236, 0.0111206 , 0.02408431, 0.08373803, 0.00525168,\n",
            "       0.02910841, 0.05827349, 0.01476373, 0.07634214, 0.12006686,\n",
            "       0.16724567, 0.07098114, 0.00878961, 0.00689446, 0.02853255,\n",
            "       0.00699596, 0.18185733, 0.00588128, 0.07629079, 0.08387256,\n",
            "       0.00792109, 0.0095734 , 0.05777772, 0.11665503, 0.01045494,\n",
            "       0.08982951, 0.02002778, 0.02686808, 0.01699162, 0.02530458,\n",
            "       0.06614989, 0.00586072, 0.05101678, 0.07141861, 0.01174694,\n",
            "       0.00266969, 0.02759562, 0.01360103, 0.09380446, 0.12019887,\n",
            "       0.10164769, 0.01007443, 0.10960882, 0.00760644, 0.06529392,\n",
            "       0.01667215, 0.10620774, 0.04046864, 0.02584535, 0.08951826,\n",
            "       0.15206273, 0.1102291 , 0.00752917, 0.11899787, 0.01103659,\n",
            "       0.01114049, 0.1394929 , 0.01973117, 0.26682103, 0.00403403,\n",
            "       0.09803003, 0.0773019 , 0.00564913, 0.01920553, 0.08034138,\n",
            "       0.03881359, 0.01291163, 0.00936507, 0.05030718, 0.12090458,\n",
            "       0.0924347 , 0.09701023, 0.00879424, 0.00771205, 0.00448745,\n",
            "       0.0078858 , 0.09932778, 0.26895207, 0.03016072, 0.0168692 ,\n",
            "       0.03096734, 0.0048473 , 0.04832331, 0.06945343, 0.00922642,\n",
            "       0.13019383, 0.15471542, 0.05243552, 0.09552981, 0.08901109,\n",
            "       0.04835864, 0.02627038, 0.00301224, 0.00547681, 0.00988417,\n",
            "       0.00636057, 0.06201667, 0.0609182 , 0.00459516, 0.0859524 ,\n",
            "       0.20025751, 0.07451246, 0.01203628, 0.11094623, 0.01243095,\n",
            "       0.13040106, 0.07726625, 0.00621438, 0.01186321, 0.15757498,\n",
            "       0.08856735, 0.15814614, 0.00758358, 0.07471117, 0.08493385,\n",
            "       0.02177962, 0.03537839, 0.0079423 , 0.02487716, 0.05487436,\n",
            "       0.07748698, 0.1347807 , 0.08441953, 0.03308927, 0.11247035,\n",
            "       0.03212244, 0.01380134, 0.00772767, 0.06586636, 0.01310626,\n",
            "       0.00560102, 0.0239225 , 0.00543899, 0.10794213, 0.01252372,\n",
            "       0.02172262, 0.10740919, 0.02833744, 0.10628797, 0.00626327],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/skip/skip_project/conv2d/bn/FusedBatchNormV3', 'index': 407, 'shape': array([72], dtype=int32), 'shape_signature': array([72], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00088899, 0.00155293, 0.00245419, 0.00197361, 0.00161865,\n",
            "       0.00155523, 0.00088751, 0.00174724, 0.0012749 , 0.00121253,\n",
            "       0.00100866, 0.00199363, 0.00164938, 0.00250699, 0.003606  ,\n",
            "       0.00262205, 0.00232712, 0.00107549, 0.00158085, 0.00230558,\n",
            "       0.00265469, 0.00233017, 0.0013989 , 0.00114601, 0.00128619,\n",
            "       0.00131128, 0.00422412, 0.00233691, 0.00176848, 0.0014639 ,\n",
            "       0.00078736, 0.00103369, 0.00158531, 0.0024211 , 0.00159514,\n",
            "       0.00182445, 0.0015116 , 0.00151371, 0.0012401 , 0.00158505,\n",
            "       0.00177346, 0.00084807, 0.00105715, 0.0015414 , 0.00091449,\n",
            "       0.00140775, 0.00088597, 0.00241332, 0.00173847, 0.00273951,\n",
            "       0.0032191 , 0.00185948, 0.00213071, 0.00197105, 0.00076633,\n",
            "       0.00195153, 0.00044133, 0.00241762, 0.00552477, 0.00211319,\n",
            "       0.00239283, 0.00133321, 0.00202026, 0.0017766 , 0.00192493,\n",
            "       0.00082465, 0.00146774, 0.00193329, 0.00211664, 0.00191477,\n",
            "       0.00171759, 0.00221337], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/skip/skip_project/conv2d/conv2d_4/Conv2D', 'index': 408, 'shape': array([72,  1,  1, 40], dtype=int32), 'shape_signature': array([72,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00092124, 0.00160928, 0.00254323, 0.00204522, 0.00167738,\n",
            "       0.00161166, 0.00091971, 0.00181064, 0.00132116, 0.00125653,\n",
            "       0.00104525, 0.00206597, 0.00170922, 0.00259795, 0.00373683,\n",
            "       0.00271718, 0.00241155, 0.00111451, 0.00163821, 0.00238923,\n",
            "       0.002751  , 0.00241471, 0.00144966, 0.00118759, 0.00133286,\n",
            "       0.00135885, 0.00437738, 0.00242169, 0.00183265, 0.00151701,\n",
            "       0.00081593, 0.00107119, 0.00164283, 0.00250894, 0.00165301,\n",
            "       0.00189065, 0.00156645, 0.00156863, 0.00128509, 0.00164256,\n",
            "       0.0018378 , 0.00087884, 0.0010955 , 0.00159732, 0.00094767,\n",
            "       0.00145882, 0.00091811, 0.00250088, 0.00180154, 0.0028389 ,\n",
            "       0.00333589, 0.00192694, 0.00220802, 0.00204256, 0.00079413,\n",
            "       0.00202234, 0.00045734, 0.00250534, 0.00572521, 0.00218986,\n",
            "       0.00247964, 0.00138158, 0.00209356, 0.00184106, 0.00199477,\n",
            "       0.00085457, 0.001521  , 0.00200343, 0.00219343, 0.00198424,\n",
            "       0.00177991, 0.00229367], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 409, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.19436018e-04, 6.48630376e-04, 1.42694882e-03, 1.36515358e-03,\n",
            "       1.63650012e-03, 3.72352544e-04, 2.88959927e-05, 8.55420876e-05,\n",
            "       5.00283568e-05, 6.66712003e-04, 1.82366915e-04, 4.20442921e-05,\n",
            "       6.50192305e-05, 1.69991353e-03, 4.77263937e-03, 8.22727889e-05,\n",
            "       5.31661753e-05, 2.03182618e-03, 1.16455136e-03, 1.09995657e-03,\n",
            "       2.38489732e-03, 3.79175835e-05, 2.75648898e-04, 5.08242694e-04,\n",
            "       7.85219949e-04, 1.05432956e-03, 7.07693689e-05, 6.34730153e-04,\n",
            "       1.31443806e-03, 3.46261106e-04, 7.22561439e-04, 3.65521919e-05,\n",
            "       1.69847847e-03, 1.85888130e-04, 1.28236122e-03, 3.20087333e-04,\n",
            "       8.69039504e-04, 1.08902314e-04, 1.02832529e-03, 5.59335167e-04,\n",
            "       1.37868791e-03, 1.97120104e-03, 6.03040447e-04, 9.72050111e-05,\n",
            "       2.01201090e-03, 7.75007182e-04, 2.49145483e-03, 1.00841666e-04,\n",
            "       7.61751580e-05, 7.65197969e-04, 7.46307924e-05, 1.10700094e-04,\n",
            "       6.38691825e-04, 3.65324580e-04, 1.89086044e-04, 1.34784888e-04,\n",
            "       7.10693945e-04, 7.78440095e-04, 1.95994944e-04, 1.12413324e-03,\n",
            "       2.07863096e-03, 1.90158389e-04, 1.24283356e-03, 1.26802525e-03,\n",
            "       3.04995594e-03, 3.24333413e-03, 8.16339671e-05, 5.10522863e-04,\n",
            "       2.10821992e-04, 7.84429314e-04, 1.67550097e-04, 1.59877911e-03,\n",
            "       1.39327766e-03, 4.09420521e-04, 9.45622232e-05, 7.22481287e-04,\n",
            "       2.08091311e-04, 1.23260275e-03, 4.58812021e-04, 6.88524917e-04,\n",
            "       2.62221810e-03, 6.58795980e-05, 1.13235984e-03, 2.58799031e-04,\n",
            "       9.14272969e-04, 3.55542434e-05, 2.98444298e-04, 1.42832927e-03,\n",
            "       1.49327359e-04, 6.87288761e-04, 8.98968574e-05, 1.39859214e-03,\n",
            "       5.38558525e-04, 2.87177856e-04, 1.02575507e-03, 3.85304884e-04,\n",
            "       6.22903754e-04, 2.66785058e-03, 1.55072703e-04, 4.65112418e-04,\n",
            "       8.30618199e-04, 7.21338380e-04, 3.18415987e-04, 2.42911672e-04,\n",
            "       5.35596907e-03, 6.26226247e-04, 3.80851307e-05, 3.95616633e-04,\n",
            "       1.28973887e-04, 1.80368355e-04, 9.28440131e-05, 1.26751245e-03,\n",
            "       7.34595931e-04, 4.80802904e-04, 1.27212389e-03, 6.43927953e-04,\n",
            "       7.78004542e-05, 7.56465597e-04, 1.93508939e-04, 2.23546322e-05,\n",
            "       9.44308937e-04, 9.95544251e-04, 2.22885079e-04, 1.12829512e-04,\n",
            "       3.44546512e-04, 1.48149300e-03, 6.18839578e-04, 4.07419662e-04,\n",
            "       6.48954068e-04, 1.59986084e-04, 5.06216951e-04, 7.87525030e-04,\n",
            "       7.26007391e-04, 1.46058551e-03, 6.07730995e-04, 4.61311138e-04,\n",
            "       2.26068529e-04, 5.90736861e-04, 3.17321974e-04, 4.28925414e-04,\n",
            "       1.17131765e-03, 6.55022275e-04, 8.07779070e-05, 4.11798857e-04,\n",
            "       1.28884189e-04, 4.42616874e-04, 1.49222935e-04, 2.27385986e-04,\n",
            "       1.70615083e-03, 8.11374630e-04, 8.85721529e-05, 1.34164910e-03,\n",
            "       7.38403236e-04, 1.22856779e-03, 1.90233870e-03, 1.84139470e-03,\n",
            "       1.19560643e-03, 1.34419580e-03, 5.96838690e-05, 9.83867096e-04,\n",
            "       4.80165996e-04, 1.41365235e-04, 6.10394578e-04, 6.04309898e-04,\n",
            "       3.07402806e-04, 1.19394821e-03, 1.40410761e-04, 4.00612567e-04,\n",
            "       6.29970105e-04, 5.72879449e-04, 7.86486198e-04, 1.03536375e-04,\n",
            "       7.30973727e-04, 3.67647666e-03, 3.65065178e-04, 4.43257578e-03,\n",
            "       3.45250301e-04, 5.90182717e-05, 8.86805647e-05, 5.68887801e-04,\n",
            "       1.29920419e-03, 3.04466486e-03, 5.50629629e-04, 1.89472848e-04,\n",
            "       1.91106956e-04, 5.68042684e-04, 1.35273417e-03, 2.11942694e-04,\n",
            "       7.42116186e-04, 1.53620425e-03, 2.69180426e-04, 1.62209049e-04,\n",
            "       1.01987203e-03, 1.56416104e-03, 6.19711180e-04, 1.03282253e-03,\n",
            "       2.98219442e-04, 6.75337680e-04, 1.57636777e-03, 9.34092241e-05,\n",
            "       6.48017085e-05, 1.34248519e-04, 1.50488922e-03, 4.64755809e-04,\n",
            "       8.63797031e-04, 7.98759225e-04, 7.80977716e-04, 8.92492186e-04,\n",
            "       6.13935001e-04, 2.02727830e-03, 5.64216461e-04, 5.70791672e-05,\n",
            "       3.18317488e-03, 9.00549581e-04, 5.52485988e-04, 5.50468685e-04,\n",
            "       3.57561483e-04, 4.53663029e-04, 5.25192183e-04, 4.36664443e-04,\n",
            "       3.69076297e-04, 1.22761863e-04, 8.79008614e-04, 2.33937229e-04,\n",
            "       5.03325311e-04, 4.12070687e-04, 1.59617324e-04, 1.48870645e-03,\n",
            "       1.33268390e-04, 2.63431831e-03, 1.11360685e-03, 1.98476599e-04,\n",
            "       6.90032030e-04, 6.05048379e-04, 7.29179810e-05, 1.15630263e-03,\n",
            "       6.79840159e-04, 2.03938107e-04, 2.32480947e-04, 1.27821800e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 410, 'shape': array([  1,   3,   3, 240], dtype=int32), 'shape_signature': array([  1,   3,   3, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00634274, 0.01287925, 0.02833359, 0.02710658, 0.03249446,\n",
            "       0.00739346, 0.00057376, 0.00169853, 0.00099337, 0.01323828,\n",
            "       0.00362109, 0.00083483, 0.00129103, 0.0337536 , 0.09476585,\n",
            "       0.00163361, 0.00105567, 0.04034407, 0.02312341, 0.02184081,\n",
            "       0.04735468, 0.00075289, 0.0054733 , 0.0100917 , 0.01559138,\n",
            "       0.02093484, 0.0014052 , 0.01260324, 0.02609957, 0.00687538,\n",
            "       0.01434723, 0.00072578, 0.0337251 , 0.00369101, 0.02546265,\n",
            "       0.00635568, 0.01725571, 0.00216237, 0.02041849, 0.0111062 ,\n",
            "       0.02737532, 0.0391403 , 0.01197401, 0.00193011, 0.03995062,\n",
            "       0.01538859, 0.04947049, 0.00200232, 0.00151254, 0.01519382,\n",
            "       0.00148187, 0.00219807, 0.01268191, 0.00725391, 0.00375451,\n",
            "       0.0026763 , 0.01411159, 0.01545676, 0.00389169, 0.02232086,\n",
            "       0.04127343, 0.0037758 , 0.02467779, 0.02517799, 0.06056013,\n",
            "       0.06439986, 0.00162093, 0.01013698, 0.0041861 , 0.01557568,\n",
            "       0.00332689, 0.03174546, 0.02766501, 0.00812948, 0.00187763,\n",
            "       0.01434564, 0.00413188, 0.02447464, 0.0091102 , 0.0136714 ,\n",
            "       0.05206694, 0.00130811, 0.02248421, 0.00513873, 0.01815386,\n",
            "       0.00070597, 0.00592593, 0.028361  , 0.00296505, 0.01364685,\n",
            "       0.001785  , 0.02777054, 0.01069365, 0.00570222, 0.02036746,\n",
            "       0.00765064, 0.01236842, 0.05297302, 0.00307913, 0.0092353 ,\n",
            "       0.01649281, 0.01432294, 0.00632249, 0.00482327, 0.10634848,\n",
            "       0.01243439, 0.00075622, 0.00785539, 0.00256091, 0.00358141,\n",
            "       0.00184352, 0.02516781, 0.01458619, 0.00954685, 0.02525938,\n",
            "       0.01278588, 0.00154481, 0.01502043, 0.00384233, 0.00044388,\n",
            "       0.01875026, 0.01976759, 0.00442562, 0.00224035, 0.00684134,\n",
            "       0.02941662, 0.01228772, 0.00808975, 0.01288567, 0.00317669,\n",
            "       0.01005148, 0.01563715, 0.01441565, 0.02900148, 0.01206715,\n",
            "       0.00915982, 0.00448883, 0.01172971, 0.00630077, 0.00851677,\n",
            "       0.02325776, 0.01300617, 0.00160393, 0.00817671, 0.00255913,\n",
            "       0.00878863, 0.00296298, 0.00451499, 0.03387744, 0.01611071,\n",
            "       0.00175869, 0.02663988, 0.01466178, 0.02439452, 0.03777296,\n",
            "       0.03656286, 0.02374004, 0.02669044, 0.00118509, 0.01953573,\n",
            "       0.00953421, 0.00280696, 0.01212004, 0.01199922, 0.00610381,\n",
            "       0.02370712, 0.00278801, 0.00795459, 0.01250873, 0.01137513,\n",
            "       0.01561652, 0.00205583, 0.01451426, 0.07300036, 0.00724876,\n",
            "       0.08801352, 0.00685531, 0.00117187, 0.00176085, 0.01129587,\n",
            "       0.02579709, 0.06045507, 0.01093334, 0.00376219, 0.00379463,\n",
            "       0.01127909, 0.02685998, 0.00420835, 0.01473551, 0.03050297,\n",
            "       0.00534486, 0.00322083, 0.02025065, 0.03105809, 0.01230503,\n",
            "       0.02050779, 0.00592147, 0.01340955, 0.03130046, 0.00185474,\n",
            "       0.00128671, 0.00266565, 0.02988118, 0.00922822, 0.01715161,\n",
            "       0.01586022, 0.01550715, 0.01772138, 0.01219033, 0.04025377,\n",
            "       0.01120312, 0.00113337, 0.06320533, 0.01788137, 0.0109702 ,\n",
            "       0.01093014, 0.00709976, 0.00900796, 0.01042825, 0.00867044,\n",
            "       0.0073284 , 0.00243757, 0.01745365, 0.00464507, 0.00999406,\n",
            "       0.0081821 , 0.00316937, 0.02955985, 0.00264619, 0.0523072 ,\n",
            "       0.02211185, 0.00394096, 0.01370132, 0.01201388, 0.00144786,\n",
            "       0.02295962, 0.01349895, 0.00404941, 0.00461616, 0.02538038],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 411, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([8.14516607e-05, 1.47446219e-04, 4.48475657e-05, 1.00197081e-04,\n",
            "       2.38688503e-04, 5.66114977e-05, 4.37650218e-04, 2.07912075e-04,\n",
            "       3.65892047e-04, 4.02748818e-04, 1.45288359e-04, 2.78146035e-04,\n",
            "       3.61096259e-04, 4.50536645e-05, 6.63429237e-05, 2.76780134e-04,\n",
            "       4.54980385e-04, 3.52880816e-05, 1.50290623e-04, 5.24757597e-05,\n",
            "       4.09181848e-05, 4.49125218e-04, 6.69928777e-05, 4.96532302e-05,\n",
            "       4.47634702e-05, 2.54250801e-04, 2.73350219e-04, 7.29828826e-05,\n",
            "       7.26782528e-05, 7.34125570e-05, 3.61089333e-04, 3.29801027e-04,\n",
            "       7.01537574e-05, 7.93675354e-05, 1.89893733e-04, 2.97427730e-04,\n",
            "       3.01581749e-04, 2.17688095e-04, 3.62683350e-05, 1.77437905e-04,\n",
            "       1.96625406e-04, 2.25475742e-05, 2.81660206e-04, 3.43518303e-04,\n",
            "       2.64318332e-05, 2.24052405e-04, 1.15127033e-04, 2.54906219e-04,\n",
            "       3.16563790e-04, 1.39978845e-04, 3.63736937e-04, 2.72877951e-04,\n",
            "       1.23281483e-04, 4.98574191e-05, 2.50417826e-04, 4.80071118e-04,\n",
            "       1.82471253e-04, 1.23198930e-04, 2.01403906e-04, 1.45063896e-04,\n",
            "       5.56999257e-05, 1.97026835e-04, 4.51628694e-05, 7.79070106e-05,\n",
            "       6.06221802e-05, 2.75029397e-05, 2.03888369e-04, 2.75540544e-04,\n",
            "       2.56665953e-04, 3.37009580e-04, 2.63446738e-04, 1.39394338e-04,\n",
            "       2.01563089e-04, 7.64139331e-05, 2.49768316e-04, 3.06386755e-05,\n",
            "       5.60257351e-04, 3.20757419e-04, 4.93836764e-04, 3.41580744e-04,\n",
            "       4.56675880e-05, 4.46272723e-04, 4.66088750e-05, 4.39941214e-04,\n",
            "       3.59159894e-04, 5.25893120e-04, 1.59283562e-04, 2.22701070e-04,\n",
            "       2.35801257e-04, 4.91174695e-04, 2.56143103e-04, 6.05906826e-05,\n",
            "       2.99153238e-04, 3.11878248e-05, 1.57540126e-04, 1.97106987e-04,\n",
            "       2.80531618e-04, 2.92377990e-05, 2.75785191e-04, 3.77402685e-05,\n",
            "       5.07952027e-05, 3.22925276e-04, 3.38419050e-04, 5.99715931e-05,\n",
            "       8.50817232e-05, 1.48078121e-04, 8.94309778e-04, 3.93789669e-04,\n",
            "       1.75702546e-04, 2.44086914e-04, 2.21815004e-04, 2.82250276e-05,\n",
            "       2.93221907e-04, 4.43587574e-04, 3.83834085e-05, 2.06115030e-04,\n",
            "       3.47690686e-04, 2.85105780e-04, 1.31533598e-04, 4.35657770e-04,\n",
            "       1.82882068e-04, 3.51197436e-04, 2.09039194e-04, 1.82145304e-04,\n",
            "       4.58248163e-04, 3.07177361e-05, 2.31373793e-04, 4.40312928e-04,\n",
            "       4.37592069e-04, 3.49472975e-04, 8.39673594e-05, 3.92864371e-04,\n",
            "       3.62741775e-05, 5.25911928e-05, 2.02956886e-04, 2.91669712e-04,\n",
            "       2.35496016e-04, 3.29255417e-04, 1.18724376e-04, 2.85281531e-05,\n",
            "       6.37417324e-05, 9.98363976e-05, 4.61114047e-04, 2.41570568e-04,\n",
            "       3.05080175e-04, 6.02944987e-04, 1.41875571e-04, 4.57039598e-04,\n",
            "       7.67326346e-05, 7.41167314e-05, 3.40348313e-04, 2.75403017e-05,\n",
            "       2.94291851e-04, 4.03221529e-05, 1.66303871e-04, 7.67376914e-05,\n",
            "       4.39691903e-05, 2.27099408e-05, 6.82127196e-04, 2.83242582e-04,\n",
            "       1.24506754e-04, 6.72590686e-05, 5.07920864e-04, 2.20946837e-04,\n",
            "       8.41848159e-05, 5.77154351e-05, 6.05894485e-04, 4.57202870e-04,\n",
            "       2.32076534e-04, 9.18383521e-05, 7.97091780e-05, 1.94861830e-04,\n",
            "       3.81601916e-04, 7.94327134e-05, 5.89000410e-04, 4.12021072e-05,\n",
            "       8.46711991e-05, 6.53231924e-04, 4.29876352e-04, 4.41402663e-04,\n",
            "       2.59584394e-05, 5.37729720e-05, 1.37526222e-04, 2.56354397e-04,\n",
            "       4.61807125e-04, 3.45500921e-05, 2.99351432e-05, 3.43888038e-04,\n",
            "       2.99375188e-05, 4.80301132e-05, 1.58826733e-04, 3.39048274e-04,\n",
            "       4.26974642e-04, 1.41337558e-04, 1.27461244e-04, 3.28493246e-04,\n",
            "       1.04385734e-04, 6.88693472e-05, 2.24427335e-04, 2.08636920e-04,\n",
            "       5.38163935e-04, 2.33308645e-04, 1.05187493e-04, 6.14093442e-05,\n",
            "       2.85260350e-04, 5.68432915e-05, 9.38706071e-05, 2.27877303e-04,\n",
            "       3.55480093e-04, 2.94521396e-05, 7.24357087e-05, 2.90340744e-04,\n",
            "       7.02852412e-05, 5.13638624e-05, 1.21913297e-04, 2.37070533e-04,\n",
            "       3.18120146e-04, 4.68439626e-04, 1.15358198e-04, 5.00138376e-05,\n",
            "       4.29122665e-05, 2.29741898e-04, 3.55420852e-05, 1.86352976e-04,\n",
            "       3.21393127e-05, 3.08451854e-04, 4.17738542e-04, 1.52023858e-04,\n",
            "       4.34356800e-04, 8.01903880e-05, 1.97810485e-04, 2.79085420e-04,\n",
            "       2.76266393e-04, 3.67633547e-05, 8.71399592e-04, 5.75458573e-04,\n",
            "       5.44205177e-05, 2.47976277e-04, 9.66028383e-05, 2.28374847e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 412, 'shape': array([240,   1,   1,  40], dtype=int32), 'shape_signature': array([240,   1,   1,  40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([8.44068709e-05, 1.52795823e-04, 4.64747136e-05, 1.03832404e-04,\n",
            "       2.47348537e-04, 5.86654605e-05, 4.53528948e-04, 2.15455482e-04,\n",
            "       3.79167264e-04, 4.17361240e-04, 1.50559674e-04, 2.88237672e-04,\n",
            "       3.74197465e-04, 4.66882921e-05, 6.87499632e-05, 2.86822207e-04,\n",
            "       4.71487874e-04, 3.65683954e-05, 1.55743430e-04, 5.43796705e-05,\n",
            "       4.24027676e-05, 4.65420278e-04, 6.94234986e-05, 5.14547355e-05,\n",
            "       4.63875658e-05, 2.63475464e-04, 2.83267844e-04, 7.56308291e-05,\n",
            "       7.53151471e-05, 7.60760959e-05, 3.74190276e-04, 3.41766776e-04,\n",
            "       7.26990547e-05, 8.22471266e-05, 1.96783411e-04, 3.08218936e-04,\n",
            "       3.12523654e-04, 2.25586205e-04, 3.75842137e-05, 1.83875658e-04,\n",
            "       2.03759322e-04, 2.33656392e-05, 2.91879318e-04, 3.55981756e-04,\n",
            "       2.73908263e-05, 2.32181425e-04, 1.19304044e-04, 2.64154660e-04,\n",
            "       3.28049267e-04, 1.45057522e-04, 3.76933953e-04, 2.82778434e-04,\n",
            "       1.27754349e-04, 5.16663349e-05, 2.59503431e-04, 4.97488945e-04,\n",
            "       1.89091632e-04, 1.27668798e-04, 2.08711193e-04, 1.50327061e-04,\n",
            "       5.77208157e-05, 2.04175318e-04, 4.68014587e-05, 8.07336110e-05,\n",
            "       6.28216585e-05, 2.85007936e-05, 2.11285791e-04, 2.85537622e-04,\n",
            "       2.65978248e-04, 3.49236885e-04, 2.73005047e-04, 1.44451813e-04,\n",
            "       2.08876154e-04, 7.91863640e-05, 2.58830347e-04, 3.17503000e-05,\n",
            "       5.80584456e-04, 3.32395051e-04, 5.11754013e-04, 3.53973883e-04,\n",
            "       4.73244872e-05, 4.62464290e-04, 4.82999276e-05, 4.55903035e-04,\n",
            "       3.72190843e-04, 5.44973416e-04, 1.65062651e-04, 2.30781050e-04,\n",
            "       2.44356546e-04, 5.08995377e-04, 2.65436422e-04, 6.27890186e-05,\n",
            "       3.10007046e-04, 3.23193744e-05, 1.63255958e-04, 2.04258380e-04,\n",
            "       2.90709810e-04, 3.02985973e-05, 2.85791146e-04, 3.91095527e-05,\n",
            "       5.26381409e-05, 3.34641576e-04, 3.50697490e-04, 6.21474683e-05,\n",
            "       8.81686356e-05, 1.53450659e-04, 9.26756882e-04, 4.08077060e-04,\n",
            "       1.82077347e-04, 2.52942817e-04, 2.29862839e-04, 2.92490804e-05,\n",
            "       3.03860521e-04, 4.59681702e-04, 3.97760268e-05, 2.13593245e-04,\n",
            "       3.60305508e-04, 2.95449921e-04, 1.36305869e-04, 4.51464206e-04,\n",
            "       1.89517348e-04, 3.63939500e-04, 2.16623506e-04, 1.88753853e-04,\n",
            "       4.74874221e-04, 3.18322309e-05, 2.39768444e-04, 4.56288253e-04,\n",
            "       4.53468674e-04, 3.62152467e-04, 8.70138392e-05, 4.07118176e-04,\n",
            "       3.75902673e-05, 5.44992945e-05, 2.10320519e-04, 3.02252010e-04,\n",
            "       2.44040217e-04, 3.41201376e-04, 1.23031903e-04, 2.95632035e-05,\n",
            "       6.60543956e-05, 1.03458638e-04, 4.77844063e-04, 2.50335172e-04,\n",
            "       3.16149002e-04, 6.24820881e-04, 1.47023064e-04, 4.73621796e-04,\n",
            "       7.95166270e-05, 7.68058162e-05, 3.52696748e-04, 2.85395126e-05,\n",
            "       3.04969260e-04, 4.17851115e-05, 1.72337663e-04, 7.95218657e-05,\n",
            "       4.55644695e-05, 2.35338975e-05, 7.06875988e-04, 2.93519115e-04,\n",
            "       1.29024076e-04, 6.96993447e-05, 5.26349118e-04, 2.28963181e-04,\n",
            "       8.72391902e-05, 5.98094521e-05, 6.27877424e-04, 4.73790977e-04,\n",
            "       2.40496680e-04, 9.51704060e-05, 8.26011674e-05, 2.01931762e-04,\n",
            "       3.95447103e-04, 8.23146693e-05, 6.10370364e-04, 4.26969928e-05,\n",
            "       8.77432176e-05, 6.76932337e-04, 4.45473008e-04, 4.57417511e-04,\n",
            "       2.69002576e-05, 5.57239509e-05, 1.42515913e-04, 2.65655370e-04,\n",
            "       4.78562288e-04, 3.58036305e-05, 3.10212417e-05, 3.56364908e-04,\n",
            "       3.10237047e-05, 4.97727306e-05, 1.64589248e-04, 3.51349532e-04,\n",
            "       4.42466029e-04, 1.46465536e-04, 1.32085755e-04, 3.40411556e-04,\n",
            "       1.08173030e-04, 7.13680492e-05, 2.32569946e-04, 2.16206638e-04,\n",
            "       5.57689462e-04, 2.41773494e-04, 1.09003879e-04, 6.36373807e-05,\n",
            "       2.95610109e-04, 5.89056654e-05, 9.72763955e-05, 2.36145090e-04,\n",
            "       3.68377543e-04, 3.05207141e-05, 7.50638064e-05, 3.00874817e-04,\n",
            "       7.28353116e-05, 5.32274316e-05, 1.26336527e-04, 2.45671865e-04,\n",
            "       3.29662114e-04, 4.85435448e-04, 1.19543598e-04, 5.18284287e-05,\n",
            "       4.44691977e-05, 2.38077337e-04, 3.68316141e-05, 1.93114189e-04,\n",
            "       3.33053831e-05, 3.19643033e-04, 4.32894827e-04, 1.57539544e-04,\n",
            "       4.50116029e-04, 8.30998324e-05, 2.04987387e-04, 2.89211137e-04,\n",
            "       2.86289811e-04, 3.80971942e-05, 9.03015491e-04, 5.96337195e-04,\n",
            "       5.63949907e-05, 2.56973290e-04, 1.00107754e-04, 2.36660693e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/rezero/mul', 'index': 413, 'shape': array([ 1,  1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.009821672923862934, -128), 'quantization_parameters': {'scales': array([0.00982167], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 414, 'shape': array([40], dtype=int32), 'shape_signature': array([40], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00135731, 0.00082002, 0.00136718, 0.00126047, 0.00092177,\n",
            "       0.00200896, 0.00220068, 0.00090996, 0.00177976, 0.00107137,\n",
            "       0.001803  , 0.00121636, 0.00131388, 0.00141088, 0.00158414,\n",
            "       0.00172244, 0.00055646, 0.0009626 , 0.00082836, 0.00292597,\n",
            "       0.00146641, 0.00181917, 0.00088388, 0.00182749, 0.00110432,\n",
            "       0.0017999 , 0.00089382, 0.00057951, 0.00184145, 0.00087353,\n",
            "       0.00063295, 0.0017809 , 0.00187128, 0.00188716, 0.00104102,\n",
            "       0.00191665, 0.00115574, 0.00106106, 0.00127106, 0.00164382],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 415, 'shape': array([ 40,   1,   1, 120], dtype=int32), 'shape_signature': array([ 40,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.02058131, 0.0124342 , 0.02073096, 0.01911297, 0.01397714,\n",
            "       0.03046248, 0.0333696 , 0.013798  , 0.02698711, 0.0162456 ,\n",
            "       0.02733948, 0.01844408, 0.01992287, 0.02139357, 0.02402085,\n",
            "       0.02611792, 0.00843782, 0.01459625, 0.01256063, 0.04436748,\n",
            "       0.02223566, 0.02758472, 0.01340262, 0.02771091, 0.01674513,\n",
            "       0.02729251, 0.01355327, 0.00878732, 0.02792253, 0.01324565,\n",
            "       0.00959758, 0.02700441, 0.02837481, 0.0286156 , 0.0157853 ,\n",
            "       0.02906283, 0.01752487, 0.01608921, 0.01927351, 0.02492579],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 416, 'shape': array([120], dtype=int32), 'shape_signature': array([120], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.80291154e-05, 2.18861296e-05, 1.43483940e-05, 1.26341365e-05,\n",
            "       3.54631920e-05, 1.30748340e-05, 1.10866067e-05, 1.80332372e-05,\n",
            "       2.30493533e-05, 3.25986111e-05, 1.95547273e-05, 1.83710672e-05,\n",
            "       2.11749484e-05, 5.16421169e-05, 5.33547340e-09, 1.09954062e-05,\n",
            "       1.37756842e-05, 2.75769744e-05, 1.83330158e-05, 9.50048252e-06,\n",
            "       2.17808447e-05, 2.06541554e-05, 2.41763955e-05, 2.86261893e-05,\n",
            "       2.85917795e-05, 3.13613673e-05, 2.89207783e-05, 1.33075409e-05,\n",
            "       1.99297283e-05, 2.50362991e-05, 5.11435319e-05, 1.97018981e-05,\n",
            "       1.00344250e-05, 2.10929084e-05, 2.64314986e-05, 1.77172078e-05,\n",
            "       2.96169655e-05, 1.81546729e-05, 4.45941623e-05, 1.89503407e-05,\n",
            "       2.56519379e-05, 2.70253186e-05, 1.76162721e-05, 2.30200258e-05,\n",
            "       6.56848533e-06, 2.42019596e-05, 1.80171883e-05, 5.99034611e-05,\n",
            "       3.56059682e-05, 1.94756376e-05, 2.66725201e-05, 2.23052721e-05,\n",
            "       2.36200376e-05, 1.62254837e-05, 2.46405380e-05, 1.84172332e-05,\n",
            "       3.75508389e-05, 4.19882235e-05, 2.33938372e-05, 2.00976938e-05,\n",
            "       2.27140808e-05, 1.48668405e-05, 1.65400652e-05, 2.55580162e-05,\n",
            "       1.58524726e-05, 2.24106989e-05, 3.01920281e-05, 1.14073382e-05,\n",
            "       3.75807322e-05, 5.59133805e-05, 2.19786343e-05, 2.78919124e-05,\n",
            "       3.19839237e-05, 1.97972113e-05, 2.42932601e-05, 3.94773524e-05,\n",
            "       3.08400813e-05, 9.46285490e-06, 2.09516802e-05, 2.67303294e-05,\n",
            "       2.39992696e-05, 2.30395126e-05, 3.95295538e-05, 1.35241271e-05,\n",
            "       1.33712156e-05, 2.54839888e-05, 2.41546932e-05, 3.42923195e-05,\n",
            "       1.00491588e-05, 2.97992083e-05, 1.37257184e-05, 2.43932136e-05,\n",
            "       5.81460918e-05, 2.86771101e-05, 1.80385086e-05, 4.69457591e-05,\n",
            "       2.06700879e-05, 4.87895777e-05, 1.74443776e-05, 1.14162731e-05,\n",
            "       3.36523917e-05, 1.69337218e-05, 4.45499354e-05, 2.97589049e-05,\n",
            "       1.73580902e-05, 3.32561067e-05, 2.60388315e-05, 1.21211206e-05,\n",
            "       1.31674587e-05, 2.20475413e-05, 1.88689246e-05, 1.11096169e-05,\n",
            "       4.88559417e-05, 1.59123210e-05, 3.17244740e-05, 1.23443961e-05,\n",
            "       1.92550724e-05, 1.90543142e-05, 2.18701680e-05, 3.05809481e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 417, 'shape': array([120,   1,   1,  64], dtype=int32), 'shape_signature': array([120,   1,   1,  64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.1349529e-03, 1.3777562e-03, 9.0324739e-04, 7.9533301e-04,\n",
            "       2.2324475e-03, 8.2307542e-04, 6.9791428e-04, 1.1352124e-03,\n",
            "       1.4509825e-03, 2.0521190e-03, 1.2309919e-03, 1.1564792e-03,\n",
            "       1.3329866e-03, 3.2509288e-03, 3.3587401e-07, 6.9217308e-04,\n",
            "       8.6719467e-04, 1.7360013e-03, 1.1540838e-03, 5.9806596e-04,\n",
            "       1.3711285e-03, 1.3002021e-03, 1.5219310e-03, 1.8020505e-03,\n",
            "       1.7998844e-03, 1.9742330e-03, 1.8205952e-03, 8.3772454e-04,\n",
            "       1.2545986e-03, 1.5760630e-03, 3.2195423e-03, 1.2402565e-03,\n",
            "       6.3167827e-04, 1.3278221e-03, 1.6638923e-03, 1.1153180e-03,\n",
            "       1.8644211e-03, 1.1428569e-03, 2.8072523e-03, 1.1929451e-03,\n",
            "       1.6148181e-03, 1.7012740e-03, 1.1089640e-03, 1.4491363e-03,\n",
            "       4.1349349e-04, 1.5235404e-03, 1.1342021e-03, 3.7709898e-03,\n",
            "       2.2414355e-03, 1.2260132e-03, 1.6790649e-03, 1.4041418e-03,\n",
            "       1.4869077e-03, 1.0214123e-03, 1.5511494e-03, 1.1593854e-03,\n",
            "       2.3638671e-03, 2.6432055e-03, 1.4726681e-03, 1.2651723e-03,\n",
            "       1.4298768e-03, 9.3588419e-04, 1.0412156e-03, 1.6089056e-03,\n",
            "       9.9793088e-04, 1.4107785e-03, 1.9006218e-03, 7.1810465e-04,\n",
            "       2.3657491e-03, 3.5198098e-03, 1.3835796e-03, 1.7558270e-03,\n",
            "       2.0134237e-03, 1.2462565e-03, 1.5292878e-03, 2.4851435e-03,\n",
            "       1.9414175e-03, 5.9569726e-04, 1.3189317e-03, 1.6827041e-03,\n",
            "       1.5107808e-03, 1.4503631e-03, 2.4884294e-03, 8.5135887e-04,\n",
            "       8.4173295e-04, 1.6042455e-03, 1.5205649e-03, 2.1587398e-03,\n",
            "       6.3260575e-04, 1.8758934e-03, 8.6404930e-04, 1.5355800e-03,\n",
            "       3.6603613e-03, 1.8052561e-03, 1.1355443e-03, 2.9552879e-03,\n",
            "       1.3012051e-03, 3.0713584e-03, 1.0981431e-03, 7.1866711e-04,\n",
            "       2.1184557e-03, 1.0659967e-03, 2.8044682e-03, 1.8733563e-03,\n",
            "       1.0927111e-03, 2.0935091e-03, 1.6391735e-03, 7.6303806e-04,\n",
            "       8.2890620e-04, 1.3879173e-03, 1.1878199e-03, 6.9936278e-04,\n",
            "       3.0755361e-03, 1.0016983e-03, 1.9970911e-03, 7.7709352e-04,\n",
            "       1.2121283e-03, 1.1994904e-03, 1.3767515e-03, 1.9251048e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 418, 'shape': array([64], dtype=int32), 'shape_signature': array([64], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.0448569e-05, 4.0759645e-05, 2.2775164e-05, 4.1065930e-05,\n",
            "       2.3812194e-05, 2.7557591e-05, 7.7003009e-05, 7.4326927e-05,\n",
            "       5.8143192e-05, 2.7344315e-05, 5.0499941e-05, 2.5454117e-05,\n",
            "       4.1324773e-05, 3.8077684e-05, 7.8700192e-05, 2.7563598e-05,\n",
            "       3.6371424e-05, 3.9467704e-05, 2.0848300e-05, 5.1688068e-05,\n",
            "       2.9553628e-05, 8.0746599e-05, 3.2393680e-05, 5.6226563e-05,\n",
            "       9.1363218e-05, 4.2601005e-05, 3.0087476e-05, 9.5151889e-05,\n",
            "       3.8471473e-05, 2.9210725e-05, 4.0736653e-05, 5.1008770e-05,\n",
            "       3.5742458e-05, 1.2557124e-04, 3.3139004e-05, 4.4831540e-05,\n",
            "       1.7393095e-05, 1.4946537e-05, 8.9344285e-06, 4.8378497e-05,\n",
            "       4.1296207e-05, 3.4205401e-05, 1.0225986e-05, 5.2013413e-05,\n",
            "       4.2328305e-05, 1.1521314e-04, 3.6563066e-05, 3.1074927e-05,\n",
            "       3.0495792e-05, 3.3310313e-05, 3.1866242e-05, 4.6244815e-05,\n",
            "       5.5277833e-05, 2.4009280e-05, 2.6557893e-05, 2.8740131e-05,\n",
            "       6.0344708e-05, 3.8473190e-05, 1.7116285e-05, 2.1551921e-05,\n",
            "       1.0019168e-04, 5.2264575e-05, 3.8138049e-05, 1.2716648e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 419, 'shape': array([ 64,   1,   1, 240], dtype=int32), 'shape_signature': array([ 64,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00051631, 0.0020141 , 0.00112541, 0.00202923, 0.00117666,\n",
            "       0.00136173, 0.00380503, 0.0036728 , 0.00287309, 0.00135119,\n",
            "       0.00249541, 0.00125779, 0.00204202, 0.00188157, 0.0038889 ,\n",
            "       0.00136203, 0.00179726, 0.00195026, 0.0010302 , 0.00255412,\n",
            "       0.00146036, 0.00399002, 0.0016007 , 0.00277838, 0.00451463,\n",
            "       0.00210509, 0.00148674, 0.00470184, 0.00190103, 0.00144342,\n",
            "       0.00201296, 0.00252055, 0.00176618, 0.00620498, 0.00163753,\n",
            "       0.00221531, 0.00085946, 0.00073857, 0.00044149, 0.00239058,\n",
            "       0.00204061, 0.00169023, 0.00050531, 0.00257019, 0.00209161,\n",
            "       0.00569315, 0.00180673, 0.00153554, 0.00150692, 0.001646  ,\n",
            "       0.00157464, 0.00228514, 0.0027315 , 0.0011864 , 0.00131233,\n",
            "       0.00142017, 0.00298188, 0.00190112, 0.00084579, 0.00106497,\n",
            "       0.00495088, 0.0025826 , 0.00188456, 0.00628381], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 420, 'shape': array([120], dtype=int32), 'shape_signature': array([120], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.0012223 , 0.00164707, 0.0059163 , 0.03487466, 0.04433073,\n",
            "       0.00719785, 0.00756053, 0.02209179, 0.00196394, 0.0033301 ,\n",
            "       0.00858146, 0.00321179, 0.00374782, 0.00148467, 0.005529  ,\n",
            "       0.0041982 , 0.00275827, 0.0036488 , 0.02496187, 0.00096718,\n",
            "       0.00775811, 0.00184327, 0.02647229, 0.01222201, 0.0015145 ,\n",
            "       0.00903645, 0.011219  , 0.02975887, 0.00184509, 0.00787659,\n",
            "       0.00818523, 0.0344648 , 0.02995159, 0.00812917, 0.03113839,\n",
            "       0.02014977, 0.00960855, 0.0209045 , 0.00081586, 0.00333373,\n",
            "       0.03784956, 0.00129864, 0.01116242, 0.00444593, 0.01872312,\n",
            "       0.04034362, 0.00300623, 0.01648263, 0.00487581, 0.01447881,\n",
            "       0.01584562, 0.00117675, 0.00278902, 0.01859449, 0.02130986,\n",
            "       0.00547553, 0.01599281, 0.00264695, 0.01098242, 0.00189652,\n",
            "       0.00151347, 0.02802068, 0.01339046, 0.01058845, 0.02077265,\n",
            "       0.00179608, 0.01531581, 0.00784737, 0.01090257, 0.00421116,\n",
            "       0.01937628, 0.00179312, 0.01766841, 0.00898134, 0.02144097,\n",
            "       0.00284643, 0.02245535, 0.00098525, 0.02062754, 0.00895915,\n",
            "       0.00200485, 0.01575843, 0.0264584 , 0.0033197 , 0.01715994,\n",
            "       0.00462511, 0.00209831, 0.04062426, 0.03391603, 0.00126717,\n",
            "       0.00454416, 0.0044836 , 0.00401742, 0.00481598, 0.02097789,\n",
            "       0.0015691 , 0.01054545, 0.0219774 , 0.0104722 , 0.01078241,\n",
            "       0.00087506, 0.00269473, 0.00694293, 0.00301618, 0.02322779,\n",
            "       0.00281832, 0.00496402, 0.03133435, 0.00150518, 0.01393636,\n",
            "       0.04029697, 0.00650649, 0.01211296, 0.01158803, 0.01314876,\n",
            "       0.00704566, 0.01338563, 0.00091413, 0.02617815, 0.0048462 ],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul', 'index': 421, 'shape': array([  1,   3,   1, 120], dtype=int32), 'shape_signature': array([  1,   3,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00510895, 0.00688438, 0.02472883, 0.1457683 , 0.18529259,\n",
            "       0.0300854 , 0.03160132, 0.09233875, 0.00820882, 0.01391908,\n",
            "       0.03586857, 0.01342455, 0.01566504, 0.00620557, 0.02310997,\n",
            "       0.01754755, 0.01152893, 0.01525116, 0.10433505, 0.00404262,\n",
            "       0.03242716, 0.00770447, 0.11064827, 0.05108529, 0.00633026,\n",
            "       0.03777033, 0.04689292, 0.12438545, 0.00771207, 0.03292239,\n",
            "       0.03421243, 0.14405517, 0.12519097, 0.03397812, 0.13015151,\n",
            "       0.08422155, 0.0401616 , 0.08737615, 0.00341012, 0.01393424,\n",
            "       0.15820272, 0.00542802, 0.04665642, 0.018583  , 0.07825845,\n",
            "       0.16862732, 0.01256537, 0.0688937 , 0.0203798 , 0.06051822,\n",
            "       0.06623118, 0.00491855, 0.0116575 , 0.07772082, 0.08907046,\n",
            "       0.02288649, 0.06684639, 0.01106367, 0.04590406, 0.00792703,\n",
            "       0.00632596, 0.11712018, 0.05596916, 0.04425735, 0.08682502,\n",
            "       0.0075072 , 0.06401667, 0.03280026, 0.04557031, 0.01760169,\n",
            "       0.08098853, 0.00749486, 0.07385   , 0.03754001, 0.08961846,\n",
            "       0.01189743, 0.09385835, 0.00411812, 0.0862185 , 0.03744724,\n",
            "       0.00837981, 0.06586671, 0.11059022, 0.01387562, 0.07172471,\n",
            "       0.01933192, 0.00877048, 0.16980037, 0.14176142, 0.00529649,\n",
            "       0.01899357, 0.01874043, 0.01679192, 0.02012974, 0.08768289,\n",
            "       0.00655848, 0.04407762, 0.09186064, 0.04377146, 0.04506806,\n",
            "       0.00365755, 0.01126338, 0.02901988, 0.01260694, 0.09708699,\n",
            "       0.01177995, 0.02074851, 0.1309706 , 0.0062913 , 0.05825089,\n",
            "       0.16843234, 0.02719569, 0.05062947, 0.04843539, 0.05495888,\n",
            "       0.02944927, 0.05594893, 0.00382086, 0.10941883, 0.02025603],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 422, 'shape': array([120], dtype=int32), 'shape_signature': array([120], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.7561904e-03, 2.2342268e-03, 2.6748210e-04, 1.4846963e-03,\n",
            "       3.0943338e-04, 8.9593307e-04, 4.5211644e-05, 1.3734781e-03,\n",
            "       3.1998800e-04, 2.4937477e-04, 1.0526996e-04, 2.3589378e-04,\n",
            "       1.4403770e-03, 4.6213492e-04, 1.7597700e-03, 4.6296339e-04,\n",
            "       1.7774102e-03, 7.8444835e-03, 4.8624340e-04, 8.8878744e-04,\n",
            "       1.6646539e-03, 4.7943875e-04, 8.4552768e-04, 4.7863831e-04,\n",
            "       1.4218141e-03, 2.5018402e-03, 7.9812156e-04, 9.8129816e-04,\n",
            "       2.6726667e-03, 8.7255677e-03, 8.1773469e-04, 4.4282991e-05,\n",
            "       2.9184171e-03, 6.2173385e-05, 2.4633293e-04, 7.3818042e-04,\n",
            "       1.3632583e-04, 1.0490180e-04, 4.8731564e-04, 1.7552815e-03,\n",
            "       1.3992785e-03, 1.0888983e-03, 4.0173274e-03, 2.3450896e-04,\n",
            "       8.9624162e-05, 8.6254149e-04, 1.8920885e-04, 1.4325109e-04,\n",
            "       2.4810201e-04, 6.9998135e-03, 1.1580741e-04, 3.7092057e-03,\n",
            "       4.0848975e-04, 3.1458732e-04, 2.3422891e-03, 1.3009316e-03,\n",
            "       6.9368070e-05, 3.0011341e-03, 2.1177819e-03, 1.5530435e-03,\n",
            "       2.1892639e-03, 6.3538394e-04, 1.9396025e-04, 7.3889183e-05,\n",
            "       3.7893996e-04, 8.0260392e-03, 3.3488360e-03, 3.2404247e-03,\n",
            "       9.8480214e-04, 1.0473467e-03, 1.3137973e-03, 3.4152559e-04,\n",
            "       1.8088930e-04, 5.6988536e-04, 1.2560558e-04, 1.2293686e-02,\n",
            "       4.1171461e-03, 1.2147273e-03, 1.0458280e-04, 2.3654912e-04,\n",
            "       1.1147415e-03, 5.3525681e-04, 5.4227683e-04, 7.0002064e-04,\n",
            "       1.8915301e-03, 1.2561895e-03, 1.4049107e-03, 8.0623105e-04,\n",
            "       1.1556909e-03, 3.5193830e-04, 5.6429551e-04, 2.0454401e-04,\n",
            "       1.4662786e-03, 1.2642544e-03, 1.3938110e-04, 3.3954871e-04,\n",
            "       3.6080258e-03, 1.6991545e-04, 1.0590998e-03, 6.0835842e-04,\n",
            "       1.0448920e-03, 7.1153877e-04, 6.2884385e-04, 5.6232623e-04,\n",
            "       7.9474133e-04, 2.7023797e-04, 2.7535656e-03, 1.9429375e-03,\n",
            "       2.2622119e-03, 1.2223523e-04, 8.9513086e-04, 1.7578738e-03,\n",
            "       3.3833948e-04, 9.0494868e-05, 7.4518706e-05, 2.1423681e-03,\n",
            "       3.2106757e-03, 2.2529778e-03, 3.0497438e-04, 1.7645520e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 423, 'shape': array([  1,   3,   3, 120], dtype=int32), 'shape_signature': array([  1,   3,   3, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.05623813, 0.03345111, 0.00400477, 0.02222905, 0.00463287,\n",
            "       0.01341402, 0.00067691, 0.02056388, 0.0047909 , 0.00373367,\n",
            "       0.00157611, 0.00353183, 0.02156549, 0.00691914, 0.02634748,\n",
            "       0.00693154, 0.02661159, 0.11744853, 0.00728009, 0.01330703,\n",
            "       0.02492339, 0.00717821, 0.01265934, 0.00716623, 0.02128757,\n",
            "       0.03745785, 0.01194957, 0.01469211, 0.04001548, 0.13064022,\n",
            "       0.01224322, 0.00066301, 0.04369488, 0.00093087, 0.00368813,\n",
            "       0.01105212, 0.00204109, 0.0015706 , 0.00729615, 0.02628028,\n",
            "       0.02095016, 0.01630311, 0.0601479 , 0.0035111 , 0.00134186,\n",
            "       0.01291407, 0.00283286, 0.00214477, 0.00371461, 0.10480203,\n",
            "       0.00173388, 0.05553466, 0.00611596, 0.00471004, 0.03506903,\n",
            "       0.0194777 , 0.00103859, 0.04493333, 0.03170768, 0.02325235,\n",
            "       0.03277792, 0.00951304, 0.002904  , 0.00110628, 0.00567353,\n",
            "       0.1201668 , 0.05013917, 0.04851602, 0.01474457, 0.015681  ,\n",
            "       0.01967033, 0.00511336, 0.0027083 , 0.00853239, 0.00188058,\n",
            "       0.18406251, 0.0616424 , 0.01818704, 0.00156583, 0.00354164,\n",
            "       0.01669004, 0.00801393, 0.00811903, 0.01048079, 0.02832021,\n",
            "       0.01880782, 0.02103449, 0.01207099, 0.01730314, 0.00526926,\n",
            "       0.0084487 , 0.00306246, 0.0219533 , 0.01892857, 0.00208683,\n",
            "       0.00508376, 0.05401979, 0.00254399, 0.01585697, 0.00910841,\n",
            "       0.01564425, 0.01065324, 0.00941512, 0.00841921, 0.01189896,\n",
            "       0.00404603, 0.04122671, 0.02908989, 0.0338701 , 0.00183012,\n",
            "       0.013402  , 0.02631909, 0.00506566, 0.0013549 , 0.0011157 ,\n",
            "       0.03207579, 0.04807061, 0.03373185, 0.00456611, 0.02641908],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 424, 'shape': array([120], dtype=int32), 'shape_signature': array([120], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.3108770e-04, 2.6044078e-04, 2.0579032e-04, 1.4582664e-05,\n",
            "       1.7966790e-04, 1.5748234e-04, 5.3263310e-04, 8.2412909e-05,\n",
            "       1.3114286e-04, 4.8130582e-04, 4.8089141e-04, 3.5962308e-04,\n",
            "       1.8750565e-04, 2.4033882e-04, 7.9288096e-05, 1.6739775e-04,\n",
            "       3.0857729e-04, 4.9236478e-05, 4.2799402e-05, 3.0167974e-04,\n",
            "       1.8100979e-04, 5.4635864e-04, 8.5296211e-05, 1.6383543e-04,\n",
            "       7.6861877e-04, 7.2509603e-05, 1.2244294e-04, 5.4034375e-05,\n",
            "       1.9250151e-04, 2.7774508e-05, 4.7746886e-05, 2.8060688e-04,\n",
            "       2.0677762e-05, 7.6567632e-04, 2.4070032e-04, 8.7038563e-05,\n",
            "       2.7032892e-04, 2.9385186e-04, 4.4835347e-04, 1.1392036e-04,\n",
            "       4.7367434e-05, 2.3382311e-04, 2.2080701e-05, 2.5834670e-04,\n",
            "       2.4638494e-04, 8.6491025e-05, 2.9430856e-04, 1.6208008e-04,\n",
            "       5.7078304e-04, 3.7347585e-05, 5.4350164e-04, 2.4415742e-04,\n",
            "       2.2965795e-04, 1.4133025e-04, 5.4477208e-05, 2.7425724e-04,\n",
            "       8.0789474e-04, 5.5463042e-05, 1.7353786e-04, 2.2508985e-04,\n",
            "       1.9619006e-04, 7.1550508e-05, 3.4695666e-04, 3.0278467e-04,\n",
            "       1.3490670e-04, 3.8090776e-04, 4.2132699e-05, 2.4021138e-05,\n",
            "       1.1107393e-04, 2.5129883e-04, 6.9123926e-05, 3.9793490e-04,\n",
            "       2.2199578e-04, 2.2017826e-04, 2.2130902e-04, 5.4802171e-05,\n",
            "       2.2784998e-05, 2.0650234e-04, 3.8755336e-04, 2.4538819e-04,\n",
            "       3.7368640e-04, 9.4626026e-05, 1.4904271e-04, 1.1359457e-04,\n",
            "       3.0058769e-05, 7.3751522e-05, 3.4938633e-04, 7.6697710e-05,\n",
            "       4.9054852e-05, 5.1215966e-04, 4.7366935e-04, 5.2049907e-04,\n",
            "       2.0425319e-04, 1.7315298e-04, 2.8946882e-04, 5.3518289e-04,\n",
            "       2.4640523e-05, 3.3744669e-04, 4.0541519e-04, 3.6056030e-05,\n",
            "       1.4825772e-04, 5.0438975e-04, 6.4577558e-04, 4.9903337e-04,\n",
            "       5.4942193e-05, 9.4110728e-05, 5.2217591e-05, 3.5742843e-05,\n",
            "       2.6824549e-04, 7.5976149e-04, 8.9497422e-05, 4.1411188e-04,\n",
            "       1.9638399e-04, 3.8803538e-04, 2.2736048e-04, 9.0803595e-05,\n",
            "       7.1247247e-05, 1.9905827e-04, 5.3889806e-05, 5.9241589e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 425, 'shape': array([120,   1,   1,  40], dtype=int32), 'shape_signature': array([120,   1,   1,  40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.54287423e-04, 3.06533242e-04, 2.42210808e-04, 1.71634838e-05,\n",
            "       2.11465274e-04, 1.85353347e-04, 6.26897789e-04, 9.69982357e-05,\n",
            "       1.54352354e-04, 5.66486677e-04, 5.65998896e-04, 4.23268677e-04,\n",
            "       2.20690141e-04, 2.82873661e-04, 9.33203919e-05, 1.97023575e-04,\n",
            "       3.63188883e-04, 5.79502812e-05, 5.03739830e-05, 3.55070602e-04,\n",
            "       2.13044652e-04, 6.43052452e-04, 1.00391815e-04, 1.92830805e-04,\n",
            "       9.04647866e-04, 8.53422534e-05, 1.44112724e-04, 6.35973047e-05,\n",
            "       2.26570162e-04, 3.26900008e-05, 5.61970628e-05, 3.30268289e-04,\n",
            "       2.43372851e-05, 9.01184685e-04, 2.83299130e-04, 1.02442529e-04,\n",
            "       3.18171369e-04, 3.45857348e-04, 5.27702447e-04, 1.34081827e-04,\n",
            "       5.57504572e-05, 2.75204802e-04, 2.59885146e-05, 3.04068555e-04,\n",
            "       2.89989810e-04, 1.01798090e-04, 3.46394867e-04, 1.90764782e-04,\n",
            "       6.71799469e-04, 4.39573087e-05, 6.39689795e-04, 2.87368050e-04,\n",
            "       2.70302495e-04, 1.66342681e-04, 6.41185106e-05, 3.22794920e-04,\n",
            "       9.50874877e-04, 6.52788149e-05, 2.04250347e-04, 2.64925940e-04,\n",
            "       2.30911508e-04, 8.42134177e-05, 4.08360589e-04, 3.56371078e-04,\n",
            "       1.58782306e-04, 4.48320294e-04, 4.95892855e-05, 2.82723649e-05,\n",
            "       1.30731642e-04, 2.95773352e-04, 8.13573861e-05, 4.68360871e-04,\n",
            "       2.61284295e-04, 2.59145105e-04, 2.60475994e-04, 6.45009859e-05,\n",
            "       2.68174554e-05, 2.43048838e-04, 4.56142006e-04, 2.88816664e-04,\n",
            "       4.39820898e-04, 1.11372814e-04, 1.75420078e-04, 1.33698384e-04,\n",
            "       3.53785290e-05, 8.68039642e-05, 4.11220244e-04, 9.02715692e-05,\n",
            "       5.77365136e-05, 6.02800981e-04, 5.57498715e-04, 6.12616306e-04,\n",
            "       2.40401627e-04, 2.03797361e-04, 3.40698607e-04, 6.29898801e-04,\n",
            "       2.90013704e-05, 3.97167547e-04, 4.77165013e-04, 4.24371756e-05,\n",
            "       1.74496177e-04, 5.93655976e-04, 7.60064053e-04, 5.87351620e-04,\n",
            "       6.46657863e-05, 1.10766312e-04, 6.14589881e-05, 4.20685610e-05,\n",
            "       3.15719226e-04, 8.94223049e-04, 1.05336556e-04, 4.87400830e-04,\n",
            "       2.31139755e-04, 4.56709357e-04, 2.67598429e-04, 1.06873893e-04,\n",
            "       8.38564883e-05, 2.34287319e-04, 6.34271491e-05, 6.97260839e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/rezero/mul', 'index': 426, 'shape': array([ 1,  1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.008425133302807808, -128), 'quantization_parameters': {'scales': array([0.00842513], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 427, 'shape': array([40], dtype=int32), 'shape_signature': array([40], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00112499, 0.00052001, 0.00063826, 0.00081726, 0.00042089,\n",
            "       0.00073682, 0.00107008, 0.00081318, 0.00085557, 0.0007432 ,\n",
            "       0.00101672, 0.00082088, 0.00095425, 0.00095564, 0.00092937,\n",
            "       0.00118894, 0.00074926, 0.00085462, 0.00064864, 0.00152757,\n",
            "       0.00071007, 0.00085411, 0.0006866 , 0.00118699, 0.00098122,\n",
            "       0.00094977, 0.0009474 , 0.00104893, 0.00089087, 0.00051382,\n",
            "       0.00125264, 0.00123316, 0.00108798, 0.0012516 , 0.00084586,\n",
            "       0.00112262, 0.00067693, 0.00075171, 0.00062126, 0.00108515],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 428, 'shape': array([40,  1,  1, 96], dtype=int32), 'shape_signature': array([40,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.02373551, 0.01097141, 0.01346631, 0.01724285, 0.00888016,\n",
            "       0.01554565, 0.02257684, 0.0171567 , 0.01805104, 0.01568025,\n",
            "       0.02145108, 0.01731917, 0.02013314, 0.02016248, 0.01960814,\n",
            "       0.02508455, 0.01580824, 0.01803108, 0.01368521, 0.0322291 ,\n",
            "       0.01498138, 0.01802031, 0.0144862 , 0.02504355, 0.02070208,\n",
            "       0.02003863, 0.01998858, 0.0221306 , 0.01879593, 0.01084075,\n",
            "       0.02642869, 0.02601763, 0.02295448, 0.02640679, 0.01784625,\n",
            "       0.02368534, 0.01428201, 0.0158599 , 0.01310763, 0.02289494],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 429, 'shape': array([96], dtype=int32), 'shape_signature': array([96], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.32810328e-05, 4.33691312e-05, 1.46915045e-05, 2.75713555e-05,\n",
            "       1.22372976e-05, 2.29142970e-05, 3.66297500e-05, 2.79543001e-05,\n",
            "       2.29193029e-05, 9.71847930e-06, 2.86821105e-05, 7.26030839e-06,\n",
            "       2.80377772e-05, 3.90726927e-05, 1.28734673e-05, 2.63480815e-05,\n",
            "       2.32270922e-05, 1.26101013e-05, 1.09008715e-05, 2.20916590e-05,\n",
            "       1.40642314e-05, 1.64311496e-05, 1.46965504e-05, 3.22649503e-05,\n",
            "       2.01577914e-05, 2.60836423e-05, 1.62051056e-05, 2.77762483e-05,\n",
            "       1.37200996e-05, 1.23404998e-05, 1.54333793e-05, 7.57029329e-06,\n",
            "       2.46021518e-05, 1.38315763e-05, 3.15649195e-05, 2.07123358e-05,\n",
            "       1.75613131e-05, 1.88190206e-05, 8.40231296e-05, 2.11976039e-05,\n",
            "       8.31048510e-06, 8.97151494e-06, 1.12892703e-05, 1.59748979e-05,\n",
            "       1.25255092e-05, 8.89623061e-06, 1.03628863e-05, 1.76540598e-05,\n",
            "       3.18589555e-05, 9.13298027e-06, 2.27286000e-05, 1.47853243e-05,\n",
            "       2.43981958e-05, 2.66636234e-05, 1.38258210e-05, 2.06492987e-05,\n",
            "       1.66556765e-05, 1.99023052e-05, 1.72056170e-05, 1.27190769e-05,\n",
            "       3.72540126e-05, 1.70116327e-05, 1.60232194e-05, 1.25937649e-05,\n",
            "       2.67342875e-05, 1.37452898e-05, 8.87983788e-06, 1.87503629e-05,\n",
            "       3.42980493e-05, 1.18472344e-05, 2.67034920e-05, 1.97243935e-05,\n",
            "       2.40372137e-05, 6.55813847e-06, 2.21312148e-05, 1.45285358e-05,\n",
            "       2.08283564e-05, 1.50105670e-05, 1.52115081e-05, 7.27895895e-06,\n",
            "       2.12736140e-05, 1.49532043e-05, 1.70897674e-05, 2.12153536e-05,\n",
            "       1.65279707e-05, 1.28893616e-05, 2.34039053e-05, 2.65120307e-05,\n",
            "       1.51768081e-05, 3.40713959e-05, 1.86144753e-05, 1.31015213e-05,\n",
            "       2.44324056e-05, 9.79880951e-06, 3.13422352e-05, 3.85413368e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 430, 'shape': array([96,  1,  1, 48], dtype=int32), 'shape_signature': array([96,  1,  1, 48], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00113665, 0.00371173, 0.00125737, 0.00235968, 0.00104732,\n",
            "       0.00196111, 0.00313494, 0.00239246, 0.00196154, 0.00083175,\n",
            "       0.00245475, 0.00062137, 0.0023996 , 0.00334402, 0.00110177,\n",
            "       0.00225499, 0.00198788, 0.00107923, 0.00093295, 0.00189071,\n",
            "       0.00120368, 0.00140625, 0.0012578 , 0.00276138, 0.0017252 ,\n",
            "       0.00223236, 0.00138691, 0.00237722, 0.00117423, 0.00105616,\n",
            "       0.00132086, 0.0006479 , 0.00210557, 0.00118377, 0.00270147,\n",
            "       0.00177266, 0.00150298, 0.00161062, 0.00719109, 0.00181419,\n",
            "       0.00071125, 0.00076782, 0.00096619, 0.00136721, 0.00107199,\n",
            "       0.00076138, 0.0008869 , 0.00151092, 0.00272664, 0.00078164,\n",
            "       0.00194522, 0.0012654 , 0.00208811, 0.002282  , 0.00118328,\n",
            "       0.00176726, 0.00142547, 0.00170333, 0.00147254, 0.00108856,\n",
            "       0.00318837, 0.00145593, 0.00137134, 0.00107783, 0.00228804,\n",
            "       0.00117639, 0.00075998, 0.00160474, 0.00293539, 0.00101394,\n",
            "       0.00228541, 0.0016881 , 0.00205722, 0.00056128, 0.00189409,\n",
            "       0.00124342, 0.00178259, 0.00128467, 0.00130187, 0.00062297,\n",
            "       0.00182069, 0.00127976, 0.00146262, 0.00181571, 0.00141454,\n",
            "       0.00110313, 0.00200301, 0.00226902, 0.0012989 , 0.00291599,\n",
            "       0.00159311, 0.00112129, 0.00209104, 0.00083863, 0.00268241,\n",
            "       0.00329855], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 431, 'shape': array([48], dtype=int32), 'shape_signature': array([48], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.4881967e-05, 6.2236046e-05, 2.7752609e-05, 6.0484919e-05,\n",
            "       7.2194496e-05, 4.0006569e-05, 6.9742979e-05, 3.9369035e-05,\n",
            "       5.1717936e-05, 3.7636779e-05, 5.5894496e-05, 5.7072670e-05,\n",
            "       7.5827804e-05, 4.0785570e-05, 6.3401603e-05, 7.2101495e-05,\n",
            "       4.9799022e-05, 4.3083084e-05, 9.3779665e-05, 6.7030443e-05,\n",
            "       7.6934499e-05, 3.5856974e-05, 4.2218369e-05, 1.5195701e-04,\n",
            "       7.3592309e-05, 3.7697460e-05, 7.1052804e-05, 7.8772166e-05,\n",
            "       1.3950773e-04, 6.9884547e-05, 4.1836309e-05, 4.0854324e-05,\n",
            "       8.5970772e-05, 4.3907858e-05, 5.6771321e-05, 1.5158375e-04,\n",
            "       1.1886318e-04, 5.0372779e-05, 6.7187124e-05, 4.2658408e-05,\n",
            "       8.7810709e-05, 1.4191701e-04, 9.9483819e-05, 4.9487866e-05,\n",
            "       6.5446438e-05, 8.1280537e-05, 8.5177671e-05, 1.0959989e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 432, 'shape': array([ 48,   1,   1, 192], dtype=int32), 'shape_signature': array([ 48,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00110054, 0.00196356, 0.0008756 , 0.00190832, 0.00227776,\n",
            "       0.00126222, 0.00220041, 0.0012421 , 0.00163172, 0.00118745,\n",
            "       0.00176349, 0.00180066, 0.00239239, 0.0012868 , 0.00200034,\n",
            "       0.00227482, 0.00157117, 0.00135928, 0.00295877, 0.00211483,\n",
            "       0.0024273 , 0.0011313 , 0.001332  , 0.00479429, 0.00232186,\n",
            "       0.00118937, 0.00224174, 0.00248528, 0.00440151, 0.00220488,\n",
            "       0.00131995, 0.00128897, 0.0027124 , 0.0013853 , 0.00179115,\n",
            "       0.00478251, 0.00375017, 0.00158928, 0.00211977, 0.00134588,\n",
            "       0.00277045, 0.00447752, 0.00313874, 0.00156136, 0.00206485,\n",
            "       0.00256442, 0.00268738, 0.00345791], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 433, 'shape': array([96], dtype=int32), 'shape_signature': array([96], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01741462, 0.00163735, 0.02116933, 0.02123393, 0.00668503,\n",
            "       0.0019756 , 0.02777157, 0.00076548, 0.01202707, 0.0111065 ,\n",
            "       0.00728206, 0.01282616, 0.00421703, 0.00546266, 0.00204891,\n",
            "       0.02093731, 0.01952096, 0.00372405, 0.02020076, 0.02709366,\n",
            "       0.03437719, 0.00813567, 0.01840258, 0.01919291, 0.01544546,\n",
            "       0.01577579, 0.03007165, 0.01273215, 0.00252854, 0.00459663,\n",
            "       0.00150146, 0.01468209, 0.02524431, 0.01264624, 0.001552  ,\n",
            "       0.00221779, 0.00546244, 0.03644316, 0.00128129, 0.00425501,\n",
            "       0.00213438, 0.02138066, 0.00113423, 0.01694163, 0.00574145,\n",
            "       0.00405358, 0.01672371, 0.00227212, 0.01129772, 0.00974211,\n",
            "       0.02169617, 0.00286199, 0.00959685, 0.00823762, 0.00185158,\n",
            "       0.02176496, 0.00543612, 0.02162052, 0.00193203, 0.00529989,\n",
            "       0.00115694, 0.00093492, 0.00308548, 0.0019699 , 0.00127918,\n",
            "       0.00300725, 0.00109905, 0.00626559, 0.0100368 , 0.00603397,\n",
            "       0.01414081, 0.02639099, 0.00322884, 0.00123498, 0.05457342,\n",
            "       0.0017363 , 0.01572508, 0.00163448, 0.00111432, 0.00538647,\n",
            "       0.00173346, 0.01951992, 0.02465674, 0.01723469, 0.01090851,\n",
            "       0.01287305, 0.03552728, 0.01135406, 0.00549607, 0.00234488,\n",
            "       0.00521685, 0.00452074, 0.00617058, 0.01689192, 0.01301006,\n",
            "       0.00173675], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul', 'index': 434, 'shape': array([ 1,  3,  1, 96], dtype=int32), 'shape_signature': array([ 1,  3,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.09261694, 0.00870797, 0.11258575, 0.11292935, 0.03555327,\n",
            "       0.0105069 , 0.14769876, 0.00407107, 0.06396408, 0.05906818,\n",
            "       0.03872847, 0.06821393, 0.02242759, 0.02905231, 0.01089678,\n",
            "       0.11135181, 0.10381918, 0.01980579, 0.10743461, 0.1440934 ,\n",
            "       0.18282972, 0.04326828, 0.09787124, 0.10207447, 0.08214425,\n",
            "       0.08390106, 0.15993138, 0.06771395, 0.01344766, 0.02444645,\n",
            "       0.0079853 , 0.0780844 , 0.13425793, 0.06725705, 0.00825409,\n",
            "       0.01179496, 0.02905113, 0.19381723, 0.00681432, 0.02262962,\n",
            "       0.01135134, 0.11370968, 0.00603222, 0.09010143, 0.03053501,\n",
            "       0.02155831, 0.08894244, 0.01208393, 0.06008516, 0.05181191,\n",
            "       0.11538766, 0.01522104, 0.05103935, 0.04381048, 0.00984734,\n",
            "       0.11575354, 0.02891115, 0.11498535, 0.0102752 , 0.02818664,\n",
            "       0.00615298, 0.00497224, 0.01640963, 0.0104766 , 0.0068031 ,\n",
            "       0.01599357, 0.00584514, 0.03332255, 0.05337913, 0.03209073,\n",
            "       0.07520566, 0.14035636, 0.01717208, 0.00656807, 0.2902402 ,\n",
            "       0.00923424, 0.08363136, 0.00869273, 0.00592632, 0.02864708,\n",
            "       0.00921912, 0.10381366, 0.131133  , 0.09165999, 0.0580152 ,\n",
            "       0.0684633 , 0.18894626, 0.06038477, 0.02922998, 0.01247089,\n",
            "       0.02774499, 0.02404286, 0.03281726, 0.08983701, 0.06919196,\n",
            "       0.00923665], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 435, 'shape': array([96], dtype=int32), 'shape_signature': array([96], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.2676153e-04, 2.0375617e-03, 6.9798157e-04, 1.7312452e-03,\n",
            "       2.1848467e-03, 1.1918462e-03, 3.6830406e-04, 1.5651624e-03,\n",
            "       8.5069175e-04, 2.4229010e-04, 9.7071752e-05, 3.8509755e-04,\n",
            "       8.8061963e-04, 3.0331998e-04, 4.8768090e-04, 4.5563086e-04,\n",
            "       1.0902587e-04, 1.5524173e-03, 5.8363442e-04, 7.7824685e-04,\n",
            "       1.2620272e-03, 4.5601436e-04, 3.2063294e-04, 4.6282662e-03,\n",
            "       2.6701638e-04, 2.8514599e-03, 9.8924502e-04, 5.8733439e-04,\n",
            "       1.2316100e-03, 2.1299683e-03, 1.4742921e-03, 5.9519720e-04,\n",
            "       6.1436655e-04, 3.1564899e-03, 3.8150980e-04, 2.2354748e-03,\n",
            "       2.7637533e-04, 2.3551314e-04, 1.2812066e-03, 4.9330940e-04,\n",
            "       1.5809733e-04, 4.8308197e-04, 2.4644271e-03, 8.3444756e-04,\n",
            "       8.9033495e-04, 4.3885020e-04, 3.0928181e-04, 5.3551246e-04,\n",
            "       1.8819330e-03, 3.0877267e-04, 4.4698876e-04, 3.4176423e-03,\n",
            "       3.8752321e-04, 3.6353676e-03, 6.2746336e-03, 1.3964550e-03,\n",
            "       2.3212493e-03, 1.8422707e-04, 1.6242607e-03, 2.4340211e-03,\n",
            "       4.9070048e-04, 7.2656793e-04, 2.8456742e-04, 1.0470339e-02,\n",
            "       2.0006646e-03, 1.7092959e-03, 2.9453754e-03, 1.6015531e-03,\n",
            "       6.4852077e-04, 4.2307312e-03, 1.7180413e-03, 9.1900164e-04,\n",
            "       2.3800819e-03, 4.6784829e-04, 3.0335615e-04, 1.2518056e-03,\n",
            "       8.7899429e-04, 7.9410383e-04, 2.9290400e-03, 4.5691449e-03,\n",
            "       2.6105409e-03, 2.6468867e-03, 1.1354224e-04, 6.3664475e-03,\n",
            "       2.7547330e-03, 2.0624837e-03, 3.6001910e-04, 3.3996711e-04,\n",
            "       1.6501126e-03, 5.0348794e-04, 7.9640839e-04, 3.7085821e-03,\n",
            "       2.9404184e-03, 1.6559573e-04, 2.9516310e-05, 3.6446622e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 436, 'shape': array([ 1,  3,  3, 96], dtype=int32), 'shape_signature': array([ 1,  3,  3, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00151581, 0.02436514, 0.00834646, 0.02070221, 0.02612637,\n",
            "       0.01425208, 0.00440418, 0.01871619, 0.01017256, 0.0028973 ,\n",
            "       0.00116078, 0.00460499, 0.01053044, 0.0036271 , 0.00583168,\n",
            "       0.00544843, 0.00130373, 0.01856379, 0.00697909, 0.00930627,\n",
            "       0.01509131, 0.00545301, 0.00383413, 0.05534475, 0.00319298,\n",
            "       0.03409772, 0.01182938, 0.00702334, 0.01472758, 0.02547014,\n",
            "       0.01762957, 0.00711736, 0.00734659, 0.03774527, 0.00456209,\n",
            "       0.02673178, 0.00330489, 0.00281626, 0.01532065, 0.00589899,\n",
            "       0.00189053, 0.00577669, 0.02946959, 0.00997831, 0.01064662,\n",
            "       0.00524777, 0.00369839, 0.00640365, 0.02250413, 0.0036923 ,\n",
            "       0.00534509, 0.04086813, 0.004634  , 0.04347168, 0.075032  ,\n",
            "       0.01669879, 0.02775747, 0.00220299, 0.01942289, 0.029106  ,\n",
            "       0.00586779, 0.00868829, 0.00340285, 0.12520419, 0.02392392,\n",
            "       0.02043974, 0.03522076, 0.01915135, 0.007755  , 0.05059103,\n",
            "       0.02054432, 0.01098941, 0.02846099, 0.00559452, 0.00362753,\n",
            "       0.01496908, 0.010511  , 0.00949588, 0.03502543, 0.05463778,\n",
            "       0.03121682, 0.03165144, 0.00135774, 0.07612991, 0.03294107,\n",
            "       0.02466316, 0.0043051 , 0.00406532, 0.01973203, 0.0060207 ,\n",
            "       0.00952344, 0.04434718, 0.03516149, 0.00198019, 0.00035296,\n",
            "       0.00435828], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 437, 'shape': array([96], dtype=int32), 'shape_signature': array([96], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.45027453e-04, 2.25895332e-04, 1.16042218e-04, 7.68268437e-05,\n",
            "       1.43690224e-04, 4.97354951e-04, 2.36746942e-04, 3.14358942e-04,\n",
            "       5.10474725e-04, 2.66258692e-04, 1.91060666e-04, 1.95435656e-04,\n",
            "       1.74627014e-04, 3.29726929e-04, 3.81675141e-04, 1.53269415e-04,\n",
            "       8.46596726e-04, 1.96138499e-04, 6.21421786e-05, 1.14208124e-04,\n",
            "       6.19138300e-05, 4.26820654e-04, 8.54945538e-05, 4.43778590e-05,\n",
            "       1.79853698e-04, 7.80738483e-05, 2.28077261e-04, 7.72323692e-05,\n",
            "       4.78579983e-04, 2.75989412e-04, 1.91116429e-04, 1.02290578e-04,\n",
            "       3.14277451e-04, 3.05792601e-05, 3.22196138e-04, 1.90305873e-04,\n",
            "       2.83684232e-04, 2.94010621e-04, 2.20829214e-04, 2.81705346e-04,\n",
            "       3.86482396e-04, 7.10451277e-05, 1.64865021e-04, 1.45451573e-04,\n",
            "       1.46554157e-04, 3.02118831e-04, 9.51820984e-05, 5.20648784e-04,\n",
            "       2.35056970e-04, 2.75409984e-04, 1.62167737e-04, 1.83866374e-04,\n",
            "       2.92054581e-04, 2.19220929e-05, 3.53627402e-05, 2.02288811e-05,\n",
            "       1.76540416e-04, 3.03376728e-04, 1.66657046e-04, 1.13798320e-04,\n",
            "       4.70377214e-04, 4.01832775e-04, 4.51227912e-04, 5.83953588e-05,\n",
            "       1.58349038e-04, 6.50020884e-05, 2.59197783e-04, 2.30726990e-04,\n",
            "       2.57388718e-04, 4.80347953e-05, 5.83051915e-05, 7.41604308e-05,\n",
            "       9.86782397e-05, 3.39101505e-04, 2.28170233e-04, 2.60477333e-04,\n",
            "       9.61509140e-05, 5.42094291e-04, 1.85587225e-04, 4.27710111e-05,\n",
            "       2.96392158e-04, 6.10610587e-05, 3.35828779e-04, 2.05033884e-05,\n",
            "       1.01272948e-04, 4.46407066e-05, 1.58050243e-04, 1.78999529e-04,\n",
            "       1.01352249e-04, 4.20505967e-04, 7.12897687e-04, 4.75297478e-04,\n",
            "       9.03464606e-05, 2.70940131e-04, 4.94264998e-04, 3.68022564e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 438, 'shape': array([96,  1,  1, 40], dtype=int32), 'shape_signature': array([96,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([4.41547221e-04, 2.89088464e-04, 1.48504463e-04, 9.83187856e-05,\n",
            "       1.83886877e-04, 6.36487559e-04, 3.02975764e-04, 4.02299338e-04,\n",
            "       6.53277559e-04, 3.40743281e-04, 2.44508963e-04, 2.50107842e-04,\n",
            "       2.23478084e-04, 4.21966455e-04, 4.88446909e-04, 1.96145789e-04,\n",
            "       1.08342804e-03, 2.51007295e-04, 7.95261512e-05, 1.46157297e-04,\n",
            "       7.92339270e-05, 5.46221680e-04, 1.09411245e-04, 5.67923526e-05,\n",
            "       2.30166901e-04, 9.99146287e-05, 2.91880773e-04, 9.88377506e-05,\n",
            "       6.12460426e-04, 3.53196112e-04, 2.44580326e-04, 1.30905872e-04,\n",
            "       4.02195059e-04, 3.91336616e-05, 4.12328955e-04, 2.43543021e-04,\n",
            "       3.63043509e-04, 3.76258657e-04, 2.82605120e-04, 3.60511069e-04,\n",
            "       4.94598993e-04, 9.09196606e-05, 2.10985221e-04, 1.86140940e-04,\n",
            "       1.87551967e-04, 3.86635133e-04, 1.21808829e-04, 6.66297739e-04,\n",
            "       3.00813030e-04, 3.52454605e-04, 2.07533376e-04, 2.35302112e-04,\n",
            "       3.73755436e-04, 2.80546919e-05, 4.52552958e-05, 2.58878117e-05,\n",
            "       2.25926735e-04, 3.88244895e-04, 2.13278545e-04, 1.45632846e-04,\n",
            "       6.01962965e-04, 5.14243555e-04, 5.77456725e-04, 7.47311788e-05,\n",
            "       2.02646421e-04, 8.31861107e-05, 3.31707095e-04, 2.95271748e-04,\n",
            "       3.29391973e-04, 6.14722958e-05, 7.46157893e-05, 9.49064561e-05,\n",
            "       1.26283005e-04, 4.33963520e-04, 2.91999750e-04, 3.33344593e-04,\n",
            "       1.23048667e-04, 6.93742535e-04, 2.37504355e-04, 5.47359959e-05,\n",
            "       3.79306439e-04, 7.81425988e-05, 4.29775246e-04, 2.62391113e-05,\n",
            "       1.29603563e-04, 5.71287273e-05, 2.02264026e-04, 2.29073776e-04,\n",
            "       1.29705048e-04, 5.38140477e-04, 9.12327378e-04, 6.08259637e-04,\n",
            "       1.15620445e-04, 3.46734334e-04, 6.32533222e-04, 4.70975094e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/rezero/mul', 'index': 439, 'shape': array([ 1,  1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.008413638919591904, 127), 'quantization_parameters': {'scales': array([0.00841364], dtype=float32), 'zero_points': array([127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 440, 'shape': array([40], dtype=int32), 'shape_signature': array([40], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00090811, 0.00034522, 0.00073674, 0.00073122, 0.00035306,\n",
            "       0.00070351, 0.00067056, 0.00074141, 0.00191834, 0.00053089,\n",
            "       0.00076043, 0.00083455, 0.00083464, 0.00105071, 0.00061143,\n",
            "       0.00073374, 0.00179898, 0.00102015, 0.00057582, 0.00168305,\n",
            "       0.0006881 , 0.00110975, 0.00068296, 0.00097657, 0.0004537 ,\n",
            "       0.00101282, 0.00088653, 0.00185223, 0.00155231, 0.00216648,\n",
            "       0.00082884, 0.00110211, 0.00078977, 0.00102221, 0.00072661,\n",
            "       0.0007857 , 0.00166758, 0.00159407, 0.00112921, 0.00116383],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 441, 'shape': array([40,  1,  1, 96], dtype=int32), 'shape_signature': array([40,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.0143872 , 0.00546935, 0.01167219, 0.01158478, 0.00559349,\n",
            "       0.01114572, 0.01062375, 0.01174616, 0.03039219, 0.00841095,\n",
            "       0.01204748, 0.01322179, 0.01322314, 0.01664646, 0.00968695,\n",
            "       0.01162464, 0.02850129, 0.01616221, 0.00912274, 0.0266645 ,\n",
            "       0.01090158, 0.01758177, 0.01082016, 0.0154718 , 0.00718804,\n",
            "       0.01604615, 0.01404537, 0.0293448 , 0.02459323, 0.03432349,\n",
            "       0.01313131, 0.01746069, 0.01251233, 0.01619492, 0.01151167,\n",
            "       0.0124479 , 0.02641939, 0.02525492, 0.01789013, 0.01843857],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block1_layer2/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block1_layer2/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block1_layer2/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer2/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 442, 'shape': array([96], dtype=int32), 'shape_signature': array([96], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.74680572e-05, 2.42212882e-05, 4.05389001e-05, 2.12948144e-05,\n",
            "       2.66228071e-05, 1.00895504e-05, 2.35622501e-05, 3.67652974e-05,\n",
            "       1.32351552e-05, 2.30189107e-05, 2.47120988e-05, 2.15088821e-05,\n",
            "       2.21932842e-05, 2.15362816e-05, 5.88346993e-05, 2.33551418e-05,\n",
            "       1.71132342e-05, 2.93641733e-05, 3.83424485e-05, 2.30738788e-05,\n",
            "       2.68961794e-05, 2.18142977e-05, 3.37610472e-05, 2.32009279e-05,\n",
            "       3.04200803e-05, 9.66290027e-05, 5.49900215e-05, 3.49219990e-05,\n",
            "       4.20140277e-05, 1.04924635e-04, 1.13682190e-05, 1.30860644e-05,\n",
            "       1.92963307e-05, 3.21011685e-05, 1.08881817e-04, 1.73909593e-05,\n",
            "       5.53901009e-05, 1.09130096e-05, 2.83281461e-05, 3.54816257e-05,\n",
            "       1.50863780e-05, 2.97723091e-05, 2.43723989e-05, 1.40343245e-05,\n",
            "       2.45496885e-05, 2.80421937e-05, 3.62477585e-05, 2.70739292e-05,\n",
            "       2.55485065e-05, 1.68278711e-05, 3.31319025e-05, 3.41538907e-05,\n",
            "       2.73815385e-05, 2.04868411e-05, 1.21179201e-05, 2.93634967e-05,\n",
            "       9.72467606e-05, 3.70701528e-05, 2.30031619e-05, 2.03017262e-05,\n",
            "       2.35636107e-05, 1.78149076e-05, 2.57544270e-05, 2.63744005e-05,\n",
            "       2.44877119e-05, 1.43572879e-05, 5.50387849e-05, 1.49986936e-05,\n",
            "       3.09178286e-05, 2.01068633e-05, 3.38053032e-05, 1.66311784e-05,\n",
            "       2.36109081e-05, 1.84342061e-05, 2.10749859e-05, 7.40532705e-05,\n",
            "       2.59036788e-05, 3.31952069e-05, 1.87855185e-05, 1.44759215e-05,\n",
            "       5.62295936e-05, 2.23703337e-05, 1.43871293e-05, 2.38125831e-05,\n",
            "       2.21117025e-05, 1.96080291e-05, 4.30676264e-05, 6.31392322e-05,\n",
            "       4.45446603e-05, 3.22118176e-05, 2.14337106e-05, 1.24802436e-05,\n",
            "       1.90276078e-05, 1.06354919e-05, 3.70388043e-05, 2.28826975e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 443, 'shape': array([96,  1,  1, 48], dtype=int32), 'shape_signature': array([96,  1,  1, 48], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00117959, 0.00163563, 0.00273753, 0.00143801, 0.0017978 ,\n",
            "       0.00068133, 0.00159112, 0.00248271, 0.00089375, 0.00155443,\n",
            "       0.00166877, 0.00145246, 0.00149868, 0.00145431, 0.00397302,\n",
            "       0.00157714, 0.00115563, 0.00198292, 0.00258921, 0.00155815,\n",
            "       0.00181626, 0.00147309, 0.00227983, 0.00156673, 0.00205422,\n",
            "       0.00652522, 0.0037134 , 0.00235823, 0.00283715, 0.00708541,\n",
            "       0.00076768, 0.00088368, 0.00130305, 0.00216775, 0.00735263,\n",
            "       0.00117439, 0.00374041, 0.00073694, 0.00191296, 0.00239602,\n",
            "       0.00101876, 0.00201048, 0.00164583, 0.00094772, 0.0016578 ,\n",
            "       0.00189365, 0.00244776, 0.00182826, 0.00172525, 0.00113636,\n",
            "       0.00223735, 0.00230636, 0.00184904, 0.00138345, 0.00081831,\n",
            "       0.00198287, 0.00656693, 0.00250329, 0.00155337, 0.00137095,\n",
            "       0.00159122, 0.00120301, 0.00173916, 0.00178103, 0.00165362,\n",
            "       0.00096953, 0.00371669, 0.00101284, 0.00208784, 0.00135779,\n",
            "       0.00228282, 0.00112308, 0.00159441, 0.00124484, 0.00142316,\n",
            "       0.00500071, 0.00174924, 0.00224162, 0.00126856, 0.00097754,\n",
            "       0.0037971 , 0.00151064, 0.00097154, 0.00160803, 0.00149317,\n",
            "       0.0013241 , 0.00290829, 0.0042637 , 0.00300804, 0.00217522,\n",
            "       0.00144739, 0.00084277, 0.00128491, 0.0007182 , 0.00250118,\n",
            "       0.00154524], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 444, 'shape': array([48], dtype=int32), 'shape_signature': array([48], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([7.5145574e-05, 6.6613837e-05, 7.6085547e-05, 3.6845660e-05,\n",
            "       6.7803056e-05, 1.3982053e-04, 5.2337411e-05, 3.4851309e-05,\n",
            "       3.3030105e-05, 5.5137840e-05, 4.5192235e-05, 6.5930326e-05,\n",
            "       8.7275279e-05, 6.7634850e-05, 3.2524757e-05, 4.3692915e-05,\n",
            "       3.7754056e-05, 3.4923338e-05, 3.3252534e-05, 4.8551698e-05,\n",
            "       4.1130410e-05, 7.3048599e-05, 3.0623203e-05, 9.2465583e-05,\n",
            "       4.4134573e-05, 2.5687257e-05, 3.3884608e-05, 5.8776906e-05,\n",
            "       3.6333189e-05, 2.3352235e-05, 2.9259112e-05, 5.3365846e-05,\n",
            "       1.3174801e-04, 3.1508993e-05, 7.6601398e-05, 5.0547318e-05,\n",
            "       5.2027834e-05, 5.1474788e-05, 8.4946310e-05, 7.2147341e-05,\n",
            "       4.7003374e-05, 6.6126835e-05, 2.7718403e-05, 3.4734225e-05,\n",
            "       9.0461581e-05, 6.8688190e-05, 5.9727248e-05, 3.4914905e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 445, 'shape': array([ 48,   1,   1, 192], dtype=int32), 'shape_signature': array([ 48,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00352363, 0.00312357, 0.0035677 , 0.00172772, 0.00317933,\n",
            "       0.00655628, 0.00245414, 0.0016342 , 0.0015488 , 0.00258545,\n",
            "       0.00211909, 0.00309152, 0.0040924 , 0.00317144, 0.00152511,\n",
            "       0.00204879, 0.00177031, 0.00163758, 0.00155923, 0.00227662,\n",
            "       0.00192863, 0.0034253 , 0.00143594, 0.00433577, 0.0020695 ,\n",
            "       0.00120449, 0.00158887, 0.00275609, 0.00170369, 0.001095  ,\n",
            "       0.00137198, 0.00250236, 0.00617775, 0.00147748, 0.00359189,\n",
            "       0.0023702 , 0.00243962, 0.00241369, 0.00398319, 0.00338304,\n",
            "       0.00220402, 0.00310073, 0.00129973, 0.00162871, 0.0042418 ,\n",
            "       0.00322084, 0.00280065, 0.00163718], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 446, 'shape': array([96], dtype=int32), 'shape_signature': array([96], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00269549, 0.00132753, 0.00221147, 0.00843565, 0.00324683,\n",
            "       0.00284526, 0.02283695, 0.0015261 , 0.0130309 , 0.00688563,\n",
            "       0.0049788 , 0.01006427, 0.02605124, 0.00159737, 0.00194305,\n",
            "       0.00588848, 0.00424523, 0.00822573, 0.00195205, 0.01777218,\n",
            "       0.01054788, 0.01090313, 0.00097617, 0.01644062, 0.01717027,\n",
            "       0.00145304, 0.00205814, 0.00201009, 0.00271762, 0.00757519,\n",
            "       0.01537562, 0.01020023, 0.00146087, 0.01286745, 0.00888176,\n",
            "       0.01248495, 0.01213684, 0.00205918, 0.00152629, 0.00119221,\n",
            "       0.00297113, 0.00300435, 0.00399064, 0.0064568 , 0.00296542,\n",
            "       0.00200654, 0.0134391 , 0.00183056, 0.00200508, 0.01097758,\n",
            "       0.00200125, 0.00137187, 0.00924914, 0.00164751, 0.00189745,\n",
            "       0.0036347 , 0.01914238, 0.01357789, 0.00257148, 0.00266669,\n",
            "       0.00265359, 0.00731043, 0.00135782, 0.00834031, 0.0241858 ,\n",
            "       0.02091057, 0.01494746, 0.00156277, 0.02244002, 0.01083837,\n",
            "       0.00816126, 0.0043504 , 0.00223155, 0.00258696, 0.00482648,\n",
            "       0.02021852, 0.00238684, 0.00124192, 0.00718625, 0.00094934,\n",
            "       0.00885076, 0.00402918, 0.01804047, 0.02918116, 0.01361241,\n",
            "       0.00090062, 0.0117737 , 0.02471131, 0.02400552, 0.01335782,\n",
            "       0.00136793, 0.01250123, 0.00082525, 0.00519751, 0.00090388,\n",
            "       0.0262835 ], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul', 'index': 447, 'shape': array([ 1,  3,  1, 96], dtype=int32), 'shape_signature': array([ 1,  3,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01521094, 0.00749137, 0.01247958, 0.04760329, 0.01832225,\n",
            "       0.01605612, 0.12887149, 0.00861197, 0.07353483, 0.03885638,\n",
            "       0.02809595, 0.05679381, 0.14701006, 0.00901411, 0.01096487,\n",
            "       0.03322935, 0.02395633, 0.04641872, 0.01101562, 0.1002904 ,\n",
            "       0.05952286, 0.06152761, 0.00550863, 0.09277626, 0.09689376,\n",
            "       0.00819964, 0.01161429, 0.01134315, 0.01533586, 0.04274766,\n",
            "       0.08676632, 0.05756103, 0.00824383, 0.07261245, 0.05012075,\n",
            "       0.07045399, 0.06848953, 0.01162017, 0.00861305, 0.00672776,\n",
            "       0.01676641, 0.01695388, 0.02251964, 0.03643644, 0.01673419,\n",
            "       0.01132314, 0.07583836, 0.01033003, 0.01131489, 0.06194769,\n",
            "       0.01129327, 0.00774163, 0.05219394, 0.00929706, 0.01070752,\n",
            "       0.02051102, 0.10802259, 0.07662157, 0.01451113, 0.01504841,\n",
            "       0.01497453, 0.04125358, 0.00766234, 0.04706533, 0.13648318,\n",
            "       0.11800068, 0.08435018, 0.0088189 , 0.12663154, 0.06116211,\n",
            "       0.0460549 , 0.02454979, 0.01259289, 0.01459848, 0.02723635,\n",
            "       0.11409539, 0.01346923, 0.00700828, 0.04055282, 0.00535725,\n",
            "       0.04994582, 0.02273714, 0.10180441, 0.16467257, 0.07681635,\n",
            "       0.00508229, 0.06644032, 0.13944872, 0.13546583, 0.07537965,\n",
            "       0.00771937, 0.07054586, 0.00465697, 0.02933012, 0.00510067,\n",
            "       0.14832073], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 448, 'shape': array([96], dtype=int32), 'shape_signature': array([96], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([9.1072370e-04, 9.9030808e-03, 1.1999453e-03, 3.8289666e-04,\n",
            "       7.8901444e-03, 5.6867190e-03, 3.2491367e-03, 1.2935090e-03,\n",
            "       3.7645505e-04, 3.5255912e-04, 1.2891529e-03, 1.3110238e-03,\n",
            "       4.8976515e-05, 1.4427082e-03, 9.0977559e-03, 1.5835279e-03,\n",
            "       9.6795772e-04, 4.2193471e-03, 2.7832878e-03, 3.5445983e-04,\n",
            "       2.1530220e-03, 6.4909551e-03, 1.0831085e-03, 6.9878675e-05,\n",
            "       1.3294419e-03, 5.3913100e-03, 3.4408318e-03, 2.6572584e-03,\n",
            "       1.3797862e-03, 7.5767277e-04, 1.2905718e-04, 3.6554356e-04,\n",
            "       1.4036904e-03, 2.7384335e-04, 1.3230140e-04, 6.9848979e-03,\n",
            "       2.3242793e-04, 8.5939484e-04, 8.5981265e-03, 2.9296442e-03,\n",
            "       1.7311331e-02, 2.2589065e-04, 3.2894996e-03, 1.8653242e-03,\n",
            "       8.4231673e-03, 6.5284008e-03, 2.9734168e-03, 1.5667762e-03,\n",
            "       5.7115621e-04, 8.6566433e-05, 1.1078652e-03, 3.1124034e-03,\n",
            "       4.7095123e-04, 2.0273654e-03, 2.5333932e-03, 1.2527403e-03,\n",
            "       1.5395151e-04, 1.0561813e-03, 2.0880655e-03, 7.4447924e-04,\n",
            "       2.1594763e-03, 5.3381785e-03, 4.7755102e-03, 4.1743405e-03,\n",
            "       1.1381860e-03, 4.2245362e-04, 2.2560310e-04, 2.2534521e-03,\n",
            "       2.9498778e-04, 2.0596794e-04, 7.6214114e-04, 3.0028343e-03,\n",
            "       9.4708102e-04, 1.2146795e-02, 1.3094896e-03, 2.0783821e-03,\n",
            "       8.4298756e-03, 2.4655852e-03, 7.5867970e-04, 2.6627085e-03,\n",
            "       1.2257802e-03, 2.1110338e-03, 4.8429915e-03, 2.6248783e-04,\n",
            "       2.0647662e-04, 6.5283282e-03, 1.1957111e-04, 3.9249161e-04,\n",
            "       7.7226711e-04, 4.2551631e-04, 3.0741238e-03, 3.6123881e-04,\n",
            "       2.2279068e-03, 1.9501474e-03, 9.3408534e-03, 2.9305907e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 449, 'shape': array([ 1,  3,  3, 96], dtype=int32), 'shape_signature': array([ 1,  3,  3, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00738186, 0.08026932, 0.00972614, 0.00310356, 0.06395348,\n",
            "       0.04609364, 0.02633584, 0.01048452, 0.00305135, 0.00285766,\n",
            "       0.01044922, 0.01062649, 0.00039698, 0.01169386, 0.07374177,\n",
            "       0.01283527, 0.00784577, 0.03419987, 0.02255991, 0.00287307,\n",
            "       0.0174513 , 0.05261237, 0.00877912, 0.0005664 , 0.01077578,\n",
            "       0.04369921, 0.02788963, 0.02153838, 0.01118384, 0.00614131,\n",
            "       0.00104607, 0.00296291, 0.0113776 , 0.00221963, 0.00107237,\n",
            "       0.05661602, 0.00188394, 0.00696582, 0.06969202, 0.0237462 ,\n",
            "       0.14031681, 0.00183095, 0.02666301, 0.01511937, 0.06827389,\n",
            "       0.05291589, 0.024101  , 0.01269949, 0.0046295 , 0.00070166,\n",
            "       0.00897979, 0.02522755, 0.00381729, 0.01643279, 0.02053439,\n",
            "       0.01015407, 0.00124785, 0.00856087, 0.01692479, 0.00603437,\n",
            "       0.01750361, 0.04326855, 0.03870785, 0.03383508, 0.00922555,\n",
            "       0.00342419, 0.00182862, 0.01826533, 0.00239102, 0.00166947,\n",
            "       0.00617753, 0.02433944, 0.00767656, 0.09845573, 0.01061405,\n",
            "       0.0168463 , 0.06832827, 0.01998478, 0.00614947, 0.02158256,\n",
            "       0.00993555, 0.01711096, 0.03925482, 0.00212759, 0.00167359,\n",
            "       0.0529153 , 0.00096918, 0.00318134, 0.0062596 , 0.00344902,\n",
            "       0.02491728, 0.00292802, 0.01805828, 0.0158069 , 0.07571219,\n",
            "       0.02375387], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 450, 'shape': array([96], dtype=int32), 'shape_signature': array([96], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.9465859e-04, 6.5131499e-05, 5.2421459e-04, 5.7235867e-04,\n",
            "       4.2359792e-05, 7.7303179e-05, 4.2350217e-05, 7.4952433e-04,\n",
            "       3.7691597e-04, 1.9211991e-04, 2.8536894e-04, 2.9205772e-04,\n",
            "       5.4512388e-04, 3.8215896e-04, 2.0429432e-04, 2.5458352e-04,\n",
            "       3.2729609e-04, 3.8510629e-05, 6.3897722e-04, 5.0417252e-04,\n",
            "       1.2186688e-04, 9.9046876e-05, 4.3552587e-04, 1.3481895e-04,\n",
            "       3.9368275e-05, 1.4119431e-04, 3.5736637e-04, 3.2036973e-04,\n",
            "       3.1866104e-04, 1.7235424e-04, 4.9020874e-04, 3.1056523e-04,\n",
            "       3.2688011e-04, 4.5466487e-04, 7.4253371e-04, 8.2091312e-05,\n",
            "       1.1160073e-03, 2.8060627e-04, 1.2918549e-04, 1.7692961e-04,\n",
            "       6.1637715e-05, 4.4837027e-04, 5.2596885e-04, 2.8641417e-04,\n",
            "       8.2047947e-05, 1.1349242e-04, 6.8593617e-05, 3.2858757e-04,\n",
            "       3.6023784e-04, 3.6091899e-04, 4.5448873e-04, 3.4097614e-04,\n",
            "       3.7849185e-04, 3.4091240e-04, 2.1447592e-04, 3.1011808e-04,\n",
            "       2.1111338e-04, 1.8585313e-04, 6.2861736e-04, 2.1379812e-04,\n",
            "       2.6285273e-04, 7.1792827e-05, 4.4770664e-04, 1.9547262e-04,\n",
            "       1.0448016e-04, 1.1625197e-04, 5.0080812e-04, 2.3842194e-04,\n",
            "       2.4490050e-04, 4.0672498e-04, 1.1833634e-04, 2.9496470e-04,\n",
            "       2.7495730e-04, 1.9905428e-05, 3.3599680e-04, 3.9591479e-05,\n",
            "       5.3243322e-05, 3.2331733e-04, 3.4612211e-04, 3.3010804e-04,\n",
            "       8.5274536e-05, 4.4903497e-04, 3.7918540e-05, 2.0579032e-04,\n",
            "       2.3970364e-04, 2.0194397e-04, 1.0730402e-03, 7.5355673e-04,\n",
            "       2.0856647e-04, 2.9839046e-04, 2.7671937e-04, 2.7558050e-04,\n",
            "       2.5591860e-04, 1.7348942e-04, 2.9912323e-04, 3.8263970e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 451, 'shape': array([96,  1,  1, 40], dtype=int32), 'shape_signature': array([96,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([4.0886880e-04, 9.0376590e-05, 7.2740112e-04, 7.9420593e-04,\n",
            "       5.8778525e-05, 1.0726603e-04, 5.8765239e-05, 1.0400413e-03,\n",
            "       5.2300928e-04, 2.6658594e-04, 3.9597845e-04, 4.0525981e-04,\n",
            "       7.5641490e-04, 5.3028448e-04, 2.8347917e-04, 3.5326055e-04,\n",
            "       4.5415666e-04, 5.3437419e-05, 8.8664592e-04, 6.9959072e-04,\n",
            "       1.6910270e-04, 1.3743763e-04, 6.0433650e-04, 1.8707503e-04,\n",
            "       5.4627490e-05, 1.9592149e-04, 4.9588224e-04, 4.4454561e-04,\n",
            "       4.4217464e-04, 2.3915905e-04, 6.8021455e-04, 4.3094088e-04,\n",
            "       4.5357944e-04, 6.3089380e-04, 1.0303411e-03, 1.1391005e-04,\n",
            "       1.5485738e-03, 3.8936976e-04, 1.7925802e-04, 2.4550784e-04,\n",
            "       8.5528605e-05, 6.2215939e-04, 7.2983536e-04, 3.9742884e-04,\n",
            "       1.1384988e-04, 1.5748228e-04, 9.5180629e-05, 4.5594870e-04,\n",
            "       4.9986667e-04, 5.0081185e-04, 6.3064939e-04, 4.7313911e-04,\n",
            "       5.2519597e-04, 4.7305066e-04, 2.9760718e-04, 4.3032042e-04,\n",
            "       2.9294132e-04, 2.5789015e-04, 8.7227061e-04, 2.9666667e-04,\n",
            "       3.6473494e-04, 9.9619858e-05, 6.2123855e-04, 2.7123815e-04,\n",
            "       1.4497686e-04, 1.6131144e-04, 6.9492223e-04, 3.3083471e-04,\n",
            "       3.3982436e-04, 5.6437234e-04, 1.6420372e-04, 4.0929357e-04,\n",
            "       3.8153125e-04, 2.7620808e-05, 4.6622974e-04, 5.4937209e-05,\n",
            "       7.3880532e-05, 4.4863572e-04, 4.8027968e-04, 4.5805852e-04,\n",
            "       1.1832710e-04, 6.2308175e-04, 5.2615836e-05, 2.8555503e-04,\n",
            "       3.3261321e-04, 2.8021782e-04, 1.4889525e-03, 1.0456367e-03,\n",
            "       2.8940721e-04, 4.1404716e-04, 3.8397629e-04, 3.8239601e-04,\n",
            "       3.5511309e-04, 2.4073423e-04, 4.1506396e-04, 5.3095155e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/rezero/mul', 'index': 452, 'shape': array([ 1,  1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.008918359875679016, 127), 'quantization_parameters': {'scales': array([0.00891836], dtype=float32), 'zero_points': array([127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 453, 'shape': array([40], dtype=int32), 'shape_signature': array([40], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00335747, 0.00064523, 0.00160354, 0.00185754, 0.00068172,\n",
            "       0.00180258, 0.00098109, 0.00073313, 0.00313521, 0.00142111,\n",
            "       0.00080781, 0.00149482, 0.00109338, 0.001781  , 0.00131059,\n",
            "       0.00097128, 0.00492014, 0.00245492, 0.00119391, 0.00093756,\n",
            "       0.00161287, 0.001366  , 0.00308576, 0.00155174, 0.00102648,\n",
            "       0.00254911, 0.00168476, 0.00297862, 0.00254869, 0.00591191,\n",
            "       0.00202872, 0.00143976, 0.00074141, 0.00177558, 0.0015243 ,\n",
            "       0.0011763 , 0.00247852, 0.0022782 , 0.0026782 , 0.00127197],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 454, 'shape': array([ 40,   1,   1, 120], dtype=int32), 'shape_signature': array([ 40,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.0376327 , 0.00723219, 0.01797347, 0.02082044, 0.0076412 ,\n",
            "       0.02020443, 0.01099672, 0.00821736, 0.0351414 , 0.01592873,\n",
            "       0.0090544 , 0.01675487, 0.0122553 , 0.01996257, 0.01468987,\n",
            "       0.01088673, 0.05514807, 0.02751635, 0.01338215, 0.01050873,\n",
            "       0.01807812, 0.01531103, 0.03458713, 0.01739292, 0.01150549,\n",
            "       0.02857208, 0.01888385, 0.03338629, 0.02856732, 0.06626447,\n",
            "       0.02273919, 0.01613776, 0.0083102 , 0.01990181, 0.01708535,\n",
            "       0.01318473, 0.0277808 , 0.02553554, 0.03001897, 0.01425704],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 455, 'shape': array([120], dtype=int32), 'shape_signature': array([120], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.9867766e-05, 2.4950516e-05, 1.2720173e-05, 1.9056672e-05,\n",
            "       2.4475867e-05, 5.4952434e-09, 2.0954752e-05, 2.1140084e-05,\n",
            "       4.7011803e-05, 4.5976565e-05, 2.4223196e-05, 1.8626233e-05,\n",
            "       2.3291159e-05, 6.2206382e-08, 2.1889817e-05, 2.6824986e-05,\n",
            "       1.8243212e-05, 1.5935308e-04, 5.1553972e-05, 2.6397336e-05,\n",
            "       2.6770502e-05, 3.4765697e-05, 2.5845246e-05, 1.5569032e-05,\n",
            "       5.7405523e-05, 2.7043385e-05, 3.3863082e-05, 3.8004655e-05,\n",
            "       1.7529363e-05, 8.3492661e-05, 4.0904615e-05, 4.6928697e-05,\n",
            "       3.3767486e-05, 2.1336861e-04, 2.2328351e-05, 3.7191239e-05,\n",
            "       6.0281629e-05, 5.6847752e-05, 3.5829504e-05, 2.4216557e-05,\n",
            "       8.2149301e-05, 6.7758010e-05, 2.9302988e-05, 3.2354765e-05,\n",
            "       4.7453483e-05, 3.5437781e-05, 1.1508969e-04, 5.3960532e-05,\n",
            "       2.6298192e-05, 1.8736644e-05, 6.1971863e-05, 2.4873834e-05,\n",
            "       2.8416698e-05, 6.0745369e-05, 6.7093853e-05, 2.6299129e-05,\n",
            "       4.3309290e-05, 4.9291732e-05, 3.3310487e-05, 2.7992963e-05,\n",
            "       6.9598456e-05, 4.7732716e-05, 6.8020265e-05, 7.5634351e-05,\n",
            "       3.0022396e-05, 9.3611205e-05, 5.4979146e-09, 4.5592769e-05,\n",
            "       1.0733055e-04, 3.0896870e-05, 6.3025465e-05, 2.6512651e-05,\n",
            "       2.7541721e-05, 1.0057894e-04, 1.9390633e-05, 2.2636186e-05,\n",
            "       2.2809165e-05, 6.4716107e-05, 9.5752403e-05, 1.7188515e-05,\n",
            "       1.1528560e-04, 7.9921621e-05, 1.3624732e-05, 7.7282210e-05,\n",
            "       5.8082031e-05, 1.1074492e-04, 2.0585647e-05, 4.2855168e-05,\n",
            "       1.9435798e-05, 4.4805296e-05, 9.4840339e-05, 1.2722578e-05,\n",
            "       2.8167806e-05, 7.6358418e-05, 6.8821668e-05, 1.1183084e-08,\n",
            "       1.7295555e-05, 3.5560639e-05, 3.7642294e-05, 4.2419077e-05,\n",
            "       4.0112285e-05, 2.5627751e-05, 7.1370880e-05, 2.8771685e-05,\n",
            "       3.3861987e-05, 1.8166817e-05, 5.6678567e-05, 5.0484290e-05,\n",
            "       2.4013245e-05, 3.1288175e-05, 3.5798330e-05, 7.4046300e-05,\n",
            "       4.8307800e-05, 1.7777396e-05, 6.6551351e-05, 1.0924696e-04,\n",
            "       5.3131786e-05, 2.0483232e-05, 2.1679245e-05, 2.5484422e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 456, 'shape': array([120,   1,   1,  64], dtype=int32), 'shape_signature': array([120,   1,   1,  64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.0504774e-03, 1.3192199e-03, 6.7255949e-04, 1.0075921e-03,\n",
            "       1.2941236e-03, 2.9055249e-07, 1.1079501e-03, 1.1177493e-03,\n",
            "       2.4856764e-03, 2.4309398e-03, 1.2807640e-03, 9.8483323e-04,\n",
            "       1.2314840e-03, 3.2890664e-06, 1.1573902e-03, 1.4183297e-03,\n",
            "       9.6458162e-04, 8.4255477e-03, 2.7258366e-03, 1.3957183e-03,\n",
            "       1.4154488e-03, 1.8381824e-03, 1.3665274e-03, 8.2318846e-04,\n",
            "       3.0352282e-03, 1.4298771e-03, 1.7904581e-03, 2.0094374e-03,\n",
            "       9.2683791e-04, 4.4145454e-03, 2.1627683e-03, 2.4812822e-03,\n",
            "       1.7854037e-03, 1.1281535e-02, 1.1805771e-03, 1.9664292e-03,\n",
            "       3.1872978e-03, 3.0057370e-03, 1.8944297e-03, 1.2804130e-03,\n",
            "       4.3435171e-03, 3.5826000e-03, 1.5493502e-03, 1.7107081e-03,\n",
            "       2.5090296e-03, 1.8737179e-03, 6.0851895e-03, 2.8530797e-03,\n",
            "       1.3904762e-03, 9.9067111e-04, 3.2766664e-03, 1.3151655e-03,\n",
            "       1.5024890e-03, 3.2118175e-03, 3.5474838e-03, 1.3905257e-03,\n",
            "       2.2899117e-03, 2.6062240e-03, 1.7612404e-03, 1.4800846e-03,\n",
            "       3.6799109e-03, 2.5237936e-03, 3.5964663e-03, 3.9990493e-03,\n",
            "       1.5873878e-03, 4.9495478e-03, 2.9069372e-07, 2.4106472e-03,\n",
            "       5.6749368e-03, 1.6336242e-03, 3.3323742e-03, 1.4018154e-03,\n",
            "       1.4562259e-03, 5.3179557e-03, 1.0252497e-03, 1.1968534e-03,\n",
            "       1.2059993e-03, 3.4217641e-03, 5.0627603e-03, 9.0881612e-04,\n",
            "       6.0955477e-03, 4.2257323e-03, 7.2038663e-04, 4.0861773e-03,\n",
            "       3.0709975e-03, 5.8554662e-03, 1.0884342e-03, 2.2659008e-03,\n",
            "       1.0276377e-03, 2.3690108e-03, 5.0145364e-03, 6.7268661e-04,\n",
            "       1.4893292e-03, 4.0373332e-03, 3.6388391e-03, 5.9128826e-07,\n",
            "       9.1447576e-04, 1.8802139e-03, 1.9902780e-03, 2.2428432e-03,\n",
            "       2.1208751e-03, 1.3550277e-03, 3.7736250e-03, 1.5212584e-03,\n",
            "       1.7904002e-03, 9.6054230e-04, 2.9967916e-03, 2.6692788e-03,\n",
            "       1.2696632e-03, 1.6543139e-03, 1.8927812e-03, 3.9150836e-03,\n",
            "       2.5542001e-03, 9.3995238e-04, 3.5187996e-03, 5.7762642e-03,\n",
            "       2.8092610e-03, 1.0830192e-03, 1.1462566e-03, 1.3474494e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 457, 'shape': array([64], dtype=int32), 'shape_signature': array([64], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.11861766e-04, 1.30491724e-04, 9.06877540e-05, 9.16129138e-05,\n",
            "       9.46073633e-05, 9.76333322e-05, 1.77595051e-04, 1.45929851e-04,\n",
            "       1.29595574e-04, 5.02959119e-05, 5.75096819e-05, 1.13664631e-04,\n",
            "       1.04365041e-04, 9.80942059e-05, 6.49119538e-05, 1.14442206e-04,\n",
            "       8.19864363e-05, 6.22840525e-05, 1.07956766e-04, 4.84713419e-05,\n",
            "       9.53024792e-05, 5.66008457e-05, 1.40030606e-04, 7.75188309e-05,\n",
            "       5.26193144e-05, 6.06333451e-05, 1.24433907e-04, 1.48394058e-04,\n",
            "       1.06725769e-04, 1.06039734e-04, 1.59758449e-04, 1.23125385e-04,\n",
            "       1.10011882e-04, 5.99100531e-05, 1.02576036e-04, 1.13246519e-04,\n",
            "       1.16331721e-04, 4.83507210e-05, 6.68916327e-05, 1.12487069e-04,\n",
            "       1.14347094e-04, 9.29280795e-05, 6.59848156e-05, 3.35440185e-04,\n",
            "       1.10045723e-04, 6.74588300e-05, 9.75531220e-05, 1.35958529e-04,\n",
            "       1.12279697e-04, 9.53750932e-05, 1.65651538e-04, 7.64877404e-05,\n",
            "       7.87458557e-05, 4.68567232e-05, 9.87703825e-05, 7.48168386e-05,\n",
            "       6.66803971e-05, 1.11790920e-04, 8.23835799e-05, 1.25479826e-04,\n",
            "       7.74325963e-05, 2.17360270e-04, 8.21921494e-05, 6.56278353e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 458, 'shape': array([ 64,   1,   1, 240], dtype=int32), 'shape_signature': array([ 64,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00349043, 0.00407174, 0.00282974, 0.0028586 , 0.00295204,\n",
            "       0.00304646, 0.00554151, 0.00455346, 0.00404378, 0.00156939,\n",
            "       0.00179448, 0.00354669, 0.00325651, 0.00306084, 0.00202545,\n",
            "       0.00357095, 0.00255823, 0.00194345, 0.00336858, 0.00151245,\n",
            "       0.00297373, 0.00176612, 0.00436939, 0.00241883, 0.00164188,\n",
            "       0.00189195, 0.00388272, 0.00463035, 0.00333017, 0.00330877,\n",
            "       0.00498495, 0.00384189, 0.00343271, 0.00186938, 0.00320069,\n",
            "       0.00353364, 0.00362991, 0.00150869, 0.00208722, 0.00350994,\n",
            "       0.00356798, 0.00289964, 0.00205893, 0.01046676, 0.00343376,\n",
            "       0.00210492, 0.00304396, 0.00424232, 0.00350347, 0.002976  ,\n",
            "       0.00516884, 0.00238665, 0.00245711, 0.00146207, 0.00308194,\n",
            "       0.00233452, 0.00208063, 0.00348822, 0.00257062, 0.00391536,\n",
            "       0.00241614, 0.00678231, 0.00256465, 0.00204779], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 459, 'shape': array([120], dtype=int32), 'shape_signature': array([120], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00276922, 0.02985116, 0.00094935, 0.00398681, 0.0065128 ,\n",
            "       0.00434417, 0.00547354, 0.00137821, 0.01407989, 0.02992997,\n",
            "       0.00613887, 0.01469098, 0.0085032 , 0.00769928, 0.00243278,\n",
            "       0.00064985, 0.00311742, 0.00430122, 0.01489159, 0.00580065,\n",
            "       0.00277857, 0.01580473, 0.00359217, 0.0064763 , 0.00135867,\n",
            "       0.00114089, 0.00060606, 0.00618935, 0.01322027, 0.00954629,\n",
            "       0.01647527, 0.00398239, 0.00675689, 0.00073157, 0.01283645,\n",
            "       0.01824421, 0.00107001, 0.01124534, 0.00188284, 0.00396828,\n",
            "       0.000825  , 0.00890207, 0.00769658, 0.01624079, 0.00086251,\n",
            "       0.0015006 , 0.00115193, 0.00104563, 0.00434633, 0.00272578,\n",
            "       0.01803577, 0.00421768, 0.00145474, 0.01068063, 0.01068917,\n",
            "       0.01954534, 0.01149546, 0.01691234, 0.01189806, 0.00307267,\n",
            "       0.00073805, 0.00673582, 0.00738535, 0.00089139, 0.01789517,\n",
            "       0.00100137, 0.0044538 , 0.00069317, 0.00176745, 0.01265371,\n",
            "       0.00470987, 0.0062931 , 0.01103483, 0.0045685 , 0.01624224,\n",
            "       0.00226195, 0.00646172, 0.00086033, 0.00092281, 0.00070769,\n",
            "       0.00137721, 0.00920053, 0.0091184 , 0.00148161, 0.01108324,\n",
            "       0.00415594, 0.00226246, 0.0099132 , 0.0116558 , 0.00294239,\n",
            "       0.00036837, 0.00238549, 0.00293532, 0.00484917, 0.0016716 ,\n",
            "       0.00066214, 0.0028111 , 0.00074624, 0.01248798, 0.00855873,\n",
            "       0.00070147, 0.00069322, 0.00284127, 0.00858409, 0.01267194,\n",
            "       0.00685763, 0.00134196, 0.00765053, 0.00155725, 0.00150859,\n",
            "       0.01388801, 0.0087019 , 0.00046332, 0.00170926, 0.0013709 ,\n",
            "       0.00076831, 0.01599938, 0.01726241, 0.00289973, 0.01166442],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul', 'index': 460, 'shape': array([  1,   3,   1, 120], dtype=int32), 'shape_signature': array([  1,   3,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01988775, 0.21438284, 0.006818  , 0.02863216, 0.04677318,\n",
            "       0.03119864, 0.03930949, 0.00989792, 0.10111792, 0.21494883,\n",
            "       0.04408768, 0.10550661, 0.06106763, 0.0552941 , 0.01747154,\n",
            "       0.00466702, 0.02238842, 0.03089018, 0.10694733, 0.04165871,\n",
            "       0.01995493, 0.11350526, 0.02579799, 0.04651099, 0.00975759,\n",
            "       0.00819353, 0.00435253, 0.0444502 , 0.0949444 , 0.0685588 ,\n",
            "       0.1183209 , 0.02860043, 0.04852613, 0.00525394, 0.09218786,\n",
            "       0.13102491, 0.00768453, 0.08076099, 0.01352204, 0.02849912,\n",
            "       0.00592491, 0.06393225, 0.0552747 , 0.11663689, 0.00619428,\n",
            "       0.01077689, 0.00827283, 0.00750942, 0.03121416, 0.01957579,\n",
            "       0.12952796, 0.03029025, 0.01044758, 0.07670532, 0.07676668,\n",
            "       0.1403693 , 0.08255723, 0.12145981, 0.08544862, 0.02206704,\n",
            "       0.00530049, 0.04837485, 0.05303954, 0.00640169, 0.1285182 ,\n",
            "       0.00719157, 0.03198595, 0.00497814, 0.01269337, 0.09087551,\n",
            "       0.03382499, 0.0451953 , 0.07924915, 0.03280973, 0.11664733,\n",
            "       0.01624467, 0.04640628, 0.00617869, 0.00662735, 0.00508247,\n",
            "       0.00989077, 0.06607567, 0.06548582, 0.01064051, 0.0795968 ,\n",
            "       0.02984681, 0.01624836, 0.0711939 , 0.08370879, 0.02113141,\n",
            "       0.00264551, 0.01713195, 0.02108063, 0.03482542, 0.01200496,\n",
            "       0.0047553 , 0.02018854, 0.00535929, 0.08968525, 0.06146645,\n",
            "       0.00503777, 0.00497854, 0.02040523, 0.0616486 , 0.09100638,\n",
            "       0.0492496 , 0.00963755, 0.05494402, 0.01118371, 0.01083428,\n",
            "       0.09973986, 0.06249468, 0.00332744, 0.01227542, 0.00984541,\n",
            "       0.00551778, 0.11490317, 0.12397391, 0.02082509, 0.08377064],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 461, 'shape': array([120], dtype=int32), 'shape_signature': array([120], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([4.80691716e-03, 1.25906430e-04, 2.06891145e-03, 3.47987888e-03,\n",
            "       3.46576155e-04, 2.42879521e-03, 1.12663081e-03, 4.89590736e-03,\n",
            "       3.63617903e-04, 1.51946605e-03, 3.30165291e-04, 6.33463962e-04,\n",
            "       3.52701230e-04, 1.28298614e-03, 1.14426999e-04, 1.54086470e-03,\n",
            "       6.72165863e-03, 6.28560374e-04, 5.83739347e-05, 6.47475885e-04,\n",
            "       5.69454208e-03, 1.65356998e-03, 2.49967678e-03, 3.16943129e-04,\n",
            "       2.91691860e-04, 4.88015532e-04, 1.30235702e-02, 2.27578054e-03,\n",
            "       2.37964932e-03, 1.29735132e-03, 1.32035115e-04, 5.25152730e-03,\n",
            "       1.76479702e-03, 4.42219171e-04, 1.13760449e-04, 2.33480489e-04,\n",
            "       3.46933003e-03, 1.65224323e-04, 1.13497274e-02, 1.00404641e-03,\n",
            "       5.18984685e-04, 1.44297909e-03, 4.30689106e-04, 1.98102411e-04,\n",
            "       6.33036194e-04, 1.54645753e-03, 1.58217624e-02, 8.71799712e-04,\n",
            "       1.54445251e-03, 1.50207127e-03, 1.67762832e-04, 2.93990644e-03,\n",
            "       5.32576488e-03, 1.18829004e-04, 2.52479163e-04, 8.49825388e-04,\n",
            "       6.06235117e-04, 2.45366216e-04, 4.42734803e-04, 2.79214117e-03,\n",
            "       9.57477605e-04, 3.88645596e-04, 1.94865948e-04, 7.13255198e-04,\n",
            "       5.67808747e-04, 1.08187059e-02, 2.31270771e-03, 4.08044364e-03,\n",
            "       1.13364030e-03, 6.88248919e-03, 4.46452759e-04, 3.59903992e-04,\n",
            "       1.44836691e-03, 6.57029101e-04, 1.78730843e-04, 6.17710827e-03,\n",
            "       1.78268267e-04, 7.85647368e-04, 1.11482223e-03, 2.06658011e-03,\n",
            "       4.59559914e-03, 8.19511246e-03, 1.36107684e-03, 3.38162947e-03,\n",
            "       3.11904051e-03, 1.47825442e-04, 6.51983125e-03, 6.21516141e-04,\n",
            "       4.61344782e-04, 4.04048990e-03, 2.08622718e-04, 1.74109563e-02,\n",
            "       2.02005496e-03, 3.78135708e-04, 2.27799709e-03, 6.88616827e-04,\n",
            "       5.91420243e-03, 5.63952606e-03, 1.42084245e-04, 2.29344791e-04,\n",
            "       1.47378969e-03, 3.07944207e-03, 1.31155655e-03, 7.76776811e-04,\n",
            "       5.06965443e-04, 1.36567955e-03, 6.80943835e-04, 2.09124386e-03,\n",
            "       1.37114455e-03, 2.30827020e-03, 1.81905925e-04, 2.64702921e-05,\n",
            "       8.53316765e-03, 1.31230277e-03, 5.04275085e-04, 3.24834371e-03,\n",
            "       4.20631877e-05, 1.86571514e-03, 5.41752018e-03, 4.80244460e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 462, 'shape': array([  1,   3,   3, 120], dtype=int32), 'shape_signature': array([  1,   3,   3, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.05919673, 0.00155053, 0.02547845, 0.04285438, 0.00426805,\n",
            "       0.02991039, 0.01387435, 0.06029264, 0.00447792, 0.01871208,\n",
            "       0.00406595, 0.00780105, 0.00434348, 0.01579985, 0.00140916,\n",
            "       0.0189756 , 0.0827766 , 0.00774066, 0.00071887, 0.0079736 ,\n",
            "       0.07012776, 0.02036356, 0.03078328, 0.00390312, 0.00359216,\n",
            "       0.00600987, 0.16038404, 0.02802603, 0.02930516, 0.01597676,\n",
            "       0.001626  , 0.06467207, 0.02173331, 0.00544589, 0.00140095,\n",
            "       0.00287529, 0.04272448, 0.00203472, 0.13977084, 0.01236474,\n",
            "       0.00639125, 0.01777015, 0.0053039 , 0.00243961, 0.00779578,\n",
            "       0.01904448, 0.19484352, 0.01073613, 0.01901979, 0.01849787,\n",
            "       0.00206598, 0.03620467, 0.0655863 , 0.00146337, 0.00310926,\n",
            "       0.01046552, 0.00746573, 0.00302166, 0.00545224, 0.03438496,\n",
            "       0.01179125, 0.00478613, 0.00239976, 0.00878367, 0.00699251,\n",
            "       0.13323136, 0.02848078, 0.05025028, 0.01396067, 0.08475721,\n",
            "       0.00549802, 0.00443218, 0.0178365 , 0.00809125, 0.00220105,\n",
            "       0.07607051, 0.00219536, 0.00967517, 0.01372893, 0.02544974,\n",
            "       0.05659438, 0.10092204, 0.01676153, 0.04164445, 0.03841069,\n",
            "       0.00182046, 0.08029111, 0.00765391, 0.00568142, 0.04975826,\n",
            "       0.00256917, 0.2144143 , 0.02487679, 0.00465671, 0.02805332,\n",
            "       0.00848025, 0.07283285, 0.06945024, 0.00174975, 0.00282436,\n",
            "       0.01814958, 0.03792304, 0.0161517 , 0.00956593, 0.00624323,\n",
            "       0.01681822, 0.00838576, 0.02575347, 0.01688552, 0.02842613,\n",
            "       0.00224015, 0.00032598, 0.10508516, 0.01616089, 0.0062101 ,\n",
            "       0.04000305, 0.000518  , 0.02297611, 0.06671625, 0.00591417],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 463, 'shape': array([120], dtype=int32), 'shape_signature': array([120], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.85027291e-04, 1.33301911e-03, 1.19513039e-04, 3.89375709e-05,\n",
            "       1.29634092e-04, 9.85985462e-05, 6.82793267e-04, 7.64395299e-05,\n",
            "       1.62471522e-04, 2.65588693e-04, 3.41167994e-04, 1.18704120e-04,\n",
            "       2.39732995e-04, 5.79708256e-04, 4.18753625e-04, 5.19200577e-04,\n",
            "       4.48083192e-05, 1.34013477e-04, 2.16005225e-04, 3.16943391e-04,\n",
            "       3.20017934e-05, 7.00310993e-05, 6.29733549e-04, 2.61701643e-04,\n",
            "       4.40046162e-04, 7.51522195e-04, 7.15443020e-05, 3.55765282e-04,\n",
            "       5.14390413e-05, 1.03898368e-04, 4.20011551e-04, 9.52377595e-05,\n",
            "       4.68174403e-05, 7.49683415e-04, 5.08397177e-04, 2.75900442e-04,\n",
            "       1.75924375e-04, 6.91782101e-04, 4.15027353e-05, 7.41250988e-04,\n",
            "       6.55531068e-04, 1.31847526e-04, 3.60862847e-04, 3.39185790e-04,\n",
            "       7.04702805e-04, 1.72155269e-04, 1.06663843e-04, 5.34981606e-04,\n",
            "       4.31982538e-04, 5.63819951e-04, 2.09161735e-04, 3.80605270e-05,\n",
            "       1.33899201e-04, 3.84198094e-04, 3.12396325e-04, 3.56261677e-04,\n",
            "       1.70472529e-04, 5.66331910e-05, 7.28512183e-04, 7.89882266e-04,\n",
            "       7.37897528e-04, 1.86704070e-04, 4.73364111e-04, 3.87718581e-04,\n",
            "       6.26628404e-04, 6.22310108e-05, 1.01561360e-04, 3.16744961e-04,\n",
            "       4.09903412e-04, 3.34397373e-05, 1.82680436e-04, 3.37916310e-04,\n",
            "       1.24364771e-04, 3.61031824e-04, 2.22321469e-04, 4.15739087e-05,\n",
            "       2.09619524e-04, 5.35382947e-04, 5.39897243e-04, 1.41338984e-04,\n",
            "       7.85917146e-05, 4.17995034e-05, 7.71770661e-04, 2.60645611e-04,\n",
            "       2.24678060e-05, 5.57636959e-04, 6.38705314e-05, 2.07167584e-04,\n",
            "       2.84270121e-04, 6.36131226e-05, 2.47466407e-04, 4.15700524e-05,\n",
            "       4.59584990e-04, 3.82183236e-04, 1.19654585e-04, 1.65749632e-04,\n",
            "       4.52206441e-05, 1.46050734e-04, 1.70691463e-04, 5.45413059e-04,\n",
            "       4.51776519e-04, 2.37042841e-04, 1.15776238e-04, 3.95943571e-05,\n",
            "       5.78347943e-04, 7.50143197e-04, 1.16174342e-04, 1.01376092e-04,\n",
            "       5.51028410e-04, 1.79533745e-04, 2.82863941e-04, 4.99844144e-04,\n",
            "       2.36479653e-04, 4.59523551e-04, 6.92983449e-04, 1.26109604e-04,\n",
            "       7.21451128e-04, 4.51658707e-04, 4.85164455e-05, 2.71388999e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 464, 'shape': array([120,   1,   1,  40], dtype=int32), 'shape_signature': array([120,   1,   1,  40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([5.52616199e-04, 1.91323564e-03, 1.71532884e-04, 5.58857319e-05,\n",
            "       1.86059275e-04, 1.41515047e-04, 9.79989301e-04, 1.09710985e-04,\n",
            "       2.33189698e-04, 3.81190155e-04, 4.89666476e-04, 1.70371874e-04,\n",
            "       3.44080385e-04, 8.32034973e-04, 6.01022446e-04, 7.45190424e-04,\n",
            "       6.43118110e-05, 1.92344844e-04, 3.10024741e-04, 4.54897759e-04,\n",
            "       4.59310540e-05, 1.00513185e-04, 9.03834531e-04, 3.75611213e-04,\n",
            "       6.31582865e-04, 1.07863348e-03, 1.02685030e-04, 5.10617450e-04,\n",
            "       7.38286544e-05, 1.49121697e-04, 6.02827873e-04, 1.36691422e-04,\n",
            "       6.71954331e-05, 1.07599434e-03, 7.29684660e-04, 3.95990268e-04,\n",
            "       2.52498110e-04, 9.92890680e-04, 5.95674246e-05, 1.06389157e-03,\n",
            "       9.40860773e-04, 1.89236147e-04, 5.17933804e-04, 4.86821489e-04,\n",
            "       1.01143529e-03, 2.47088436e-04, 1.53090878e-04, 7.67840364e-04,\n",
            "       6.20009436e-04, 8.09231075e-04, 3.00202519e-04, 5.46269403e-05,\n",
            "       1.92180843e-04, 5.51426085e-04, 4.48371517e-04, 5.11329912e-04,\n",
            "       2.44673254e-04, 8.12836370e-05, 1.04560808e-03, 1.13369036e-03,\n",
            "       1.05907850e-03, 2.67969823e-04, 6.79402961e-04, 5.56478917e-04,\n",
            "       8.99377803e-04, 8.93179895e-05, 1.45767466e-04, 4.54612949e-04,\n",
            "       5.88320021e-04, 4.79948867e-05, 2.62194837e-04, 4.84999473e-04,\n",
            "       1.78496412e-04, 5.18176355e-04, 3.19090235e-04, 5.96695754e-05,\n",
            "       3.00859567e-04, 7.68416387e-04, 7.74895656e-04, 2.02858893e-04,\n",
            "       1.12799942e-04, 5.99933664e-05, 1.10769540e-03, 3.74095544e-04,\n",
            "       3.22472551e-05, 8.00356793e-04, 9.16711360e-05, 2.97340390e-04,\n",
            "       4.08002961e-04, 9.13016920e-05, 3.55179858e-04, 5.96640421e-05,\n",
            "       6.59626268e-04, 5.48534212e-04, 1.71736043e-04, 2.37894652e-04,\n",
            "       6.49036083e-05, 2.09621503e-04, 2.44987488e-04, 7.82812247e-04,\n",
            "       6.48419023e-04, 3.40219296e-04, 1.66169586e-04, 5.68283976e-05,\n",
            "       8.30082572e-04, 1.07665430e-03, 1.66740967e-04, 1.45501559e-04,\n",
            "       7.90871796e-04, 2.57678505e-04, 4.05984698e-04, 7.17408780e-04,\n",
            "       3.39410966e-04, 6.59538084e-04, 9.94614908e-04, 1.81000694e-04,\n",
            "       1.03547354e-03, 6.48249930e-04, 6.96339557e-05, 3.89515131e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/rezero/mul', 'index': 465, 'shape': array([ 1,  1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.008726373314857483, 127), 'quantization_parameters': {'scales': array([0.00872637], dtype=float32), 'zero_points': array([127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 466, 'shape': array([40], dtype=int32), 'shape_signature': array([40], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00143962, 0.00083445, 0.00154093, 0.0008738 , 0.0007058 ,\n",
            "       0.00079028, 0.00078585, 0.00098462, 0.00147609, 0.00116557,\n",
            "       0.00092288, 0.00116849, 0.00137847, 0.00064165, 0.00116188,\n",
            "       0.00104629, 0.00101367, 0.00096505, 0.00143892, 0.00061459,\n",
            "       0.00119418, 0.00098471, 0.00098368, 0.00122974, 0.00110757,\n",
            "       0.0017849 , 0.00127391, 0.0010976 , 0.00065265, 0.00095532,\n",
            "       0.00129745, 0.00075006, 0.00144207, 0.00103984, 0.0008049 ,\n",
            "       0.00175376, 0.00104686, 0.00153266, 0.00066856, 0.00160017],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 467, 'shape': array([40,  1,  1, 96], dtype=int32), 'shape_signature': array([40,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01879343, 0.01089334, 0.02011603, 0.01140692, 0.00921379,\n",
            "       0.01031668, 0.01025887, 0.01285368, 0.01926956, 0.01521582,\n",
            "       0.01204773, 0.01525403, 0.01799521, 0.00837635, 0.01516766,\n",
            "       0.0136587 , 0.01323293, 0.0125982 , 0.01878424, 0.00802315,\n",
            "       0.01558933, 0.01285478, 0.01284143, 0.01605362, 0.01445877,\n",
            "       0.02330093, 0.01663019, 0.01432856, 0.00852001, 0.01247112,\n",
            "       0.01693754, 0.00979165, 0.01882542, 0.01357454, 0.01050755,\n",
            "       0.0228944 , 0.01366616, 0.02000808, 0.00872765, 0.0208893 ],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 468, 'shape': array([96], dtype=int32), 'shape_signature': array([96], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.6456270e-05, 1.8295146e-05, 1.2614919e-05, 2.0763549e-05,\n",
            "       2.6652957e-05, 1.6421303e-05, 2.8508275e-05, 2.7359227e-05,\n",
            "       1.8635177e-05, 1.8127756e-05, 2.5320865e-05, 1.3283124e-05,\n",
            "       4.7326117e-05, 1.3851521e-05, 1.2147743e-05, 2.0012341e-05,\n",
            "       2.8099588e-05, 2.6165317e-05, 3.5266516e-05, 4.9793845e-05,\n",
            "       3.5062534e-05, 3.6859419e-05, 5.4488526e-05, 2.5635803e-05,\n",
            "       2.4454406e-05, 2.1616663e-05, 2.4306779e-05, 2.4919986e-05,\n",
            "       2.0726568e-05, 2.3842380e-05, 1.0748086e-05, 1.2605083e-05,\n",
            "       2.9396577e-05, 2.9864275e-05, 3.5797686e-05, 2.5306485e-05,\n",
            "       2.2477421e-05, 2.3260754e-05, 2.5817519e-05, 5.9092436e-05,\n",
            "       2.1988531e-05, 2.9796833e-05, 3.1241336e-05, 3.0753850e-05,\n",
            "       2.1328002e-05, 2.0580885e-05, 3.8061349e-05, 1.7869175e-05,\n",
            "       2.3374309e-05, 1.6779088e-05, 1.8702196e-05, 2.5354186e-05,\n",
            "       2.1723110e-05, 2.3601402e-05, 2.6446456e-05, 3.5163608e-05,\n",
            "       2.4832176e-05, 2.3148970e-05, 2.6309926e-05, 2.7149550e-05,\n",
            "       2.5639440e-05, 1.2636821e-05, 1.9267985e-05, 2.2360675e-05,\n",
            "       2.9961173e-05, 3.9546248e-05, 1.6021717e-05, 1.8647512e-05,\n",
            "       1.8600160e-05, 1.4897779e-05, 4.5214310e-05, 1.8204866e-05,\n",
            "       2.5809395e-05, 2.9916993e-05, 3.1342490e-05, 4.9893923e-05,\n",
            "       2.7567494e-05, 2.4176876e-05, 3.6659250e-05, 2.0746875e-05,\n",
            "       1.7379316e-05, 1.7941824e-05, 2.2655100e-05, 3.5125566e-05,\n",
            "       1.4990975e-05, 1.7092718e-05, 3.7170703e-05, 2.3031289e-05,\n",
            "       2.8792854e-05, 2.7933840e-05, 2.0987756e-05, 2.0129994e-05,\n",
            "       2.0167794e-05, 1.7114007e-05, 1.0849701e-05, 1.6448626e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 469, 'shape': array([96,  1,  1, 48], dtype=int32), 'shape_signature': array([96,  1,  1, 48], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00130656, 0.00145255, 0.00100157, 0.00164853, 0.00211613,\n",
            "       0.00130378, 0.00226343, 0.0021722 , 0.00147955, 0.00143926,\n",
            "       0.00201036, 0.00105462, 0.00375748, 0.00109975, 0.00096448,\n",
            "       0.00158889, 0.00223098, 0.00207741, 0.00280001, 0.00395341,\n",
            "       0.00278381, 0.00292647, 0.00432615, 0.00203537, 0.00194157,\n",
            "       0.00171627, 0.00192985, 0.00197854, 0.0016456 , 0.00189298,\n",
            "       0.00085335, 0.00100079, 0.00233396, 0.00237109, 0.00284218,\n",
            "       0.00200922, 0.00178461, 0.0018468 , 0.0020498 , 0.00469168,\n",
            "       0.00174579, 0.00236574, 0.00248042, 0.00244172, 0.00169335,\n",
            "       0.00163403, 0.0030219 , 0.00141873, 0.00185582, 0.00133219,\n",
            "       0.00148487, 0.00201301, 0.00172472, 0.00187385, 0.00209973,\n",
            "       0.00279183, 0.00197156, 0.00183793, 0.00208889, 0.00215555,\n",
            "       0.00203566, 0.00100331, 0.00152979, 0.00177534, 0.00237878,\n",
            "       0.0031398 , 0.00127205, 0.00148053, 0.00147677, 0.00118282,\n",
            "       0.00358982, 0.00144539, 0.00204915, 0.00237528, 0.00248846,\n",
            "       0.00396136, 0.00218874, 0.00191954, 0.00291058, 0.00164721,\n",
            "       0.00137984, 0.0014245 , 0.00179871, 0.00278881, 0.00119022,\n",
            "       0.00135709, 0.00295119, 0.00182858, 0.00228603, 0.00221782,\n",
            "       0.00166634, 0.00159823, 0.00160123, 0.00135878, 0.00086142,\n",
            "       0.00130595], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 470, 'shape': array([48], dtype=int32), 'shape_signature': array([48], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.4951612e-05, 2.5864691e-05, 2.3285231e-05, 4.3925349e-05,\n",
            "       5.5393069e-05, 3.3270429e-05, 5.6547990e-05, 4.1315896e-05,\n",
            "       6.3202933e-05, 4.8557122e-05, 4.3372875e-05, 7.5574346e-05,\n",
            "       1.1697483e-04, 3.5404537e-05, 4.3014254e-05, 3.7538648e-05,\n",
            "       4.7941590e-05, 4.6149551e-05, 5.1729119e-05, 2.5419660e-05,\n",
            "       5.2916268e-05, 4.8915328e-05, 3.0131816e-05, 2.8768882e-05,\n",
            "       4.2332722e-05, 7.5647535e-05, 6.3359388e-05, 2.3728277e-05,\n",
            "       9.9916499e-05, 5.0735067e-05, 2.4419031e-05, 6.3562504e-05,\n",
            "       2.3987597e-05, 3.8660430e-05, 2.6631866e-05, 8.4126485e-05,\n",
            "       3.4310731e-05, 6.7596637e-05, 6.3547377e-05, 3.9334263e-05,\n",
            "       5.4860604e-05, 4.4465425e-05, 2.7114886e-05, 5.6245433e-05,\n",
            "       3.6573216e-05, 5.4948781e-05, 3.4390792e-05, 4.9283666e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 471, 'shape': array([ 48,   1,   1, 192], dtype=int32), 'shape_signature': array([ 48,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00123412, 0.00127929, 0.0011517 , 0.00217258, 0.00273978,\n",
            "       0.00164558, 0.0027969 , 0.00204351, 0.00312606, 0.00240167,\n",
            "       0.00214525, 0.00373796, 0.00578566, 0.00175113, 0.00212752,\n",
            "       0.00185669, 0.00237123, 0.00228259, 0.00255856, 0.00125727,\n",
            "       0.00261728, 0.00241939, 0.00149034, 0.00142293, 0.00209381,\n",
            "       0.00374158, 0.0031338 , 0.00117362, 0.00494194, 0.00250939,\n",
            "       0.00120778, 0.00314385, 0.00118644, 0.00191217, 0.00131723,\n",
            "       0.00416096, 0.00169703, 0.00334338, 0.0031431 , 0.0019455 ,\n",
            "       0.00271345, 0.00219929, 0.00134112, 0.00278194, 0.00180894,\n",
            "       0.00271781, 0.00170099, 0.00243761], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 472, 'shape': array([96], dtype=int32), 'shape_signature': array([96], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01584223, 0.01482737, 0.00051475, 0.03836236, 0.01234001,\n",
            "       0.01788919, 0.00074606, 0.00411167, 0.01380067, 0.00568973,\n",
            "       0.00071827, 0.00804121, 0.00080966, 0.0165095 , 0.00875622,\n",
            "       0.00207537, 0.03155525, 0.01261902, 0.01569572, 0.00212383,\n",
            "       0.00078674, 0.00709561, 0.00175478, 0.02630508, 0.00232925,\n",
            "       0.00750531, 0.00349379, 0.00258887, 0.00152799, 0.00150959,\n",
            "       0.00335987, 0.01635231, 0.02626415, 0.00060889, 0.00905544,\n",
            "       0.02955249, 0.0030697 , 0.02473454, 0.03600647, 0.0006495 ,\n",
            "       0.00195769, 0.00101402, 0.00811314, 0.00296941, 0.01421593,\n",
            "       0.00105486, 0.01296707, 0.00534581, 0.0129793 , 0.00111591,\n",
            "       0.01630559, 0.01184288, 0.03137971, 0.00116832, 0.02750199,\n",
            "       0.0160392 , 0.02646279, 0.00665215, 0.00500927, 0.02138206,\n",
            "       0.01599027, 0.00125405, 0.00146816, 0.00449972, 0.00198106,\n",
            "       0.02935614, 0.01853163, 0.01973669, 0.01859523, 0.00123568,\n",
            "       0.01871579, 0.03323145, 0.01995875, 0.0090675 , 0.00833573,\n",
            "       0.00188943, 0.00080034, 0.02739708, 0.00136282, 0.00138049,\n",
            "       0.00172852, 0.00718488, 0.00082531, 0.0011804 , 0.01061869,\n",
            "       0.0016051 , 0.01038273, 0.00924776, 0.00086562, 0.02886403,\n",
            "       0.00631538, 0.01675795, 0.00120655, 0.00674939, 0.00119184,\n",
            "       0.02900424], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul', 'index': 473, 'shape': array([ 1,  3,  1, 96], dtype=int32), 'shape_signature': array([ 1,  3,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.11672803, 0.10925032, 0.00379276, 0.28265977, 0.09092308,\n",
            "       0.1318103 , 0.00549712, 0.0302954 , 0.10168546, 0.04192279,\n",
            "       0.00529234, 0.0592489 , 0.00596567, 0.12164459, 0.06451716,\n",
            "       0.01529163, 0.23250398, 0.09297887, 0.11564848, 0.0156487 ,\n",
            "       0.00579679, 0.05228154, 0.01292951, 0.19381988, 0.01716225,\n",
            "       0.05530025, 0.02574282, 0.0190752 , 0.01125848, 0.01112291,\n",
            "       0.02475606, 0.12048635, 0.19351833, 0.00448643, 0.06672188,\n",
            "       0.21774732, 0.022618  , 0.18224789, 0.2653012 , 0.00478561,\n",
            "       0.01442457, 0.00747147, 0.05977889, 0.02187905, 0.10474518,\n",
            "       0.00777237, 0.09554338, 0.03938876, 0.0956335 , 0.00822221,\n",
            "       0.12014213, 0.08726019, 0.23121054, 0.00860835, 0.20263894,\n",
            "       0.11817934, 0.19498192, 0.04901409, 0.03690911, 0.1575463 ,\n",
            "       0.1178188 , 0.00924005, 0.01081766, 0.03315463, 0.01459674,\n",
            "       0.21630059, 0.13654391, 0.14542298, 0.13701251, 0.00910466,\n",
            "       0.13790081, 0.24485447, 0.14705914, 0.06681072, 0.06141895,\n",
            "       0.01392161, 0.00589703, 0.20186594, 0.01004146, 0.01017163,\n",
            "       0.01273599, 0.05293931, 0.006081  , 0.00869733, 0.07824014,\n",
            "       0.01182663, 0.07650159, 0.0681389 , 0.00637805, 0.2126746 ,\n",
            "       0.04653272, 0.12347515, 0.00889003, 0.04973054, 0.00878167,\n",
            "       0.21370773], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/skip/skip_project/conv2d/bn/FusedBatchNormV3', 'index': 474, 'shape': array([40], dtype=int32), 'shape_signature': array([40], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([6.9475682e-03, 5.5192397e-03, 5.1957538e-04, 2.5724513e-03,\n",
            "       5.3778482e-03, 8.6029398e-04, 3.6564388e-03, 4.6365671e-03,\n",
            "       1.1027164e-03, 4.5102364e-03, 1.8511241e-03, 3.9223084e-04,\n",
            "       3.7696250e-03, 3.3016659e-03, 2.5853179e-03, 4.5510964e-03,\n",
            "       3.2292178e-03, 2.4765155e-03, 3.5414597e-04, 1.7713866e-03,\n",
            "       1.8098335e-03, 6.5171544e-04, 3.2385697e-03, 4.0412164e-05,\n",
            "       3.5718083e-03, 7.1856583e-04, 7.4277975e-04, 3.2820336e-03,\n",
            "       1.1570036e-03, 4.2111096e-03, 2.8415073e-03, 2.2894170e-03,\n",
            "       2.5226397e-03, 6.9872773e-04, 2.4979033e-03, 1.7209823e-05,\n",
            "       4.3953992e-03, 5.4835947e-04, 4.0756669e-03, 1.2428038e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/skip/skip_project/conv2d/conv2d_4/Conv2D', 'index': 475, 'shape': array([40,  1,  1, 16], dtype=int32), 'shape_signature': array([40,  1,  1, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([6.0785562e-03, 4.8288852e-03, 4.5458614e-04, 2.2506854e-03,\n",
            "       4.7051790e-03, 7.5268716e-04, 3.1990861e-03, 4.0566185e-03,\n",
            "       9.6478709e-04, 3.9460897e-03, 1.6195829e-03, 3.4317005e-04,\n",
            "       3.2981148e-03, 2.8886888e-03, 2.2619427e-03, 3.9818385e-03,\n",
            "       2.8253025e-03, 2.1667494e-03, 3.0984890e-04, 1.5498190e-03,\n",
            "       1.5834569e-03, 5.7019794e-04, 2.8334847e-03, 3.5357352e-05,\n",
            "       3.1250415e-03, 6.2868657e-04, 6.4987177e-04, 2.8715122e-03,\n",
            "       1.0122838e-03, 3.6843778e-03, 2.4860874e-03, 2.0030534e-03,\n",
            "       2.2071043e-03, 6.1132986e-04, 2.1854620e-03, 1.5057193e-05,\n",
            "       3.8456165e-03, 4.7976986e-04, 3.5658765e-03, 1.0873521e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 476, 'shape': array([96], dtype=int32), 'shape_signature': array([96], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.90691819e-04, 1.38165662e-04, 2.82324548e-03, 1.98557740e-03,\n",
            "       5.53683436e-04, 1.73208493e-04, 4.44775826e-04, 2.16527819e-03,\n",
            "       9.92835034e-04, 1.73835782e-03, 3.40204942e-03, 2.71635305e-04,\n",
            "       2.35758140e-04, 1.82460251e-04, 5.19498892e-04, 1.31634146e-03,\n",
            "       1.89977698e-03, 3.41591449e-03, 1.91139523e-04, 1.20985787e-03,\n",
            "       3.63158435e-03, 8.82152875e-04, 3.21553089e-04, 3.24685680e-04,\n",
            "       1.02638984e-02, 3.52592528e-04, 2.52241647e-04, 1.56763615e-03,\n",
            "       1.11579029e-02, 5.00267977e-03, 8.59403692e-04, 4.22664307e-04,\n",
            "       1.63994511e-04, 2.24326868e-02, 1.31402150e-04, 2.51010922e-03,\n",
            "       3.78499652e-04, 1.16343040e-03, 1.38887309e-03, 3.38743161e-03,\n",
            "       8.62579420e-03, 2.70106830e-03, 2.51802063e-04, 2.08388153e-03,\n",
            "       1.84616947e-03, 3.55134741e-03, 1.63107819e-04, 1.17223361e-03,\n",
            "       1.71215666e-04, 2.34444253e-03, 5.25094045e-04, 4.26625280e-04,\n",
            "       1.08785600e-04, 7.24920537e-03, 1.75620022e-04, 3.03915091e-04,\n",
            "       2.41551592e-04, 6.16673206e-04, 3.32836498e-04, 2.41638991e-04,\n",
            "       1.50739812e-04, 1.45766803e-03, 4.85185906e-03, 5.48169774e-04,\n",
            "       6.61688566e-04, 1.66291735e-04, 1.72749409e-04, 4.81337728e-03,\n",
            "       4.80473158e-04, 1.65889901e-03, 1.11908856e-04, 6.28718553e-05,\n",
            "       5.85741643e-03, 2.34003252e-04, 9.99303535e-04, 3.65236861e-04,\n",
            "       1.45999773e-03, 1.02568523e-03, 1.76561903e-03, 5.27185667e-03,\n",
            "       6.25634158e-04, 4.82067990e-04, 3.25891972e-02, 5.04772353e-04,\n",
            "       4.08901542e-04, 8.30833614e-03, 8.48308147e-04, 5.74021426e-04,\n",
            "       1.76124636e-03, 1.94863824e-03, 1.05245772e-03, 2.56632268e-03,\n",
            "       9.42014903e-03, 3.11666925e-04, 1.21325320e-02, 1.29409513e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 477, 'shape': array([ 1,  3,  3, 96], dtype=int32), 'shape_signature': array([ 1,  3,  3, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.0014428 , 0.00104538, 0.021361  , 0.01502311, 0.00418923,\n",
            "       0.00131052, 0.00336523, 0.01638274, 0.0075119 , 0.01315262,\n",
            "       0.0257403 , 0.00205522, 0.00178377, 0.00138052, 0.00393059,\n",
            "       0.00995959, 0.01437393, 0.0258452 , 0.00144618, 0.00915392,\n",
            "       0.02747699, 0.00667447, 0.00243291, 0.00245661, 0.07765784,\n",
            "       0.00266776, 0.00190849, 0.01186092, 0.08442198, 0.03785085,\n",
            "       0.00650235, 0.00319793, 0.0012408 , 0.1697283 , 0.0009942 ,\n",
            "       0.01899178, 0.00286377, 0.00880265, 0.01050837, 0.0256297 ,\n",
            "       0.06526376, 0.02043659, 0.00190516, 0.01576689, 0.01396833,\n",
            "       0.0268699 , 0.00123409, 0.00886925, 0.00129544, 0.01773832,\n",
            "       0.00397292, 0.0032279 , 0.00082308, 0.05484832, 0.00132876,\n",
            "       0.00229946, 0.00182761, 0.00466582, 0.00251828, 0.00182827,\n",
            "       0.00114051, 0.01102888, 0.03670973, 0.00414752, 0.00500641,\n",
            "       0.00125818, 0.00130704, 0.03641857, 0.00363532, 0.01255142,\n",
            "       0.00084672, 0.0004757 , 0.04431789, 0.0017705 , 0.00756085,\n",
            "       0.00276342, 0.01104651, 0.00776045, 0.01335888, 0.03988748,\n",
            "       0.00473362, 0.00364738, 0.24657364, 0.00381917, 0.0030938 ,\n",
            "       0.06286183, 0.0064184 , 0.00434311, 0.01332579, 0.01474362,\n",
            "       0.00796302, 0.01941709, 0.07127394, 0.00235811, 0.09179614,\n",
            "       0.00097913], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 478, 'shape': array([96], dtype=int32), 'shape_signature': array([96], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.2465828e-03, 1.7384098e-04, 2.5013174e-04, 2.1589100e-05,\n",
            "       4.7655695e-04, 6.2366464e-04, 9.0460962e-04, 7.8954377e-05,\n",
            "       1.3517877e-04, 7.1721217e-05, 2.9784025e-04, 7.1976997e-04,\n",
            "       1.2044556e-03, 5.3284626e-04, 2.7895346e-04, 4.1187755e-04,\n",
            "       5.2131283e-05, 5.6166693e-05, 1.3143512e-03, 2.5352745e-04,\n",
            "       3.4479241e-04, 1.9481620e-04, 6.3359592e-04, 1.0055515e-03,\n",
            "       4.9086662e-05, 2.5538451e-04, 1.0575373e-03, 4.5924319e-04,\n",
            "       1.5583109e-04, 2.3932075e-04, 1.4484758e-04, 2.7986910e-04,\n",
            "       2.3678194e-04, 5.9971520e-05, 9.1515057e-04, 1.0958688e-04,\n",
            "       4.3940663e-04, 7.7185498e-05, 2.9124354e-05, 1.2658080e-04,\n",
            "       9.8166121e-05, 4.3672626e-04, 2.3597326e-04, 5.1710010e-04,\n",
            "       1.2556423e-04, 1.9272516e-04, 3.0110247e-04, 9.8077158e-05,\n",
            "       2.0536110e-04, 3.8332850e-04, 2.0265375e-04, 8.0997171e-04,\n",
            "       3.7638185e-04, 1.6672281e-04, 8.7071428e-05, 4.2763446e-04,\n",
            "       4.1852231e-04, 1.0409160e-04, 1.1349578e-03, 9.2915834e-05,\n",
            "       3.8287445e-04, 2.6865755e-04, 8.8065535e-05, 4.8909837e-04,\n",
            "       9.6579164e-04, 2.7785619e-04, 6.6048879e-04, 4.0080067e-05,\n",
            "       1.5414396e-04, 3.3572430e-04, 5.4851040e-04, 4.8009955e-04,\n",
            "       1.7414038e-04, 6.9286174e-04, 7.5313190e-05, 7.8654767e-04,\n",
            "       6.3721125e-04, 5.4676140e-05, 1.2325928e-04, 1.8917739e-04,\n",
            "       5.3125340e-04, 2.2716136e-04, 3.8175996e-05, 5.1244895e-04,\n",
            "       3.5581170e-04, 1.0794591e-04, 1.2764271e-04, 2.4572739e-04,\n",
            "       4.4377436e-04, 5.4479384e-05, 2.0299127e-04, 4.2569456e-05,\n",
            "       1.4521768e-04, 3.1327613e-04, 9.4468895e-05, 4.0037365e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 479, 'shape': array([96,  1,  1, 16], dtype=int32), 'shape_signature': array([96,  1,  1, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.09065848e-03, 1.52096691e-04, 2.18844900e-04, 1.88887043e-05,\n",
            "       4.16948518e-04, 5.45655785e-04, 7.91459752e-04, 6.90786474e-05,\n",
            "       1.18270415e-04, 6.27502232e-05, 2.60585948e-04, 6.29740127e-04,\n",
            "       1.05380057e-03, 4.66197089e-04, 2.44061550e-04, 3.60359321e-04,\n",
            "       4.56106281e-05, 4.91412829e-05, 1.14995032e-03, 2.21815862e-04,\n",
            "       3.01665277e-04, 1.70448300e-04, 5.54344850e-04, 8.79775675e-04,\n",
            "       4.29468309e-05, 2.23440642e-04, 9.25258966e-04, 4.01800382e-04,\n",
            "       1.36339513e-04, 2.09386169e-04, 1.26729836e-04, 2.44862662e-04,\n",
            "       2.07164907e-04, 5.24701973e-05, 8.00682232e-04, 9.58795936e-05,\n",
            "       3.84445011e-04, 6.75310221e-05, 2.54814386e-05, 1.10747889e-04,\n",
            "       8.58873609e-05, 3.82099912e-04, 2.06457378e-04, 4.52420471e-04,\n",
            "       1.09858476e-04, 1.68618819e-04, 2.63440132e-04, 8.58095227e-05,\n",
            "       1.79674229e-04, 3.35381221e-04, 1.77305526e-04, 7.08659296e-04,\n",
            "       3.29303468e-04, 1.45868878e-04, 7.61804113e-05, 3.74145311e-04,\n",
            "       3.66172928e-04, 9.10716772e-05, 9.92995570e-04, 8.12937869e-05,\n",
            "       3.34983954e-04, 2.35053478e-04, 7.70501720e-05, 4.27921244e-04,\n",
            "       8.44989030e-04, 2.43101531e-04, 5.77873900e-04, 3.50667942e-05,\n",
            "       1.34863410e-04, 2.93731428e-04, 4.79901908e-04, 4.20048018e-04,\n",
            "       1.52358654e-04, 6.06197573e-04, 6.58929057e-05, 6.88165135e-04,\n",
            "       5.57507970e-04, 4.78371694e-05, 1.07841828e-04, 1.65514808e-04,\n",
            "       4.64803481e-04, 1.98747686e-04, 3.34008873e-05, 4.48351115e-04,\n",
            "       3.11306270e-04, 9.44438798e-05, 1.11676971e-04, 2.14991451e-04,\n",
            "       3.88266431e-04, 4.76650239e-05, 1.77600828e-04, 3.72448085e-05,\n",
            "       1.27053645e-04, 2.74091115e-04, 8.26525866e-05, 3.50294344e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/rezero/mul', 'index': 480, 'shape': array([ 1,  1, 43, 43, 16], dtype=int32), 'shape_signature': array([ 1,  1, 43, 43, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.008756594732403755, -128), 'quantization_parameters': {'scales': array([0.00875659], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 481, 'shape': array([16], dtype=int32), 'shape_signature': array([16], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00131471, 0.00192485, 0.00084038, 0.00130651, 0.00246682,\n",
            "       0.00161789, 0.00183929, 0.00136528, 0.00223159, 0.00160521,\n",
            "       0.00226679, 0.00183563, 0.0012787 , 0.00181517, 0.00168424,\n",
            "       0.00125054], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 482, 'shape': array([16,  1,  1, 64], dtype=int32), 'shape_signature': array([16,  1,  1, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.02490794, 0.03646731, 0.01592147, 0.02475253, 0.04673524,\n",
            "       0.03065178, 0.0348464 , 0.02586593, 0.04227863, 0.03041163,\n",
            "       0.04294549, 0.03477694, 0.02422566, 0.03438941, 0.03190891,\n",
            "       0.02369224], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 483, 'shape': array([64], dtype=int32), 'shape_signature': array([64], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([7.89006936e-06, 2.62800968e-05, 1.55381931e-05, 1.18314892e-05,\n",
            "       1.34647544e-05, 9.10889412e-06, 4.12309928e-05, 1.27996063e-05,\n",
            "       7.98804558e-06, 1.35706505e-05, 2.27538658e-05, 1.21149433e-05,\n",
            "       1.11568406e-05, 2.58813070e-05, 2.68919975e-05, 6.17108299e-06,\n",
            "       1.61339522e-05, 2.82189922e-05, 1.18262433e-05, 7.63339995e-06,\n",
            "       1.61619846e-05, 2.56230505e-05, 1.89297389e-05, 3.73647126e-05,\n",
            "       2.14869124e-05, 2.48747183e-05, 1.88008289e-05, 3.67737266e-05,\n",
            "       1.53594774e-05, 1.51957320e-05, 1.68058268e-05, 2.81444100e-05,\n",
            "       1.67157614e-05, 1.80946117e-05, 8.73203771e-06, 1.03010807e-05,\n",
            "       1.00778525e-05, 1.93249016e-05, 1.76842750e-05, 1.30769495e-05,\n",
            "       8.09427820e-06, 3.06541442e-05, 2.18006044e-05, 7.56985219e-06,\n",
            "       3.02833705e-05, 2.10439266e-05, 3.18997481e-05, 1.03789107e-05,\n",
            "       2.39302553e-05, 2.39347901e-05, 2.83883383e-05, 1.27483518e-05,\n",
            "       1.50551314e-05, 7.33654360e-06, 2.83199242e-05, 2.55815430e-05,\n",
            "       1.51732420e-05, 2.65001981e-05, 1.74456800e-05, 7.65728691e-06,\n",
            "       1.31775014e-05, 1.24181652e-05, 1.56364622e-05, 1.48524641e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 484, 'shape': array([64,  1,  1, 32], dtype=int32), 'shape_signature': array([64,  1,  1, 32], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00113901, 0.00379379, 0.00224309, 0.00170799, 0.00194377,\n",
            "       0.00131496, 0.00595209, 0.00184775, 0.00115315, 0.00195905,\n",
            "       0.00328474, 0.00174891, 0.0016106 , 0.00373622, 0.00388212,\n",
            "       0.00089086, 0.00232909, 0.00407368, 0.00170723, 0.00110196,\n",
            "       0.00233314, 0.00369894, 0.00273269, 0.00539396, 0.00310184,\n",
            "       0.00359091, 0.00271408, 0.00530864, 0.00221729, 0.00219365,\n",
            "       0.00242608, 0.00406292, 0.00241308, 0.00261213, 0.00126055,\n",
            "       0.00148706, 0.00145484, 0.00278974, 0.0025529 , 0.00188778,\n",
            "       0.00116849, 0.00442522, 0.00314713, 0.00109278, 0.0043717 ,\n",
            "       0.00303789, 0.00460504, 0.0014983 , 0.00345456, 0.00345522,\n",
            "       0.00409813, 0.00184035, 0.00217335, 0.0010591 , 0.00408825,\n",
            "       0.00369294, 0.0021904 , 0.00382556, 0.00251845, 0.0011054 ,\n",
            "       0.0019023 , 0.00179268, 0.00225727, 0.0021441 ], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 485, 'shape': array([32], dtype=int32), 'shape_signature': array([32], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.2837019e-05, 4.5278433e-05, 1.5900707e-05, 2.0657120e-05,\n",
            "       4.0058632e-05, 3.1599520e-05, 3.4411125e-05, 3.2714674e-05,\n",
            "       4.5983823e-05, 5.8305406e-05, 1.3830173e-05, 3.1960502e-05,\n",
            "       2.1236461e-05, 2.5187732e-05, 3.8994796e-05, 3.7324869e-05,\n",
            "       3.6289388e-05, 1.6284164e-05, 3.2445616e-05, 3.0423394e-05,\n",
            "       2.4777808e-05, 4.5427365e-05, 4.8239763e-05, 4.0608524e-05,\n",
            "       3.4392258e-05, 3.9532959e-05, 2.4035495e-05, 2.5934834e-05,\n",
            "       2.0817743e-05, 2.6623336e-05, 2.3238863e-05, 2.4362618e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 486, 'shape': array([ 32,   1,   1, 128], dtype=int32), 'shape_signature': array([ 32,   1,   1, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00323288, 0.00445777, 0.00156546, 0.00203374, 0.00394387,\n",
            "       0.00311105, 0.00338786, 0.00322084, 0.00452722, 0.00574031,\n",
            "       0.00136161, 0.00314659, 0.00209078, 0.00247979, 0.00383913,\n",
            "       0.00367472, 0.00357278, 0.00160321, 0.00319435, 0.00299526,\n",
            "       0.00243943, 0.00447243, 0.00474932, 0.00399801, 0.003386  ,\n",
            "       0.00389211, 0.00236635, 0.00255335, 0.00204956, 0.00262113,\n",
            "       0.00228792, 0.00239856], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 487, 'shape': array([64], dtype=int32), 'shape_signature': array([64], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00112473, 0.01933867, 0.00055531, 0.02973698, 0.00840774,\n",
            "       0.01186035, 0.00067432, 0.00255478, 0.00978346, 0.00452839,\n",
            "       0.00935924, 0.01676828, 0.00214445, 0.00420663, 0.00241687,\n",
            "       0.00876914, 0.01863336, 0.00336102, 0.01755923, 0.00491683,\n",
            "       0.00128432, 0.00355962, 0.00594325, 0.01941912, 0.00125864,\n",
            "       0.0472757 , 0.01105631, 0.01491895, 0.00059172, 0.00363397,\n",
            "       0.0214176 , 0.0019333 , 0.00049078, 0.00094242, 0.00790601,\n",
            "       0.00147188, 0.03416998, 0.00326862, 0.00126198, 0.01008906,\n",
            "       0.00109227, 0.00351063, 0.00178293, 0.00224558, 0.01349567,\n",
            "       0.00211887, 0.00802926, 0.02462733, 0.0011512 , 0.00527809,\n",
            "       0.00731377, 0.00506787, 0.00232678, 0.01233069, 0.00228273,\n",
            "       0.00475008, 0.00198059, 0.0008494 , 0.00164824, 0.00935827,\n",
            "       0.00298404, 0.00114734, 0.012845  , 0.0076713 ], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul', 'index': 488, 'shape': array([ 1,  3,  1, 64], dtype=int32), 'shape_signature': array([ 1,  3,  1, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00541218, 0.09305752, 0.00267216, 0.1430941 , 0.04045795,\n",
            "       0.05707188, 0.00324481, 0.01229357, 0.04707792, 0.02179055,\n",
            "       0.04503657, 0.08068879, 0.0103191 , 0.02024228, 0.01162994,\n",
            "       0.04219701, 0.08966355, 0.01617318, 0.08449487, 0.02365976,\n",
            "       0.00618014, 0.01712885, 0.02859885, 0.09344462, 0.00605656,\n",
            "       0.22749025, 0.05320288, 0.07178987, 0.00284733, 0.01748664,\n",
            "       0.10306132, 0.009303  , 0.00236161, 0.00453492, 0.03804366,\n",
            "       0.00708269, 0.16442564, 0.01572855, 0.00607265, 0.04854845,\n",
            "       0.005256  , 0.01689311, 0.00857945, 0.01080572, 0.06494102,\n",
            "       0.01019597, 0.03863674, 0.1185065 , 0.00553954, 0.02539812,\n",
            "       0.0351938 , 0.02438654, 0.01119644, 0.05933516, 0.01098446,\n",
            "       0.02285733, 0.00953056, 0.00408733, 0.00793132, 0.04503192,\n",
            "       0.01435917, 0.00552097, 0.06181   , 0.03691423], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 489, 'shape': array([64], dtype=int32), 'shape_signature': array([64], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([9.93786380e-04, 1.20644014e-04, 1.48489131e-02, 2.01943959e-03,\n",
            "       9.80690774e-03, 3.43582251e-05, 9.48624918e-04, 4.19714110e-04,\n",
            "       1.07534451e-03, 1.36595673e-03, 7.51584128e-04, 3.29743576e-04,\n",
            "       2.25769822e-03, 1.29372661e-03, 2.27295584e-03, 2.83491844e-03,\n",
            "       4.40108730e-03, 1.33017800e-03, 2.83195375e-04, 1.24422112e-03,\n",
            "       2.57224799e-03, 8.36492574e-04, 2.95370724e-03, 5.43097849e-04,\n",
            "       4.54914849e-03, 2.16749636e-03, 3.76897573e-04, 7.33197230e-05,\n",
            "       2.85437773e-03, 4.62638307e-03, 1.84648670e-04, 3.32396594e-04,\n",
            "       1.68761273e-03, 1.88197731e-03, 1.85909297e-03, 4.37193271e-03,\n",
            "       9.86841274e-04, 5.90404088e-04, 2.93121696e-03, 7.64572003e-04,\n",
            "       1.17002451e-03, 1.47043467e-02, 5.10019856e-03, 1.01890042e-03,\n",
            "       1.36495320e-04, 1.92603411e-03, 1.89639151e-03, 2.38879220e-04,\n",
            "       6.46316737e-04, 1.53610427e-02, 7.14973954e-04, 2.05229199e-03,\n",
            "       8.74498161e-04, 5.77998813e-04, 2.46804697e-03, 9.30236827e-04,\n",
            "       1.11014964e-02, 1.15292836e-02, 3.14843543e-02, 1.96698689e-04,\n",
            "       8.14994215e-04, 7.24779861e-03, 1.14142153e-04, 1.81052054e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 490, 'shape': array([ 1,  3,  3, 64], dtype=int32), 'shape_signature': array([ 1,  3,  3, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00859567, 0.0010435 , 0.12843446, 0.01746698, 0.08482406,\n",
            "       0.00029718, 0.00820505, 0.00363028, 0.0093011 , 0.01181473,\n",
            "       0.00650077, 0.00285209, 0.01952778, 0.01118998, 0.01965975,\n",
            "       0.0245204 , 0.03806685, 0.01150527, 0.00244948, 0.01076179,\n",
            "       0.02224845, 0.00723517, 0.02554785, 0.00469748, 0.03934749,\n",
            "       0.01874758, 0.00325994, 0.00063417, 0.02468871, 0.04001553,\n",
            "       0.0015971 , 0.00287504, 0.01459687, 0.01627801, 0.01608007,\n",
            "       0.03781468, 0.0085356 , 0.00510665, 0.02535332, 0.0066131 ,\n",
            "       0.01012003, 0.12718405, 0.04411376, 0.0088129 , 0.00118061,\n",
            "       0.01665908, 0.01640268, 0.00206617, 0.00559026, 0.13286409,\n",
            "       0.00618411, 0.01775113, 0.0075639 , 0.00499935, 0.02134717,\n",
            "       0.00804601, 0.09602149, 0.0997216 , 0.27232137, 0.00170133,\n",
            "       0.00704923, 0.06268924, 0.00098726, 0.01565995], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 491, 'shape': array([64], dtype=int32), 'shape_signature': array([64], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([5.46616968e-04, 1.33170828e-03, 2.60349771e-04, 1.22652651e-04,\n",
            "       4.92956242e-05, 1.61467365e-03, 4.23320365e-04, 9.85080842e-04,\n",
            "       4.13469214e-04, 5.38580876e-04, 5.45475574e-04, 4.55359987e-04,\n",
            "       5.72504709e-04, 6.15483586e-05, 3.29309201e-04, 1.13535745e-04,\n",
            "       6.41813749e-05, 6.04433066e-04, 7.69171806e-04, 2.40935216e-04,\n",
            "       3.08361778e-04, 5.15965512e-04, 3.82992410e-04, 3.51984025e-04,\n",
            "       3.09532508e-04, 2.40184017e-04, 1.68617597e-04, 5.59331966e-04,\n",
            "       4.58111579e-04, 3.25424597e-04, 6.28019799e-04, 2.01409624e-04,\n",
            "       9.41515085e-04, 9.59047058e-04, 4.75889479e-04, 1.41938173e-04,\n",
            "       3.27258225e-04, 9.00575193e-04, 1.96533321e-04, 3.17806320e-04,\n",
            "       3.87498265e-04, 7.04706908e-05, 3.82055005e-04, 4.25128441e-04,\n",
            "       3.60578590e-04, 3.66160093e-04, 2.17350782e-04, 3.66012624e-04,\n",
            "       8.17019085e-04, 5.17152148e-05, 3.36572382e-04, 6.36575453e-04,\n",
            "       8.87597154e-04, 3.34766693e-04, 3.29640548e-04, 2.99027131e-04,\n",
            "       1.46069477e-04, 1.44358055e-04, 6.70799564e-05, 3.50001006e-04,\n",
            "       4.76176327e-04, 2.26525241e-04, 1.32547412e-03, 6.30215509e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 492, 'shape': array([64,  1,  1, 16], dtype=int32), 'shape_signature': array([64,  1,  1, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([5.06962009e-04, 1.23509800e-03, 2.41462403e-04, 1.13754671e-04,\n",
            "       4.57194183e-05, 1.49753538e-03, 3.92610120e-04, 9.13617085e-04,\n",
            "       3.83473642e-04, 4.99508926e-04, 5.05903445e-04, 4.22325393e-04,\n",
            "       5.30971738e-04, 5.70832672e-05, 3.05419089e-04, 1.05299165e-04,\n",
            "       5.95252677e-05, 5.60583780e-04, 7.13371381e-04, 2.23456300e-04,\n",
            "       2.85991322e-04, 4.78534203e-04, 3.55207798e-04, 3.26448964e-04,\n",
            "       2.87077128e-04, 2.22759598e-04, 1.56385038e-04, 5.18754590e-04,\n",
            "       4.24877362e-04, 3.01816297e-04, 5.82459383e-04, 1.86798134e-04,\n",
            "       8.73211829e-04, 8.89471907e-04, 4.41365555e-04, 1.31641107e-04,\n",
            "       3.03516921e-04, 8.35241983e-04, 1.82275588e-04, 2.94750702e-04,\n",
            "       3.59386759e-04, 6.53583193e-05, 3.54338408e-04, 3.94287024e-04,\n",
            "       3.34420009e-04, 3.39596590e-04, 2.01582821e-04, 3.39459832e-04,\n",
            "       7.57747504e-04, 4.79634764e-05, 3.12155375e-04, 5.90394367e-04,\n",
            "       8.23205453e-04, 3.10480682e-04, 3.05726397e-04, 2.77333864e-04,\n",
            "       1.35472699e-04, 1.33885434e-04, 6.22135631e-05, 3.24609806e-04,\n",
            "       4.41631593e-04, 2.10091719e-04, 1.22931611e-03, 5.84495836e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/rezero/mul', 'index': 493, 'shape': array([ 1,  1, 43, 43, 16], dtype=int32), 'shape_signature': array([ 1,  1, 43, 43, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.008475329726934433, -128), 'quantization_parameters': {'scales': array([0.00847533], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 494, 'shape': array([16], dtype=int32), 'shape_signature': array([16], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.0008944 , 0.00114117, 0.0015594 , 0.00098124, 0.00057854,\n",
            "       0.00123456, 0.00102982, 0.00086111, 0.00118684, 0.00070237,\n",
            "       0.00121133, 0.00154899, 0.00079194, 0.00093402, 0.00102453,\n",
            "       0.00078967], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 495, 'shape': array([16,  1,  1, 40], dtype=int32), 'shape_signature': array([16,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01759072, 0.0224441 , 0.0306696 , 0.01929869, 0.01137841,\n",
            "       0.0242809 , 0.02025406, 0.01693593, 0.02334226, 0.01381391,\n",
            "       0.02382402, 0.03046499, 0.01557562, 0.01837002, 0.02015008,\n",
            "       0.01553099], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block0_layer1/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block0_layer1/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block0_layer1/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block1_layer4/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block0_layer1/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 496, 'shape': array([40], dtype=int32), 'shape_signature': array([40], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.24658518e-05, 1.76899121e-05, 1.53336441e-05, 1.20926552e-05,\n",
            "       1.39993399e-05, 2.36930555e-05, 2.89498457e-05, 2.79581072e-05,\n",
            "       9.34027685e-06, 3.00334505e-05, 1.09552457e-05, 1.84322780e-05,\n",
            "       1.43437337e-05, 5.37078781e-09, 1.87867736e-05, 1.88019458e-05,\n",
            "       4.57364804e-05, 1.57882914e-05, 3.10043361e-05, 2.56418352e-05,\n",
            "       1.75912901e-05, 2.08358906e-05, 3.92136899e-05, 3.34892284e-05,\n",
            "       3.42963322e-05, 3.37559977e-05, 2.54370680e-05, 1.72879281e-05,\n",
            "       1.71593965e-05, 2.65936160e-05, 3.24259818e-05, 1.28930351e-05,\n",
            "       1.53684377e-05, 1.67827220e-05, 2.07916619e-05, 9.30881288e-06,\n",
            "       1.10549818e-05, 1.40892125e-05, 3.31809279e-05, 1.77942256e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 497, 'shape': array([40,  1,  1, 24], dtype=int32), 'shape_signature': array([40,  1,  1, 24], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.5527478e-03, 2.2034573e-03, 1.9099603e-03, 1.5062623e-03,\n",
            "       1.7437591e-03, 2.9512094e-03, 3.6059958e-03, 3.4824647e-03,\n",
            "       1.1634259e-03, 3.7409696e-03, 1.3645865e-03, 2.2959264e-03,\n",
            "       1.7866569e-03, 6.6898588e-07, 2.3400823e-03, 2.3419722e-03,\n",
            "       5.6969407e-03, 1.9665912e-03, 3.8619032e-03, 3.1939496e-03,\n",
            "       2.1911729e-03, 2.5953206e-03, 4.8844609e-03, 4.1714218e-03,\n",
            "       4.2719548e-03, 4.2046504e-03, 3.1684437e-03, 2.1533861e-03,\n",
            "       2.1373762e-03, 3.3125035e-03, 4.0389835e-03, 1.6059577e-03,\n",
            "       1.9142942e-03, 2.0904576e-03, 2.5898116e-03, 1.1595066e-03,\n",
            "       1.3770097e-03, 1.7549538e-03, 4.1330196e-03, 2.2164506e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 498, 'shape': array([24], dtype=int32), 'shape_signature': array([24], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.19192659e-05, 1.10322384e-04, 3.61898856e-05, 5.77051724e-05,\n",
            "       6.04170164e-05, 5.36787775e-05, 4.14641690e-05, 5.69368458e-05,\n",
            "       2.48257820e-05, 5.93883815e-05, 4.43427816e-05, 2.01124967e-05,\n",
            "       2.75126731e-05, 2.72063880e-05, 4.74119915e-05, 3.58330108e-05,\n",
            "       4.57118949e-05, 3.81784848e-05, 4.58031427e-05, 3.05969552e-05,\n",
            "       5.21216243e-05, 3.00458414e-05, 2.10425533e-05, 4.07897787e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 499, 'shape': array([24,  1,  1, 80], dtype=int32), 'shape_signature': array([24,  1,  1, 80], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00215364, 0.00744361, 0.00244178, 0.00389345, 0.00407642,\n",
            "       0.00362178, 0.00279765, 0.00384161, 0.00167503, 0.00400702,\n",
            "       0.00299187, 0.00135702, 0.00185632, 0.00183565, 0.00319896,\n",
            "       0.00241771, 0.00308425, 0.00257596, 0.0030904 , 0.00206442,\n",
            "       0.00351672, 0.00202724, 0.00141977, 0.00275215], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 500, 'shape': array([40], dtype=int32), 'shape_signature': array([40], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00241682, 0.00063456, 0.01656349, 0.00907467, 0.00275802,\n",
            "       0.00322882, 0.00591243, 0.00242282, 0.00274083, 0.0140651 ,\n",
            "       0.0007757 , 0.01022428, 0.00241614, 0.00116266, 0.00574536,\n",
            "       0.0009494 , 0.00751574, 0.00119177, 0.00149487, 0.00145818,\n",
            "       0.00117671, 0.00216808, 0.0012684 , 0.0007315 , 0.00262898,\n",
            "       0.00160348, 0.00221569, 0.00283122, 0.00218709, 0.00428227,\n",
            "       0.00022209, 0.00083901, 0.00668129, 0.00146112, 0.0105663 ,\n",
            "       0.02677933, 0.00252984, 0.00118853, 0.00224533, 0.00302847],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block1_layer4/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul', 'index': 501, 'shape': array([ 1,  3,  1, 40], dtype=int32), 'shape_signature': array([ 1,  3,  1, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01258533, 0.00330438, 0.08625264, 0.04725536, 0.01436212,\n",
            "       0.01681373, 0.03078837, 0.01261656, 0.01427257, 0.07324252,\n",
            "       0.0040394 , 0.05324184, 0.0125818 , 0.00605443, 0.02991837,\n",
            "       0.00494388, 0.03913745, 0.00620603, 0.00778437, 0.00759331,\n",
            "       0.0061276 , 0.01129006, 0.00660505, 0.00380921, 0.01369015,\n",
            "       0.00834996, 0.01153797, 0.01474328, 0.01138903, 0.02229948,\n",
            "       0.00115652, 0.00436907, 0.03479209, 0.00760863, 0.05502287,\n",
            "       0.13945054, 0.01317389, 0.00618912, 0.01169229, 0.01577044],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 502, 'shape': array([40], dtype=int32), 'shape_signature': array([40], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00120632, 0.00395886, 0.00045863, 0.00404114, 0.00144534,\n",
            "       0.00139063, 0.00060901, 0.00150469, 0.00099496, 0.00212449,\n",
            "       0.00250577, 0.00049989, 0.00790645, 0.00310963, 0.00301042,\n",
            "       0.01315114, 0.00229502, 0.00436598, 0.00070679, 0.00082134,\n",
            "       0.01571925, 0.00014932, 0.00154126, 0.00087369, 0.00272993,\n",
            "       0.00064389, 0.00164857, 0.00859253, 0.00171502, 0.01559873,\n",
            "       0.00317072, 0.00141298, 0.00490139, 0.00268758, 0.00029375,\n",
            "       0.00130428, 0.00078261, 0.03136695, 0.00043283, 0.01242622],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block1_layer4/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 503, 'shape': array([ 1,  3,  3, 40], dtype=int32), 'shape_signature': array([ 1,  3,  3, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00805972, 0.02645018, 0.00306422, 0.02699997, 0.00965669,\n",
            "       0.00929118, 0.00406898, 0.01005327, 0.00664759, 0.0141943 ,\n",
            "       0.01674172, 0.00333992, 0.0528251 , 0.02077625, 0.02011342,\n",
            "       0.08786631, 0.01533365, 0.02917027, 0.00472225, 0.00548758,\n",
            "       0.10502455, 0.00099767, 0.01029759, 0.00583735, 0.01823941,\n",
            "       0.00430198, 0.01101453, 0.05740897, 0.01145848, 0.1042193 ,\n",
            "       0.02118444, 0.00944053, 0.03274747, 0.01795645, 0.00196261,\n",
            "       0.00871422, 0.00522883, 0.20957105, 0.00289186, 0.08302293],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 504, 'shape': array([40], dtype=int32), 'shape_signature': array([40], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([8.83271219e-04, 9.62662161e-04, 1.31885777e-03, 1.22428872e-04,\n",
            "       1.05043477e-03, 8.25243886e-04, 1.44713512e-03, 8.08010111e-04,\n",
            "       7.67118530e-04, 8.46376497e-05, 9.99228912e-04, 4.26476327e-04,\n",
            "       2.72978679e-04, 8.22291826e-04, 1.56963448e-04, 1.72738117e-04,\n",
            "       1.51742803e-04, 7.77005334e-05, 1.84759253e-03, 1.28654891e-03,\n",
            "       6.88581131e-05, 2.59191962e-03, 1.12269854e-03, 1.70174389e-04,\n",
            "       5.33210579e-04, 2.50399084e-04, 1.06439181e-03, 1.82753152e-04,\n",
            "       7.82705494e-04, 1.64476194e-04, 2.95932958e-04, 1.29446923e-03,\n",
            "       1.28318570e-04, 1.35918369e-03, 9.42721206e-04, 3.30227413e-05,\n",
            "       1.11907430e-03, 1.17973104e-04, 2.31135520e-03, 1.35602590e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 505, 'shape': array([40,  1,  1, 16], dtype=int32), 'shape_signature': array([40,  1,  1, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([8.5687824e-04, 9.3389692e-04, 1.2794491e-03, 1.1877058e-04,\n",
            "       1.0190468e-03, 8.0058485e-04, 1.4038933e-03, 7.8386604e-04,\n",
            "       7.4419630e-04, 8.2108600e-05, 9.6937100e-04, 4.1373281e-04,\n",
            "       2.6482184e-04, 7.9772098e-04, 1.5227323e-04, 1.6757654e-04,\n",
            "       1.4720859e-04, 7.5378768e-05, 1.7923848e-03, 1.2481057e-03,\n",
            "       6.6800567e-05, 2.5144706e-03, 1.0891513e-03, 1.6508943e-04,\n",
            "       5.1727775e-04, 2.4291693e-04, 1.0325868e-03, 1.7729231e-04,\n",
            "       7.5931754e-04, 1.5956149e-04, 2.8709020e-04, 1.2557893e-03,\n",
            "       1.2448429e-04, 1.3185700e-03, 9.1455184e-04, 3.2035990e-05,\n",
            "       1.0856353e-03, 1.1444796e-04, 2.2422897e-03, 1.3155065e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/rezero/mul', 'index': 506, 'shape': array([ 1,  1, 43, 43, 16], dtype=int32), 'shape_signature': array([ 1,  1, 43, 43, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.009517853148281574, 127), 'quantization_parameters': {'scales': array([0.00951785], dtype=float32), 'zero_points': array([127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 507, 'shape': array([16], dtype=int32), 'shape_signature': array([16], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00278285, 0.00298597, 0.00199843, 0.00130075, 0.00329972,\n",
            "       0.00161824, 0.0023413 , 0.00196529, 0.00293345, 0.00167767,\n",
            "       0.00286409, 0.0028431 , 0.0028506 , 0.0016237 , 0.00153719,\n",
            "       0.00233038], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/projection/conv2d/conv2d_3/Conv2D', 'index': 508, 'shape': array([16,  1,  1, 40], dtype=int32), 'shape_signature': array([16,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01303278, 0.01398405, 0.00935915, 0.00609176, 0.01545342,\n",
            "       0.00757862, 0.01096493, 0.00920396, 0.0137381 , 0.00785695,\n",
            "       0.01341324, 0.01331498, 0.01335007, 0.0076042 , 0.00719906,\n",
            "       0.01091375], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_expand/conv2d/activation_2/mul/y', 'index': 509, 'shape': array([], dtype=int32), 'shape_signature': array([], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0006536078290082514, -128), 'quantization_parameters': {'scales': array([0.00065361], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block1_layer4/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x', 'index': 510, 'shape': array([40], dtype=int32), 'shape_signature': array([40], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.2046187e-06, 5.1452611e-09, 2.1555438e-06, 1.2516055e-06,\n",
            "       1.2287264e-06, 7.5496274e-07, 3.0804193e-07, 5.7723573e-09,\n",
            "       1.5119031e-06, 1.5886676e-06, 3.1576947e-06, 5.1622426e-09,\n",
            "       1.0238028e-06, 1.4186620e-06, 2.2672684e-06, 1.0716772e-06,\n",
            "       5.1639062e-09, 2.1543492e-06, 1.9841164e-06, 2.5205129e-06,\n",
            "       2.8666507e-06, 1.6800658e-06, 2.7680258e-06, 1.2685006e-06,\n",
            "       8.2484263e-07, 5.1801603e-09, 9.9744170e-07, 9.0727872e-07,\n",
            "       2.8984291e-06, 1.5554391e-06, 1.4531862e-06, 5.1654405e-09,\n",
            "       5.2946789e-09, 5.2020228e-09, 1.4097683e-06, 1.7126398e-06,\n",
            "       1.0992687e-06, 1.4954666e-06, 1.7162301e-06, 1.9368692e-06],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_expand/conv2d/conv2d_2/Conv2D', 'index': 511, 'shape': array([40,  1,  1, 24], dtype=int32), 'shape_signature': array([40,  1,  1, 24], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([8.1914099e-04, 3.4987788e-06, 1.4657703e-03, 8.5109205e-04,\n",
            "       8.3553430e-04, 5.1337486e-04, 2.0946859e-04, 3.9252045e-06,\n",
            "       1.0280944e-03, 1.0802944e-03, 2.1472331e-03, 3.5103262e-06,\n",
            "       6.9618621e-04, 9.6469052e-04, 1.5417432e-03, 7.2874076e-04,\n",
            "       3.5114576e-06, 1.4649580e-03, 1.3491996e-03, 1.7139494e-03,\n",
            "       1.9493232e-03, 1.1424451e-03, 1.8822582e-03, 8.6258072e-04,\n",
            "       5.6089321e-04, 3.5225103e-06, 6.7826058e-04, 6.1694975e-04,\n",
            "       1.9709326e-03, 1.0576990e-03, 9.8816701e-04, 3.5125008e-06,\n",
            "       3.6003830e-06, 3.5373769e-06, 9.5864281e-04, 1.1645955e-03,\n",
            "       7.4750301e-04, 1.0169176e-03, 1.1670369e-03, 1.3170716e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 512, 'shape': array([24], dtype=int32), 'shape_signature': array([24], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.4928971e-05, 2.5105708e-05, 2.3196246e-05, 2.0001557e-05,\n",
            "       2.1445458e-05, 1.8442230e-05, 2.8825099e-05, 2.8330101e-05,\n",
            "       1.5946687e-05, 1.6560109e-05, 2.2701210e-05, 2.0324196e-05,\n",
            "       1.8373130e-05, 3.0421665e-05, 1.9134275e-05, 2.3398605e-05,\n",
            "       3.5806876e-05, 1.8654338e-05, 2.1348815e-05, 1.7651917e-05,\n",
            "       2.3216988e-05, 1.7877557e-05, 1.5860103e-05, 1.9058853e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D', 'index': 513, 'shape': array([24,  1,  1, 80], dtype=int32), 'shape_signature': array([24,  1,  1, 80], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00067916, 0.00114212, 0.00105526, 0.00090992, 0.00097561,\n",
            "       0.00083898, 0.00131133, 0.00128881, 0.00072546, 0.00075336,\n",
            "       0.00103274, 0.0009246 , 0.00083584, 0.00138396, 0.00087047,\n",
            "       0.00106446, 0.00162895, 0.00084863, 0.00097121, 0.00080303,\n",
            "       0.0010562 , 0.0008133 , 0.00072152, 0.00086704], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/skip/skip_project/conv2d/bn/FusedBatchNormV3', 'index': 514, 'shape': array([16], dtype=int32), 'shape_signature': array([16], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00049925, 0.00037983, 0.00577382, 0.00193359, 0.00063582,\n",
            "       0.00337409, 0.00192969, 0.00291549, 0.00276305, 0.00286711,\n",
            "       0.00362912, 0.00073218, 0.00458597, 0.00587381, 0.00407732,\n",
            "       0.00495529], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/skip/skip_project/conv2d/conv2d_4/Conv2D', 'index': 515, 'shape': array([16,  1,  1, 16], dtype=int32), 'shape_signature': array([16,  1,  1, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00222547, 0.00169313, 0.02573743, 0.0086192 , 0.00283423,\n",
            "       0.0150404 , 0.00860179, 0.01299613, 0.0123166 , 0.01278046,\n",
            "       0.01617721, 0.00326378, 0.02044246, 0.02618314, 0.01817511,\n",
            "       0.02208876], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 516, 'shape': array([40], dtype=int32), 'shape_signature': array([40], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00059085, 0.00044835, 0.00224916, 0.00543014, 0.00734076,\n",
            "       0.00220217, 0.00245194, 0.00262512, 0.00217047, 0.00292577,\n",
            "       0.00116726, 0.0015413 , 0.00547556, 0.00037007, 0.00703403,\n",
            "       0.00405907, 0.00025099, 0.00515859, 0.00186404, 0.00048754,\n",
            "       0.00651696, 0.00573164, 0.00497791, 0.00379671, 0.0002674 ,\n",
            "       0.00019181, 0.00166144, 0.00048875, 0.00014735, 0.00290275,\n",
            "       0.00232319, 0.00319254, 0.00352071, 0.00189632, 0.0111592 ,\n",
            "       0.00569697, 0.00183428, 0.01140617, 0.00606684, 0.0197254 ],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block1_layer4/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/feature/conv2d/bn/batchnorm/mul', 'index': 517, 'shape': array([ 1,  5,  5, 40], dtype=int32), 'shape_signature': array([ 1,  5,  5, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00350601, 0.00266045, 0.01334616, 0.03222166, 0.04355898,\n",
            "       0.01306737, 0.01454943, 0.01557708, 0.01287926, 0.0173611 ,\n",
            "       0.00692636, 0.00914583, 0.03249118, 0.00219593, 0.04173886,\n",
            "       0.02408588, 0.00148932, 0.03061029, 0.01106093, 0.00289296,\n",
            "       0.03867065, 0.03401069, 0.02953814, 0.0225291 , 0.00158668,\n",
            "       0.00113819, 0.00985876, 0.00290016, 0.00087438, 0.01722446,\n",
            "       0.01378548, 0.01894405, 0.02089133, 0.01125246, 0.06621703,\n",
            "       0.03380498, 0.01088434, 0.06768247, 0.0359997 , 0.11704758],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 518, 'shape': array([40], dtype=int32), 'shape_signature': array([40], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00202909, 0.00075954, 0.00086159, 0.00141184, 0.00037452,\n",
            "       0.00045965, 0.00066335, 0.00101658, 0.00085951, 0.00109662,\n",
            "       0.00101796, 0.00077255, 0.00088536, 0.00148758, 0.0007674 ,\n",
            "       0.00079591, 0.00313524, 0.00024855, 0.00175878, 0.00145702,\n",
            "       0.00068815, 0.00047472, 0.00091352, 0.00137785, 0.00072099,\n",
            "       0.00234203, 0.00217099, 0.00162586, 0.00317773, 0.00045881,\n",
            "       0.00081768, 0.00072099, 0.00054525, 0.00030056, 0.00069601,\n",
            "       0.00041764, 0.00206335, 0.00043523, 0.00060937, 0.00010185],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/conv2d/Conv2D', 'index': 519, 'shape': array([40,  1,  1, 16], dtype=int32), 'shape_signature': array([40,  1,  1, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00904488, 0.00338573, 0.00384062, 0.00629345, 0.00166945,\n",
            "       0.00204894, 0.00295695, 0.00453151, 0.00383136, 0.00488832,\n",
            "       0.00453766, 0.00344372, 0.0039466 , 0.00663107, 0.00342076,\n",
            "       0.00354785, 0.01397569, 0.00110792, 0.00783994, 0.00649485,\n",
            "       0.0030675 , 0.00211612, 0.00407209, 0.00614191, 0.00321389,\n",
            "       0.01043985, 0.00967742, 0.00724746, 0.01416508, 0.00204519,\n",
            "       0.00364489, 0.00321391, 0.00243049, 0.00133978, 0.00310253,\n",
            "       0.00186169, 0.00919762, 0.00194009, 0.00271633, 0.00045402],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/stem/stem/conv2d/bn/batchnorm/sub', 'index': 520, 'shape': array([16], dtype=int32), 'shape_signature': array([16], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.2217987e-04, 4.7687287e-04, 2.7345028e-05, 7.3500771e-05,\n",
            "       9.1486902e-05, 2.1358673e-04, 3.1607412e-04, 6.2793045e-04,\n",
            "       4.0769987e-04, 7.5333694e-05, 3.2791379e-04, 9.5616328e-05,\n",
            "       1.1124681e-04, 6.4188767e-05, 7.6405624e-05, 1.3025930e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/stem/stem/conv2d/conv2d/Conv2D', 'index': 521, 'shape': array([16,  3,  3,  3], dtype=int32), 'shape_signature': array([16,  3,  3,  3], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.03115587, 0.12160257, 0.00697298, 0.0187427 , 0.02332916,\n",
            "       0.05446461, 0.0805989 , 0.16012226, 0.10396346, 0.01921009,\n",
            "       0.08361801, 0.02438216, 0.02836793, 0.01636813, 0.01948343,\n",
            "       0.03321612], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/stem/stem/conv2d/Reshape', 'index': 522, 'shape': array([  1, 172, 172,   3], dtype=int32), 'shape_signature': array([  1, 172, 172,   3], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.003921568859368563, -128), 'quantization_parameters': {'scales': array([0.00392157], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/stem/stem/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block0_layer2/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/stem/stem/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/stem/stem/conv2d/bn/batchnorm/sub', 'index': 523, 'shape': array([ 1, 86, 86, 16], dtype=int32), 'shape_signature': array([ 1, 86, 86, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4322871267795563, -4), 'quantization_parameters': {'scales': array([0.43228713], dtype=float32), 'zero_points': array([-4], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/stem/stem/conv2d/activation_56/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/stem/stem/conv2d/activation_56/Relu6;movinet_classifier_2/movinet_1/stem/stem/conv2d/activation_56/add;movinet_classifier_2/movinet_1/stem/stem/conv2d/activation_56/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 524, 'shape': array([ 1, 86, 86, 16], dtype=int32), 'shape_signature': array([ 1, 86, 86, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2243354320526123, -126), 'quantization_parameters': {'scales': array([0.22433543], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block1_layer4/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 525, 'shape': array([ 1, 86, 86, 40], dtype=int32), 'shape_signature': array([ 1, 86, 86, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4204806685447693, 26), 'quantization_parameters': {'scales': array([0.42048067], dtype=float32), 'zero_points': array([26], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Relu6;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/add;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 526, 'shape': array([ 1, 86, 86, 40], dtype=int32), 'shape_signature': array([ 1, 86, 86, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.16852465271949768, -126), 'quantization_parameters': {'scales': array([0.16852465], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block1_layer4/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block0_layer0/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 527, 'shape': array([ 1, 43, 43, 40], dtype=int32), 'shape_signature': array([ 1, 43, 43, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.0572385787963867, 3), 'quantization_parameters': {'scales': array([1.0572386], dtype=float32), 'zero_points': array([3], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/feature/conv2d/activation_58/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block0_layer0/bneck/feature/conv2d/activation_58/Relu6;movinet_classifier_2/movinet_1/block0_layer0/bneck/feature/conv2d/activation_58/add;movinet_classifier_2/movinet_1/block0_layer0/bneck/feature/conv2d/activation_58/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 528, 'shape': array([ 1, 43, 43, 40], dtype=int32), 'shape_signature': array([ 1, 43, 43, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.517523467540741, -127), 'quantization_parameters': {'scales': array([0.51752347], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/feature/conv2d/Reshape_1', 'index': 529, 'shape': array([ 1,  1, 43, 43, 40], dtype=int32), 'shape_signature': array([ 1,  1, 43, 43, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.517523467540741, -127), 'quantization_parameters': {'scales': array([0.51752347], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/spatial_average_pool3d_26/Mean', 'index': 530, 'shape': array([ 1,  1,  1,  1, 40], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.021981634199619293, -113), 'quantization_parameters': {'scales': array([0.02198163], dtype=float32), 'zero_points': array([-113], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/spatial_average_pool3d_26/Mean1', 'index': 531, 'shape': array([ 1,  1,  1,  1, 40], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/skip/skip_pool/AvgPool', 'index': 532, 'shape': array([ 1, 43, 43, 16], dtype=int32), 'shape_signature': array([ 1, 43, 43, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2243354320526123, -126), 'quantization_parameters': {'scales': array([0.22433543], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/skip/skip_project/conv2d/bn/FusedBatchNormV3;movinet_classifier_2/movinet_1/block0_layer2/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/skip/skip_project/conv2d/conv2d_4/Conv2D', 'index': 533, 'shape': array([ 1, 43, 43, 16], dtype=int32), 'shape_signature': array([ 1, 43, 43, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.460361123085022, -9), 'quantization_parameters': {'scales': array([0.46036112], dtype=float32), 'zero_points': array([-9], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/skip/skip_project/conv2d/Reshape_1', 'index': 534, 'shape': array([ 1,  1, 43, 43, 16], dtype=int32), 'shape_signature': array([ 1,  1, 43, 43, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.460361123085022, -9), 'quantization_parameters': {'scales': array([0.46036112], dtype=float32), 'zero_points': array([-9], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/global_average_pool3d_27/add_1', 'index': 535, 'shape': array([ 1,  1,  1,  1, 40], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.48881497979164124, -111), 'quantization_parameters': {'scales': array([0.48881498], dtype=float32), 'zero_points': array([-111], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize', 'index': 536, 'shape': array([ 1,  1,  1,  1, 40], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:1', 'index': 537, 'shape': array([ 1,  1,  1,  1, 40], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.48881497979164124, -111), 'quantization_parameters': {'scales': array([0.48881498], dtype=float32), 'zero_points': array([-111], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:2', 'index': 538, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/global_average_pool3d_27/Reshape', 'index': 539, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/global_average_pool3d_27/Cast', 'index': 540, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/global_average_pool3d_27/truediv', 'index': 541, 'shape': array([ 1,  1,  1,  1, 40], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/concat', 'index': 542, 'shape': array([ 1,  1,  1,  1, 80], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 80], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize', 'index': 543, 'shape': array([ 1,  1,  1,  1, 80], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 80], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.021981634199619293, -113), 'quantization_parameters': {'scales': array([0.02198163], dtype=float32), 'zero_points': array([-113], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_reduce/conv2d/Reshape', 'index': 544, 'shape': array([ 1,  1,  1, 80], dtype=int32), 'shape_signature': array([ 1,  1,  1, 80], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.021981634199619293, -113), 'quantization_parameters': {'scales': array([0.02198163], dtype=float32), 'zero_points': array([-113], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block0_layer1/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 545, 'shape': array([ 1,  1,  1, 24], dtype=int32), 'shape_signature': array([ 1,  1,  1, 24], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.017952164635062218, 127), 'quantization_parameters': {'scales': array([0.01795216], dtype=float32), 'zero_points': array([127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 546, 'shape': array([ 1,  1,  1, 24], dtype=int32), 'shape_signature': array([ 1,  1,  1, 24], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.001470587681978941, 127), 'quantization_parameters': {'scales': array([0.00147059], dtype=float32), 'zero_points': array([127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block1_layer4/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 547, 'shape': array([ 1,  1,  1, 40], dtype=int32), 'shape_signature': array([ 1,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0235294122248888, -128), 'quantization_parameters': {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 548, 'shape': array([ 1,  1,  1, 40], dtype=int32), 'shape_signature': array([ 1,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00392164709046483, -128), 'quantization_parameters': {'scales': array([0.00392165], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/se_expand/conv2d/Reshape_1', 'index': 549, 'shape': array([ 1,  1,  1,  1, 40], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00392164709046483, -128), 'quantization_parameters': {'scales': array([0.00392165], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/mul1', 'index': 550, 'shape': array([ 1,  1, 43, 43, 40], dtype=int32), 'shape_signature': array([ 1,  1, 43, 43, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00392164709046483, -128), 'quantization_parameters': {'scales': array([0.00392165], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/se/mul2', 'index': 551, 'shape': array([ 1,  1, 43, 43, 40], dtype=int32), 'shape_signature': array([ 1,  1, 43, 43, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2135266810655594, -126), 'quantization_parameters': {'scales': array([0.21352668], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/projection/conv2d/Reshape', 'index': 552, 'shape': array([ 1, 43, 43, 40], dtype=int32), 'shape_signature': array([ 1, 43, 43, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2135266810655594, -126), 'quantization_parameters': {'scales': array([0.21352668], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block0_layer2/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 553, 'shape': array([ 1, 43, 43, 16], dtype=int32), 'shape_signature': array([ 1, 43, 43, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.426899254322052, 16), 'quantization_parameters': {'scales': array([0.42689925], dtype=float32), 'zero_points': array([16], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/projection/conv2d/Reshape_1', 'index': 554, 'shape': array([ 1,  1, 43, 43, 16], dtype=int32), 'shape_signature': array([ 1,  1, 43, 43, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.426899254322052, 16), 'quantization_parameters': {'scales': array([0.42689925], dtype=float32), 'zero_points': array([16], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/rezero/mul1', 'index': 555, 'shape': array([ 1,  1, 43, 43, 16], dtype=int32), 'shape_signature': array([ 1,  1, 43, 43, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.0361069440841675, -17), 'quantization_parameters': {'scales': array([1.036107], dtype=float32), 'zero_points': array([-17], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer0/bneck/add', 'index': 556, 'shape': array([ 1,  1, 43, 43, 16], dtype=int32), 'shape_signature': array([ 1,  1, 43, 43, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.0308012962341309, -15), 'quantization_parameters': {'scales': array([1.0308013], dtype=float32), 'zero_points': array([-15], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/expansion/conv2d/Reshape', 'index': 557, 'shape': array([ 1, 43, 43, 16], dtype=int32), 'shape_signature': array([ 1, 43, 43, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.0308012962341309, -15), 'quantization_parameters': {'scales': array([1.0308013], dtype=float32), 'zero_points': array([-15], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block1_layer4/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block0_layer1/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block0_layer1/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 558, 'shape': array([ 1, 43, 43, 40], dtype=int32), 'shape_signature': array([ 1, 43, 43, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.3635409474372864, 23), 'quantization_parameters': {'scales': array([0.36354095], dtype=float32), 'zero_points': array([23], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/expansion/conv2d/activation_59/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block0_layer1/bneck/expansion/conv2d/activation_59/Relu6;movinet_classifier_2/movinet_1/block0_layer1/bneck/expansion/conv2d/activation_59/add;movinet_classifier_2/movinet_1/block0_layer1/bneck/expansion/conv2d/activation_59/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 559, 'shape': array([ 1, 43, 43, 40], dtype=int32), 'shape_signature': array([ 1, 43, 43, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.14967216551303864, -125), 'quantization_parameters': {'scales': array([0.14967217], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block1_layer4/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 560, 'shape': array([ 1, 43, 43, 40], dtype=int32), 'shape_signature': array([ 1, 43, 43, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.3617061972618103, -7), 'quantization_parameters': {'scales': array([0.3617062], dtype=float32), 'zero_points': array([-7], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d/activation_60/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d/activation_60/Relu6;movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d/activation_60/add;movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d/activation_60/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 561, 'shape': array([ 1, 43, 43, 40], dtype=int32), 'shape_signature': array([ 1, 43, 43, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.19203461706638336, -126), 'quantization_parameters': {'scales': array([0.19203462], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d/Reshape_1', 'index': 562, 'shape': array([ 1,  1, 43, 43, 40], dtype=int32), 'shape_signature': array([ 1,  1, 43, 43, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.19203461706638336, -126), 'quantization_parameters': {'scales': array([0.19203462], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:4', 'index': 563, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/se/global_average_pool3d_28/Reshape', 'index': 564, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/se/global_average_pool3d_28/Cast', 'index': 565, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/stream_buffer_19/concat', 'index': 566, 'shape': array([ 1,  3, 43, 43, 40], dtype=int32), 'shape_signature': array([ 1,  3, 43, 43, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.19203461706638336, -126), 'quantization_parameters': {'scales': array([0.19203462], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d_temporal/Reshape', 'index': 567, 'shape': array([   1,    3, 1849,   40], dtype=int32), 'shape_signature': array([   1,    3, 1849,   40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.19203461706638336, -126), 'quantization_parameters': {'scales': array([0.19203462], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/add_1;movinet_classifier_2/movinet_1/block1_layer4/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul;movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 568, 'shape': array([   1,    1, 1849,   40], dtype=int32), 'shape_signature': array([   1,    1, 1849,   40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.3696657717227936, 3), 'quantization_parameters': {'scales': array([0.36966577], dtype=float32), 'zero_points': array([3], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d_temporal/activation_60/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d_temporal/activation_60/Relu6;movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d_temporal/activation_60/add;movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d_temporal/activation_60/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 569, 'shape': array([   1,    1, 1849,   40], dtype=int32), 'shape_signature': array([   1,    1, 1849,   40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.18158483505249023, -126), 'quantization_parameters': {'scales': array([0.18158484], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/feature/conv2d_temporal/Reshape_1', 'index': 570, 'shape': array([ 1,  1, 43, 43, 40], dtype=int32), 'shape_signature': array([ 1,  1, 43, 43, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.18158483505249023, -126), 'quantization_parameters': {'scales': array([0.18158484], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/se/spatial_average_pool3d_27/Mean', 'index': 571, 'shape': array([ 1,  1,  1,  1, 40], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.014821084216237068, -104), 'quantization_parameters': {'scales': array([0.01482108], dtype=float32), 'zero_points': array([-104], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/se/spatial_average_pool3d_27/Mean1', 'index': 572, 'shape': array([ 1,  1,  1,  1, 40], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/se/global_average_pool3d_28/add_1', 'index': 573, 'shape': array([ 1,  1,  1,  1, 40], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.37730416655540466, -107), 'quantization_parameters': {'scales': array([0.37730417], dtype=float32), 'zero_points': array([-107], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize1', 'index': 574, 'shape': array([ 1,  1,  1,  1, 40], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:3', 'index': 575, 'shape': array([ 1,  1,  1,  1, 40], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.37730416655540466, -107), 'quantization_parameters': {'scales': array([0.37730417], dtype=float32), 'zero_points': array([-107], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/se/global_average_pool3d_28/truediv', 'index': 576, 'shape': array([ 1,  1,  1,  1, 40], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/se/concat', 'index': 577, 'shape': array([ 1,  1,  1,  1, 80], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 80], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize1', 'index': 578, 'shape': array([ 1,  1,  1,  1, 80], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 80], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.014821084216237068, -104), 'quantization_parameters': {'scales': array([0.01482108], dtype=float32), 'zero_points': array([-104], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/se/se_reduce/conv2d/Reshape', 'index': 579, 'shape': array([ 1,  1,  1, 80], dtype=int32), 'shape_signature': array([ 1,  1,  1, 80], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.014821084216237068, -104), 'quantization_parameters': {'scales': array([0.01482108], dtype=float32), 'zero_points': array([-104], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block0_layer1/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block0_layer1/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 580, 'shape': array([ 1,  1,  1, 24], dtype=int32), 'shape_signature': array([ 1,  1,  1, 24], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.03966761752963066, 76), 'quantization_parameters': {'scales': array([0.03966762], dtype=float32), 'zero_points': array([76], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block0_layer1/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block0_layer1/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block0_layer1/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 581, 'shape': array([ 1,  1,  1, 24], dtype=int32), 'shape_signature': array([ 1,  1,  1, 24], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.008028252981603146, -81), 'quantization_parameters': {'scales': array([0.00802825], dtype=float32), 'zero_points': array([-81], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block0_layer1/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block0_layer1/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block0_layer1/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block1_layer4/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block0_layer1/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 582, 'shape': array([ 1,  1,  1, 40], dtype=int32), 'shape_signature': array([ 1,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.022615069523453712, -128), 'quantization_parameters': {'scales': array([0.02261507], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 583, 'shape': array([ 1,  1,  1, 40], dtype=int32), 'shape_signature': array([ 1,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0037692536134272814, -128), 'quantization_parameters': {'scales': array([0.00376925], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/se/se_expand/conv2d/Reshape_1', 'index': 584, 'shape': array([ 1,  1,  1,  1, 40], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0037692536134272814, -128), 'quantization_parameters': {'scales': array([0.00376925], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/se/mul', 'index': 585, 'shape': array([ 1,  1, 43, 43, 40], dtype=int32), 'shape_signature': array([ 1,  1, 43, 43, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0037692536134272814, -128), 'quantization_parameters': {'scales': array([0.00376925], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/se/mul1', 'index': 586, 'shape': array([ 1,  1, 43, 43, 40], dtype=int32), 'shape_signature': array([ 1,  1, 43, 43, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.05084502696990967, -121), 'quantization_parameters': {'scales': array([0.05084503], dtype=float32), 'zero_points': array([-121], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/projection/conv2d/Reshape', 'index': 587, 'shape': array([ 1, 43, 43, 40], dtype=int32), 'shape_signature': array([ 1, 43, 43, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.05084502696990967, -121), 'quantization_parameters': {'scales': array([0.05084503], dtype=float32), 'zero_points': array([-121], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block0_layer2/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block0_layer1/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block0_layer1/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 588, 'shape': array([ 1, 43, 43, 16], dtype=int32), 'shape_signature': array([ 1, 43, 43, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.19887632131576538, -2), 'quantization_parameters': {'scales': array([0.19887632], dtype=float32), 'zero_points': array([-2], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/projection/conv2d/Reshape_1', 'index': 589, 'shape': array([ 1,  1, 43, 43, 16], dtype=int32), 'shape_signature': array([ 1,  1, 43, 43, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.19887632131576538, -2), 'quantization_parameters': {'scales': array([0.19887632], dtype=float32), 'zero_points': array([-2], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/rezero/mul1', 'index': 590, 'shape': array([ 1,  1, 43, 43, 16], dtype=int32), 'shape_signature': array([ 1,  1, 43, 43, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.42981332540512085, -2), 'quantization_parameters': {'scales': array([0.42981333], dtype=float32), 'zero_points': array([-2], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer1/bneck/add', 'index': 591, 'shape': array([ 1,  1, 43, 43, 16], dtype=int32), 'shape_signature': array([ 1,  1, 43, 43, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.0782207250595093, -11), 'quantization_parameters': {'scales': array([1.0782207], dtype=float32), 'zero_points': array([-11], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/expansion/conv2d/Reshape', 'index': 592, 'shape': array([ 1, 43, 43, 16], dtype=int32), 'shape_signature': array([ 1, 43, 43, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.0782207250595093, -11), 'quantization_parameters': {'scales': array([1.0782207], dtype=float32), 'zero_points': array([-11], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block0_layer2/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block0_layer2/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 593, 'shape': array([ 1, 43, 43, 64], dtype=int32), 'shape_signature': array([ 1, 43, 43, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.22465826570987701, -3), 'quantization_parameters': {'scales': array([0.22465827], dtype=float32), 'zero_points': array([-3], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/expansion/conv2d/activation_61/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block0_layer2/bneck/expansion/conv2d/activation_61/Relu6;movinet_classifier_2/movinet_1/block0_layer2/bneck/expansion/conv2d/activation_61/add;movinet_classifier_2/movinet_1/block0_layer2/bneck/expansion/conv2d/activation_61/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 594, 'shape': array([ 1, 43, 43, 64], dtype=int32), 'shape_signature': array([ 1, 43, 43, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11561470478773117, -125), 'quantization_parameters': {'scales': array([0.1156147], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 595, 'shape': array([ 1, 43, 43, 64], dtype=int32), 'shape_signature': array([ 1, 43, 43, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.37513914704322815, -13), 'quantization_parameters': {'scales': array([0.37513915], dtype=float32), 'zero_points': array([-13], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d/activation_62/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d/activation_62/Relu6;movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d/activation_62/add;movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d/activation_62/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 596, 'shape': array([ 1, 43, 43, 64], dtype=int32), 'shape_signature': array([ 1, 43, 43, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.20781420171260834, -126), 'quantization_parameters': {'scales': array([0.2078142], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d/Reshape_1', 'index': 597, 'shape': array([ 1,  1, 43, 43, 64], dtype=int32), 'shape_signature': array([ 1,  1, 43, 43, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.20781420171260834, -126), 'quantization_parameters': {'scales': array([0.2078142], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:5', 'index': 598, 'shape': array([ 1,  2, 43, 43, 40], dtype=int32), 'shape_signature': array([ 1,  2, 43, 43, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.19203461706638336, -126), 'quantization_parameters': {'scales': array([0.19203462], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:7', 'index': 599, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/se/global_average_pool3d_29/Reshape', 'index': 600, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/se/global_average_pool3d_29/Cast', 'index': 601, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/stream_buffer_20/concat', 'index': 602, 'shape': array([ 1,  3, 43, 43, 64], dtype=int32), 'shape_signature': array([ 1,  3, 43, 43, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.20781420171260834, -126), 'quantization_parameters': {'scales': array([0.2078142], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d_temporal/Reshape', 'index': 603, 'shape': array([   1,    3, 1849,   64], dtype=int32), 'shape_signature': array([   1,    3, 1849,   64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.20781420171260834, -126), 'quantization_parameters': {'scales': array([0.2078142], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/add_1;movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul;movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 604, 'shape': array([   1,    1, 1849,   64], dtype=int32), 'shape_signature': array([   1,    1, 1849,   64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.494875967502594, -3), 'quantization_parameters': {'scales': array([0.49487597], dtype=float32), 'zero_points': array([-3], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d_temporal/activation_62/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d_temporal/activation_62/Relu6;movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d_temporal/activation_62/add;movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d_temporal/activation_62/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 605, 'shape': array([   1,    1, 1849,   64], dtype=int32), 'shape_signature': array([   1,    1, 1849,   64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.25422969460487366, -127), 'quantization_parameters': {'scales': array([0.2542297], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/feature/conv2d_temporal/Reshape_1', 'index': 606, 'shape': array([ 1,  1, 43, 43, 64], dtype=int32), 'shape_signature': array([ 1,  1, 43, 43, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.25422969460487366, -127), 'quantization_parameters': {'scales': array([0.2542297], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/se/spatial_average_pool3d_28/Mean', 'index': 607, 'shape': array([ 1,  1,  1,  1, 64], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.010157194919884205, -92), 'quantization_parameters': {'scales': array([0.01015719], dtype=float32), 'zero_points': array([-92], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/se/spatial_average_pool3d_28/Mean1', 'index': 608, 'shape': array([ 1,  1,  1,  1, 64], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 64], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/se/global_average_pool3d_29/add_1', 'index': 609, 'shape': array([ 1,  1,  1,  1, 64], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.24153223633766174, -89), 'quantization_parameters': {'scales': array([0.24153224], dtype=float32), 'zero_points': array([-89], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize2', 'index': 610, 'shape': array([ 1,  1,  1,  1, 64], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 64], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:6', 'index': 611, 'shape': array([ 1,  1,  1,  1, 64], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.24153223633766174, -89), 'quantization_parameters': {'scales': array([0.24153224], dtype=float32), 'zero_points': array([-89], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/se/global_average_pool3d_29/truediv', 'index': 612, 'shape': array([ 1,  1,  1,  1, 64], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 64], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/se/concat', 'index': 613, 'shape': array([  1,   1,   1,   1, 128], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 128], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize2', 'index': 614, 'shape': array([  1,   1,   1,   1, 128], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.010157194919884205, -92), 'quantization_parameters': {'scales': array([0.01015719], dtype=float32), 'zero_points': array([-92], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_reduce/conv2d/Reshape', 'index': 615, 'shape': array([  1,   1,   1, 128], dtype=int32), 'shape_signature': array([  1,   1,   1, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.010157194919884205, -92), 'quantization_parameters': {'scales': array([0.01015719], dtype=float32), 'zero_points': array([-92], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 616, 'shape': array([ 1,  1,  1, 32], dtype=int32), 'shape_signature': array([ 1,  1,  1, 32], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.013736152090132236, -1), 'quantization_parameters': {'scales': array([0.01373615], dtype=float32), 'zero_points': array([-1], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 617, 'shape': array([ 1,  1,  1, 32], dtype=int32), 'shape_signature': array([ 1,  1,  1, 32], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.006927142851054668, -74), 'quantization_parameters': {'scales': array([0.00692714], dtype=float32), 'zero_points': array([-74], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 618, 'shape': array([ 1,  1,  1, 64], dtype=int32), 'shape_signature': array([ 1,  1,  1, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.020020367577672005, -128), 'quantization_parameters': {'scales': array([0.02002037], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 619, 'shape': array([ 1,  1,  1, 64], dtype=int32), 'shape_signature': array([ 1,  1,  1, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0033367944415658712, -128), 'quantization_parameters': {'scales': array([0.00333679], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/se/se_expand/conv2d/Reshape_1', 'index': 620, 'shape': array([ 1,  1,  1,  1, 64], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0033367944415658712, -128), 'quantization_parameters': {'scales': array([0.00333679], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/se/mul1', 'index': 621, 'shape': array([ 1,  1, 43, 43, 64], dtype=int32), 'shape_signature': array([ 1,  1, 43, 43, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0033367944415658712, -128), 'quantization_parameters': {'scales': array([0.00333679], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/se/mul2', 'index': 622, 'shape': array([ 1,  1, 43, 43, 64], dtype=int32), 'shape_signature': array([ 1,  1, 43, 43, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.05278286337852478, -122), 'quantization_parameters': {'scales': array([0.05278286], dtype=float32), 'zero_points': array([-122], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/projection/conv2d/Reshape', 'index': 623, 'shape': array([ 1, 43, 43, 64], dtype=int32), 'shape_signature': array([ 1, 43, 43, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.05278286337852478, -122), 'quantization_parameters': {'scales': array([0.05278286], dtype=float32), 'zero_points': array([-122], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block0_layer2/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block0_layer2/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 624, 'shape': array([ 1, 43, 43, 16], dtype=int32), 'shape_signature': array([ 1, 43, 43, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.3483392596244812, -20), 'quantization_parameters': {'scales': array([0.34833926], dtype=float32), 'zero_points': array([-20], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/projection/conv2d/Reshape_1', 'index': 625, 'shape': array([ 1,  1, 43, 43, 16], dtype=int32), 'shape_signature': array([ 1,  1, 43, 43, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.3483392596244812, -20), 'quantization_parameters': {'scales': array([0.34833926], dtype=float32), 'zero_points': array([-20], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/rezero/mul1', 'index': 626, 'shape': array([ 1,  1, 43, 43, 16], dtype=int32), 'shape_signature': array([ 1,  1, 43, 43, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.7778176665306091, -20), 'quantization_parameters': {'scales': array([0.77781767], dtype=float32), 'zero_points': array([-20], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block0_layer2/bneck/add', 'index': 627, 'shape': array([ 1,  1, 43, 43, 16], dtype=int32), 'shape_signature': array([ 1,  1, 43, 43, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.1429635286331177, -15), 'quantization_parameters': {'scales': array([1.1429635], dtype=float32), 'zero_points': array([-15], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/expansion/conv2d/Reshape', 'index': 628, 'shape': array([ 1, 43, 43, 16], dtype=int32), 'shape_signature': array([ 1, 43, 43, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.1429635286331177, -15), 'quantization_parameters': {'scales': array([1.1429635], dtype=float32), 'zero_points': array([-15], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer0/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block1_layer0/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 629, 'shape': array([ 1, 43, 43, 96], dtype=int32), 'shape_signature': array([ 1, 43, 43, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2605106830596924, -1), 'quantization_parameters': {'scales': array([0.26051068], dtype=float32), 'zero_points': array([-1], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/expansion/conv2d/activation_63/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block1_layer0/bneck/expansion/conv2d/activation_63/Relu6;movinet_classifier_2/movinet_1/block1_layer0/bneck/expansion/conv2d/activation_63/add;movinet_classifier_2/movinet_1/block1_layer0/bneck/expansion/conv2d/activation_63/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 630, 'shape': array([ 1, 43, 43, 96], dtype=int32), 'shape_signature': array([ 1, 43, 43, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1321682184934616, -125), 'quantization_parameters': {'scales': array([0.13216822], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 631, 'shape': array([ 1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2915612459182739, 10), 'quantization_parameters': {'scales': array([0.29156125], dtype=float32), 'zero_points': array([10], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d/activation_64/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d/activation_64/Relu6;movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d/activation_64/add;movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d/activation_64/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 632, 'shape': array([ 1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1357191950082779, -125), 'quantization_parameters': {'scales': array([0.1357192], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d/Reshape_1', 'index': 633, 'shape': array([ 1,  1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1357191950082779, -125), 'quantization_parameters': {'scales': array([0.1357192], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/skip/Reshape', 'index': 634, 'shape': array([ 1, 43, 43, 16], dtype=int32), 'shape_signature': array([ 1, 43, 43, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.1429635286331177, -15), 'quantization_parameters': {'scales': array([1.1429635], dtype=float32), 'zero_points': array([-15], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/skip/skip_pool/AvgPool', 'index': 635, 'shape': array([ 1, 22, 22, 16], dtype=int32), 'shape_signature': array([ 1, 22, 22, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.1429635286331177, -15), 'quantization_parameters': {'scales': array([1.1429635], dtype=float32), 'zero_points': array([-15], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/skip/skip_project/conv2d/bn/FusedBatchNormV3;movinet_classifier_2/movinet_1/block1_layer4/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block1_layer0/bneck/skip/skip_project/conv2d/conv2d_4/Conv2D', 'index': 636, 'shape': array([ 1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4115184545516968, -9), 'quantization_parameters': {'scales': array([0.41151845], dtype=float32), 'zero_points': array([-9], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/skip/skip_project/conv2d/Reshape_1', 'index': 637, 'shape': array([ 1,  1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4115184545516968, -9), 'quantization_parameters': {'scales': array([0.41151845], dtype=float32), 'zero_points': array([-9], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:8', 'index': 638, 'shape': array([ 1,  2, 43, 43, 64], dtype=int32), 'shape_signature': array([ 1,  2, 43, 43, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.20781420171260834, -126), 'quantization_parameters': {'scales': array([0.2078142], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:10', 'index': 639, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/se/global_average_pool3d_30/Reshape', 'index': 640, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/se/global_average_pool3d_30/Cast', 'index': 641, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/stream_buffer_21/concat', 'index': 642, 'shape': array([ 1,  3, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1,  3, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1357191950082779, -125), 'quantization_parameters': {'scales': array([0.1357192], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d_temporal/Reshape', 'index': 643, 'shape': array([  1,   3, 484,  96], dtype=int32), 'shape_signature': array([  1,   3, 484,  96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1357191950082779, -125), 'quantization_parameters': {'scales': array([0.1357192], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/add_1;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul;movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 644, 'shape': array([  1,   1, 484,  96], dtype=int32), 'shape_signature': array([  1,   1, 484,  96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.35402360558509827, -9), 'quantization_parameters': {'scales': array([0.3540236], dtype=float32), 'zero_points': array([-9], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d_temporal/activation_64/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d_temporal/activation_64/Relu6;movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d_temporal/activation_64/add;movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d_temporal/activation_64/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 645, 'shape': array([  1,   1, 484,  96], dtype=int32), 'shape_signature': array([  1,   1, 484,  96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.19061167538166046, -126), 'quantization_parameters': {'scales': array([0.19061168], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/feature/conv2d_temporal/Reshape_1', 'index': 646, 'shape': array([ 1,  1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.19061167538166046, -126), 'quantization_parameters': {'scales': array([0.19061168], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/se/spatial_average_pool3d_29/Mean', 'index': 647, 'shape': array([ 1,  1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.02021806128323078, -110), 'quantization_parameters': {'scales': array([0.02021806], dtype=float32), 'zero_points': array([-110], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/se/spatial_average_pool3d_29/Mean1', 'index': 648, 'shape': array([ 1,  1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/se/global_average_pool3d_30/add_1', 'index': 649, 'shape': array([ 1,  1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2411906123161316, -85), 'quantization_parameters': {'scales': array([0.24119061], dtype=float32), 'zero_points': array([-85], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize3', 'index': 650, 'shape': array([ 1,  1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:9', 'index': 651, 'shape': array([ 1,  1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2411906123161316, -85), 'quantization_parameters': {'scales': array([0.24119061], dtype=float32), 'zero_points': array([-85], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/se/global_average_pool3d_30/truediv', 'index': 652, 'shape': array([ 1,  1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/se/concat', 'index': 653, 'shape': array([  1,   1,   1,   1, 192], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize3', 'index': 654, 'shape': array([  1,   1,   1,   1, 192], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.02021806128323078, -110), 'quantization_parameters': {'scales': array([0.02021806], dtype=float32), 'zero_points': array([-110], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_reduce/conv2d/Reshape', 'index': 655, 'shape': array([  1,   1,   1, 192], dtype=int32), 'shape_signature': array([  1,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.02021806128323078, -110), 'quantization_parameters': {'scales': array([0.02021806], dtype=float32), 'zero_points': array([-110], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 656, 'shape': array([ 1,  1,  1, 48], dtype=int32), 'shape_signature': array([ 1,  1,  1, 48], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0380399227142334, 51), 'quantization_parameters': {'scales': array([0.03803992], dtype=float32), 'zero_points': array([51], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 657, 'shape': array([ 1,  1,  1, 48], dtype=int32), 'shape_signature': array([ 1,  1,  1, 48], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.012595159932971, -98), 'quantization_parameters': {'scales': array([0.01259516], dtype=float32), 'zero_points': array([-98], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 658, 'shape': array([ 1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0226939357817173, -128), 'quantization_parameters': {'scales': array([0.02269394], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 659, 'shape': array([ 1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0037823980674147606, -128), 'quantization_parameters': {'scales': array([0.0037824], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/se/se_expand/conv2d/Reshape_1', 'index': 660, 'shape': array([ 1,  1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0037823980674147606, -128), 'quantization_parameters': {'scales': array([0.0037824], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/se/mul1', 'index': 661, 'shape': array([ 1,  1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0037823980674147606, -128), 'quantization_parameters': {'scales': array([0.0037824], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/se/mul2', 'index': 662, 'shape': array([ 1,  1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0766022652387619, -123), 'quantization_parameters': {'scales': array([0.07660227], dtype=float32), 'zero_points': array([-123], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/projection/conv2d/Reshape', 'index': 663, 'shape': array([ 1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0766022652387619, -123), 'quantization_parameters': {'scales': array([0.07660227], dtype=float32), 'zero_points': array([-123], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block1_layer4/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block1_layer0/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block1_layer0/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 664, 'shape': array([ 1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.32882454991340637, 5), 'quantization_parameters': {'scales': array([0.32882455], dtype=float32), 'zero_points': array([5], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/projection/conv2d/Reshape_1', 'index': 665, 'shape': array([ 1,  1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.32882454991340637, 5), 'quantization_parameters': {'scales': array([0.32882455], dtype=float32), 'zero_points': array([5], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/rezero/mul1', 'index': 666, 'shape': array([ 1,  1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.7317086458206177, -6), 'quantization_parameters': {'scales': array([0.73170865], dtype=float32), 'zero_points': array([-6], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer0/bneck/add', 'index': 667, 'shape': array([ 1,  1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.6967354416847229, -7), 'quantization_parameters': {'scales': array([0.69673544], dtype=float32), 'zero_points': array([-7], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/expansion/conv2d/Reshape', 'index': 668, 'shape': array([ 1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.6967354416847229, -7), 'quantization_parameters': {'scales': array([0.69673544], dtype=float32), 'zero_points': array([-7], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer1/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block1_layer1/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 669, 'shape': array([  1,  22,  22, 120], dtype=int32), 'shape_signature': array([  1,  22,  22, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.21392226219177246, 32), 'quantization_parameters': {'scales': array([0.21392226], dtype=float32), 'zero_points': array([32], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/expansion/conv2d/activation_65/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block1_layer1/bneck/expansion/conv2d/activation_65/Relu6;movinet_classifier_2/movinet_1/block1_layer1/bneck/expansion/conv2d/activation_65/add;movinet_classifier_2/movinet_1/block1_layer1/bneck/expansion/conv2d/activation_65/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 670, 'shape': array([  1,  22,  22, 120], dtype=int32), 'shape_signature': array([  1,  22,  22, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.08120240271091461, -123), 'quantization_parameters': {'scales': array([0.0812024], dtype=float32), 'zero_points': array([-123], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 671, 'shape': array([  1,  22,  22, 120], dtype=int32), 'shape_signature': array([  1,  22,  22, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2912995517253876, 6), 'quantization_parameters': {'scales': array([0.29129955], dtype=float32), 'zero_points': array([6], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d/activation_66/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d/activation_66/Relu6;movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d/activation_66/add;movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d/activation_66/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 672, 'shape': array([  1,  22,  22, 120], dtype=int32), 'shape_signature': array([  1,  22,  22, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1392422914505005, -125), 'quantization_parameters': {'scales': array([0.13924229], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d/Reshape_1', 'index': 673, 'shape': array([  1,   1,  22,  22, 120], dtype=int32), 'shape_signature': array([  1,   1,  22,  22, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1392422914505005, -125), 'quantization_parameters': {'scales': array([0.13924229], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:11', 'index': 674, 'shape': array([ 1,  2, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1,  2, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1357191950082779, -125), 'quantization_parameters': {'scales': array([0.1357192], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:13', 'index': 675, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/se/global_average_pool3d_31/Reshape', 'index': 676, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/se/global_average_pool3d_31/Cast', 'index': 677, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/stream_buffer_22/concat', 'index': 678, 'shape': array([  1,   3,  22,  22, 120], dtype=int32), 'shape_signature': array([  1,   3,  22,  22, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1392422914505005, -125), 'quantization_parameters': {'scales': array([0.13924229], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d_temporal/Reshape', 'index': 679, 'shape': array([  1,   3, 484, 120], dtype=int32), 'shape_signature': array([  1,   3, 484, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1392422914505005, -125), 'quantization_parameters': {'scales': array([0.13924229], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/add_1;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul;movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 680, 'shape': array([  1,   1, 484, 120], dtype=int32), 'shape_signature': array([  1,   1, 484, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.5599331855773926, -61), 'quantization_parameters': {'scales': array([1.5599332], dtype=float32), 'zero_points': array([-61], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d_temporal/activation_66/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d_temporal/activation_66/Relu6;movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d_temporal/activation_66/add;movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d_temporal/activation_66/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 681, 'shape': array([  1,   1, 484, 120], dtype=int32), 'shape_signature': array([  1,   1, 484, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.1513774394989014, -128), 'quantization_parameters': {'scales': array([1.1513774], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/feature/conv2d_temporal/Reshape_1', 'index': 682, 'shape': array([  1,   1,  22,  22, 120], dtype=int32), 'shape_signature': array([  1,   1,  22,  22, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.1513774394989014, -128), 'quantization_parameters': {'scales': array([1.1513774], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/se/spatial_average_pool3d_30/Mean', 'index': 683, 'shape': array([  1,   1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.03204812481999397, -117), 'quantization_parameters': {'scales': array([0.03204812], dtype=float32), 'zero_points': array([-117], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/se/spatial_average_pool3d_30/Mean1', 'index': 684, 'shape': array([  1,   1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/se/global_average_pool3d_31/add_1', 'index': 685, 'shape': array([  1,   1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.5691986680030823, -110), 'quantization_parameters': {'scales': array([0.56919867], dtype=float32), 'zero_points': array([-110], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize4', 'index': 686, 'shape': array([  1,   1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:12', 'index': 687, 'shape': array([  1,   1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.5691986680030823, -110), 'quantization_parameters': {'scales': array([0.56919867], dtype=float32), 'zero_points': array([-110], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/se/global_average_pool3d_31/truediv', 'index': 688, 'shape': array([  1,   1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/se/concat', 'index': 689, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize4', 'index': 690, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.03204812481999397, -117), 'quantization_parameters': {'scales': array([0.03204812], dtype=float32), 'zero_points': array([-117], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_reduce/conv2d/Reshape', 'index': 691, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.03204812481999397, -117), 'quantization_parameters': {'scales': array([0.03204812], dtype=float32), 'zero_points': array([-117], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 692, 'shape': array([ 1,  1,  1, 64], dtype=int32), 'shape_signature': array([ 1,  1,  1, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0568857416510582, 49), 'quantization_parameters': {'scales': array([0.05688574], dtype=float32), 'zero_points': array([49], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 693, 'shape': array([ 1,  1,  1, 64], dtype=int32), 'shape_signature': array([ 1,  1,  1, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.018913082778453827, -108), 'quantization_parameters': {'scales': array([0.01891308], dtype=float32), 'zero_points': array([-108], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 694, 'shape': array([  1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0235294122248888, -128), 'quantization_parameters': {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 695, 'shape': array([  1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00392164709046483, -128), 'quantization_parameters': {'scales': array([0.00392165], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/se/se_expand/conv2d/Reshape_1', 'index': 696, 'shape': array([  1,   1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00392164709046483, -128), 'quantization_parameters': {'scales': array([0.00392165], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/se/mul1', 'index': 697, 'shape': array([  1,   1,  22,  22, 120], dtype=int32), 'shape_signature': array([  1,   1,  22,  22, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00392164709046483, -128), 'quantization_parameters': {'scales': array([0.00392165], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/se/mul2', 'index': 698, 'shape': array([  1,   1,  22,  22, 120], dtype=int32), 'shape_signature': array([  1,   1,  22,  22, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0892169401049614, -124), 'quantization_parameters': {'scales': array([0.08921694], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/projection/conv2d/Reshape', 'index': 699, 'shape': array([  1,  22,  22, 120], dtype=int32), 'shape_signature': array([  1,  22,  22, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0892169401049614, -124), 'quantization_parameters': {'scales': array([0.08921694], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block1_layer4/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block1_layer1/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block1_layer1/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 700, 'shape': array([ 1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.27348172664642334, 8), 'quantization_parameters': {'scales': array([0.27348173], dtype=float32), 'zero_points': array([8], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/projection/conv2d/Reshape_1', 'index': 701, 'shape': array([ 1,  1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.27348172664642334, 8), 'quantization_parameters': {'scales': array([0.27348173], dtype=float32), 'zero_points': array([8], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/rezero/mul1', 'index': 702, 'shape': array([ 1,  1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.621947169303894, -9), 'quantization_parameters': {'scales': array([0.62194717], dtype=float32), 'zero_points': array([-9], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer1/bneck/add', 'index': 703, 'shape': array([ 1,  1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.720667839050293, -1), 'quantization_parameters': {'scales': array([0.72066784], dtype=float32), 'zero_points': array([-1], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/expansion/conv2d/Reshape', 'index': 704, 'shape': array([ 1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.720667839050293, -1), 'quantization_parameters': {'scales': array([0.72066784], dtype=float32), 'zero_points': array([-1], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer2/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block1_layer2/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 705, 'shape': array([ 1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.22879749536514282, -9), 'quantization_parameters': {'scales': array([0.2287975], dtype=float32), 'zero_points': array([-9], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/expansion/conv2d/activation_67/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block1_layer2/bneck/expansion/conv2d/activation_67/Relu6;movinet_classifier_2/movinet_1/block1_layer2/bneck/expansion/conv2d/activation_67/add;movinet_classifier_2/movinet_1/block1_layer2/bneck/expansion/conv2d/activation_67/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 706, 'shape': array([ 1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.12337317317724228, -125), 'quantization_parameters': {'scales': array([0.12337317], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 707, 'shape': array([ 1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2679089605808258, -40), 'quantization_parameters': {'scales': array([0.26790896], dtype=float32), 'zero_points': array([-40], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d/activation_68/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d/activation_68/Relu6;movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d/activation_68/add;movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d/activation_68/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 708, 'shape': array([ 1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.17720718681812286, -126), 'quantization_parameters': {'scales': array([0.17720719], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d/Reshape_1', 'index': 709, 'shape': array([ 1,  1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.17720718681812286, -126), 'quantization_parameters': {'scales': array([0.17720719], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:14', 'index': 710, 'shape': array([  1,   2,  22,  22, 120], dtype=int32), 'shape_signature': array([  1,   2,  22,  22, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1392422914505005, -125), 'quantization_parameters': {'scales': array([0.13924229], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:16', 'index': 711, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/se/global_average_pool3d_32/Reshape', 'index': 712, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/se/global_average_pool3d_32/Cast', 'index': 713, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/stream_buffer_23/concat', 'index': 714, 'shape': array([ 1,  3, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1,  3, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.17720718681812286, -126), 'quantization_parameters': {'scales': array([0.17720719], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d_temporal/Reshape', 'index': 715, 'shape': array([  1,   3, 484,  96], dtype=int32), 'shape_signature': array([  1,   3, 484,  96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.17720718681812286, -126), 'quantization_parameters': {'scales': array([0.17720719], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/add_1;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul;movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 716, 'shape': array([  1,   1, 484,  96], dtype=int32), 'shape_signature': array([  1,   1, 484,  96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.8154394626617432, -85), 'quantization_parameters': {'scales': array([0.81543946], dtype=float32), 'zero_points': array([-85], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d_temporal/activation_68/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d_temporal/activation_68/Relu6;movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d_temporal/activation_68/add;movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d_temporal/activation_68/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 717, 'shape': array([  1,   1, 484,  96], dtype=int32), 'shape_signature': array([  1,   1, 484,  96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.6782182455062866, -127), 'quantization_parameters': {'scales': array([0.67821825], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/feature/conv2d_temporal/Reshape_1', 'index': 718, 'shape': array([ 1,  1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.6782182455062866, -127), 'quantization_parameters': {'scales': array([0.67821825], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/se/spatial_average_pool3d_31/Mean', 'index': 719, 'shape': array([ 1,  1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.021326204761862755, -112), 'quantization_parameters': {'scales': array([0.0213262], dtype=float32), 'zero_points': array([-112], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/se/spatial_average_pool3d_31/Mean1', 'index': 720, 'shape': array([ 1,  1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/se/global_average_pool3d_32/add_1', 'index': 721, 'shape': array([ 1,  1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2898816466331482, -94), 'quantization_parameters': {'scales': array([0.28988165], dtype=float32), 'zero_points': array([-94], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize5', 'index': 722, 'shape': array([ 1,  1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:15', 'index': 723, 'shape': array([ 1,  1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2898816466331482, -94), 'quantization_parameters': {'scales': array([0.28988165], dtype=float32), 'zero_points': array([-94], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/se/global_average_pool3d_32/truediv', 'index': 724, 'shape': array([ 1,  1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/se/concat', 'index': 725, 'shape': array([  1,   1,   1,   1, 192], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize5', 'index': 726, 'shape': array([  1,   1,   1,   1, 192], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.021326204761862755, -112), 'quantization_parameters': {'scales': array([0.0213262], dtype=float32), 'zero_points': array([-112], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/se/se_reduce/conv2d/Reshape', 'index': 727, 'shape': array([  1,   1,   1, 192], dtype=int32), 'shape_signature': array([  1,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.021326204761862755, -112), 'quantization_parameters': {'scales': array([0.0213262], dtype=float32), 'zero_points': array([-112], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer2/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer2/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 728, 'shape': array([ 1,  1,  1, 48], dtype=int32), 'shape_signature': array([ 1,  1,  1, 48], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04498632252216339, 51), 'quantization_parameters': {'scales': array([0.04498632], dtype=float32), 'zero_points': array([51], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block1_layer2/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block1_layer2/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block1_layer2/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 729, 'shape': array([ 1,  1,  1, 48], dtype=int32), 'shape_signature': array([ 1,  1,  1, 48], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.014808550477027893, -103), 'quantization_parameters': {'scales': array([0.01480855], dtype=float32), 'zero_points': array([-103], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block1_layer2/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block1_layer2/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block1_layer2/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer2/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 730, 'shape': array([ 1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.021740810945630074, -128), 'quantization_parameters': {'scales': array([0.02174081], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 731, 'shape': array([ 1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.003623540746048093, -128), 'quantization_parameters': {'scales': array([0.00362354], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/se/se_expand/conv2d/Reshape_1', 'index': 732, 'shape': array([ 1,  1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.003623540746048093, -128), 'quantization_parameters': {'scales': array([0.00362354], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/se/mul', 'index': 733, 'shape': array([ 1,  1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.003623540746048093, -128), 'quantization_parameters': {'scales': array([0.00362354], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/se/mul1', 'index': 734, 'shape': array([ 1,  1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.06311937421560287, -123), 'quantization_parameters': {'scales': array([0.06311937], dtype=float32), 'zero_points': array([-123], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/projection/conv2d/Reshape', 'index': 735, 'shape': array([ 1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.06311937421560287, -123), 'quantization_parameters': {'scales': array([0.06311937], dtype=float32), 'zero_points': array([-123], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block1_layer4/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block1_layer2/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block1_layer2/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 736, 'shape': array([ 1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.14696817100048065, -8), 'quantization_parameters': {'scales': array([0.14696817], dtype=float32), 'zero_points': array([-8], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/projection/conv2d/Reshape_1', 'index': 737, 'shape': array([ 1,  1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.14696817100048065, -8), 'quantization_parameters': {'scales': array([0.14696817], dtype=float32), 'zero_points': array([-8], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/rezero/mul1', 'index': 738, 'shape': array([ 1,  1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.31531694531440735, 7), 'quantization_parameters': {'scales': array([0.31531695], dtype=float32), 'zero_points': array([7], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer2/bneck/add', 'index': 739, 'shape': array([ 1,  1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.7814055681228638, -5), 'quantization_parameters': {'scales': array([0.78140557], dtype=float32), 'zero_points': array([-5], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/expansion/conv2d/Reshape', 'index': 740, 'shape': array([ 1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.7814055681228638, -5), 'quantization_parameters': {'scales': array([0.78140557], dtype=float32), 'zero_points': array([-5], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer3/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block1_layer3/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 741, 'shape': array([ 1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.14389263093471527, -19), 'quantization_parameters': {'scales': array([0.14389263], dtype=float32), 'zero_points': array([-19], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/expansion/conv2d/activation_69/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block1_layer3/bneck/expansion/conv2d/activation_69/Relu6;movinet_classifier_2/movinet_1/block1_layer3/bneck/expansion/conv2d/activation_69/add;movinet_classifier_2/movinet_1/block1_layer3/bneck/expansion/conv2d/activation_69/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 742, 'shape': array([ 1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.08362610638141632, -124), 'quantization_parameters': {'scales': array([0.08362611], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 743, 'shape': array([ 1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2651994824409485, -43), 'quantization_parameters': {'scales': array([0.26519948], dtype=float32), 'zero_points': array([-43], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d/activation_70/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d/activation_70/Relu6;movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d/activation_70/add;movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d/activation_70/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 744, 'shape': array([ 1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1880284696817398, -126), 'quantization_parameters': {'scales': array([0.18802847], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d/Reshape_1', 'index': 745, 'shape': array([ 1,  1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1880284696817398, -126), 'quantization_parameters': {'scales': array([0.18802847], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:17', 'index': 746, 'shape': array([ 1,  2, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1,  2, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.17720718681812286, -126), 'quantization_parameters': {'scales': array([0.17720719], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:19', 'index': 747, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/se/global_average_pool3d_33/Reshape', 'index': 748, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/se/global_average_pool3d_33/Cast', 'index': 749, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/stream_buffer_24/concat', 'index': 750, 'shape': array([ 1,  3, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1,  3, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1880284696817398, -126), 'quantization_parameters': {'scales': array([0.18802847], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d_temporal/Reshape', 'index': 751, 'shape': array([  1,   3, 484,  96], dtype=int32), 'shape_signature': array([  1,   3, 484,  96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1880284696817398, -126), 'quantization_parameters': {'scales': array([0.18802847], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/add_1;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul;movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 752, 'shape': array([  1,   1, 484,  96], dtype=int32), 'shape_signature': array([  1,   1, 484,  96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.3070600032806396, -39), 'quantization_parameters': {'scales': array([1.30706], dtype=float32), 'zero_points': array([-39], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d_temporal/activation_70/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d_temporal/activation_70/Relu6;movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d_temporal/activation_70/add;movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d_temporal/activation_70/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 753, 'shape': array([  1,   1, 484,  96], dtype=int32), 'shape_signature': array([  1,   1, 484,  96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.8524154424667358, -128), 'quantization_parameters': {'scales': array([0.85241544], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/feature/conv2d_temporal/Reshape_1', 'index': 754, 'shape': array([ 1,  1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.8524154424667358, -128), 'quantization_parameters': {'scales': array([0.85241544], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/se/spatial_average_pool3d_32/Mean', 'index': 755, 'shape': array([ 1,  1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.031695444136857986, -117), 'quantization_parameters': {'scales': array([0.03169544], dtype=float32), 'zero_points': array([-117], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/se/spatial_average_pool3d_32/Mean1', 'index': 756, 'shape': array([ 1,  1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/se/global_average_pool3d_33/add_1', 'index': 757, 'shape': array([ 1,  1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.6833214163780212, -113), 'quantization_parameters': {'scales': array([0.6833214], dtype=float32), 'zero_points': array([-113], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize6', 'index': 758, 'shape': array([ 1,  1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:18', 'index': 759, 'shape': array([ 1,  1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.6833214163780212, -113), 'quantization_parameters': {'scales': array([0.6833214], dtype=float32), 'zero_points': array([-113], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/se/global_average_pool3d_33/truediv', 'index': 760, 'shape': array([ 1,  1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/se/concat', 'index': 761, 'shape': array([  1,   1,   1,   1, 192], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize6', 'index': 762, 'shape': array([  1,   1,   1,   1, 192], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.031695444136857986, -117), 'quantization_parameters': {'scales': array([0.03169544], dtype=float32), 'zero_points': array([-117], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_reduce/conv2d/Reshape', 'index': 763, 'shape': array([  1,   1,   1, 192], dtype=int32), 'shape_signature': array([  1,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.031695444136857986, -117), 'quantization_parameters': {'scales': array([0.03169544], dtype=float32), 'zero_points': array([-117], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 764, 'shape': array([ 1,  1,  1, 48], dtype=int32), 'shape_signature': array([ 1,  1,  1, 48], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.05265473574399948, 75), 'quantization_parameters': {'scales': array([0.05265474], dtype=float32), 'zero_points': array([75], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 765, 'shape': array([ 1,  1,  1, 48], dtype=int32), 'shape_signature': array([ 1,  1,  1, 48], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.01168434415012598, -96), 'quantization_parameters': {'scales': array([0.01168434], dtype=float32), 'zero_points': array([-96], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 766, 'shape': array([ 1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.022565117105841637, -128), 'quantization_parameters': {'scales': array([0.02256512], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 767, 'shape': array([ 1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0037609280552715063, -128), 'quantization_parameters': {'scales': array([0.00376093], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/se/se_expand/conv2d/Reshape_1', 'index': 768, 'shape': array([ 1,  1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0037609280552715063, -128), 'quantization_parameters': {'scales': array([0.00376093], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/se/mul', 'index': 769, 'shape': array([ 1,  1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0037609280552715063, -128), 'quantization_parameters': {'scales': array([0.00376093], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/se/mul1', 'index': 770, 'shape': array([ 1,  1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04739709571003914, -120), 'quantization_parameters': {'scales': array([0.0473971], dtype=float32), 'zero_points': array([-120], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/projection/conv2d/Reshape', 'index': 771, 'shape': array([ 1, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04739709571003914, -120), 'quantization_parameters': {'scales': array([0.0473971], dtype=float32), 'zero_points': array([-120], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block1_layer4/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block1_layer3/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block1_layer3/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 772, 'shape': array([ 1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.20682862401008606, -1), 'quantization_parameters': {'scales': array([0.20682862], dtype=float32), 'zero_points': array([-1], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/projection/conv2d/Reshape_1', 'index': 773, 'shape': array([ 1,  1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.20682862401008606, -1), 'quantization_parameters': {'scales': array([0.20682862], dtype=float32), 'zero_points': array([-1], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/rezero/mul1', 'index': 774, 'shape': array([ 1,  1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4443524479866028, -1), 'quantization_parameters': {'scales': array([0.44435245], dtype=float32), 'zero_points': array([-1], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer3/bneck/add', 'index': 775, 'shape': array([ 1,  1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.8496330976486206, -10), 'quantization_parameters': {'scales': array([0.8496331], dtype=float32), 'zero_points': array([-10], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/expansion/conv2d/Reshape', 'index': 776, 'shape': array([ 1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.8496330976486206, -10), 'quantization_parameters': {'scales': array([0.8496331], dtype=float32), 'zero_points': array([-10], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer4/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block1_layer4/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 777, 'shape': array([  1,  22,  22, 120], dtype=int32), 'shape_signature': array([  1,  22,  22, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.13486795127391815, 3), 'quantization_parameters': {'scales': array([0.13486795], dtype=float32), 'zero_points': array([3], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/expansion/conv2d/activation_71/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block1_layer4/bneck/expansion/conv2d/activation_71/Relu6;movinet_classifier_2/movinet_1/block1_layer4/bneck/expansion/conv2d/activation_71/add;movinet_classifier_2/movinet_1/block1_layer4/bneck/expansion/conv2d/activation_71/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 778, 'shape': array([  1,  22,  22, 120], dtype=int32), 'shape_signature': array([  1,  22,  22, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.06679081916809082, -122), 'quantization_parameters': {'scales': array([0.06679082], dtype=float32), 'zero_points': array([-122], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 779, 'shape': array([  1,  22,  22, 120], dtype=int32), 'shape_signature': array([  1,  22,  22, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.32466772198677063, -60), 'quantization_parameters': {'scales': array([0.32466772], dtype=float32), 'zero_points': array([-60], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d/activation_72/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d/activation_72/Relu6;movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d/activation_72/add;movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d/activation_72/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 780, 'shape': array([  1,  22,  22, 120], dtype=int32), 'shape_signature': array([  1,  22,  22, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.23924721777439117, -126), 'quantization_parameters': {'scales': array([0.23924722], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d/Reshape_1', 'index': 781, 'shape': array([  1,   1,  22,  22, 120], dtype=int32), 'shape_signature': array([  1,   1,  22,  22, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.23924721777439117, -126), 'quantization_parameters': {'scales': array([0.23924722], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:20', 'index': 782, 'shape': array([ 1,  2, 22, 22, 96], dtype=int32), 'shape_signature': array([ 1,  2, 22, 22, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1880284696817398, -126), 'quantization_parameters': {'scales': array([0.18802847], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:22', 'index': 783, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/se/global_average_pool3d_34/Reshape', 'index': 784, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/se/global_average_pool3d_34/Cast', 'index': 785, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/stream_buffer_25/concat', 'index': 786, 'shape': array([  1,   3,  22,  22, 120], dtype=int32), 'shape_signature': array([  1,   3,  22,  22, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.23924721777439117, -126), 'quantization_parameters': {'scales': array([0.23924722], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d_temporal/Reshape', 'index': 787, 'shape': array([  1,   3, 484, 120], dtype=int32), 'shape_signature': array([  1,   3, 484, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.23924721777439117, -126), 'quantization_parameters': {'scales': array([0.23924722], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/add_1;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul;movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 788, 'shape': array([  1,   1, 484, 120], dtype=int32), 'shape_signature': array([  1,   1, 484, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.5580756068229675, -56), 'quantization_parameters': {'scales': array([0.5580756], dtype=float32), 'zero_points': array([-56], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d_temporal/activation_72/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d_temporal/activation_72/Relu6;movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d_temporal/activation_72/add;movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d_temporal/activation_72/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 789, 'shape': array([  1,   1, 484, 120], dtype=int32), 'shape_signature': array([  1,   1, 484, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4028622508049011, -127), 'quantization_parameters': {'scales': array([0.40286225], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/feature/conv2d_temporal/Reshape_1', 'index': 790, 'shape': array([  1,   1,  22,  22, 120], dtype=int32), 'shape_signature': array([  1,   1,  22,  22, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4028622508049011, -127), 'quantization_parameters': {'scales': array([0.40286225], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/se/spatial_average_pool3d_33/Mean', 'index': 791, 'shape': array([  1,   1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.020237155258655548, -110), 'quantization_parameters': {'scales': array([0.02023716], dtype=float32), 'zero_points': array([-110], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/se/spatial_average_pool3d_33/Mean1', 'index': 792, 'shape': array([  1,   1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/se/global_average_pool3d_34/add_1', 'index': 793, 'shape': array([  1,   1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.3323576748371124, -95), 'quantization_parameters': {'scales': array([0.33235767], dtype=float32), 'zero_points': array([-95], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize7', 'index': 794, 'shape': array([  1,   1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:21', 'index': 795, 'shape': array([  1,   1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.3323576748371124, -95), 'quantization_parameters': {'scales': array([0.33235767], dtype=float32), 'zero_points': array([-95], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/se/global_average_pool3d_34/truediv', 'index': 796, 'shape': array([  1,   1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/se/concat', 'index': 797, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize7', 'index': 798, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.020237155258655548, -110), 'quantization_parameters': {'scales': array([0.02023716], dtype=float32), 'zero_points': array([-110], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_reduce/conv2d/Reshape', 'index': 799, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.020237155258655548, -110), 'quantization_parameters': {'scales': array([0.02023716], dtype=float32), 'zero_points': array([-110], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 800, 'shape': array([ 1,  1,  1, 64], dtype=int32), 'shape_signature': array([ 1,  1,  1, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04248795285820961, 40), 'quantization_parameters': {'scales': array([0.04248795], dtype=float32), 'zero_points': array([40], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 801, 'shape': array([ 1,  1,  1, 64], dtype=int32), 'shape_signature': array([ 1,  1,  1, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.01588534191250801, -104), 'quantization_parameters': {'scales': array([0.01588534], dtype=float32), 'zero_points': array([-104], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 802, 'shape': array([  1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.022466357797384262, -128), 'quantization_parameters': {'scales': array([0.02246636], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 803, 'shape': array([  1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0037444678600877523, -128), 'quantization_parameters': {'scales': array([0.00374447], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/se/se_expand/conv2d/Reshape_1', 'index': 804, 'shape': array([  1,   1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0037444678600877523, -128), 'quantization_parameters': {'scales': array([0.00374447], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/se/mul', 'index': 805, 'shape': array([  1,   1,  22,  22, 120], dtype=int32), 'shape_signature': array([  1,   1,  22,  22, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0037444678600877523, -128), 'quantization_parameters': {'scales': array([0.00374447], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/se/mul1', 'index': 806, 'shape': array([  1,   1,  22,  22, 120], dtype=int32), 'shape_signature': array([  1,   1,  22,  22, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.06594856083393097, -123), 'quantization_parameters': {'scales': array([0.06594856], dtype=float32), 'zero_points': array([-123], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/projection/conv2d/Reshape', 'index': 807, 'shape': array([  1,  22,  22, 120], dtype=int32), 'shape_signature': array([  1,  22,  22, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.06594856083393097, -123), 'quantization_parameters': {'scales': array([0.06594856], dtype=float32), 'zero_points': array([-123], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block1_layer4/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block1_layer4/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 808, 'shape': array([ 1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2162443995475769, -16), 'quantization_parameters': {'scales': array([0.2162444], dtype=float32), 'zero_points': array([-16], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/projection/conv2d/Reshape_1', 'index': 809, 'shape': array([ 1,  1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2162443995475769, -16), 'quantization_parameters': {'scales': array([0.2162444], dtype=float32), 'zero_points': array([-16], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/rezero/mul1', 'index': 810, 'shape': array([ 1,  1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.5415898561477661, -16), 'quantization_parameters': {'scales': array([0.54158986], dtype=float32), 'zero_points': array([-16], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block1_layer4/bneck/add', 'index': 811, 'shape': array([ 1,  1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1,  1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.9649885296821594, -4), 'quantization_parameters': {'scales': array([0.9649885], dtype=float32), 'zero_points': array([-4], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/expansion/conv2d/Reshape', 'index': 812, 'shape': array([ 1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.9649885296821594, -4), 'quantization_parameters': {'scales': array([0.9649885], dtype=float32), 'zero_points': array([-4], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer0/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block2_layer0/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 813, 'shape': array([  1,  22,  22, 240], dtype=int32), 'shape_signature': array([  1,  22,  22, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.15250800549983978, 45), 'quantization_parameters': {'scales': array([0.152508], dtype=float32), 'zero_points': array([45], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/expansion/conv2d/activation_73/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block2_layer0/bneck/expansion/conv2d/activation_73/Relu6;movinet_classifier_2/movinet_1/block2_layer0/bneck/expansion/conv2d/activation_73/add;movinet_classifier_2/movinet_1/block2_layer0/bneck/expansion/conv2d/activation_73/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 814, 'shape': array([  1,  22,  22, 240], dtype=int32), 'shape_signature': array([  1,  22,  22, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.050362441688776016, -121), 'quantization_parameters': {'scales': array([0.05036244], dtype=float32), 'zero_points': array([-121], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 815, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.16428795456886292, -32), 'quantization_parameters': {'scales': array([0.16428795], dtype=float32), 'zero_points': array([-32], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d/activation_74/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d/activation_74/Relu6;movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d/activation_74/add;movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d/activation_74/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 816, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11277470737695694, -125), 'quantization_parameters': {'scales': array([0.11277471], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d/Reshape_1', 'index': 817, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11277470737695694, -125), 'quantization_parameters': {'scales': array([0.11277471], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/skip/Reshape', 'index': 818, 'shape': array([ 1, 22, 22, 40], dtype=int32), 'shape_signature': array([ 1, 22, 22, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.9649885296821594, -4), 'quantization_parameters': {'scales': array([0.9649885], dtype=float32), 'zero_points': array([-4], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/skip/skip_pool/AvgPool', 'index': 819, 'shape': array([ 1, 11, 11, 40], dtype=int32), 'shape_signature': array([ 1, 11, 11, 40], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.9649885296821594, -4), 'quantization_parameters': {'scales': array([0.9649885], dtype=float32), 'zero_points': array([-4], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/skip/skip_project/conv2d/bn/FusedBatchNormV3;movinet_classifier_2/movinet_1/block3_layer5/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block2_layer0/bneck/skip/skip_project/conv2d/conv2d_4/Conv2D', 'index': 820, 'shape': array([ 1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4172159731388092, 26), 'quantization_parameters': {'scales': array([0.41721597], dtype=float32), 'zero_points': array([26], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/skip/skip_project/conv2d/Reshape_1', 'index': 821, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4172159731388092, 26), 'quantization_parameters': {'scales': array([0.41721597], dtype=float32), 'zero_points': array([26], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:23', 'index': 822, 'shape': array([  1,   2,  22,  22, 120], dtype=int32), 'shape_signature': array([  1,   2,  22,  22, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.23924721777439117, -126), 'quantization_parameters': {'scales': array([0.23924722], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:25', 'index': 823, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/se/global_average_pool3d_35/Reshape', 'index': 824, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/se/global_average_pool3d_35/Cast', 'index': 825, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/stream_buffer_26/concat', 'index': 826, 'shape': array([  1,   5,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   5,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11277470737695694, -125), 'quantization_parameters': {'scales': array([0.11277471], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d_temporal/Reshape', 'index': 827, 'shape': array([  1,   5, 121, 240], dtype=int32), 'shape_signature': array([  1,   5, 121, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11277470737695694, -125), 'quantization_parameters': {'scales': array([0.11277471], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul;movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 828, 'shape': array([  1,   1, 121, 240], dtype=int32), 'shape_signature': array([  1,   1, 121, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.5511337518692017, -46), 'quantization_parameters': {'scales': array([0.55113375], dtype=float32), 'zero_points': array([-46], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d_temporal/activation_74/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d_temporal/activation_74/Relu6;movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d_temporal/activation_74/add;movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d_temporal/activation_74/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 829, 'shape': array([  1,   1, 121, 240], dtype=int32), 'shape_signature': array([  1,   1, 121, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.376414030790329, -127), 'quantization_parameters': {'scales': array([0.37641403], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/feature/conv2d_temporal/Reshape_1', 'index': 830, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.376414030790329, -127), 'quantization_parameters': {'scales': array([0.37641403], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/se/spatial_average_pool3d_34/Mean', 'index': 831, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.025793444365262985, -114), 'quantization_parameters': {'scales': array([0.02579344], dtype=float32), 'zero_points': array([-114], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/se/spatial_average_pool3d_34/Mean1', 'index': 832, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/se/global_average_pool3d_35/add_1', 'index': 833, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4887387752532959, -107), 'quantization_parameters': {'scales': array([0.48873878], dtype=float32), 'zero_points': array([-107], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize8', 'index': 834, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:24', 'index': 835, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4887387752532959, -107), 'quantization_parameters': {'scales': array([0.48873878], dtype=float32), 'zero_points': array([-107], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/se/global_average_pool3d_35/truediv', 'index': 836, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/se/concat', 'index': 837, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize8', 'index': 838, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.025793444365262985, -114), 'quantization_parameters': {'scales': array([0.02579344], dtype=float32), 'zero_points': array([-114], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_reduce/conv2d/Reshape', 'index': 839, 'shape': array([  1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.025793444365262985, -114), 'quantization_parameters': {'scales': array([0.02579344], dtype=float32), 'zero_points': array([-114], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 840, 'shape': array([  1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.05957596004009247, 30), 'quantization_parameters': {'scales': array([0.05957596], dtype=float32), 'zero_points': array([30], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 841, 'shape': array([  1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.024159086868166924, -112), 'quantization_parameters': {'scales': array([0.02415909], dtype=float32), 'zero_points': array([-112], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 842, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0235294122248888, -128), 'quantization_parameters': {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 843, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00392164709046483, -128), 'quantization_parameters': {'scales': array([0.00392165], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/se/se_expand/conv2d/Reshape_1', 'index': 844, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00392164709046483, -128), 'quantization_parameters': {'scales': array([0.00392165], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/se/mul1', 'index': 845, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00392164709046483, -128), 'quantization_parameters': {'scales': array([0.00392165], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/se/mul2', 'index': 846, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.05831005051732063, -122), 'quantization_parameters': {'scales': array([0.05831005], dtype=float32), 'zero_points': array([-122], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/projection/conv2d/Reshape', 'index': 847, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.05831005051732063, -122), 'quantization_parameters': {'scales': array([0.05831005], dtype=float32), 'zero_points': array([-122], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block3_layer5/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block2_layer0/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block2_layer0/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 848, 'shape': array([ 1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.13750146329402924, -4), 'quantization_parameters': {'scales': array([0.13750146], dtype=float32), 'zero_points': array([-4], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/projection/conv2d/Reshape_1', 'index': 849, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.13750146329402924, -4), 'quantization_parameters': {'scales': array([0.13750146], dtype=float32), 'zero_points': array([-4], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/rezero/mul1', 'index': 850, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2870393693447113, 3), 'quantization_parameters': {'scales': array([0.28703937], dtype=float32), 'zero_points': array([3], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer0/bneck/add', 'index': 851, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.6270672082901001, 28), 'quantization_parameters': {'scales': array([0.6270672], dtype=float32), 'zero_points': array([28], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/expansion/conv2d/Reshape', 'index': 852, 'shape': array([ 1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.6270672082901001, 28), 'quantization_parameters': {'scales': array([0.6270672], dtype=float32), 'zero_points': array([28], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block2_layer1/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block2_layer1/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 853, 'shape': array([  1,  11,  11, 160], dtype=int32), 'shape_signature': array([  1,  11,  11, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10264729708433151, -16), 'quantization_parameters': {'scales': array([0.1026473], dtype=float32), 'zero_points': array([-16], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/expansion/conv2d/activation_75/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block2_layer1/bneck/expansion/conv2d/activation_75/Relu6;movinet_classifier_2/movinet_1/block2_layer1/bneck/expansion/conv2d/activation_75/add;movinet_classifier_2/movinet_1/block2_layer1/bneck/expansion/conv2d/activation_75/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 854, 'shape': array([  1,  11,  11, 160], dtype=int32), 'shape_signature': array([  1,  11,  11, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.05916706845164299, -122), 'quantization_parameters': {'scales': array([0.05916707], dtype=float32), 'zero_points': array([-122], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 855, 'shape': array([  1,  11,  11, 160], dtype=int32), 'shape_signature': array([  1,  11,  11, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.20981146395206451, -22), 'quantization_parameters': {'scales': array([0.20981146], dtype=float32), 'zero_points': array([-22], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d/activation_76/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d/activation_76/Relu6;movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d/activation_76/add;movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d/activation_76/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 856, 'shape': array([  1,  11,  11, 160], dtype=int32), 'shape_signature': array([  1,  11,  11, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.12421826273202896, -125), 'quantization_parameters': {'scales': array([0.12421826], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d/Reshape_1', 'index': 857, 'shape': array([  1,   1,  11,  11, 160], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.12421826273202896, -125), 'quantization_parameters': {'scales': array([0.12421826], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:26', 'index': 858, 'shape': array([  1,   4,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   4,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11277470737695694, -125), 'quantization_parameters': {'scales': array([0.11277471], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:28', 'index': 859, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/se/global_average_pool3d_36/Reshape', 'index': 860, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/se/global_average_pool3d_36/Cast', 'index': 861, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/stream_buffer_27/concat', 'index': 862, 'shape': array([  1,   3,  11,  11, 160], dtype=int32), 'shape_signature': array([  1,   3,  11,  11, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.12421826273202896, -125), 'quantization_parameters': {'scales': array([0.12421826], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d_temporal/Reshape', 'index': 863, 'shape': array([  1,   3, 121, 160], dtype=int32), 'shape_signature': array([  1,   3, 121, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.12421826273202896, -125), 'quantization_parameters': {'scales': array([0.12421826], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/add_1;movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul;movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 864, 'shape': array([  1,   1, 121, 160], dtype=int32), 'shape_signature': array([  1,   1, 121, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.36841386556625366, -56), 'quantization_parameters': {'scales': array([0.36841387], dtype=float32), 'zero_points': array([-56], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d_temporal/activation_76/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d_temporal/activation_76/Relu6;movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d_temporal/activation_76/add;movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d_temporal/activation_76/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 865, 'shape': array([  1,   1, 121, 160], dtype=int32), 'shape_signature': array([  1,   1, 121, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2663643956184387, -127), 'quantization_parameters': {'scales': array([0.2663644], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/feature/conv2d_temporal/Reshape_1', 'index': 866, 'shape': array([  1,   1,  11,  11, 160], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2663643956184387, -127), 'quantization_parameters': {'scales': array([0.2663644], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/se/spatial_average_pool3d_35/Mean', 'index': 867, 'shape': array([  1,   1,   1,   1, 160], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.03830680251121521, -118), 'quantization_parameters': {'scales': array([0.0383068], dtype=float32), 'zero_points': array([-118], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/se/spatial_average_pool3d_35/Mean1', 'index': 868, 'shape': array([  1,   1,   1,   1, 160], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 160], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/se/global_average_pool3d_36/add_1', 'index': 869, 'shape': array([  1,   1,   1,   1, 160], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.5530773401260376, -109), 'quantization_parameters': {'scales': array([0.55307734], dtype=float32), 'zero_points': array([-109], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize9', 'index': 870, 'shape': array([  1,   1,   1,   1, 160], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 160], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:27', 'index': 871, 'shape': array([  1,   1,   1,   1, 160], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.5530773401260376, -109), 'quantization_parameters': {'scales': array([0.55307734], dtype=float32), 'zero_points': array([-109], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/se/global_average_pool3d_36/truediv', 'index': 872, 'shape': array([  1,   1,   1,   1, 160], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 160], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/se/concat', 'index': 873, 'shape': array([  1,   1,   1,   1, 320], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 320], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize9', 'index': 874, 'shape': array([  1,   1,   1,   1, 320], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 320], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.03830680251121521, -118), 'quantization_parameters': {'scales': array([0.0383068], dtype=float32), 'zero_points': array([-118], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_reduce/conv2d/Reshape', 'index': 875, 'shape': array([  1,   1,   1, 320], dtype=int32), 'shape_signature': array([  1,   1,   1, 320], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.03830680251121521, -118), 'quantization_parameters': {'scales': array([0.0383068], dtype=float32), 'zero_points': array([-118], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 876, 'shape': array([ 1,  1,  1, 80], dtype=int32), 'shape_signature': array([ 1,  1,  1, 80], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04864545911550522, 47), 'quantization_parameters': {'scales': array([0.04864546], dtype=float32), 'zero_points': array([47], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 877, 'shape': array([ 1,  1,  1, 80], dtype=int32), 'shape_signature': array([ 1,  1,  1, 80], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.016694845631718636, -106), 'quantization_parameters': {'scales': array([0.01669485], dtype=float32), 'zero_points': array([-106], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 878, 'shape': array([  1,   1,   1, 160], dtype=int32), 'shape_signature': array([  1,   1,   1, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.022002605721354485, -128), 'quantization_parameters': {'scales': array([0.02200261], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 879, 'shape': array([  1,   1,   1, 160], dtype=int32), 'shape_signature': array([  1,   1,   1, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0036671741399914026, -128), 'quantization_parameters': {'scales': array([0.00366717], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/se/se_expand/conv2d/Reshape_1', 'index': 880, 'shape': array([  1,   1,   1,   1, 160], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0036671741399914026, -128), 'quantization_parameters': {'scales': array([0.00366717], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/se/mul1', 'index': 881, 'shape': array([  1,   1,  11,  11, 160], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0036671741399914026, -128), 'quantization_parameters': {'scales': array([0.00366717], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/se/mul2', 'index': 882, 'shape': array([  1,   1,  11,  11, 160], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.026454156264662743, -115), 'quantization_parameters': {'scales': array([0.02645416], dtype=float32), 'zero_points': array([-115], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/projection/conv2d/Reshape', 'index': 883, 'shape': array([  1,  11,  11, 160], dtype=int32), 'shape_signature': array([  1,  11,  11, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.026454156264662743, -115), 'quantization_parameters': {'scales': array([0.02645416], dtype=float32), 'zero_points': array([-115], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block3_layer5/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block2_layer1/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block2_layer1/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 884, 'shape': array([ 1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.12034210562705994, 18), 'quantization_parameters': {'scales': array([0.12034211], dtype=float32), 'zero_points': array([18], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/projection/conv2d/Reshape_1', 'index': 885, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.12034210562705994, 18), 'quantization_parameters': {'scales': array([0.12034211], dtype=float32), 'zero_points': array([18], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/rezero/mul1', 'index': 886, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2140474170446396, 18), 'quantization_parameters': {'scales': array([0.21404742], dtype=float32), 'zero_points': array([18], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer1/bneck/add', 'index': 887, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.7020654678344727, 22), 'quantization_parameters': {'scales': array([0.70206547], dtype=float32), 'zero_points': array([22], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/expansion/conv2d/Reshape', 'index': 888, 'shape': array([ 1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.7020654678344727, 22), 'quantization_parameters': {'scales': array([0.70206547], dtype=float32), 'zero_points': array([22], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer2/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block2_layer2/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 889, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.13882161676883698, -29), 'quantization_parameters': {'scales': array([0.13882162], dtype=float32), 'zero_points': array([-29], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/expansion/conv2d/activation_77/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block2_layer2/bneck/expansion/conv2d/activation_77/Relu6;movinet_classifier_2/movinet_1/block2_layer2/bneck/expansion/conv2d/activation_77/add;movinet_classifier_2/movinet_1/block2_layer2/bneck/expansion/conv2d/activation_77/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 890, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.08642733097076416, -124), 'quantization_parameters': {'scales': array([0.08642733], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 891, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.20069274306297302, -3), 'quantization_parameters': {'scales': array([0.20069274], dtype=float32), 'zero_points': array([-3], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d/activation_78/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d/activation_78/Relu6;movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d/activation_78/add;movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d/activation_78/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 892, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10641761869192123, -124), 'quantization_parameters': {'scales': array([0.10641762], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d/Reshape_1', 'index': 893, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10641761869192123, -124), 'quantization_parameters': {'scales': array([0.10641762], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:29', 'index': 894, 'shape': array([  1,   2,  11,  11, 160], dtype=int32), 'shape_signature': array([  1,   2,  11,  11, 160], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.12421826273202896, -125), 'quantization_parameters': {'scales': array([0.12421826], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:31', 'index': 895, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/se/global_average_pool3d_37/Reshape', 'index': 896, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/se/global_average_pool3d_37/Cast', 'index': 897, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/stream_buffer_28/concat', 'index': 898, 'shape': array([  1,   3,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   3,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10641761869192123, -124), 'quantization_parameters': {'scales': array([0.10641762], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d_temporal/Reshape', 'index': 899, 'shape': array([  1,   3, 121, 240], dtype=int32), 'shape_signature': array([  1,   3, 121, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10641761869192123, -124), 'quantization_parameters': {'scales': array([0.10641762], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul;movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 900, 'shape': array([  1,   1, 121, 240], dtype=int32), 'shape_signature': array([  1,   1, 121, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.41237008571624756, -19), 'quantization_parameters': {'scales': array([0.4123701], dtype=float32), 'zero_points': array([-19], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d_temporal/activation_78/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d_temporal/activation_78/Relu6;movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d_temporal/activation_78/add;movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d_temporal/activation_78/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 901, 'shape': array([  1,   1, 121, 240], dtype=int32), 'shape_signature': array([  1,   1, 121, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.23812250792980194, -126), 'quantization_parameters': {'scales': array([0.23812251], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/feature/conv2d_temporal/Reshape_1', 'index': 902, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.23812250792980194, -126), 'quantization_parameters': {'scales': array([0.23812251], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/se/spatial_average_pool3d_36/Mean', 'index': 903, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.03602863475680351, -118), 'quantization_parameters': {'scales': array([0.03602863], dtype=float32), 'zero_points': array([-118], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/se/spatial_average_pool3d_36/Mean1', 'index': 904, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/se/global_average_pool3d_37/add_1', 'index': 905, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.7973808646202087, -114), 'quantization_parameters': {'scales': array([0.79738086], dtype=float32), 'zero_points': array([-114], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize10', 'index': 906, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:30', 'index': 907, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.7973808646202087, -114), 'quantization_parameters': {'scales': array([0.79738086], dtype=float32), 'zero_points': array([-114], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/se/global_average_pool3d_37/truediv', 'index': 908, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/se/concat', 'index': 909, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize10', 'index': 910, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.03602863475680351, -118), 'quantization_parameters': {'scales': array([0.03602863], dtype=float32), 'zero_points': array([-118], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/se/se_reduce/conv2d/Reshape', 'index': 911, 'shape': array([  1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.03602863475680351, -118), 'quantization_parameters': {'scales': array([0.03602863], dtype=float32), 'zero_points': array([-118], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer2/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer2/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 912, 'shape': array([  1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.044851288199424744, 22), 'quantization_parameters': {'scales': array([0.04485129], dtype=float32), 'zero_points': array([22], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block2_layer2/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block2_layer2/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block2_layer2/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 913, 'shape': array([  1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.019976038485765457, -109), 'quantization_parameters': {'scales': array([0.01997604], dtype=float32), 'zero_points': array([-109], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block2_layer2/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block2_layer2/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block2_layer2/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer2/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 914, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.022371452301740646, -128), 'quantization_parameters': {'scales': array([0.02237145], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 915, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0037286498118191957, -128), 'quantization_parameters': {'scales': array([0.00372865], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/se/se_expand/conv2d/Reshape_1', 'index': 916, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0037286498118191957, -128), 'quantization_parameters': {'scales': array([0.00372865], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/se/mul', 'index': 917, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0037286498118191957, -128), 'quantization_parameters': {'scales': array([0.00372865], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/se/mul1', 'index': 918, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.031129347160458565, -117), 'quantization_parameters': {'scales': array([0.03112935], dtype=float32), 'zero_points': array([-117], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/projection/conv2d/Reshape', 'index': 919, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.031129347160458565, -117), 'quantization_parameters': {'scales': array([0.03112935], dtype=float32), 'zero_points': array([-117], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block3_layer5/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block2_layer2/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block2_layer2/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 920, 'shape': array([ 1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.134134441614151, 11), 'quantization_parameters': {'scales': array([0.13413444], dtype=float32), 'zero_points': array([11], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/projection/conv2d/Reshape_1', 'index': 921, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.134134441614151, 11), 'quantization_parameters': {'scales': array([0.13413444], dtype=float32), 'zero_points': array([11], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/rezero/mul1', 'index': 922, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2538455128669739, -12), 'quantization_parameters': {'scales': array([0.2538455], dtype=float32), 'zero_points': array([-12], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer2/bneck/add', 'index': 923, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.646461546421051, 15), 'quantization_parameters': {'scales': array([0.64646155], dtype=float32), 'zero_points': array([15], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/expansion/conv2d/Reshape', 'index': 924, 'shape': array([ 1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.646461546421051, 15), 'quantization_parameters': {'scales': array([0.64646155], dtype=float32), 'zero_points': array([15], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer3/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block2_layer3/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 925, 'shape': array([  1,  11,  11, 192], dtype=int32), 'shape_signature': array([  1,  11,  11, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.094419926404953, -9), 'quantization_parameters': {'scales': array([0.09441993], dtype=float32), 'zero_points': array([-9], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/expansion/conv2d/activation_79/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block2_layer3/bneck/expansion/conv2d/activation_79/Relu6;movinet_classifier_2/movinet_1/block2_layer3/bneck/expansion/conv2d/activation_79/add;movinet_classifier_2/movinet_1/block2_layer3/bneck/expansion/conv2d/activation_79/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 926, 'shape': array([  1,  11,  11, 192], dtype=int32), 'shape_signature': array([  1,  11,  11, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.05198143050074577, -121), 'quantization_parameters': {'scales': array([0.05198143], dtype=float32), 'zero_points': array([-121], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 927, 'shape': array([  1,  11,  11, 192], dtype=int32), 'shape_signature': array([  1,  11,  11, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.20370198786258698, -18), 'quantization_parameters': {'scales': array([0.20370199], dtype=float32), 'zero_points': array([-18], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d/activation_80/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d/activation_80/Relu6;movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d/activation_80/add;movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d/activation_80/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 928, 'shape': array([  1,  11,  11, 192], dtype=int32), 'shape_signature': array([  1,  11,  11, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1339057981967926, -125), 'quantization_parameters': {'scales': array([0.1339058], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d/Reshape_1', 'index': 929, 'shape': array([  1,   1,  11,  11, 192], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1339057981967926, -125), 'quantization_parameters': {'scales': array([0.1339058], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:32', 'index': 930, 'shape': array([  1,   2,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   2,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10641761869192123, -124), 'quantization_parameters': {'scales': array([0.10641762], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:34', 'index': 931, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/se/global_average_pool3d_38/Reshape', 'index': 932, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/se/global_average_pool3d_38/Cast', 'index': 933, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/stream_buffer_29/concat', 'index': 934, 'shape': array([  1,   3,  11,  11, 192], dtype=int32), 'shape_signature': array([  1,   3,  11,  11, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1339057981967926, -125), 'quantization_parameters': {'scales': array([0.1339058], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d_temporal/Reshape', 'index': 935, 'shape': array([  1,   3, 121, 192], dtype=int32), 'shape_signature': array([  1,   3, 121, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1339057981967926, -125), 'quantization_parameters': {'scales': array([0.1339058], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul;movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 936, 'shape': array([  1,   1, 121, 192], dtype=int32), 'shape_signature': array([  1,   1, 121, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.40894225239753723, -57), 'quantization_parameters': {'scales': array([0.40894225], dtype=float32), 'zero_points': array([-57], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d_temporal/activation_80/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d_temporal/activation_80/Relu6;movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d_temporal/activation_80/add;movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d_temporal/activation_80/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 937, 'shape': array([  1,   1, 121, 192], dtype=int32), 'shape_signature': array([  1,   1, 121, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2967504858970642, -127), 'quantization_parameters': {'scales': array([0.2967505], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/feature/conv2d_temporal/Reshape_1', 'index': 938, 'shape': array([  1,   1,  11,  11, 192], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2967504858970642, -127), 'quantization_parameters': {'scales': array([0.2967505], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/se/spatial_average_pool3d_37/Mean', 'index': 939, 'shape': array([  1,   1,   1,   1, 192], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.02607182413339615, -114), 'quantization_parameters': {'scales': array([0.02607182], dtype=float32), 'zero_points': array([-114], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/se/spatial_average_pool3d_37/Mean1', 'index': 940, 'shape': array([  1,   1,   1,   1, 192], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/se/global_average_pool3d_38/add_1', 'index': 941, 'shape': array([  1,   1,   1,   1, 192], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4730553925037384, -105), 'quantization_parameters': {'scales': array([0.4730554], dtype=float32), 'zero_points': array([-105], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize11', 'index': 942, 'shape': array([  1,   1,   1,   1, 192], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:33', 'index': 943, 'shape': array([  1,   1,   1,   1, 192], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4730553925037384, -105), 'quantization_parameters': {'scales': array([0.4730554], dtype=float32), 'zero_points': array([-105], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/se/global_average_pool3d_38/truediv', 'index': 944, 'shape': array([  1,   1,   1,   1, 192], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/se/concat', 'index': 945, 'shape': array([  1,   1,   1,   1, 384], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize11', 'index': 946, 'shape': array([  1,   1,   1,   1, 384], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.02607182413339615, -114), 'quantization_parameters': {'scales': array([0.02607182], dtype=float32), 'zero_points': array([-114], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/Reshape', 'index': 947, 'shape': array([  1,   1,   1, 384], dtype=int32), 'shape_signature': array([  1,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.02607182413339615, -114), 'quantization_parameters': {'scales': array([0.02607182], dtype=float32), 'zero_points': array([-114], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 948, 'shape': array([ 1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.03671880438923836, -8), 'quantization_parameters': {'scales': array([0.0367188], dtype=float32), 'zero_points': array([-8], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 949, 'shape': array([ 1,  1,  1, 96], dtype=int32), 'shape_signature': array([ 1,  1,  1, 96], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.020953869447112083, -110), 'quantization_parameters': {'scales': array([0.02095387], dtype=float32), 'zero_points': array([-110], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 950, 'shape': array([  1,   1,   1, 192], dtype=int32), 'shape_signature': array([  1,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.022664373740553856, -128), 'quantization_parameters': {'scales': array([0.02266437], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 951, 'shape': array([  1,   1,   1, 192], dtype=int32), 'shape_signature': array([  1,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0037774709053337574, -128), 'quantization_parameters': {'scales': array([0.00377747], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/se/se_expand/conv2d/Reshape_1', 'index': 952, 'shape': array([  1,   1,   1,   1, 192], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0037774709053337574, -128), 'quantization_parameters': {'scales': array([0.00377747], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/se/mul1', 'index': 953, 'shape': array([  1,   1,  11,  11, 192], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0037774709053337574, -128), 'quantization_parameters': {'scales': array([0.00377747], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/se/mul2', 'index': 954, 'shape': array([  1,   1,  11,  11, 192], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.03741820156574249, -119), 'quantization_parameters': {'scales': array([0.0374182], dtype=float32), 'zero_points': array([-119], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/projection/conv2d/Reshape', 'index': 955, 'shape': array([  1,  11,  11, 192], dtype=int32), 'shape_signature': array([  1,  11,  11, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.03741820156574249, -119), 'quantization_parameters': {'scales': array([0.0374182], dtype=float32), 'zero_points': array([-119], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block3_layer5/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block2_layer3/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block2_layer3/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 956, 'shape': array([ 1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.14478464424610138, -2), 'quantization_parameters': {'scales': array([0.14478464], dtype=float32), 'zero_points': array([-2], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/projection/conv2d/Reshape_1', 'index': 957, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.14478464424610138, -2), 'quantization_parameters': {'scales': array([0.14478464], dtype=float32), 'zero_points': array([-2], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/rezero/mul1', 'index': 958, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.26754748821258545, -2), 'quantization_parameters': {'scales': array([0.2675475], dtype=float32), 'zero_points': array([-2], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer3/bneck/add', 'index': 959, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.7434254288673401, 20), 'quantization_parameters': {'scales': array([0.7434254], dtype=float32), 'zero_points': array([20], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/expansion/conv2d/Reshape', 'index': 960, 'shape': array([ 1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.7434254288673401, 20), 'quantization_parameters': {'scales': array([0.7434254], dtype=float32), 'zero_points': array([20], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer4/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block2_layer4/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 961, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.12761655449867249, -1), 'quantization_parameters': {'scales': array([0.12761655], dtype=float32), 'zero_points': array([-1], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/expansion/conv2d/activation_81/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block2_layer4/bneck/expansion/conv2d/activation_81/Relu6;movinet_classifier_2/movinet_1/block2_layer4/bneck/expansion/conv2d/activation_81/add;movinet_classifier_2/movinet_1/block2_layer4/bneck/expansion/conv2d/activation_81/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 962, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.06573287397623062, -122), 'quantization_parameters': {'scales': array([0.06573287], dtype=float32), 'zero_points': array([-122], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 963, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.17076541483402252, -11), 'quantization_parameters': {'scales': array([0.17076541], dtype=float32), 'zero_points': array([-11], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d/activation_82/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d/activation_82/Relu6;movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d/activation_82/add;movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d/activation_82/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 964, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.09928026050329208, -124), 'quantization_parameters': {'scales': array([0.09928026], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d/Reshape_1', 'index': 965, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.09928026050329208, -124), 'quantization_parameters': {'scales': array([0.09928026], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:35', 'index': 966, 'shape': array([  1,   2,  11,  11, 192], dtype=int32), 'shape_signature': array([  1,   2,  11,  11, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1339057981967926, -125), 'quantization_parameters': {'scales': array([0.1339058], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:37', 'index': 967, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/se/global_average_pool3d_39/Reshape', 'index': 968, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/se/global_average_pool3d_39/Cast', 'index': 969, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/stream_buffer_30/concat', 'index': 970, 'shape': array([  1,   3,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   3,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.09928026050329208, -124), 'quantization_parameters': {'scales': array([0.09928026], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d_temporal/Reshape', 'index': 971, 'shape': array([  1,   3, 121, 240], dtype=int32), 'shape_signature': array([  1,   3, 121, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.09928026050329208, -124), 'quantization_parameters': {'scales': array([0.09928026], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul;movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 972, 'shape': array([  1,   1, 121, 240], dtype=int32), 'shape_signature': array([  1,   1, 121, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.6722081899642944, -76), 'quantization_parameters': {'scales': array([0.6722082], dtype=float32), 'zero_points': array([-76], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d_temporal/activation_82/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d_temporal/activation_82/Relu6;movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d_temporal/activation_82/add;movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d_temporal/activation_82/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 973, 'shape': array([  1,   1, 121, 240], dtype=int32), 'shape_signature': array([  1,   1, 121, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.5366621613502502, -127), 'quantization_parameters': {'scales': array([0.53666216], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/feature/conv2d_temporal/Reshape_1', 'index': 974, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.5366621613502502, -127), 'quantization_parameters': {'scales': array([0.53666216], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/se/spatial_average_pool3d_38/Mean', 'index': 975, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04663270339369774, -120), 'quantization_parameters': {'scales': array([0.0466327], dtype=float32), 'zero_points': array([-120], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/se/spatial_average_pool3d_38/Mean1', 'index': 976, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/se/global_average_pool3d_39/add_1', 'index': 977, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.9277412295341492, -117), 'quantization_parameters': {'scales': array([0.9277412], dtype=float32), 'zero_points': array([-117], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize12', 'index': 978, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:36', 'index': 979, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.9277412295341492, -117), 'quantization_parameters': {'scales': array([0.9277412], dtype=float32), 'zero_points': array([-117], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/se/global_average_pool3d_39/truediv', 'index': 980, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/se/concat', 'index': 981, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize12', 'index': 982, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04663270339369774, -120), 'quantization_parameters': {'scales': array([0.0466327], dtype=float32), 'zero_points': array([-120], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/se/se_reduce/conv2d/Reshape', 'index': 983, 'shape': array([  1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04663270339369774, -120), 'quantization_parameters': {'scales': array([0.0466327], dtype=float32), 'zero_points': array([-120], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer4/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer4/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 984, 'shape': array([  1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.058284152299165726, 43), 'quantization_parameters': {'scales': array([0.05828415], dtype=float32), 'zero_points': array([43], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block2_layer4/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block2_layer4/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block2_layer4/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 985, 'shape': array([  1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.02058185264468193, -110), 'quantization_parameters': {'scales': array([0.02058185], dtype=float32), 'zero_points': array([-110], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block2_layer4/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block2_layer4/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block2_layer4/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block2_layer4/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 986, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.02052309922873974, -128), 'quantization_parameters': {'scales': array([0.0205231], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 987, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.003420584835112095, -128), 'quantization_parameters': {'scales': array([0.00342058], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/se/se_expand/conv2d/Reshape_1', 'index': 988, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.003420584835112095, -128), 'quantization_parameters': {'scales': array([0.00342058], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/se/mul', 'index': 989, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.003420584835112095, -128), 'quantization_parameters': {'scales': array([0.00342058], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/se/mul1', 'index': 990, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.03812887892127037, -119), 'quantization_parameters': {'scales': array([0.03812888], dtype=float32), 'zero_points': array([-119], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/projection/conv2d/Reshape', 'index': 991, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.03812887892127037, -119), 'quantization_parameters': {'scales': array([0.03812888], dtype=float32), 'zero_points': array([-119], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block3_layer5/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block2_layer4/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block2_layer4/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 992, 'shape': array([ 1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11351779103279114, 6), 'quantization_parameters': {'scales': array([0.11351779], dtype=float32), 'zero_points': array([6], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/projection/conv2d/Reshape_1', 'index': 993, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11351779103279114, 6), 'quantization_parameters': {'scales': array([0.11351779], dtype=float32), 'zero_points': array([6], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/rezero/mul1', 'index': 994, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.22711937129497528, 6), 'quantization_parameters': {'scales': array([0.22711937], dtype=float32), 'zero_points': array([6], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block2_layer4/bneck/add', 'index': 995, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.7949722409248352, 16), 'quantization_parameters': {'scales': array([0.79497224], dtype=float32), 'zero_points': array([16], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/expansion/conv2d/Reshape', 'index': 996, 'shape': array([ 1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.7949722409248352, 16), 'quantization_parameters': {'scales': array([0.79497224], dtype=float32), 'zero_points': array([16], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer0/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block3_layer0/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 997, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11744946241378784, -9), 'quantization_parameters': {'scales': array([0.11744946], dtype=float32), 'zero_points': array([-9], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/expansion/conv2d/activation_83/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block3_layer0/bneck/expansion/conv2d/activation_83/Relu6;movinet_classifier_2/movinet_1/block3_layer0/bneck/expansion/conv2d/activation_83/add;movinet_classifier_2/movinet_1/block3_layer0/bneck/expansion/conv2d/activation_83/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 998, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.06388802826404572, -122), 'quantization_parameters': {'scales': array([0.06388803], dtype=float32), 'zero_points': array([-122], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 999, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.16169939935207367, -1), 'quantization_parameters': {'scales': array([0.1616994], dtype=float32), 'zero_points': array([-1], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d/activation_84/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d/activation_84/Relu6;movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d/activation_84/add;movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d/activation_84/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1000, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.08295381814241409, -123), 'quantization_parameters': {'scales': array([0.08295382], dtype=float32), 'zero_points': array([-123], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d/Reshape_1', 'index': 1001, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.08295381814241409, -123), 'quantization_parameters': {'scales': array([0.08295382], dtype=float32), 'zero_points': array([-123], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:38', 'index': 1002, 'shape': array([  1,   2,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   2,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.09928026050329208, -124), 'quantization_parameters': {'scales': array([0.09928026], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:40', 'index': 1003, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/se/global_average_pool3d_40/Reshape', 'index': 1004, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/se/global_average_pool3d_40/Cast', 'index': 1005, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/stream_buffer_31/concat', 'index': 1006, 'shape': array([  1,   5,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   5,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.08295381814241409, -123), 'quantization_parameters': {'scales': array([0.08295382], dtype=float32), 'zero_points': array([-123], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d_temporal/Reshape', 'index': 1007, 'shape': array([  1,   5, 121, 240], dtype=int32), 'shape_signature': array([  1,   5, 121, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.08295381814241409, -123), 'quantization_parameters': {'scales': array([0.08295382], dtype=float32), 'zero_points': array([-123], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul;movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 1008, 'shape': array([  1,   1, 121, 240], dtype=int32), 'shape_signature': array([  1,   1, 121, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.36490675806999207, -59), 'quantization_parameters': {'scales': array([0.36490676], dtype=float32), 'zero_points': array([-59], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d_temporal/activation_84/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d_temporal/activation_84/Relu6;movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d_temporal/activation_84/add;movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d_temporal/activation_84/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1009, 'shape': array([  1,   1, 121, 240], dtype=int32), 'shape_signature': array([  1,   1, 121, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2673598825931549, -127), 'quantization_parameters': {'scales': array([0.26735988], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/feature/conv2d_temporal/Reshape_1', 'index': 1010, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2673598825931549, -127), 'quantization_parameters': {'scales': array([0.26735988], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/se/spatial_average_pool3d_39/Mean', 'index': 1011, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.022471560165286064, -111), 'quantization_parameters': {'scales': array([0.02247156], dtype=float32), 'zero_points': array([-111], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/se/spatial_average_pool3d_39/Mean1', 'index': 1012, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/se/global_average_pool3d_40/add_1', 'index': 1013, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.381149023771286, -100), 'quantization_parameters': {'scales': array([0.38114902], dtype=float32), 'zero_points': array([-100], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize13', 'index': 1014, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:39', 'index': 1015, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.381149023771286, -100), 'quantization_parameters': {'scales': array([0.38114902], dtype=float32), 'zero_points': array([-100], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/se/global_average_pool3d_40/truediv', 'index': 1016, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/se/concat', 'index': 1017, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize13', 'index': 1018, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.022471560165286064, -111), 'quantization_parameters': {'scales': array([0.02247156], dtype=float32), 'zero_points': array([-111], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/se/se_reduce/conv2d/Reshape', 'index': 1019, 'shape': array([  1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.022471560165286064, -111), 'quantization_parameters': {'scales': array([0.02247156], dtype=float32), 'zero_points': array([-111], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer0/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer0/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 1020, 'shape': array([  1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.03937537968158722, 51), 'quantization_parameters': {'scales': array([0.03937538], dtype=float32), 'zero_points': array([51], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block3_layer0/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block3_layer0/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block3_layer0/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1021, 'shape': array([  1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.013202104717493057, -100), 'quantization_parameters': {'scales': array([0.0132021], dtype=float32), 'zero_points': array([-100], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block3_layer0/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block3_layer0/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block3_layer0/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer0/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 1022, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.02009066939353943, -128), 'quantization_parameters': {'scales': array([0.02009067], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 1023, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.003348511876538396, -128), 'quantization_parameters': {'scales': array([0.00334851], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/se/se_expand/conv2d/Reshape_1', 'index': 1024, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.003348511876538396, -128), 'quantization_parameters': {'scales': array([0.00334851], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/se/mul', 'index': 1025, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.003348511876538396, -128), 'quantization_parameters': {'scales': array([0.00334851], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/se/mul1', 'index': 1026, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.027375029399991035, -116), 'quantization_parameters': {'scales': array([0.02737503], dtype=float32), 'zero_points': array([-116], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/projection/conv2d/Reshape', 'index': 1027, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.027375029399991035, -116), 'quantization_parameters': {'scales': array([0.02737503], dtype=float32), 'zero_points': array([-116], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block3_layer5/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block3_layer0/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block3_layer0/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 1028, 'shape': array([ 1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.14676906168460846, 0), 'quantization_parameters': {'scales': array([0.14676906], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/projection/conv2d/Reshape_1', 'index': 1029, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.14676906168460846, 0), 'quantization_parameters': {'scales': array([0.14676906], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/rezero/mul1', 'index': 1030, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.30546796321868896, -1), 'quantization_parameters': {'scales': array([0.30546796], dtype=float32), 'zero_points': array([-1], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer0/bneck/add', 'index': 1031, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.8218382596969604, 12), 'quantization_parameters': {'scales': array([0.82183826], dtype=float32), 'zero_points': array([12], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/expansion/conv2d/Reshape', 'index': 1032, 'shape': array([ 1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.8218382596969604, 12), 'quantization_parameters': {'scales': array([0.82183826], dtype=float32), 'zero_points': array([12], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer1/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block3_layer1/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 1033, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.09927196800708771, -7), 'quantization_parameters': {'scales': array([0.09927197], dtype=float32), 'zero_points': array([-7], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/expansion/conv2d/activation_85/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block3_layer1/bneck/expansion/conv2d/activation_85/Relu6;movinet_classifier_2/movinet_1/block3_layer1/bneck/expansion/conv2d/activation_85/add;movinet_classifier_2/movinet_1/block3_layer1/bneck/expansion/conv2d/activation_85/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1034, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.053498681634664536, -121), 'quantization_parameters': {'scales': array([0.05349868], dtype=float32), 'zero_points': array([-121], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 1035, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.18010732531547546, -18), 'quantization_parameters': {'scales': array([0.18010733], dtype=float32), 'zero_points': array([-18], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d/activation_86/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d/activation_86/Relu6;movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d/activation_86/add;movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d/activation_86/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1036, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10401120036840439, -124), 'quantization_parameters': {'scales': array([0.1040112], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d/Reshape_1', 'index': 1037, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10401120036840439, -124), 'quantization_parameters': {'scales': array([0.1040112], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:41', 'index': 1038, 'shape': array([  1,   4,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   4,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.08295381814241409, -123), 'quantization_parameters': {'scales': array([0.08295382], dtype=float32), 'zero_points': array([-123], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:43', 'index': 1039, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/se/global_average_pool3d_41/Reshape', 'index': 1040, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/se/global_average_pool3d_41/Cast', 'index': 1041, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/stream_buffer_32/concat', 'index': 1042, 'shape': array([  1,   3,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   3,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10401120036840439, -124), 'quantization_parameters': {'scales': array([0.1040112], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d_temporal/Reshape', 'index': 1043, 'shape': array([  1,   3, 121, 240], dtype=int32), 'shape_signature': array([  1,   3, 121, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10401120036840439, -124), 'quantization_parameters': {'scales': array([0.1040112], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul;movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 1044, 'shape': array([  1,   1, 121, 240], dtype=int32), 'shape_signature': array([  1,   1, 121, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4248962998390198, -45), 'quantization_parameters': {'scales': array([0.4248963], dtype=float32), 'zero_points': array([-45], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d_temporal/activation_86/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d_temporal/activation_86/Relu6;movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d_temporal/activation_86/add;movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d_temporal/activation_86/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1045, 'shape': array([  1,   1, 121, 240], dtype=int32), 'shape_signature': array([  1,   1, 121, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2875179052352905, -127), 'quantization_parameters': {'scales': array([0.2875179], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/feature/conv2d_temporal/Reshape_1', 'index': 1046, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2875179052352905, -127), 'quantization_parameters': {'scales': array([0.2875179], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/se/spatial_average_pool3d_40/Mean', 'index': 1047, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04263457655906677, -119), 'quantization_parameters': {'scales': array([0.04263458], dtype=float32), 'zero_points': array([-119], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/se/spatial_average_pool3d_40/Mean1', 'index': 1048, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/se/global_average_pool3d_41/add_1', 'index': 1049, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.44789817929267883, -105), 'quantization_parameters': {'scales': array([0.44789818], dtype=float32), 'zero_points': array([-105], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize14', 'index': 1050, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:42', 'index': 1051, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.44789817929267883, -105), 'quantization_parameters': {'scales': array([0.44789818], dtype=float32), 'zero_points': array([-105], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/se/global_average_pool3d_41/truediv', 'index': 1052, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/se/concat', 'index': 1053, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize14', 'index': 1054, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04263457655906677, -119), 'quantization_parameters': {'scales': array([0.04263458], dtype=float32), 'zero_points': array([-119], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/se/se_reduce/conv2d/Reshape', 'index': 1055, 'shape': array([  1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04263457655906677, -119), 'quantization_parameters': {'scales': array([0.04263458], dtype=float32), 'zero_points': array([-119], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer1/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer1/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 1056, 'shape': array([  1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04249028488993645, -13), 'quantization_parameters': {'scales': array([0.04249028], dtype=float32), 'zero_points': array([-13], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block3_layer1/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block3_layer1/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block3_layer1/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1057, 'shape': array([  1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.024854524061083794, -113), 'quantization_parameters': {'scales': array([0.02485452], dtype=float32), 'zero_points': array([-113], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block3_layer1/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block3_layer1/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block3_layer1/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer1/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 1058, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.021241988986730576, -128), 'quantization_parameters': {'scales': array([0.02124199], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 1059, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0035404020454734564, -128), 'quantization_parameters': {'scales': array([0.0035404], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/se/se_expand/conv2d/Reshape_1', 'index': 1060, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0035404020454734564, -128), 'quantization_parameters': {'scales': array([0.0035404], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/se/mul', 'index': 1061, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0035404020454734564, -128), 'quantization_parameters': {'scales': array([0.0035404], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/se/mul1', 'index': 1062, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.037022702395915985, -119), 'quantization_parameters': {'scales': array([0.0370227], dtype=float32), 'zero_points': array([-119], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/projection/conv2d/Reshape', 'index': 1063, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.037022702395915985, -119), 'quantization_parameters': {'scales': array([0.0370227], dtype=float32), 'zero_points': array([-119], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block3_layer5/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block3_layer1/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block3_layer1/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 1064, 'shape': array([ 1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11705492436885834, -8), 'quantization_parameters': {'scales': array([0.11705492], dtype=float32), 'zero_points': array([-8], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/projection/conv2d/Reshape_1', 'index': 1065, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11705492436885834, -8), 'quantization_parameters': {'scales': array([0.11705492], dtype=float32), 'zero_points': array([-8], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/rezero/mul1', 'index': 1066, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.255259245634079, 7), 'quantization_parameters': {'scales': array([0.25525925], dtype=float32), 'zero_points': array([7], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer1/bneck/add', 'index': 1067, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.825039267539978, 6), 'quantization_parameters': {'scales': array([0.82503927], dtype=float32), 'zero_points': array([6], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/expansion/conv2d/Reshape', 'index': 1068, 'shape': array([ 1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.825039267539978, 6), 'quantization_parameters': {'scales': array([0.82503927], dtype=float32), 'zero_points': array([6], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer2/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block3_layer2/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 1069, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10079264640808105, 12), 'quantization_parameters': {'scales': array([0.10079265], dtype=float32), 'zero_points': array([12], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/expansion/conv2d/activation_87/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block3_layer2/bneck/expansion/conv2d/activation_87/Relu6;movinet_classifier_2/movinet_1/block3_layer2/bneck/expansion/conv2d/activation_87/add;movinet_classifier_2/movinet_1/block3_layer2/bneck/expansion/conv2d/activation_87/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1070, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0468541644513607, -120), 'quantization_parameters': {'scales': array([0.04685416], dtype=float32), 'zero_points': array([-120], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 1071, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.13819612562656403, -26), 'quantization_parameters': {'scales': array([0.13819613], dtype=float32), 'zero_points': array([-26], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d/activation_88/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d/activation_88/Relu6;movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d/activation_88/add;movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d/activation_88/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1072, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.08464442193508148, -124), 'quantization_parameters': {'scales': array([0.08464442], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d/Reshape_1', 'index': 1073, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.08464442193508148, -124), 'quantization_parameters': {'scales': array([0.08464442], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:44', 'index': 1074, 'shape': array([  1,   2,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   2,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10401120036840439, -124), 'quantization_parameters': {'scales': array([0.1040112], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:46', 'index': 1075, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/se/global_average_pool3d_42/Reshape', 'index': 1076, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/se/global_average_pool3d_42/Cast', 'index': 1077, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/stream_buffer_33/concat', 'index': 1078, 'shape': array([  1,   3,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   3,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.08464442193508148, -124), 'quantization_parameters': {'scales': array([0.08464442], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d_temporal/Reshape', 'index': 1079, 'shape': array([  1,   3, 121, 240], dtype=int32), 'shape_signature': array([  1,   3, 121, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.08464442193508148, -124), 'quantization_parameters': {'scales': array([0.08464442], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul;movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 1080, 'shape': array([  1,   1, 121, 240], dtype=int32), 'shape_signature': array([  1,   1, 121, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.3771358132362366, -14), 'quantization_parameters': {'scales': array([0.3771358], dtype=float32), 'zero_points': array([-14], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d_temporal/activation_88/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d_temporal/activation_88/Relu6;movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d_temporal/activation_88/add;movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d_temporal/activation_88/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1081, 'shape': array([  1,   1, 121, 240], dtype=int32), 'shape_signature': array([  1,   1, 121, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.20962439477443695, -126), 'quantization_parameters': {'scales': array([0.2096244], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/feature/conv2d_temporal/Reshape_1', 'index': 1082, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.20962439477443695, -126), 'quantization_parameters': {'scales': array([0.2096244], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/se/spatial_average_pool3d_41/Mean', 'index': 1083, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.02529057115316391, -113), 'quantization_parameters': {'scales': array([0.02529057], dtype=float32), 'zero_points': array([-113], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/se/spatial_average_pool3d_41/Mean1', 'index': 1084, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/se/global_average_pool3d_42/add_1', 'index': 1085, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.3292146623134613, -98), 'quantization_parameters': {'scales': array([0.32921466], dtype=float32), 'zero_points': array([-98], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize15', 'index': 1086, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:45', 'index': 1087, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.3292146623134613, -98), 'quantization_parameters': {'scales': array([0.32921466], dtype=float32), 'zero_points': array([-98], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/se/global_average_pool3d_42/truediv', 'index': 1088, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/se/concat', 'index': 1089, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize15', 'index': 1090, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.02529057115316391, -113), 'quantization_parameters': {'scales': array([0.02529057], dtype=float32), 'zero_points': array([-113], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/se/se_reduce/conv2d/Reshape', 'index': 1091, 'shape': array([  1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.02529057115316391, -113), 'quantization_parameters': {'scales': array([0.02529057], dtype=float32), 'zero_points': array([-113], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer2/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer2/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 1092, 'shape': array([  1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.03183036670088768, 29), 'quantization_parameters': {'scales': array([0.03183037], dtype=float32), 'zero_points': array([29], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block3_layer2/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block3_layer2/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block3_layer2/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1093, 'shape': array([  1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.013665102422237396, -101), 'quantization_parameters': {'scales': array([0.0136651], dtype=float32), 'zero_points': array([-101], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block3_layer2/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block3_layer2/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block3_layer2/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer2/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 1094, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.01990697532892227, -128), 'quantization_parameters': {'scales': array([0.01990698], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 1095, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.003317895345389843, -128), 'quantization_parameters': {'scales': array([0.0033179], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/se/se_expand/conv2d/Reshape_1', 'index': 1096, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.003317895345389843, -128), 'quantization_parameters': {'scales': array([0.0033179], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/se/mul', 'index': 1097, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.003317895345389843, -128), 'quantization_parameters': {'scales': array([0.0033179], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/se/mul1', 'index': 1098, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04614753648638725, -121), 'quantization_parameters': {'scales': array([0.04614754], dtype=float32), 'zero_points': array([-121], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/projection/conv2d/Reshape', 'index': 1099, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04614753648638725, -121), 'quantization_parameters': {'scales': array([0.04614754], dtype=float32), 'zero_points': array([-121], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block3_layer5/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block3_layer2/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block3_layer2/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 1100, 'shape': array([ 1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.18816639482975006, 22), 'quantization_parameters': {'scales': array([0.1881664], dtype=float32), 'zero_points': array([22], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/projection/conv2d/Reshape_1', 'index': 1101, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.18816639482975006, 22), 'quantization_parameters': {'scales': array([0.1881664], dtype=float32), 'zero_points': array([22], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/rezero/mul1', 'index': 1102, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4166703224182129, 22), 'quantization_parameters': {'scales': array([0.41667032], dtype=float32), 'zero_points': array([22], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer2/bneck/add', 'index': 1103, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.8341922760009766, 1), 'quantization_parameters': {'scales': array([0.8341923], dtype=float32), 'zero_points': array([1], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/expansion/conv2d/Reshape', 'index': 1104, 'shape': array([ 1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.8341922760009766, 1), 'quantization_parameters': {'scales': array([0.8341923], dtype=float32), 'zero_points': array([1], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer3/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block3_layer3/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 1105, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10323289036750793, 7), 'quantization_parameters': {'scales': array([0.10323289], dtype=float32), 'zero_points': array([7], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/expansion/conv2d/activation_89/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block3_layer3/bneck/expansion/conv2d/activation_89/Relu6;movinet_classifier_2/movinet_1/block3_layer3/bneck/expansion/conv2d/activation_89/add;movinet_classifier_2/movinet_1/block3_layer3/bneck/expansion/conv2d/activation_89/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1106, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04999162256717682, -120), 'quantization_parameters': {'scales': array([0.04999162], dtype=float32), 'zero_points': array([-120], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 1107, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.14582008123397827, -13), 'quantization_parameters': {'scales': array([0.14582008], dtype=float32), 'zero_points': array([-13], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d/activation_90/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d/activation_90/Relu6;movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d/activation_90/add;movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d/activation_90/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1108, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.09885547310113907, -124), 'quantization_parameters': {'scales': array([0.09885547], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d/Reshape_1', 'index': 1109, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.09885547310113907, -124), 'quantization_parameters': {'scales': array([0.09885547], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:47', 'index': 1110, 'shape': array([  1,   2,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   2,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.08464442193508148, -124), 'quantization_parameters': {'scales': array([0.08464442], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:49', 'index': 1111, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/se/global_average_pool3d_43/Reshape', 'index': 1112, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/se/global_average_pool3d_43/Cast', 'index': 1113, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/stream_buffer_34/concat', 'index': 1114, 'shape': array([  1,   3,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   3,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.09885547310113907, -124), 'quantization_parameters': {'scales': array([0.09885547], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d_temporal/Reshape', 'index': 1115, 'shape': array([  1,   3, 121, 240], dtype=int32), 'shape_signature': array([  1,   3, 121, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.09885547310113907, -124), 'quantization_parameters': {'scales': array([0.09885547], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul;movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 1116, 'shape': array([  1,   1, 121, 240], dtype=int32), 'shape_signature': array([  1,   1, 121, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4428635537624359, -54), 'quantization_parameters': {'scales': array([0.44286355], dtype=float32), 'zero_points': array([-54], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d_temporal/activation_90/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d_temporal/activation_90/Relu6;movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d_temporal/activation_90/add;movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d_temporal/activation_90/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1117, 'shape': array([  1,   1, 121, 240], dtype=int32), 'shape_signature': array([  1,   1, 121, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.3157573938369751, -127), 'quantization_parameters': {'scales': array([0.3157574], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/feature/conv2d_temporal/Reshape_1', 'index': 1118, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.3157573938369751, -127), 'quantization_parameters': {'scales': array([0.3157574], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/se/spatial_average_pool3d_42/Mean', 'index': 1119, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.032699547708034515, -117), 'quantization_parameters': {'scales': array([0.03269955], dtype=float32), 'zero_points': array([-117], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/se/spatial_average_pool3d_42/Mean1', 'index': 1120, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/se/global_average_pool3d_43/add_1', 'index': 1121, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.8756934404373169, -116), 'quantization_parameters': {'scales': array([0.87569344], dtype=float32), 'zero_points': array([-116], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize16', 'index': 1122, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:48', 'index': 1123, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.8756934404373169, -116), 'quantization_parameters': {'scales': array([0.87569344], dtype=float32), 'zero_points': array([-116], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/se/global_average_pool3d_43/truediv', 'index': 1124, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/se/concat', 'index': 1125, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize16', 'index': 1126, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.032699547708034515, -117), 'quantization_parameters': {'scales': array([0.03269955], dtype=float32), 'zero_points': array([-117], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/se/se_reduce/conv2d/Reshape', 'index': 1127, 'shape': array([  1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.032699547708034515, -117), 'quantization_parameters': {'scales': array([0.03269955], dtype=float32), 'zero_points': array([-117], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer3/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 1128, 'shape': array([  1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.046873558312654495, 12), 'quantization_parameters': {'scales': array([0.04687356], dtype=float32), 'zero_points': array([12], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block3_layer3/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block3_layer3/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block3_layer3/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1129, 'shape': array([  1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.02265108935534954, -111), 'quantization_parameters': {'scales': array([0.02265109], dtype=float32), 'zero_points': array([-111], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block3_layer3/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block3_layer3/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block3_layer3/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer3/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 1130, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.02032959833741188, -128), 'quantization_parameters': {'scales': array([0.0203296], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 1131, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0033883340656757355, -128), 'quantization_parameters': {'scales': array([0.00338833], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/se/se_expand/conv2d/Reshape_1', 'index': 1132, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0033883340656757355, -128), 'quantization_parameters': {'scales': array([0.00338833], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/se/mul', 'index': 1133, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0033883340656757355, -128), 'quantization_parameters': {'scales': array([0.00338833], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/se/mul1', 'index': 1134, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04174673929810524, -120), 'quantization_parameters': {'scales': array([0.04174674], dtype=float32), 'zero_points': array([-120], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/projection/conv2d/Reshape', 'index': 1135, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04174673929810524, -120), 'quantization_parameters': {'scales': array([0.04174674], dtype=float32), 'zero_points': array([-120], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block3_layer5/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block3_layer3/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block3_layer3/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 1136, 'shape': array([ 1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.20496581494808197, 34), 'quantization_parameters': {'scales': array([0.20496581], dtype=float32), 'zero_points': array([34], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/projection/conv2d/Reshape_1', 'index': 1137, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.20496581494808197, 34), 'quantization_parameters': {'scales': array([0.20496581], dtype=float32), 'zero_points': array([34], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/rezero/mul1', 'index': 1138, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4521971344947815, 34), 'quantization_parameters': {'scales': array([0.45219713], dtype=float32), 'zero_points': array([34], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer3/bneck/add', 'index': 1139, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.8666291832923889, -1), 'quantization_parameters': {'scales': array([0.8666292], dtype=float32), 'zero_points': array([-1], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/expansion/conv2d/Reshape', 'index': 1140, 'shape': array([ 1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.8666291832923889, -1), 'quantization_parameters': {'scales': array([0.8666292], dtype=float32), 'zero_points': array([-1], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer6/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block3_layer4/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block3_layer4/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 1141, 'shape': array([  1,  11,  11, 144], dtype=int32), 'shape_signature': array([  1,  11,  11, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10890553891658783, 10), 'quantization_parameters': {'scales': array([0.10890554], dtype=float32), 'zero_points': array([10], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/expansion/conv2d/activation_91/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block3_layer4/bneck/expansion/conv2d/activation_91/Relu6;movinet_classifier_2/movinet_1/block3_layer4/bneck/expansion/conv2d/activation_91/add;movinet_classifier_2/movinet_1/block3_layer4/bneck/expansion/conv2d/activation_91/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1142, 'shape': array([  1,  11,  11, 144], dtype=int32), 'shape_signature': array([  1,  11,  11, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.05132952705025673, -121), 'quantization_parameters': {'scales': array([0.05132953], dtype=float32), 'zero_points': array([-121], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer6/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block3_layer4/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block3_layer4/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block3_layer4/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block3_layer4/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 1143, 'shape': array([  1,  11,  11, 144], dtype=int32), 'shape_signature': array([  1,  11,  11, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.13095839321613312, 21), 'quantization_parameters': {'scales': array([0.1309584], dtype=float32), 'zero_points': array([21], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/feature/conv2d/activation_92/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block3_layer4/bneck/feature/conv2d/activation_92/Relu6;movinet_classifier_2/movinet_1/block3_layer4/bneck/feature/conv2d/activation_92/add;movinet_classifier_2/movinet_1/block3_layer4/bneck/feature/conv2d/activation_92/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1144, 'shape': array([  1,  11,  11, 144], dtype=int32), 'shape_signature': array([  1,  11,  11, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.05587669834494591, -121), 'quantization_parameters': {'scales': array([0.0558767], dtype=float32), 'zero_points': array([-121], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/feature/conv2d/Reshape_1', 'index': 1145, 'shape': array([  1,   1,  11,  11, 144], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.05587669834494591, -121), 'quantization_parameters': {'scales': array([0.0558767], dtype=float32), 'zero_points': array([-121], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/se/spatial_average_pool3d_43/Mean', 'index': 1146, 'shape': array([  1,   1,   1,   1, 144], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.011646238155663013, -97), 'quantization_parameters': {'scales': array([0.01164624], dtype=float32), 'zero_points': array([-97], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/se/spatial_average_pool3d_43/Mean1', 'index': 1147, 'shape': array([  1,   1,   1,   1, 144], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 144], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:50', 'index': 1148, 'shape': array([  1,   2,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   2,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.09885547310113907, -124), 'quantization_parameters': {'scales': array([0.09885547], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/se/global_average_pool3d_44/add_1', 'index': 1149, 'shape': array([  1,   1,   1,   1, 144], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.34283000230789185, -98), 'quantization_parameters': {'scales': array([0.34283], dtype=float32), 'zero_points': array([-98], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize17', 'index': 1150, 'shape': array([  1,   1,   1,   1, 144], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 144], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:51', 'index': 1151, 'shape': array([  1,   1,   1,   1, 144], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.34283000230789185, -98), 'quantization_parameters': {'scales': array([0.34283], dtype=float32), 'zero_points': array([-98], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:52', 'index': 1152, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/se/global_average_pool3d_44/Reshape', 'index': 1153, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/se/global_average_pool3d_44/Cast', 'index': 1154, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/se/global_average_pool3d_44/truediv', 'index': 1155, 'shape': array([  1,   1,   1,   1, 144], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 144], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/se/concat', 'index': 1156, 'shape': array([  1,   1,   1,   1, 288], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 288], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize17', 'index': 1157, 'shape': array([  1,   1,   1,   1, 288], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 288], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.011646238155663013, -97), 'quantization_parameters': {'scales': array([0.01164624], dtype=float32), 'zero_points': array([-97], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_reduce/conv2d/Reshape', 'index': 1158, 'shape': array([  1,   1,   1, 288], dtype=int32), 'shape_signature': array([  1,   1,   1, 288], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.011646238155663013, -97), 'quantization_parameters': {'scales': array([0.01164624], dtype=float32), 'zero_points': array([-97], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block3_layer5/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 1159, 'shape': array([ 1,  1,  1, 72], dtype=int32), 'shape_signature': array([ 1,  1,  1, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.002077331766486168, -121), 'quantization_parameters': {'scales': array([0.00207733], dtype=float32), 'zero_points': array([-121], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1160, 'shape': array([ 1,  1,  1, 72], dtype=int32), 'shape_signature': array([ 1,  1,  1, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0012120034079998732, -122), 'quantization_parameters': {'scales': array([0.001212], dtype=float32), 'zero_points': array([-122], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer6/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 1161, 'shape': array([  1,   1,   1, 144], dtype=int32), 'shape_signature': array([  1,   1,   1, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.020057326182723045, -128), 'quantization_parameters': {'scales': array([0.02005733], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 1162, 'shape': array([  1,   1,   1, 144], dtype=int32), 'shape_signature': array([  1,   1,   1, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0033429544419050217, -128), 'quantization_parameters': {'scales': array([0.00334295], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/se/se_expand/conv2d/Reshape_1', 'index': 1163, 'shape': array([  1,   1,   1,   1, 144], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0033429544419050217, -128), 'quantization_parameters': {'scales': array([0.00334295], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/se/mul1', 'index': 1164, 'shape': array([  1,   1,  11,  11, 144], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0033429544419050217, -128), 'quantization_parameters': {'scales': array([0.00334295], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/se/mul2', 'index': 1165, 'shape': array([  1,   1,  11,  11, 144], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.014408735558390617, -106), 'quantization_parameters': {'scales': array([0.01440874], dtype=float32), 'zero_points': array([-106], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/projection/conv2d/Reshape', 'index': 1166, 'shape': array([  1,  11,  11, 144], dtype=int32), 'shape_signature': array([  1,  11,  11, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.014408735558390617, -106), 'quantization_parameters': {'scales': array([0.01440874], dtype=float32), 'zero_points': array([-106], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block3_layer5/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block3_layer4/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block3_layer4/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 1167, 'shape': array([ 1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.13653968274593353, -6), 'quantization_parameters': {'scales': array([0.13653968], dtype=float32), 'zero_points': array([-6], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/projection/conv2d/Reshape_1', 'index': 1168, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.13653968274593353, -6), 'quantization_parameters': {'scales': array([0.13653968], dtype=float32), 'zero_points': array([-6], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/rezero/mul1', 'index': 1169, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.28446272015571594, 5), 'quantization_parameters': {'scales': array([0.28446272], dtype=float32), 'zero_points': array([5], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer4/bneck/add', 'index': 1170, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.9638120532035828, 5), 'quantization_parameters': {'scales': array([0.96381205], dtype=float32), 'zero_points': array([5], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/expansion/conv2d/Reshape', 'index': 1171, 'shape': array([ 1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.9638120532035828, 5), 'quantization_parameters': {'scales': array([0.96381205], dtype=float32), 'zero_points': array([5], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer5/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block3_layer5/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 1172, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10371768474578857, 8), 'quantization_parameters': {'scales': array([0.10371768], dtype=float32), 'zero_points': array([8], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/expansion/conv2d/activation_93/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block3_layer5/bneck/expansion/conv2d/activation_93/Relu6;movinet_classifier_2/movinet_1/block3_layer5/bneck/expansion/conv2d/activation_93/add;movinet_classifier_2/movinet_1/block3_layer5/bneck/expansion/conv2d/activation_93/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1173, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04967343807220459, -120), 'quantization_parameters': {'scales': array([0.04967344], dtype=float32), 'zero_points': array([-120], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 1174, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2276240885257721, -44), 'quantization_parameters': {'scales': array([0.22762409], dtype=float32), 'zero_points': array([-44], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d/activation_94/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d/activation_94/Relu6;movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d/activation_94/add;movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d/activation_94/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1175, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.15381567180156708, -126), 'quantization_parameters': {'scales': array([0.15381567], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d/Reshape_1', 'index': 1176, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.15381567180156708, -126), 'quantization_parameters': {'scales': array([0.15381567], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:54', 'index': 1177, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/se/global_average_pool3d_45/Reshape', 'index': 1178, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/se/global_average_pool3d_45/Cast', 'index': 1179, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/stream_buffer_35/concat', 'index': 1180, 'shape': array([  1,   3,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   3,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.15381567180156708, -126), 'quantization_parameters': {'scales': array([0.15381567], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d_temporal/Reshape', 'index': 1181, 'shape': array([  1,   3, 121, 240], dtype=int32), 'shape_signature': array([  1,   3, 121, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.15381567180156708, -126), 'quantization_parameters': {'scales': array([0.15381567], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul;movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 1182, 'shape': array([  1,   1, 121, 240], dtype=int32), 'shape_signature': array([  1,   1, 121, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.3699514865875244, -60), 'quantization_parameters': {'scales': array([0.3699515], dtype=float32), 'zero_points': array([-60], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d_temporal/activation_94/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d_temporal/activation_94/Relu6;movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d_temporal/activation_94/add;movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d_temporal/activation_94/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1183, 'shape': array([  1,   1, 121, 240], dtype=int32), 'shape_signature': array([  1,   1, 121, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2721489369869232, -127), 'quantization_parameters': {'scales': array([0.27214894], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/feature/conv2d_temporal/Reshape_1', 'index': 1184, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2721489369869232, -127), 'quantization_parameters': {'scales': array([0.27214894], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/se/spatial_average_pool3d_44/Mean', 'index': 1185, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.02526838332414627, -113), 'quantization_parameters': {'scales': array([0.02526838], dtype=float32), 'zero_points': array([-113], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/se/spatial_average_pool3d_44/Mean1', 'index': 1186, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/se/global_average_pool3d_45/add_1', 'index': 1187, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.6846233010292053, -112), 'quantization_parameters': {'scales': array([0.6846233], dtype=float32), 'zero_points': array([-112], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize18', 'index': 1188, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:53', 'index': 1189, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.6846233010292053, -112), 'quantization_parameters': {'scales': array([0.6846233], dtype=float32), 'zero_points': array([-112], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/se/global_average_pool3d_45/truediv', 'index': 1190, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/se/concat', 'index': 1191, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize18', 'index': 1192, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.02526838332414627, -113), 'quantization_parameters': {'scales': array([0.02526838], dtype=float32), 'zero_points': array([-113], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/Reshape', 'index': 1193, 'shape': array([  1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.02526838332414627, -113), 'quantization_parameters': {'scales': array([0.02526838], dtype=float32), 'zero_points': array([-113], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 1194, 'shape': array([  1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.041624121367931366, 21), 'quantization_parameters': {'scales': array([0.04162412], dtype=float32), 'zero_points': array([21], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1195, 'shape': array([  1,   1,   1, 120], dtype=int32), 'shape_signature': array([  1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.018748991191387177, -108), 'quantization_parameters': {'scales': array([0.01874899], dtype=float32), 'zero_points': array([-108], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 1196, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.019260577857494354, -128), 'quantization_parameters': {'scales': array([0.01926058], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 1197, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0032101606484502554, -128), 'quantization_parameters': {'scales': array([0.00321016], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/se/se_expand/conv2d/Reshape_1', 'index': 1198, 'shape': array([  1,   1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0032101606484502554, -128), 'quantization_parameters': {'scales': array([0.00321016], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/se/mul', 'index': 1199, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0032101606484502554, -128), 'quantization_parameters': {'scales': array([0.00321016], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/se/mul1', 'index': 1200, 'shape': array([  1,   1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04936782643198967, -122), 'quantization_parameters': {'scales': array([0.04936783], dtype=float32), 'zero_points': array([-122], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/projection/conv2d/Reshape', 'index': 1201, 'shape': array([  1,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04936782643198967, -122), 'quantization_parameters': {'scales': array([0.04936783], dtype=float32), 'zero_points': array([-122], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block3_layer5/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block3_layer5/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 1202, 'shape': array([ 1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.16173331439495087, -8), 'quantization_parameters': {'scales': array([0.16173331], dtype=float32), 'zero_points': array([-8], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/projection/conv2d/Reshape_1', 'index': 1203, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.16173331439495087, -8), 'quantization_parameters': {'scales': array([0.16173331], dtype=float32), 'zero_points': array([-8], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/rezero/mul1', 'index': 1204, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.34808313846588135, 7), 'quantization_parameters': {'scales': array([0.34808314], dtype=float32), 'zero_points': array([7], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block3_layer5/bneck/add', 'index': 1205, 'shape': array([ 1,  1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1,  1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.0433251857757568, -5), 'quantization_parameters': {'scales': array([1.0433252], dtype=float32), 'zero_points': array([-5], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/expansion/conv2d/Reshape', 'index': 1206, 'shape': array([ 1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.0433251857757568, -5), 'quantization_parameters': {'scales': array([1.0433252], dtype=float32), 'zero_points': array([-5], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer0/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block4_layer0/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 1207, 'shape': array([  1,  11,  11, 480], dtype=int32), 'shape_signature': array([  1,  11,  11, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11362695693969727, 17), 'quantization_parameters': {'scales': array([0.11362696], dtype=float32), 'zero_points': array([17], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/expansion/conv2d/activation_95/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block4_layer0/bneck/expansion/conv2d/activation_95/Relu6;movinet_classifier_2/movinet_1/block4_layer0/bneck/expansion/conv2d/activation_95/add;movinet_classifier_2/movinet_1/block4_layer0/bneck/expansion/conv2d/activation_95/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1208, 'shape': array([  1,  11,  11, 480], dtype=int32), 'shape_signature': array([  1,  11,  11, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.05054214969277382, -121), 'quantization_parameters': {'scales': array([0.05054215], dtype=float32), 'zero_points': array([-121], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 1209, 'shape': array([  1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.18175910413265228, -67), 'quantization_parameters': {'scales': array([0.1817591], dtype=float32), 'zero_points': array([-67], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d/activation_96/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d/activation_96/Relu6;movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d/activation_96/add;movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d/activation_96/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1210, 'shape': array([  1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.14083890616893768, -125), 'quantization_parameters': {'scales': array([0.1408389], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d/Reshape_1', 'index': 1211, 'shape': array([  1,   1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.14083890616893768, -125), 'quantization_parameters': {'scales': array([0.1408389], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/skip/Reshape', 'index': 1212, 'shape': array([ 1, 11, 11, 72], dtype=int32), 'shape_signature': array([ 1, 11, 11, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.0433251857757568, -5), 'quantization_parameters': {'scales': array([1.0433252], dtype=float32), 'zero_points': array([-5], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/skip/skip_pool/AvgPool', 'index': 1213, 'shape': array([ 1,  6,  6, 72], dtype=int32), 'shape_signature': array([ 1,  6,  6, 72], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.0433251857757568, -5), 'quantization_parameters': {'scales': array([1.0433252], dtype=float32), 'zero_points': array([-5], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/skip/skip_project/conv2d/bn/FusedBatchNormV3;movinet_classifier_2/movinet_1/block4_layer6/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block4_layer0/bneck/skip/skip_project/conv2d/conv2d_4/Conv2D', 'index': 1214, 'shape': array([  1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.351997047662735, -11), 'quantization_parameters': {'scales': array([0.35199705], dtype=float32), 'zero_points': array([-11], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/skip/skip_project/conv2d/Reshape_1', 'index': 1215, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.351997047662735, -11), 'quantization_parameters': {'scales': array([0.35199705], dtype=float32), 'zero_points': array([-11], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:55', 'index': 1216, 'shape': array([  1,   2,  11,  11, 240], dtype=int32), 'shape_signature': array([  1,   2,  11,  11, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.15381567180156708, -126), 'quantization_parameters': {'scales': array([0.15381567], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:57', 'index': 1217, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/se/global_average_pool3d_46/Reshape', 'index': 1218, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/se/global_average_pool3d_46/Cast', 'index': 1219, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/stream_buffer_36/concat', 'index': 1220, 'shape': array([  1,   5,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   5,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.14083890616893768, -125), 'quantization_parameters': {'scales': array([0.1408389], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d_temporal/Reshape', 'index': 1221, 'shape': array([  1,   5,  36, 480], dtype=int32), 'shape_signature': array([  1,   5,  36, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.14083890616893768, -125), 'quantization_parameters': {'scales': array([0.1408389], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul;movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 1222, 'shape': array([  1,   1,  36, 480], dtype=int32), 'shape_signature': array([  1,   1,  36, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4102652668952942, -32), 'quantization_parameters': {'scales': array([0.41026527], dtype=float32), 'zero_points': array([-32], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d_temporal/activation_96/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d_temporal/activation_96/Relu6;movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d_temporal/activation_96/add;movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d_temporal/activation_96/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1223, 'shape': array([  1,   1,  36, 480], dtype=int32), 'shape_signature': array([  1,   1,  36, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2565271854400635, -127), 'quantization_parameters': {'scales': array([0.2565272], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/feature/conv2d_temporal/Reshape_1', 'index': 1224, 'shape': array([  1,   1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2565271854400635, -127), 'quantization_parameters': {'scales': array([0.2565272], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/se/spatial_average_pool3d_45/Mean', 'index': 1225, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.034913260489702225, -117), 'quantization_parameters': {'scales': array([0.03491326], dtype=float32), 'zero_points': array([-117], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/se/spatial_average_pool3d_45/Mean1', 'index': 1226, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/se/global_average_pool3d_46/add_1', 'index': 1227, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4893612563610077, -106), 'quantization_parameters': {'scales': array([0.48936126], dtype=float32), 'zero_points': array([-106], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize19', 'index': 1228, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:56', 'index': 1229, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4893612563610077, -106), 'quantization_parameters': {'scales': array([0.48936126], dtype=float32), 'zero_points': array([-106], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/se/global_average_pool3d_46/truediv', 'index': 1230, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/se/concat', 'index': 1231, 'shape': array([  1,   1,   1,   1, 960], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 960], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize19', 'index': 1232, 'shape': array([  1,   1,   1,   1, 960], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 960], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.034913260489702225, -117), 'quantization_parameters': {'scales': array([0.03491326], dtype=float32), 'zero_points': array([-117], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_reduce/conv2d/Reshape', 'index': 1233, 'shape': array([  1,   1,   1, 960], dtype=int32), 'shape_signature': array([  1,   1,   1, 960], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.034913260489702225, -117), 'quantization_parameters': {'scales': array([0.03491326], dtype=float32), 'zero_points': array([-117], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 1234, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.040821440517902374, 17), 'quantization_parameters': {'scales': array([0.04082144], dtype=float32), 'zero_points': array([17], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1235, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.019028009846806526, -108), 'quantization_parameters': {'scales': array([0.01902801], dtype=float32), 'zero_points': array([-108], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 1236, 'shape': array([  1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.020932180806994438, -128), 'quantization_parameters': {'scales': array([0.02093218], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 1237, 'shape': array([  1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0034887664951384068, -128), 'quantization_parameters': {'scales': array([0.00348877], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/se/se_expand/conv2d/Reshape_1', 'index': 1238, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0034887664951384068, -128), 'quantization_parameters': {'scales': array([0.00348877], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/se/mul1', 'index': 1239, 'shape': array([  1,   1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0034887664951384068, -128), 'quantization_parameters': {'scales': array([0.00348877], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/se/mul2', 'index': 1240, 'shape': array([  1,   1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04500260204076767, -121), 'quantization_parameters': {'scales': array([0.0450026], dtype=float32), 'zero_points': array([-121], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/projection/conv2d/Reshape', 'index': 1241, 'shape': array([  1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04500260204076767, -121), 'quantization_parameters': {'scales': array([0.0450026], dtype=float32), 'zero_points': array([-121], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer6/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block4_layer0/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block4_layer0/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 1242, 'shape': array([  1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11418018490076065, 3), 'quantization_parameters': {'scales': array([0.11418018], dtype=float32), 'zero_points': array([3], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/projection/conv2d/Reshape_1', 'index': 1243, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11418018490076065, 3), 'quantization_parameters': {'scales': array([0.11418018], dtype=float32), 'zero_points': array([3], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/rezero/mul1', 'index': 1244, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.20981737971305847, 3), 'quantization_parameters': {'scales': array([0.20981738], dtype=float32), 'zero_points': array([3], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer0/bneck/add', 'index': 1245, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.34669387340545654, -3), 'quantization_parameters': {'scales': array([0.34669387], dtype=float32), 'zero_points': array([-3], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/expansion/conv2d/Reshape', 'index': 1246, 'shape': array([  1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.34669387340545654, -3), 'quantization_parameters': {'scales': array([0.34669387], dtype=float32), 'zero_points': array([-3], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer1/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block4_layer1/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 1247, 'shape': array([  1,   6,   6, 384], dtype=int32), 'shape_signature': array([  1,   6,   6, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.09771250933408737, -1), 'quantization_parameters': {'scales': array([0.09771251], dtype=float32), 'zero_points': array([-1], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/expansion/conv2d/activation_97/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block4_layer1/bneck/expansion/conv2d/activation_97/Relu6;movinet_classifier_2/movinet_1/block4_layer1/bneck/expansion/conv2d/activation_97/add;movinet_classifier_2/movinet_1/block4_layer1/bneck/expansion/conv2d/activation_97/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1248, 'shape': array([  1,   6,   6, 384], dtype=int32), 'shape_signature': array([  1,   6,   6, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.05060810595750809, -121), 'quantization_parameters': {'scales': array([0.05060811], dtype=float32), 'zero_points': array([-121], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer1/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block4_layer1/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer1/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block4_layer1/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 1249, 'shape': array([  1,   6,   6, 384], dtype=int32), 'shape_signature': array([  1,   6,   6, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1741156131029129, -26), 'quantization_parameters': {'scales': array([0.17411561], dtype=float32), 'zero_points': array([-26], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/feature/conv2d/activation_98/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block4_layer1/bneck/feature/conv2d/activation_98/Relu6;movinet_classifier_2/movinet_1/block4_layer1/bneck/feature/conv2d/activation_98/add;movinet_classifier_2/movinet_1/block4_layer1/bneck/feature/conv2d/activation_98/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1250, 'shape': array([  1,   6,   6, 384], dtype=int32), 'shape_signature': array([  1,   6,   6, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10576523840427399, -124), 'quantization_parameters': {'scales': array([0.10576524], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/feature/conv2d/Reshape_1', 'index': 1251, 'shape': array([  1,   1,   6,   6, 384], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10576523840427399, -124), 'quantization_parameters': {'scales': array([0.10576524], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/se/spatial_average_pool3d_46/Mean', 'index': 1252, 'shape': array([  1,   1,   1,   1, 384], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.031951311975717545, -117), 'quantization_parameters': {'scales': array([0.03195131], dtype=float32), 'zero_points': array([-117], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/se/spatial_average_pool3d_46/Mean1', 'index': 1253, 'shape': array([  1,   1,   1,   1, 384], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:58', 'index': 1254, 'shape': array([  1,   4,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   4,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.14083890616893768, -125), 'quantization_parameters': {'scales': array([0.1408389], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/se/global_average_pool3d_47/add_1', 'index': 1255, 'shape': array([  1,   1,   1,   1, 384], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.5704593658447266, -110), 'quantization_parameters': {'scales': array([0.57045937], dtype=float32), 'zero_points': array([-110], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize20', 'index': 1256, 'shape': array([  1,   1,   1,   1, 384], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:59', 'index': 1257, 'shape': array([  1,   1,   1,   1, 384], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.5704593658447266, -110), 'quantization_parameters': {'scales': array([0.57045937], dtype=float32), 'zero_points': array([-110], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:60', 'index': 1258, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/se/global_average_pool3d_47/Reshape', 'index': 1259, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/se/global_average_pool3d_47/Cast', 'index': 1260, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/se/global_average_pool3d_47/truediv', 'index': 1261, 'shape': array([  1,   1,   1,   1, 384], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/se/concat', 'index': 1262, 'shape': array([  1,   1,   1,   1, 768], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 768], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize20', 'index': 1263, 'shape': array([  1,   1,   1,   1, 768], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 768], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.031951311975717545, -117), 'quantization_parameters': {'scales': array([0.03195131], dtype=float32), 'zero_points': array([-117], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_reduce/conv2d/Reshape', 'index': 1264, 'shape': array([  1,   1,   1, 768], dtype=int32), 'shape_signature': array([  1,   1,   1, 768], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.031951311975717545, -117), 'quantization_parameters': {'scales': array([0.03195131], dtype=float32), 'zero_points': array([-117], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 1265, 'shape': array([  1,   1,   1, 192], dtype=int32), 'shape_signature': array([  1,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.03895391896367073, -10), 'quantization_parameters': {'scales': array([0.03895392], dtype=float32), 'zero_points': array([-10], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1266, 'shape': array([  1,   1,   1, 192], dtype=int32), 'shape_signature': array([  1,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.02243221178650856, -111), 'quantization_parameters': {'scales': array([0.02243221], dtype=float32), 'zero_points': array([-111], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 1267, 'shape': array([  1,   1,   1, 384], dtype=int32), 'shape_signature': array([  1,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.02021593227982521, -128), 'quantization_parameters': {'scales': array([0.02021593], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 1268, 'shape': array([  1,   1,   1, 384], dtype=int32), 'shape_signature': array([  1,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.003369389334693551, -128), 'quantization_parameters': {'scales': array([0.00336939], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/se/se_expand/conv2d/Reshape_1', 'index': 1269, 'shape': array([  1,   1,   1,   1, 384], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.003369389334693551, -128), 'quantization_parameters': {'scales': array([0.00336939], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/se/mul1', 'index': 1270, 'shape': array([  1,   1,   6,   6, 384], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.003369389334693551, -128), 'quantization_parameters': {'scales': array([0.00336939], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/se/mul2', 'index': 1271, 'shape': array([  1,   1,   6,   6, 384], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.016566215083003044, -109), 'quantization_parameters': {'scales': array([0.01656622], dtype=float32), 'zero_points': array([-109], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/projection/conv2d/Reshape', 'index': 1272, 'shape': array([  1,   6,   6, 384], dtype=int32), 'shape_signature': array([  1,   6,   6, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.016566215083003044, -109), 'quantization_parameters': {'scales': array([0.01656622], dtype=float32), 'zero_points': array([-109], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer6/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block4_layer1/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block4_layer1/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 1273, 'shape': array([  1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.08724889904260635, -8), 'quantization_parameters': {'scales': array([0.0872489], dtype=float32), 'zero_points': array([-8], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/projection/conv2d/Reshape_1', 'index': 1274, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.08724889904260635, -8), 'quantization_parameters': {'scales': array([0.0872489], dtype=float32), 'zero_points': array([-8], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/rezero/mul1', 'index': 1275, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.13385769724845886, -8), 'quantization_parameters': {'scales': array([0.1338577], dtype=float32), 'zero_points': array([-8], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer1/bneck/add', 'index': 1276, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.35134413838386536, -6), 'quantization_parameters': {'scales': array([0.35134414], dtype=float32), 'zero_points': array([-6], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/expansion/conv2d/Reshape', 'index': 1277, 'shape': array([  1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.35134413838386536, -6), 'quantization_parameters': {'scales': array([0.35134414], dtype=float32), 'zero_points': array([-6], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer2/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block4_layer2/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 1278, 'shape': array([  1,   6,   6, 384], dtype=int32), 'shape_signature': array([  1,   6,   6, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1011352390050888, 23), 'quantization_parameters': {'scales': array([0.10113524], dtype=float32), 'zero_points': array([23], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/expansion/conv2d/activation_99/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block4_layer2/bneck/expansion/conv2d/activation_99/Relu6;movinet_classifier_2/movinet_1/block4_layer2/bneck/expansion/conv2d/activation_99/add;movinet_classifier_2/movinet_1/block4_layer2/bneck/expansion/conv2d/activation_99/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1279, 'shape': array([  1,   6,   6, 384], dtype=int32), 'shape_signature': array([  1,   6,   6, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04261798411607742, -119), 'quantization_parameters': {'scales': array([0.04261798], dtype=float32), 'zero_points': array([-119], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer2/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block4_layer2/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer2/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block4_layer2/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 1280, 'shape': array([  1,   6,   6, 384], dtype=int32), 'shape_signature': array([  1,   6,   6, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.18080486357212067, -36), 'quantization_parameters': {'scales': array([0.18080486], dtype=float32), 'zero_points': array([-36], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/feature/conv2d/activation_100/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block4_layer2/bneck/feature/conv2d/activation_100/Relu6;movinet_classifier_2/movinet_1/block4_layer2/bneck/feature/conv2d/activation_100/add;movinet_classifier_2/movinet_1/block4_layer2/bneck/feature/conv2d/activation_100/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1281, 'shape': array([  1,   6,   6, 384], dtype=int32), 'shape_signature': array([  1,   6,   6, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11712954938411713, -125), 'quantization_parameters': {'scales': array([0.11712955], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/feature/conv2d/Reshape_1', 'index': 1282, 'shape': array([  1,   1,   6,   6, 384], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11712954938411713, -125), 'quantization_parameters': {'scales': array([0.11712955], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/se/spatial_average_pool3d_47/Mean', 'index': 1283, 'shape': array([  1,   1,   1,   1, 384], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.03934995457530022, -119), 'quantization_parameters': {'scales': array([0.03934995], dtype=float32), 'zero_points': array([-119], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/se/spatial_average_pool3d_47/Mean1', 'index': 1284, 'shape': array([  1,   1,   1,   1, 384], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/se/global_average_pool3d_48/add_1', 'index': 1285, 'shape': array([  1,   1,   1,   1, 384], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.6490894556045532, -112), 'quantization_parameters': {'scales': array([0.64908946], dtype=float32), 'zero_points': array([-112], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize21', 'index': 1286, 'shape': array([  1,   1,   1,   1, 384], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:61', 'index': 1287, 'shape': array([  1,   1,   1,   1, 384], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.6490894556045532, -112), 'quantization_parameters': {'scales': array([0.64908946], dtype=float32), 'zero_points': array([-112], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:62', 'index': 1288, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/se/global_average_pool3d_48/Reshape', 'index': 1289, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/se/global_average_pool3d_48/Cast', 'index': 1290, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/se/global_average_pool3d_48/truediv', 'index': 1291, 'shape': array([  1,   1,   1,   1, 384], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/se/concat', 'index': 1292, 'shape': array([  1,   1,   1,   1, 768], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 768], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize21', 'index': 1293, 'shape': array([  1,   1,   1,   1, 768], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 768], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.03934995457530022, -119), 'quantization_parameters': {'scales': array([0.03934995], dtype=float32), 'zero_points': array([-119], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_reduce/conv2d/Reshape', 'index': 1294, 'shape': array([  1,   1,   1, 768], dtype=int32), 'shape_signature': array([  1,   1,   1, 768], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.03934995457530022, -119), 'quantization_parameters': {'scales': array([0.03934995], dtype=float32), 'zero_points': array([-119], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 1295, 'shape': array([  1,   1,   1, 192], dtype=int32), 'shape_signature': array([  1,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04473858326673508, 23), 'quantization_parameters': {'scales': array([0.04473858], dtype=float32), 'zero_points': array([23], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1296, 'shape': array([  1,   1,   1, 192], dtype=int32), 'shape_signature': array([  1,   1,   1, 192], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.019779859110713005, -109), 'quantization_parameters': {'scales': array([0.01977986], dtype=float32), 'zero_points': array([-109], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 1297, 'shape': array([  1,   1,   1, 384], dtype=int32), 'shape_signature': array([  1,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.022042308002710342, -128), 'quantization_parameters': {'scales': array([0.02204231], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 1298, 'shape': array([  1,   1,   1, 384], dtype=int32), 'shape_signature': array([  1,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0036737914197146893, -128), 'quantization_parameters': {'scales': array([0.00367379], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/se/se_expand/conv2d/Reshape_1', 'index': 1299, 'shape': array([  1,   1,   1,   1, 384], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0036737914197146893, -128), 'quantization_parameters': {'scales': array([0.00367379], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/se/mul', 'index': 1300, 'shape': array([  1,   1,   6,   6, 384], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0036737914197146893, -128), 'quantization_parameters': {'scales': array([0.00367379], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/se/mul1', 'index': 1301, 'shape': array([  1,   1,   6,   6, 384], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.027140391990542412, -115), 'quantization_parameters': {'scales': array([0.02714039], dtype=float32), 'zero_points': array([-115], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/projection/conv2d/Reshape', 'index': 1302, 'shape': array([  1,   6,   6, 384], dtype=int32), 'shape_signature': array([  1,   6,   6, 384], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.027140391990542412, -115), 'quantization_parameters': {'scales': array([0.02714039], dtype=float32), 'zero_points': array([-115], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer6/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block4_layer2/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block4_layer2/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 1303, 'shape': array([  1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.09327299892902374, 12), 'quantization_parameters': {'scales': array([0.093273], dtype=float32), 'zero_points': array([12], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/projection/conv2d/Reshape_1', 'index': 1304, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.09327299892902374, 12), 'quantization_parameters': {'scales': array([0.093273], dtype=float32), 'zero_points': array([12], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/rezero/mul1', 'index': 1305, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.15193428099155426, 12), 'quantization_parameters': {'scales': array([0.15193428], dtype=float32), 'zero_points': array([12], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer2/bneck/add', 'index': 1306, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.38458874821662903, -1), 'quantization_parameters': {'scales': array([0.38458875], dtype=float32), 'zero_points': array([-1], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/expansion/conv2d/Reshape', 'index': 1307, 'shape': array([  1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.38458874821662903, -1), 'quantization_parameters': {'scales': array([0.38458875], dtype=float32), 'zero_points': array([-1], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer3/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block4_layer3/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 1308, 'shape': array([  1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.08975963294506073, 20), 'quantization_parameters': {'scales': array([0.08975963], dtype=float32), 'zero_points': array([20], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/expansion/conv2d/activation_101/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block4_layer3/bneck/expansion/conv2d/activation_101/Relu6;movinet_classifier_2/movinet_1/block4_layer3/bneck/expansion/conv2d/activation_101/add;movinet_classifier_2/movinet_1/block4_layer3/bneck/expansion/conv2d/activation_101/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1309, 'shape': array([  1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.03927173092961311, -118), 'quantization_parameters': {'scales': array([0.03927173], dtype=float32), 'zero_points': array([-118], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer3/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block4_layer3/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer3/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block4_layer3/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 1310, 'shape': array([  1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1939268261194229, -32), 'quantization_parameters': {'scales': array([0.19392683], dtype=float32), 'zero_points': array([-32], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/feature/conv2d/activation_102/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block4_layer3/bneck/feature/conv2d/activation_102/Relu6;movinet_classifier_2/movinet_1/block4_layer3/bneck/feature/conv2d/activation_102/add;movinet_classifier_2/movinet_1/block4_layer3/bneck/feature/conv2d/activation_102/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1311, 'shape': array([  1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.12202287465333939, -125), 'quantization_parameters': {'scales': array([0.12202287], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/feature/conv2d/Reshape_1', 'index': 1312, 'shape': array([  1,   1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.12202287465333939, -125), 'quantization_parameters': {'scales': array([0.12202287], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/se/spatial_average_pool3d_48/Mean', 'index': 1313, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.042090173810720444, -119), 'quantization_parameters': {'scales': array([0.04209017], dtype=float32), 'zero_points': array([-119], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/se/spatial_average_pool3d_48/Mean1', 'index': 1314, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/se/global_average_pool3d_49/add_1', 'index': 1315, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.7778401970863342, -114), 'quantization_parameters': {'scales': array([0.7778402], dtype=float32), 'zero_points': array([-114], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize22', 'index': 1316, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:63', 'index': 1317, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.7778401970863342, -114), 'quantization_parameters': {'scales': array([0.7778402], dtype=float32), 'zero_points': array([-114], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:64', 'index': 1318, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/se/global_average_pool3d_49/Reshape', 'index': 1319, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/se/global_average_pool3d_49/Cast', 'index': 1320, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/se/global_average_pool3d_49/truediv', 'index': 1321, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/se/concat', 'index': 1322, 'shape': array([  1,   1,   1,   1, 960], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 960], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize22', 'index': 1323, 'shape': array([  1,   1,   1,   1, 960], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 960], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.042090173810720444, -119), 'quantization_parameters': {'scales': array([0.04209017], dtype=float32), 'zero_points': array([-119], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/se/se_reduce/conv2d/Reshape', 'index': 1324, 'shape': array([  1,   1,   1, 960], dtype=int32), 'shape_signature': array([  1,   1,   1, 960], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.042090173810720444, -119), 'quantization_parameters': {'scales': array([0.04209017], dtype=float32), 'zero_points': array([-119], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block4_layer3/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block4_layer3/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 1325, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.06576643139123917, 12), 'quantization_parameters': {'scales': array([0.06576643], dtype=float32), 'zero_points': array([12], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block4_layer3/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block4_layer3/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block4_layer3/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1326, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0312546044588089, -116), 'quantization_parameters': {'scales': array([0.0312546], dtype=float32), 'zero_points': array([-116], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block4_layer3/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block4_layer3/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block4_layer3/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer3/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 1327, 'shape': array([  1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.021771399304270744, -128), 'quantization_parameters': {'scales': array([0.0217714], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 1328, 'shape': array([  1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.003628638805821538, -128), 'quantization_parameters': {'scales': array([0.00362864], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/se/se_expand/conv2d/Reshape_1', 'index': 1329, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.003628638805821538, -128), 'quantization_parameters': {'scales': array([0.00362864], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/se/mul', 'index': 1330, 'shape': array([  1,   1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.003628638805821538, -128), 'quantization_parameters': {'scales': array([0.00362864], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/se/mul1', 'index': 1331, 'shape': array([  1,   1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.018844543024897575, -110), 'quantization_parameters': {'scales': array([0.01884454], dtype=float32), 'zero_points': array([-110], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/projection/conv2d/Reshape', 'index': 1332, 'shape': array([  1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.018844543024897575, -110), 'quantization_parameters': {'scales': array([0.01884454], dtype=float32), 'zero_points': array([-110], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer6/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block4_layer3/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block4_layer3/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 1333, 'shape': array([  1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.07440363615751266, 3), 'quantization_parameters': {'scales': array([0.07440364], dtype=float32), 'zero_points': array([3], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/projection/conv2d/Reshape_1', 'index': 1334, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.07440363615751266, 3), 'quantization_parameters': {'scales': array([0.07440364], dtype=float32), 'zero_points': array([3], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/rezero/mul1', 'index': 1335, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.12292011082172394, -4), 'quantization_parameters': {'scales': array([0.12292011], dtype=float32), 'zero_points': array([-4], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer3/bneck/add', 'index': 1336, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4130500555038452, -4), 'quantization_parameters': {'scales': array([0.41305006], dtype=float32), 'zero_points': array([-4], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/expansion/conv2d/Reshape', 'index': 1337, 'shape': array([  1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4130500555038452, -4), 'quantization_parameters': {'scales': array([0.41305006], dtype=float32), 'zero_points': array([-4], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer4/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block4_layer4/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 1338, 'shape': array([  1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11436872184276581, 11), 'quantization_parameters': {'scales': array([0.11436872], dtype=float32), 'zero_points': array([11], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/expansion/conv2d/activation_103/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block4_layer4/bneck/expansion/conv2d/activation_103/Relu6;movinet_classifier_2/movinet_1/block4_layer4/bneck/expansion/conv2d/activation_103/add;movinet_classifier_2/movinet_1/block4_layer4/bneck/expansion/conv2d/activation_103/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1339, 'shape': array([  1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.05368718504905701, -121), 'quantization_parameters': {'scales': array([0.05368719], dtype=float32), 'zero_points': array([-121], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer4/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block4_layer4/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer4/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block4_layer4/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 1340, 'shape': array([  1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2377994805574417, -60), 'quantization_parameters': {'scales': array([0.23779948], dtype=float32), 'zero_points': array([-60], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/feature/conv2d/activation_104/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block4_layer4/bneck/feature/conv2d/activation_104/Relu6;movinet_classifier_2/movinet_1/block4_layer4/bneck/feature/conv2d/activation_104/add;movinet_classifier_2/movinet_1/block4_layer4/bneck/feature/conv2d/activation_104/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1341, 'shape': array([  1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.17556573450565338, -126), 'quantization_parameters': {'scales': array([0.17556573], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/feature/conv2d/Reshape_1', 'index': 1342, 'shape': array([  1,   1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.17556573450565338, -126), 'quantization_parameters': {'scales': array([0.17556573], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/se/spatial_average_pool3d_49/Mean', 'index': 1343, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10871884971857071, -125), 'quantization_parameters': {'scales': array([0.10871885], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/se/spatial_average_pool3d_49/Mean1', 'index': 1344, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/se/global_average_pool3d_50/add_1', 'index': 1345, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.7034834623336792, -113), 'quantization_parameters': {'scales': array([0.70348346], dtype=float32), 'zero_points': array([-113], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize23', 'index': 1346, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:65', 'index': 1347, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.7034834623336792, -113), 'quantization_parameters': {'scales': array([0.70348346], dtype=float32), 'zero_points': array([-113], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:66', 'index': 1348, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/se/global_average_pool3d_50/Reshape', 'index': 1349, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/se/global_average_pool3d_50/Cast', 'index': 1350, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/se/global_average_pool3d_50/truediv', 'index': 1351, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/se/concat', 'index': 1352, 'shape': array([  1,   1,   1,   1, 960], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 960], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize23', 'index': 1353, 'shape': array([  1,   1,   1,   1, 960], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 960], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10871884971857071, -125), 'quantization_parameters': {'scales': array([0.10871885], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/se/se_reduce/conv2d/Reshape', 'index': 1354, 'shape': array([  1,   1,   1, 960], dtype=int32), 'shape_signature': array([  1,   1,   1, 960], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10871884971857071, -125), 'quantization_parameters': {'scales': array([0.10871885], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block4_layer4/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block4_layer4/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 1355, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.09376624971628189, 20), 'quantization_parameters': {'scales': array([0.09376625], dtype=float32), 'zero_points': array([20], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block4_layer4/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block4_layer4/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block4_layer4/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1356, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04078460857272148, -119), 'quantization_parameters': {'scales': array([0.04078461], dtype=float32), 'zero_points': array([-119], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block4_layer4/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block4_layer4/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block4_layer4/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer4/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 1357, 'shape': array([  1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0235294122248888, -128), 'quantization_parameters': {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 1358, 'shape': array([  1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00392164709046483, -128), 'quantization_parameters': {'scales': array([0.00392165], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/se/se_expand/conv2d/Reshape_1', 'index': 1359, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00392164709046483, -128), 'quantization_parameters': {'scales': array([0.00392165], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/se/mul', 'index': 1360, 'shape': array([  1,   1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00392164709046483, -128), 'quantization_parameters': {'scales': array([0.00392165], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/se/mul1', 'index': 1361, 'shape': array([  1,   1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.033734533935785294, -117), 'quantization_parameters': {'scales': array([0.03373453], dtype=float32), 'zero_points': array([-117], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/projection/conv2d/Reshape', 'index': 1362, 'shape': array([  1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.033734533935785294, -117), 'quantization_parameters': {'scales': array([0.03373453], dtype=float32), 'zero_points': array([-117], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer6/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block4_layer4/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block4_layer4/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 1363, 'shape': array([  1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.09697579592466354, -19), 'quantization_parameters': {'scales': array([0.0969758], dtype=float32), 'zero_points': array([-19], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/projection/conv2d/Reshape_1', 'index': 1364, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.09697579592466354, -19), 'quantization_parameters': {'scales': array([0.0969758], dtype=float32), 'zero_points': array([-19], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/rezero/mul1', 'index': 1365, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.20001402497291565, -19), 'quantization_parameters': {'scales': array([0.20001402], dtype=float32), 'zero_points': array([-19], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer4/bneck/add', 'index': 1366, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4729648232460022, 7), 'quantization_parameters': {'scales': array([0.47296482], dtype=float32), 'zero_points': array([7], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/expansion/conv2d/Reshape', 'index': 1367, 'shape': array([  1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.4729648232460022, 7), 'quantization_parameters': {'scales': array([0.47296482], dtype=float32), 'zero_points': array([7], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer5/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block4_layer5/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 1368, 'shape': array([  1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.08749925345182419, 0), 'quantization_parameters': {'scales': array([0.08749925], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/expansion/conv2d/activation_105/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block4_layer5/bneck/expansion/conv2d/activation_105/Relu6;movinet_classifier_2/movinet_1/block4_layer5/bneck/expansion/conv2d/activation_105/add;movinet_classifier_2/movinet_1/block4_layer5/bneck/expansion/conv2d/activation_105/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1369, 'shape': array([  1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.045024581253528595, -120), 'quantization_parameters': {'scales': array([0.04502458], dtype=float32), 'zero_points': array([-120], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 1370, 'shape': array([  1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.15018729865550995, -47), 'quantization_parameters': {'scales': array([0.1501873], dtype=float32), 'zero_points': array([-47], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d/activation_106/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d/activation_106/Relu6;movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d/activation_106/add;movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d/activation_106/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1371, 'shape': array([  1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11984407156705856, -125), 'quantization_parameters': {'scales': array([0.11984407], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d/Reshape_1', 'index': 1372, 'shape': array([  1,   1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11984407156705856, -125), 'quantization_parameters': {'scales': array([0.11984407], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:68', 'index': 1373, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/se/global_average_pool3d_51/Reshape', 'index': 1374, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/se/global_average_pool3d_51/Cast', 'index': 1375, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/stream_buffer_37/concat', 'index': 1376, 'shape': array([  1,   3,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   3,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11984407156705856, -125), 'quantization_parameters': {'scales': array([0.11984407], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d_temporal/Reshape', 'index': 1377, 'shape': array([  1,   3,  36, 480], dtype=int32), 'shape_signature': array([  1,   3,  36, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11984407156705856, -125), 'quantization_parameters': {'scales': array([0.11984407], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul_1;movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d_temporal/depthwise_conv2d_1/depthwise;movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/mul;movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d_temporal/bn_temporal/batchnorm/sub', 'index': 1378, 'shape': array([  1,   1,  36, 480], dtype=int32), 'shape_signature': array([  1,   1,  36, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.3494579792022705, -32), 'quantization_parameters': {'scales': array([0.34945798], dtype=float32), 'zero_points': array([-32], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d_temporal/activation_106/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d_temporal/activation_106/Relu6;movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d_temporal/activation_106/add;movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d_temporal/activation_106/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1379, 'shape': array([  1,   1,  36, 480], dtype=int32), 'shape_signature': array([  1,   1,  36, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2188120186328888, -126), 'quantization_parameters': {'scales': array([0.21881202], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/feature/conv2d_temporal/Reshape_1', 'index': 1380, 'shape': array([  1,   1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2188120186328888, -126), 'quantization_parameters': {'scales': array([0.21881202], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/se/spatial_average_pool3d_50/Mean', 'index': 1381, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0868777260184288, -124), 'quantization_parameters': {'scales': array([0.08687773], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/se/spatial_average_pool3d_50/Mean1', 'index': 1382, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/se/global_average_pool3d_51/add_1', 'index': 1383, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.5740520358085632, -109), 'quantization_parameters': {'scales': array([0.57405204], dtype=float32), 'zero_points': array([-109], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize24', 'index': 1384, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:67', 'index': 1385, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.5740520358085632, -109), 'quantization_parameters': {'scales': array([0.57405204], dtype=float32), 'zero_points': array([-109], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/se/global_average_pool3d_51/truediv', 'index': 1386, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/se/concat', 'index': 1387, 'shape': array([  1,   1,   1,   1, 960], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 960], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize24', 'index': 1388, 'shape': array([  1,   1,   1,   1, 960], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 960], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0868777260184288, -124), 'quantization_parameters': {'scales': array([0.08687773], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/Reshape', 'index': 1389, 'shape': array([  1,   1,   1, 960], dtype=int32), 'shape_signature': array([  1,   1,   1, 960], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0868777260184288, -124), 'quantization_parameters': {'scales': array([0.08687773], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 1390, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.3420250713825226, 103), 'quantization_parameters': {'scales': array([0.34202507], dtype=float32), 'zero_points': array([103], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1391, 'shape': array([  1,   1,   1, 240], dtype=int32), 'shape_signature': array([  1,   1,   1, 240], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.03302222490310669, -117), 'quantization_parameters': {'scales': array([0.03302222], dtype=float32), 'zero_points': array([-117], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 1392, 'shape': array([  1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.018529387190937996, -128), 'quantization_parameters': {'scales': array([0.01852939], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 1393, 'shape': array([  1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0030882928986102343, -128), 'quantization_parameters': {'scales': array([0.00308829], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/se/se_expand/conv2d/Reshape_1', 'index': 1394, 'shape': array([  1,   1,   1,   1, 480], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0030882928986102343, -128), 'quantization_parameters': {'scales': array([0.00308829], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/se/mul', 'index': 1395, 'shape': array([  1,   1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0030882928986102343, -128), 'quantization_parameters': {'scales': array([0.00308829], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/se/mul1', 'index': 1396, 'shape': array([  1,   1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04695188254117966, -122), 'quantization_parameters': {'scales': array([0.04695188], dtype=float32), 'zero_points': array([-122], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/projection/conv2d/Reshape', 'index': 1397, 'shape': array([  1,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04695188254117966, -122), 'quantization_parameters': {'scales': array([0.04695188], dtype=float32), 'zero_points': array([-122], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer6/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block4_layer5/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block4_layer5/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 1398, 'shape': array([  1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10108214616775513, -6), 'quantization_parameters': {'scales': array([0.10108215], dtype=float32), 'zero_points': array([-6], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/projection/conv2d/Reshape_1', 'index': 1399, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10108214616775513, -6), 'quantization_parameters': {'scales': array([0.10108215], dtype=float32), 'zero_points': array([-6], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/rezero/mul1', 'index': 1400, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.22894060611724854, 5), 'quantization_parameters': {'scales': array([0.2289406], dtype=float32), 'zero_points': array([5], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer5/bneck/add', 'index': 1401, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.546760618686676, 7), 'quantization_parameters': {'scales': array([0.5467606], dtype=float32), 'zero_points': array([7], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/expansion/conv2d/Reshape', 'index': 1402, 'shape': array([  1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.546760618686676, 7), 'quantization_parameters': {'scales': array([0.5467606], dtype=float32), 'zero_points': array([7], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/expansion/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer6/bneck/expansion/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/block4_layer6/bneck/expansion/conv2d/bn/batchnorm/sub', 'index': 1403, 'shape': array([  1,   6,   6, 576], dtype=int32), 'shape_signature': array([  1,   6,   6, 576], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.1553337574005127, 17), 'quantization_parameters': {'scales': array([0.15533376], dtype=float32), 'zero_points': array([17], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/expansion/conv2d/activation_107/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block4_layer6/bneck/expansion/conv2d/activation_107/Relu6;movinet_classifier_2/movinet_1/block4_layer6/bneck/expansion/conv2d/activation_107/add;movinet_classifier_2/movinet_1/block4_layer6/bneck/expansion/conv2d/activation_107/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1404, 'shape': array([  1,   6,   6, 576], dtype=int32), 'shape_signature': array([  1,   6,   6, 576], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.06820078939199448, -123), 'quantization_parameters': {'scales': array([0.06820079], dtype=float32), 'zero_points': array([-123], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/feature/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block4_layer6/bneck/feature/conv2d/bn/batchnorm/mul_1;movinet_classifier_2/movinet_1/block4_layer6/bneck/feature/conv2d/depthwise_conv2d/depthwise;movinet_classifier_2/movinet_1/block4_layer6/bneck/feature/conv2d/bn/batchnorm/mul;movinet_classifier_2/movinet_1/block4_layer6/bneck/feature/conv2d/bn/batchnorm/sub', 'index': 1405, 'shape': array([  1,   6,   6, 576], dtype=int32), 'shape_signature': array([  1,   6,   6, 576], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.3751024901866913, -59), 'quantization_parameters': {'scales': array([0.3751025], dtype=float32), 'zero_points': array([-59], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/feature/conv2d/activation_108/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block4_layer6/bneck/feature/conv2d/activation_108/Relu6;movinet_classifier_2/movinet_1/block4_layer6/bneck/feature/conv2d/activation_108/add;movinet_classifier_2/movinet_1/block4_layer6/bneck/feature/conv2d/activation_108/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1406, 'shape': array([  1,   6,   6, 576], dtype=int32), 'shape_signature': array([  1,   6,   6, 576], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.27449530363082886, -127), 'quantization_parameters': {'scales': array([0.2744953], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/feature/conv2d/Reshape_1', 'index': 1407, 'shape': array([  1,   1,   6,   6, 576], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 576], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.27449530363082886, -127), 'quantization_parameters': {'scales': array([0.2744953], dtype=float32), 'zero_points': array([-127], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/se/spatial_average_pool3d_51/Mean', 'index': 1408, 'shape': array([  1,   1,   1,   1, 576], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 576], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.21178926527500153, -126), 'quantization_parameters': {'scales': array([0.21178927], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/se/spatial_average_pool3d_51/Mean1', 'index': 1409, 'shape': array([  1,   1,   1,   1, 576], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 576], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:69', 'index': 1410, 'shape': array([  1,   2,   6,   6, 480], dtype=int32), 'shape_signature': array([  1,   2,   6,   6, 480], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11984407156705856, -125), 'quantization_parameters': {'scales': array([0.11984407], dtype=float32), 'zero_points': array([-125], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/se/global_average_pool3d_52/add_1', 'index': 1411, 'shape': array([  1,   1,   1,   1, 576], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 576], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.7915980219841003, -115), 'quantization_parameters': {'scales': array([0.791598], dtype=float32), 'zero_points': array([-115], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize25', 'index': 1412, 'shape': array([  1,   1,   1,   1, 576], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 576], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:70', 'index': 1413, 'shape': array([  1,   1,   1,   1, 576], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 576], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.7915980219841003, -115), 'quantization_parameters': {'scales': array([0.791598], dtype=float32), 'zero_points': array([-115], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:71', 'index': 1414, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/se/global_average_pool3d_52/Reshape', 'index': 1415, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/se/global_average_pool3d_52/Cast', 'index': 1416, 'shape': array([1, 1, 1, 1, 1], dtype=int32), 'shape_signature': array([1, 1, 1, 1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/se/global_average_pool3d_52/truediv', 'index': 1417, 'shape': array([  1,   1,   1,   1, 576], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 576], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/se/concat', 'index': 1418, 'shape': array([   1,    1,    1,    1, 1152], dtype=int32), 'shape_signature': array([   1,    1,    1,    1, 1152], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize25', 'index': 1419, 'shape': array([   1,    1,    1,    1, 1152], dtype=int32), 'shape_signature': array([   1,    1,    1,    1, 1152], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.21178926527500153, -126), 'quantization_parameters': {'scales': array([0.21178927], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_reduce/conv2d/Reshape', 'index': 1420, 'shape': array([   1,    1,    1, 1152], dtype=int32), 'shape_signature': array([   1,    1,    1, 1152], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.21178926527500153, -126), 'quantization_parameters': {'scales': array([0.21178927], dtype=float32), 'zero_points': array([-126], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_reduce/conv2d/conv2d_1/Conv2D;movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_reduce/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 1421, 'shape': array([  1,   1,   1, 288], dtype=int32), 'shape_signature': array([  1,   1,   1, 288], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.0123704671859741, 119), 'quantization_parameters': {'scales': array([1.0123705], dtype=float32), 'zero_points': array([119], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_reduce/conv2d/activation_1/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_reduce/conv2d/activation_1/Relu6;movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_reduce/conv2d/activation_1/add;movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_reduce/conv2d/activation_1/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1422, 'shape': array([  1,   1,   1, 288], dtype=int32), 'shape_signature': array([  1,   1,   1, 288], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.03469075635075569, -117), 'quantization_parameters': {'scales': array([0.03469076], dtype=float32), 'zero_points': array([-117], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_expand/conv2d/activation_2/Relu6;movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_expand/conv2d/activation_2/add;movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd/ReadVariableOp;movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_expand/conv2d/conv2d_2/BiasAdd;movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_expand/conv2d/conv2d_2/Conv2D;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x1', 'index': 1423, 'shape': array([  1,   1,   1, 576], dtype=int32), 'shape_signature': array([  1,   1,   1, 576], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0235294122248888, -128), 'quantization_parameters': {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_expand/conv2d/activation_2/mul', 'index': 1424, 'shape': array([  1,   1,   1, 576], dtype=int32), 'shape_signature': array([  1,   1,   1, 576], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00392164709046483, -128), 'quantization_parameters': {'scales': array([0.00392165], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/se/se_expand/conv2d/Reshape_1', 'index': 1425, 'shape': array([  1,   1,   1,   1, 576], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 576], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00392164709046483, -128), 'quantization_parameters': {'scales': array([0.00392165], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/se/mul1', 'index': 1426, 'shape': array([  1,   1,   6,   6, 576], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 576], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00392164709046483, -128), 'quantization_parameters': {'scales': array([0.00392165], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/se/mul2', 'index': 1427, 'shape': array([  1,   1,   6,   6, 576], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 576], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04066435620188713, -120), 'quantization_parameters': {'scales': array([0.04066436], dtype=float32), 'zero_points': array([-120], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/projection/conv2d/Reshape', 'index': 1428, 'shape': array([  1,   6,   6, 576], dtype=int32), 'shape_signature': array([  1,   6,   6, 576], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04066435620188713, -120), 'quantization_parameters': {'scales': array([0.04066436], dtype=float32), 'zero_points': array([-120], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/projection/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/block4_layer6/bneck/projection/conv2d/conv2d_3/Conv2D;movinet_classifier_2/movinet_1/block4_layer6/bneck/projection/conv2d/bn/batchnorm/sub', 'index': 1429, 'shape': array([  1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0811319425702095, -10), 'quantization_parameters': {'scales': array([0.08113194], dtype=float32), 'zero_points': array([-10], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/projection/conv2d/Reshape_1', 'index': 1430, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0811319425702095, -10), 'quantization_parameters': {'scales': array([0.08113194], dtype=float32), 'zero_points': array([-10], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/rezero/mul1', 'index': 1431, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.22008024156093597, -10), 'quantization_parameters': {'scales': array([0.22008024], dtype=float32), 'zero_points': array([-10], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/block4_layer6/bneck/add', 'index': 1432, 'shape': array([  1,   1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.5637142658233643, 5), 'quantization_parameters': {'scales': array([0.56371427], dtype=float32), 'zero_points': array([5], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/head/project/conv2d/Reshape', 'index': 1433, 'shape': array([  1,   6,   6, 144], dtype=int32), 'shape_signature': array([  1,   6,   6, 144], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.5637142658233643, 5), 'quantization_parameters': {'scales': array([0.56371427], dtype=float32), 'zero_points': array([5], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/head/project/conv2d/bn/batchnorm/add_1;movinet_classifier_2/movinet_1/head/project/conv2d/conv2d/Conv2D;movinet_classifier_2/movinet_1/head/project/conv2d/bn/batchnorm/sub', 'index': 1434, 'shape': array([  1,   6,   6, 640], dtype=int32), 'shape_signature': array([  1,   6,   6, 640], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.21597960591316223, 10), 'quantization_parameters': {'scales': array([0.2159796], dtype=float32), 'zero_points': array([10], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/head/project/conv2d/activation_109/mul_1;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/Cast/x;movinet_classifier_2/movinet_1/head/project/conv2d/activation_109/Relu6;movinet_classifier_2/movinet_1/head/project/conv2d/activation_109/add;movinet_classifier_2/movinet_1/head/project/conv2d/activation_109/mul;movinet_classifier_2/movinet_1/block0_layer0/bneck/expansion/conv2d/activation_57/mul_1/y', 'index': 1435, 'shape': array([  1,   6,   6, 640], dtype=int32), 'shape_signature': array([  1,   6,   6, 640], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10025379061698914, -124), 'quantization_parameters': {'scales': array([0.10025379], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/head/project/conv2d/Reshape_1', 'index': 1436, 'shape': array([  1,   1,   6,   6, 640], dtype=int32), 'shape_signature': array([  1,   1,   6,   6, 640], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.10025379061698914, -124), 'quantization_parameters': {'scales': array([0.10025379], dtype=float32), 'zero_points': array([-124], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/head/global_average_pool3d_53/Sum', 'index': 1437, 'shape': array([  1,   1,   1,   1, 640], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 640], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.5923935770988464, -108), 'quantization_parameters': {'scales': array([0.5923936], dtype=float32), 'zero_points': array([-108], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/head/global_average_pool3d_53/truediv;movinet_classifier_2/movinet_1/head/global_average_pool3d_53/Cast1', 'index': 1438, 'shape': array([  1,   1,   1,   1, 640], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 640], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.016455378383398056, -108), 'quantization_parameters': {'scales': array([0.01645538], dtype=float32), 'zero_points': array([-108], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:72', 'index': 1439, 'shape': array([  1,   1,   1,   1, 640], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 640], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.2301606386899948, -99), 'quantization_parameters': {'scales': array([0.23016064], dtype=float32), 'zero_points': array([-99], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.dequantize26', 'index': 1440, 'shape': array([  1,   1,   1,   1, 640], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 640], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:73', 'index': 1441, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/head/global_average_pool3d_53/Cast_1', 'index': 1442, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/movinet_1/head/global_average_pool3d_53/truediv_1', 'index': 1443, 'shape': array([  1,   1,   1,   1, 640], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 640], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'tfl.quantize26', 'index': 1444, 'shape': array([  1,   1,   1,   1, 640], dtype=int32), 'shape_signature': array([  1,   1,   1,   1, 640], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.013520467095077038, -104), 'quantization_parameters': {'scales': array([0.01352047], dtype=float32), 'zero_points': array([-104], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/classifier_head_2/head/conv2d/Reshape', 'index': 1445, 'shape': array([  1,   1,   1, 640], dtype=int32), 'shape_signature': array([  1,   1,   1, 640], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.013520467095077038, -104), 'quantization_parameters': {'scales': array([0.01352047], dtype=float32), 'zero_points': array([-104], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/classifier_head_2/head/conv2d/conv2d/BiasAdd;movinet_classifier_2/classifier_head_2/head/conv2d/conv2d/Conv2D;movinet_classifier_2/classifier_head_2/head/conv2d/conv2d/BiasAdd/ReadVariableOp', 'index': 1446, 'shape': array([   1,    1,    1, 2048], dtype=int32), 'shape_signature': array([   1,    1,    1, 2048], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0160833727568388, -2), 'quantization_parameters': {'scales': array([0.01608337], dtype=float32), 'zero_points': array([-2], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/classifier_head_2/head/conv2d/activation_110/Sigmoid', 'index': 1447, 'shape': array([   1,    1,    1, 2048], dtype=int32), 'shape_signature': array([   1,    1,    1, 2048], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00390625, -128), 'quantization_parameters': {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/classifier_head_2/head/conv2d/activation_110/mul_1', 'index': 1448, 'shape': array([   1,    1,    1, 2048], dtype=int32), 'shape_signature': array([   1,    1,    1, 2048], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.008305234834551811, -94), 'quantization_parameters': {'scales': array([0.00830523], dtype=float32), 'zero_points': array([-94], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'movinet_classifier_2/classifier_head_2/classifier/conv2d/conv2d_1/BiasAdd;movinet_classifier_2/classifier_head_2/classifier/conv2d/conv2d_1/Conv2D;movinet_classifier_2/classifier_head_2/classifier/conv2d/conv2d_1/BiasAdd/ReadVariableOp', 'index': 1449, 'shape': array([ 1,  1,  1, 10], dtype=int32), 'shape_signature': array([ 1,  1,  1, 10], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.07030367106199265, -23), 'quantization_parameters': {'scales': array([0.07030367], dtype=float32), 'zero_points': array([-23], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:0', 'index': 1450, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.07030367106199265, -23), 'quantization_parameters': {'scales': array([0.07030367], dtype=float32), 'zero_points': array([-23], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1451, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1452, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1453, 'shape': array([40], dtype=int32), 'shape_signature': array([40], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1455, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1456, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1457, 'shape': array([40], dtype=int32), 'shape_signature': array([40], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1459, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1460, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1461, 'shape': array([64], dtype=int32), 'shape_signature': array([64], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1463, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1464, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1465, 'shape': array([96], dtype=int32), 'shape_signature': array([96], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1467, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1468, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1469, 'shape': array([120], dtype=int32), 'shape_signature': array([120], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1471, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1472, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1473, 'shape': array([96], dtype=int32), 'shape_signature': array([96], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1475, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1476, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1477, 'shape': array([96], dtype=int32), 'shape_signature': array([96], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1479, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1480, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1481, 'shape': array([120], dtype=int32), 'shape_signature': array([120], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1483, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1484, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1485, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1487, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1488, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1489, 'shape': array([160], dtype=int32), 'shape_signature': array([160], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1491, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1492, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1493, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1495, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1496, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1497, 'shape': array([192], dtype=int32), 'shape_signature': array([192], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1499, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1500, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1501, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1503, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1504, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1505, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1507, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1508, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1509, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1511, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1512, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1513, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1515, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1516, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1517, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1519, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1520, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1521, 'shape': array([144], dtype=int32), 'shape_signature': array([144], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1523, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1524, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1525, 'shape': array([240], dtype=int32), 'shape_signature': array([240], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1527, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1528, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1529, 'shape': array([480], dtype=int32), 'shape_signature': array([480], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1531, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1532, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1533, 'shape': array([384], dtype=int32), 'shape_signature': array([384], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1535, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1536, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1537, 'shape': array([384], dtype=int32), 'shape_signature': array([384], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1539, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1540, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1541, 'shape': array([480], dtype=int32), 'shape_signature': array([480], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1543, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1544, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1545, 'shape': array([480], dtype=int32), 'shape_signature': array([480], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1547, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1548, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1549, 'shape': array([480], dtype=int32), 'shape_signature': array([480], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1551, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1552, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1553, 'shape': array([576], dtype=int32), 'shape_signature': array([576], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1555, 'shape': array([5], dtype=int32), 'shape_signature': array([5], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1556, 'shape': array([3], dtype=int32), 'shape_signature': array([3], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1557, 'shape': array([640], dtype=int32), 'shape_signature': array([640], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': '', 'index': 1559, 'shape': array([ 1, 86, 86, 27], dtype=int32), 'shape_signature': array([ 1, 86, 86, 27], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check inference with quantized model"
      ],
      "metadata": {
        "id": "YP_To1Jp4OPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the interpreter and signature runner\n",
        "\n",
        "runner = interpreter.get_signature_runner()\n",
        "\n",
        "# To run on a video, pass in one frame at a time\n",
        "#init_states_fn = model.init_states\n",
        "init_states = init_states_fn(tf.shape(tf.ones(shape=[1, 1, resolution, resolution, 3])))\n",
        "states = init_states\n",
        "for frames, label in list(test_ds.take(1)):\n",
        "  if label.numpy() == 0:\n",
        "    label_str = \"Action1\"\n",
        "  elif label.numpy() == 1:\n",
        "    label_str = \"Action2\"\n",
        "  elif label.numpy() == 2:\n",
        "    label_str = \"Action3\"\n",
        "  print(\"True label = \", label_str)\n",
        "\n",
        "  for clip in frames:\n",
        "    # Input shape: [1, 1, 172, 172, 3]\n",
        "    outputs = runner(**states, image=clip)\n",
        "    logits = outputs.pop('logits')[0]\n",
        "    states = outputs\n",
        "\n",
        "probs = tf.nn.softmax(logits)\n",
        "top_k = get_top_k(probs)\n",
        "print()\n",
        "print(\"Model probabilities for each label:\")\n",
        "for label, prob in top_k:\n",
        "  print(label, prob)\n",
        "\n",
        "frames, label = list(test_ds.take(1))[0]\n",
        "to_gif(frames.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "goHiSr-A4MpN",
        "outputId": "530f32c9-9b47-4055-cba6-c0c74362acf9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True label =  Action3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-7890a2970343>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mclip\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Input shape: [1, 1, 172, 172, 3]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logits'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/interpreter.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;31m# Set the input values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m       self._interpreter_wrapper.SetTensor(self._inputs[input_name], value,\n\u001b[0m\u001b[1;32m    247\u001b[0m                                           self._subgraph_index)\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot set tensor: Got value of type FLOAT32 but expected type INT8 for input 5, name: serving_default_state_block2_layer4_stream_buffer:0 "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "gpuClass": "premium",
      "mount_file_id": "https://github.com/rosan-international/video_classifier/blob/main/transfer_learning_with_movinet_seizures_stream.ipynb",
      "authorship_tag": "ABX9TyMemRMUlu+aYpoKUSr7kFOz",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}